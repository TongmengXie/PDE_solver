{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "We have been given a PDE: \n",
    "and boundary condition: u(x,0)=sin(pi*x), anorther boundary condition: u , which could be used as residuals\n",
    "\n",
    "- Independent variables: x,t (input)\n",
    "- Dependent variables: u (outputs)\n",
    "\n",
    "\n",
    "We have to find out u(x,t) for all x in range [0,1] and t in range [0,0.5]\n",
    "\n",
    "\n",
    "When we solved this problem analytically, we found the solution: u(x,t) =sin(pi*x) when t = 0. This boundary condition is used as one loss term:\n",
    "- We choose a \"resolution\", say 500 sections between [0, 2] for x, and calculates u using the boundary condition (where t = 0). So we have a calculated u spanning length 500\n",
    "\n",
    "\n",
    "Our f (PDE residual) is f = d^2u/dx^2 - du/dt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We consider Net as our solution u_theta(x,t)\n",
    "\n",
    "\"\"\"\n",
    "When forming the network, we have to keep in mind the number of inputs and outputs\n",
    "In ur case: #inputs = 2 (x,t)\n",
    "and #outputs = 1\n",
    "\n",
    "You can add ass many hidden layers as you want with as many neurons.\n",
    "More complex the network, the more prepared it is to find complex solutions, but it also requires more data.\n",
    "\n",
    "Let us create this network:\n",
    "min 5 hidden layer with 5 neurons each.\n",
    "\"\"\"\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden_layer1 = nn.Linear(2,5)\n",
    "        self.hidden_layer2 = nn.Linear(5,5)\n",
    "        self.hidden_layer3 = nn.Linear(5,5)\n",
    "        self.hidden_layer4 = nn.Linear(5,5)\n",
    "        self.hidden_layer5 = nn.Linear(5,5)\n",
    "        self.output_layer = nn.Linear(5,1)\n",
    "\n",
    "    def forward(self, x,t):\n",
    "        inputs = torch.cat([x,t],axis=1) # combined two arrays of 1 columns each to one array of 2 columns\n",
    "        layer1_out = torch.sigmoid(self.hidden_layer1(inputs)) # non-linearity\n",
    "        layer2_out = torch.sigmoid(self.hidden_layer2(layer1_out))\n",
    "        layer3_out = torch.sigmoid(self.hidden_layer3(layer2_out))\n",
    "        layer4_out = torch.sigmoid(self.hidden_layer4(layer3_out))\n",
    "        layer5_out = torch.sigmoid(self.hidden_layer5(layer4_out))\n",
    "        output = self.output_layer(layer5_out) ## For regression, no activation is used in output layer\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (2) Model\n",
    "net = Net()\n",
    "net = net.to(device)\n",
    "mse_cost_function = torch.nn.MSELoss() # Mean squared error\n",
    "optimizer = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PDE as loss function. Thus would use the network which we call as u_theta\n",
    "def f(x,t, net):\n",
    "    u = net(x,t) # the dependent variable u is given by the network based on independent variables x,t\n",
    "    ## Based on our f = d^2u/dx^2 - 2du/dt - u, we need d^2u/dx^2 and du/dt\n",
    "    u_x = torch.autograd.grad(u.sum(), x, create_graph=True)[0]\n",
    "    u_x_2 = torch.autograd.grad(u_x.sum(), x, create_graph=True)[0]\n",
    "    u_t = torch.autograd.grad(u.sum(), t, create_graph=True)[0]\n",
    "    pde = u_x_2 - u_t\n",
    "    return pde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "## Data from Boundary Conditions\n",
    "# u(x,0)=sin(πx)\n",
    "## BC just gives us datapoints for training\n",
    "\n",
    "# BC tells us that for any x in range[0,1] and time=0, the value of u is given by u(x,0)=sin(πx)\n",
    "# Take say 500 random numbers of x\n",
    "x_bc = np.random.uniform(low=0.0, high=1, size=(500,1))\n",
    "t_bc = np.zeros((500,1))\n",
    "# compute u based on BC\n",
    "u_bc = 6*np.sin(math.pi*x_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Traning Loss: tensor(19.7150)\n",
      "1 Traning Loss: tensor(19.6719)\n",
      "2 Traning Loss: tensor(19.6289)\n",
      "3 Traning Loss: tensor(19.5858)\n",
      "4 Traning Loss: tensor(19.5429)\n",
      "5 Traning Loss: tensor(19.4999)\n",
      "6 Traning Loss: tensor(19.4571)\n",
      "7 Traning Loss: tensor(19.4142)\n",
      "8 Traning Loss: tensor(19.3714)\n",
      "9 Traning Loss: tensor(19.3287)\n",
      "10 Traning Loss: tensor(19.2860)\n",
      "11 Traning Loss: tensor(19.2433)\n",
      "12 Traning Loss: tensor(19.2007)\n",
      "13 Traning Loss: tensor(19.1581)\n",
      "14 Traning Loss: tensor(19.1156)\n",
      "15 Traning Loss: tensor(19.0731)\n",
      "16 Traning Loss: tensor(19.0307)\n",
      "17 Traning Loss: tensor(18.9883)\n",
      "18 Traning Loss: tensor(18.9460)\n",
      "19 Traning Loss: tensor(18.9037)\n",
      "20 Traning Loss: tensor(18.8615)\n",
      "21 Traning Loss: tensor(18.8193)\n",
      "22 Traning Loss: tensor(18.7772)\n",
      "23 Traning Loss: tensor(18.7351)\n",
      "24 Traning Loss: tensor(18.6931)\n",
      "25 Traning Loss: tensor(18.6511)\n",
      "26 Traning Loss: tensor(18.6092)\n",
      "27 Traning Loss: tensor(18.5673)\n",
      "28 Traning Loss: tensor(18.5255)\n",
      "29 Traning Loss: tensor(18.4837)\n",
      "30 Traning Loss: tensor(18.4419)\n",
      "31 Traning Loss: tensor(18.4002)\n",
      "32 Traning Loss: tensor(18.3586)\n",
      "33 Traning Loss: tensor(18.3170)\n",
      "34 Traning Loss: tensor(18.2755)\n",
      "35 Traning Loss: tensor(18.2340)\n",
      "36 Traning Loss: tensor(18.1925)\n",
      "37 Traning Loss: tensor(18.1511)\n",
      "38 Traning Loss: tensor(18.1098)\n",
      "39 Traning Loss: tensor(18.0685)\n",
      "40 Traning Loss: tensor(18.0272)\n",
      "41 Traning Loss: tensor(17.9860)\n",
      "42 Traning Loss: tensor(17.9448)\n",
      "43 Traning Loss: tensor(17.9037)\n",
      "44 Traning Loss: tensor(17.8627)\n",
      "45 Traning Loss: tensor(17.8216)\n",
      "46 Traning Loss: tensor(17.7807)\n",
      "47 Traning Loss: tensor(17.7397)\n",
      "48 Traning Loss: tensor(17.6989)\n",
      "49 Traning Loss: tensor(17.6580)\n",
      "50 Traning Loss: tensor(17.6173)\n",
      "51 Traning Loss: tensor(17.5765)\n",
      "52 Traning Loss: tensor(17.5358)\n",
      "53 Traning Loss: tensor(17.4952)\n",
      "54 Traning Loss: tensor(17.4546)\n",
      "55 Traning Loss: tensor(17.4141)\n",
      "56 Traning Loss: tensor(17.3736)\n",
      "57 Traning Loss: tensor(17.3331)\n",
      "58 Traning Loss: tensor(17.2927)\n",
      "59 Traning Loss: tensor(17.2523)\n",
      "60 Traning Loss: tensor(17.2120)\n",
      "61 Traning Loss: tensor(17.1718)\n",
      "62 Traning Loss: tensor(17.1315)\n",
      "63 Traning Loss: tensor(17.0914)\n",
      "64 Traning Loss: tensor(17.0512)\n",
      "65 Traning Loss: tensor(17.0112)\n",
      "66 Traning Loss: tensor(16.9711)\n",
      "67 Traning Loss: tensor(16.9312)\n",
      "68 Traning Loss: tensor(16.8912)\n",
      "69 Traning Loss: tensor(16.8513)\n",
      "70 Traning Loss: tensor(16.8115)\n",
      "71 Traning Loss: tensor(16.7717)\n",
      "72 Traning Loss: tensor(16.7319)\n",
      "73 Traning Loss: tensor(16.6922)\n",
      "74 Traning Loss: tensor(16.6526)\n",
      "75 Traning Loss: tensor(16.6129)\n",
      "76 Traning Loss: tensor(16.5734)\n",
      "77 Traning Loss: tensor(16.5339)\n",
      "78 Traning Loss: tensor(16.4944)\n",
      "79 Traning Loss: tensor(16.4550)\n",
      "80 Traning Loss: tensor(16.4156)\n",
      "81 Traning Loss: tensor(16.3762)\n",
      "82 Traning Loss: tensor(16.3370)\n",
      "83 Traning Loss: tensor(16.2977)\n",
      "84 Traning Loss: tensor(16.2585)\n",
      "85 Traning Loss: tensor(16.2194)\n",
      "86 Traning Loss: tensor(16.1803)\n",
      "87 Traning Loss: tensor(16.1412)\n",
      "88 Traning Loss: tensor(16.1022)\n",
      "89 Traning Loss: tensor(16.0633)\n",
      "90 Traning Loss: tensor(16.0243)\n",
      "91 Traning Loss: tensor(15.9855)\n",
      "92 Traning Loss: tensor(15.9467)\n",
      "93 Traning Loss: tensor(15.9079)\n",
      "94 Traning Loss: tensor(15.8692)\n",
      "95 Traning Loss: tensor(15.8305)\n",
      "96 Traning Loss: tensor(15.7919)\n",
      "97 Traning Loss: tensor(15.7533)\n",
      "98 Traning Loss: tensor(15.7147)\n",
      "99 Traning Loss: tensor(15.6763)\n",
      "100 Traning Loss: tensor(15.6378)\n",
      "101 Traning Loss: tensor(15.5994)\n",
      "102 Traning Loss: tensor(15.5611)\n",
      "103 Traning Loss: tensor(15.5228)\n",
      "104 Traning Loss: tensor(15.4845)\n",
      "105 Traning Loss: tensor(15.4463)\n",
      "106 Traning Loss: tensor(15.4082)\n",
      "107 Traning Loss: tensor(15.3701)\n",
      "108 Traning Loss: tensor(15.3320)\n",
      "109 Traning Loss: tensor(15.2940)\n",
      "110 Traning Loss: tensor(15.2561)\n",
      "111 Traning Loss: tensor(15.2181)\n",
      "112 Traning Loss: tensor(15.1803)\n",
      "113 Traning Loss: tensor(15.1425)\n",
      "114 Traning Loss: tensor(15.1047)\n",
      "115 Traning Loss: tensor(15.0670)\n",
      "116 Traning Loss: tensor(15.0293)\n",
      "117 Traning Loss: tensor(14.9917)\n",
      "118 Traning Loss: tensor(14.9541)\n",
      "119 Traning Loss: tensor(14.9166)\n",
      "120 Traning Loss: tensor(14.8791)\n",
      "121 Traning Loss: tensor(14.8417)\n",
      "122 Traning Loss: tensor(14.8043)\n",
      "123 Traning Loss: tensor(14.7670)\n",
      "124 Traning Loss: tensor(14.7297)\n",
      "125 Traning Loss: tensor(14.6925)\n",
      "126 Traning Loss: tensor(14.6553)\n",
      "127 Traning Loss: tensor(14.6182)\n",
      "128 Traning Loss: tensor(14.5812)\n",
      "129 Traning Loss: tensor(14.5441)\n",
      "130 Traning Loss: tensor(14.5072)\n",
      "131 Traning Loss: tensor(14.4703)\n",
      "132 Traning Loss: tensor(14.4334)\n",
      "133 Traning Loss: tensor(14.3966)\n",
      "134 Traning Loss: tensor(14.3598)\n",
      "135 Traning Loss: tensor(14.3231)\n",
      "136 Traning Loss: tensor(14.2864)\n",
      "137 Traning Loss: tensor(14.2498)\n",
      "138 Traning Loss: tensor(14.2133)\n",
      "139 Traning Loss: tensor(14.1768)\n",
      "140 Traning Loss: tensor(14.1403)\n",
      "141 Traning Loss: tensor(14.1039)\n",
      "142 Traning Loss: tensor(14.0676)\n",
      "143 Traning Loss: tensor(14.0313)\n",
      "144 Traning Loss: tensor(13.9951)\n",
      "145 Traning Loss: tensor(13.9589)\n",
      "146 Traning Loss: tensor(13.9228)\n",
      "147 Traning Loss: tensor(13.8867)\n",
      "148 Traning Loss: tensor(13.8507)\n",
      "149 Traning Loss: tensor(13.8147)\n",
      "150 Traning Loss: tensor(13.7788)\n",
      "151 Traning Loss: tensor(13.7430)\n",
      "152 Traning Loss: tensor(13.7072)\n",
      "153 Traning Loss: tensor(13.6715)\n",
      "154 Traning Loss: tensor(13.6358)\n",
      "155 Traning Loss: tensor(13.6002)\n",
      "156 Traning Loss: tensor(13.5646)\n",
      "157 Traning Loss: tensor(13.5291)\n",
      "158 Traning Loss: tensor(13.4936)\n",
      "159 Traning Loss: tensor(13.4582)\n",
      "160 Traning Loss: tensor(13.4229)\n",
      "161 Traning Loss: tensor(13.3876)\n",
      "162 Traning Loss: tensor(13.3524)\n",
      "163 Traning Loss: tensor(13.3173)\n",
      "164 Traning Loss: tensor(13.2822)\n",
      "165 Traning Loss: tensor(13.2471)\n",
      "166 Traning Loss: tensor(13.2122)\n",
      "167 Traning Loss: tensor(13.1772)\n",
      "168 Traning Loss: tensor(13.1424)\n",
      "169 Traning Loss: tensor(13.1076)\n",
      "170 Traning Loss: tensor(13.0729)\n",
      "171 Traning Loss: tensor(13.0382)\n",
      "172 Traning Loss: tensor(13.0036)\n",
      "173 Traning Loss: tensor(12.9691)\n",
      "174 Traning Loss: tensor(12.9346)\n",
      "175 Traning Loss: tensor(12.9002)\n",
      "176 Traning Loss: tensor(12.8658)\n",
      "177 Traning Loss: tensor(12.8315)\n",
      "178 Traning Loss: tensor(12.7973)\n",
      "179 Traning Loss: tensor(12.7631)\n",
      "180 Traning Loss: tensor(12.7291)\n",
      "181 Traning Loss: tensor(12.6950)\n",
      "182 Traning Loss: tensor(12.6611)\n",
      "183 Traning Loss: tensor(12.6272)\n",
      "184 Traning Loss: tensor(12.5933)\n",
      "185 Traning Loss: tensor(12.5596)\n",
      "186 Traning Loss: tensor(12.5259)\n",
      "187 Traning Loss: tensor(12.4923)\n",
      "188 Traning Loss: tensor(12.4587)\n",
      "189 Traning Loss: tensor(12.4252)\n",
      "190 Traning Loss: tensor(12.3918)\n",
      "191 Traning Loss: tensor(12.3585)\n",
      "192 Traning Loss: tensor(12.3252)\n",
      "193 Traning Loss: tensor(12.2920)\n",
      "194 Traning Loss: tensor(12.2588)\n",
      "195 Traning Loss: tensor(12.2258)\n",
      "196 Traning Loss: tensor(12.1928)\n",
      "197 Traning Loss: tensor(12.1599)\n",
      "198 Traning Loss: tensor(12.1270)\n",
      "199 Traning Loss: tensor(12.0943)\n",
      "200 Traning Loss: tensor(12.0616)\n",
      "201 Traning Loss: tensor(12.0289)\n",
      "202 Traning Loss: tensor(11.9964)\n",
      "203 Traning Loss: tensor(11.9639)\n",
      "204 Traning Loss: tensor(11.9315)\n",
      "205 Traning Loss: tensor(11.8992)\n",
      "206 Traning Loss: tensor(11.8669)\n",
      "207 Traning Loss: tensor(11.8347)\n",
      "208 Traning Loss: tensor(11.8026)\n",
      "209 Traning Loss: tensor(11.7706)\n",
      "210 Traning Loss: tensor(11.7387)\n",
      "211 Traning Loss: tensor(11.7068)\n",
      "212 Traning Loss: tensor(11.6750)\n",
      "213 Traning Loss: tensor(11.6433)\n",
      "214 Traning Loss: tensor(11.6117)\n",
      "215 Traning Loss: tensor(11.5801)\n",
      "216 Traning Loss: tensor(11.5486)\n",
      "217 Traning Loss: tensor(11.5172)\n",
      "218 Traning Loss: tensor(11.4859)\n",
      "219 Traning Loss: tensor(11.4547)\n",
      "220 Traning Loss: tensor(11.4235)\n",
      "221 Traning Loss: tensor(11.3925)\n",
      "222 Traning Loss: tensor(11.3615)\n",
      "223 Traning Loss: tensor(11.3306)\n",
      "224 Traning Loss: tensor(11.2998)\n",
      "225 Traning Loss: tensor(11.2690)\n",
      "226 Traning Loss: tensor(11.2384)\n",
      "227 Traning Loss: tensor(11.2078)\n",
      "228 Traning Loss: tensor(11.1773)\n",
      "229 Traning Loss: tensor(11.1469)\n",
      "230 Traning Loss: tensor(11.1166)\n",
      "231 Traning Loss: tensor(11.0863)\n",
      "232 Traning Loss: tensor(11.0562)\n",
      "233 Traning Loss: tensor(11.0261)\n",
      "234 Traning Loss: tensor(10.9962)\n",
      "235 Traning Loss: tensor(10.9663)\n",
      "236 Traning Loss: tensor(10.9365)\n",
      "237 Traning Loss: tensor(10.9067)\n",
      "238 Traning Loss: tensor(10.8771)\n",
      "239 Traning Loss: tensor(10.8476)\n",
      "240 Traning Loss: tensor(10.8181)\n",
      "241 Traning Loss: tensor(10.7887)\n",
      "242 Traning Loss: tensor(10.7594)\n",
      "243 Traning Loss: tensor(10.7302)\n",
      "244 Traning Loss: tensor(10.7011)\n",
      "245 Traning Loss: tensor(10.6721)\n",
      "246 Traning Loss: tensor(10.6432)\n",
      "247 Traning Loss: tensor(10.6144)\n",
      "248 Traning Loss: tensor(10.5856)\n",
      "249 Traning Loss: tensor(10.5569)\n",
      "250 Traning Loss: tensor(10.5284)\n",
      "251 Traning Loss: tensor(10.4999)\n",
      "252 Traning Loss: tensor(10.4715)\n",
      "253 Traning Loss: tensor(10.4432)\n",
      "254 Traning Loss: tensor(10.4150)\n",
      "255 Traning Loss: tensor(10.3869)\n",
      "256 Traning Loss: tensor(10.3588)\n",
      "257 Traning Loss: tensor(10.3309)\n",
      "258 Traning Loss: tensor(10.3031)\n",
      "259 Traning Loss: tensor(10.2753)\n",
      "260 Traning Loss: tensor(10.2476)\n",
      "261 Traning Loss: tensor(10.2201)\n",
      "262 Traning Loss: tensor(10.1926)\n",
      "263 Traning Loss: tensor(10.1652)\n",
      "264 Traning Loss: tensor(10.1379)\n",
      "265 Traning Loss: tensor(10.1107)\n",
      "266 Traning Loss: tensor(10.0836)\n",
      "267 Traning Loss: tensor(10.0565)\n",
      "268 Traning Loss: tensor(10.0296)\n",
      "269 Traning Loss: tensor(10.0028)\n",
      "270 Traning Loss: tensor(9.9760)\n",
      "271 Traning Loss: tensor(9.9493)\n",
      "272 Traning Loss: tensor(9.9228)\n",
      "273 Traning Loss: tensor(9.8963)\n",
      "274 Traning Loss: tensor(9.8699)\n",
      "275 Traning Loss: tensor(9.8436)\n",
      "276 Traning Loss: tensor(9.8174)\n",
      "277 Traning Loss: tensor(9.7913)\n",
      "278 Traning Loss: tensor(9.7653)\n",
      "279 Traning Loss: tensor(9.7394)\n",
      "280 Traning Loss: tensor(9.7136)\n",
      "281 Traning Loss: tensor(9.6878)\n",
      "282 Traning Loss: tensor(9.6622)\n",
      "283 Traning Loss: tensor(9.6366)\n",
      "284 Traning Loss: tensor(9.6111)\n",
      "285 Traning Loss: tensor(9.5858)\n",
      "286 Traning Loss: tensor(9.5605)\n",
      "287 Traning Loss: tensor(9.5353)\n",
      "288 Traning Loss: tensor(9.5102)\n",
      "289 Traning Loss: tensor(9.4852)\n",
      "290 Traning Loss: tensor(9.4603)\n",
      "291 Traning Loss: tensor(9.4355)\n",
      "292 Traning Loss: tensor(9.4107)\n",
      "293 Traning Loss: tensor(9.3861)\n",
      "294 Traning Loss: tensor(9.3615)\n",
      "295 Traning Loss: tensor(9.3371)\n",
      "296 Traning Loss: tensor(9.3127)\n",
      "297 Traning Loss: tensor(9.2884)\n",
      "298 Traning Loss: tensor(9.2642)\n",
      "299 Traning Loss: tensor(9.2401)\n",
      "300 Traning Loss: tensor(9.2161)\n",
      "301 Traning Loss: tensor(9.1922)\n",
      "302 Traning Loss: tensor(9.1683)\n",
      "303 Traning Loss: tensor(9.1446)\n",
      "304 Traning Loss: tensor(9.1209)\n",
      "305 Traning Loss: tensor(9.0974)\n",
      "306 Traning Loss: tensor(9.0739)\n",
      "307 Traning Loss: tensor(9.0505)\n",
      "308 Traning Loss: tensor(9.0272)\n",
      "309 Traning Loss: tensor(9.0040)\n",
      "310 Traning Loss: tensor(8.9809)\n",
      "311 Traning Loss: tensor(8.9579)\n",
      "312 Traning Loss: tensor(8.9349)\n",
      "313 Traning Loss: tensor(8.9120)\n",
      "314 Traning Loss: tensor(8.8893)\n",
      "315 Traning Loss: tensor(8.8666)\n",
      "316 Traning Loss: tensor(8.8440)\n",
      "317 Traning Loss: tensor(8.8215)\n",
      "318 Traning Loss: tensor(8.7991)\n",
      "319 Traning Loss: tensor(8.7767)\n",
      "320 Traning Loss: tensor(8.7545)\n",
      "321 Traning Loss: tensor(8.7323)\n",
      "322 Traning Loss: tensor(8.7102)\n",
      "323 Traning Loss: tensor(8.6882)\n",
      "324 Traning Loss: tensor(8.6663)\n",
      "325 Traning Loss: tensor(8.6445)\n",
      "326 Traning Loss: tensor(8.6227)\n",
      "327 Traning Loss: tensor(8.6011)\n",
      "328 Traning Loss: tensor(8.5795)\n",
      "329 Traning Loss: tensor(8.5580)\n",
      "330 Traning Loss: tensor(8.5366)\n",
      "331 Traning Loss: tensor(8.5153)\n",
      "332 Traning Loss: tensor(8.4940)\n",
      "333 Traning Loss: tensor(8.4729)\n",
      "334 Traning Loss: tensor(8.4518)\n",
      "335 Traning Loss: tensor(8.4308)\n",
      "336 Traning Loss: tensor(8.4099)\n",
      "337 Traning Loss: tensor(8.3891)\n",
      "338 Traning Loss: tensor(8.3683)\n",
      "339 Traning Loss: tensor(8.3477)\n",
      "340 Traning Loss: tensor(8.3271)\n",
      "341 Traning Loss: tensor(8.3066)\n",
      "342 Traning Loss: tensor(8.2861)\n",
      "343 Traning Loss: tensor(8.2658)\n",
      "344 Traning Loss: tensor(8.2455)\n",
      "345 Traning Loss: tensor(8.2253)\n",
      "346 Traning Loss: tensor(8.2052)\n",
      "347 Traning Loss: tensor(8.1852)\n",
      "348 Traning Loss: tensor(8.1653)\n",
      "349 Traning Loss: tensor(8.1454)\n",
      "350 Traning Loss: tensor(8.1256)\n",
      "351 Traning Loss: tensor(8.1059)\n",
      "352 Traning Loss: tensor(8.0863)\n",
      "353 Traning Loss: tensor(8.0667)\n",
      "354 Traning Loss: tensor(8.0472)\n",
      "355 Traning Loss: tensor(8.0278)\n",
      "356 Traning Loss: tensor(8.0085)\n",
      "357 Traning Loss: tensor(7.9892)\n",
      "358 Traning Loss: tensor(7.9700)\n",
      "359 Traning Loss: tensor(7.9509)\n",
      "360 Traning Loss: tensor(7.9319)\n",
      "361 Traning Loss: tensor(7.9130)\n",
      "362 Traning Loss: tensor(7.8941)\n",
      "363 Traning Loss: tensor(7.8753)\n",
      "364 Traning Loss: tensor(7.8566)\n",
      "365 Traning Loss: tensor(7.8379)\n",
      "366 Traning Loss: tensor(7.8193)\n",
      "367 Traning Loss: tensor(7.8008)\n",
      "368 Traning Loss: tensor(7.7824)\n",
      "369 Traning Loss: tensor(7.7640)\n",
      "370 Traning Loss: tensor(7.7457)\n",
      "371 Traning Loss: tensor(7.7275)\n",
      "372 Traning Loss: tensor(7.7094)\n",
      "373 Traning Loss: tensor(7.6913)\n",
      "374 Traning Loss: tensor(7.6733)\n",
      "375 Traning Loss: tensor(7.6554)\n",
      "376 Traning Loss: tensor(7.6375)\n",
      "377 Traning Loss: tensor(7.6197)\n",
      "378 Traning Loss: tensor(7.6020)\n",
      "379 Traning Loss: tensor(7.5844)\n",
      "380 Traning Loss: tensor(7.5668)\n",
      "381 Traning Loss: tensor(7.5493)\n",
      "382 Traning Loss: tensor(7.5318)\n",
      "383 Traning Loss: tensor(7.5145)\n",
      "384 Traning Loss: tensor(7.4972)\n",
      "385 Traning Loss: tensor(7.4799)\n",
      "386 Traning Loss: tensor(7.4628)\n",
      "387 Traning Loss: tensor(7.4457)\n",
      "388 Traning Loss: tensor(7.4286)\n",
      "389 Traning Loss: tensor(7.4117)\n",
      "390 Traning Loss: tensor(7.3948)\n",
      "391 Traning Loss: tensor(7.3780)\n",
      "392 Traning Loss: tensor(7.3612)\n",
      "393 Traning Loss: tensor(7.3445)\n",
      "394 Traning Loss: tensor(7.3279)\n",
      "395 Traning Loss: tensor(7.3113)\n",
      "396 Traning Loss: tensor(7.2948)\n",
      "397 Traning Loss: tensor(7.2784)\n",
      "398 Traning Loss: tensor(7.2620)\n",
      "399 Traning Loss: tensor(7.2457)\n",
      "400 Traning Loss: tensor(7.2295)\n",
      "401 Traning Loss: tensor(7.2133)\n",
      "402 Traning Loss: tensor(7.1972)\n",
      "403 Traning Loss: tensor(7.1811)\n",
      "404 Traning Loss: tensor(7.1651)\n",
      "405 Traning Loss: tensor(7.1492)\n",
      "406 Traning Loss: tensor(7.1334)\n",
      "407 Traning Loss: tensor(7.1176)\n",
      "408 Traning Loss: tensor(7.1018)\n",
      "409 Traning Loss: tensor(7.0862)\n",
      "410 Traning Loss: tensor(7.0705)\n",
      "411 Traning Loss: tensor(7.0550)\n",
      "412 Traning Loss: tensor(7.0395)\n",
      "413 Traning Loss: tensor(7.0241)\n",
      "414 Traning Loss: tensor(7.0087)\n",
      "415 Traning Loss: tensor(6.9934)\n",
      "416 Traning Loss: tensor(6.9782)\n",
      "417 Traning Loss: tensor(6.9630)\n",
      "418 Traning Loss: tensor(6.9479)\n",
      "419 Traning Loss: tensor(6.9328)\n",
      "420 Traning Loss: tensor(6.9178)\n",
      "421 Traning Loss: tensor(6.9028)\n",
      "422 Traning Loss: tensor(6.8879)\n",
      "423 Traning Loss: tensor(6.8731)\n",
      "424 Traning Loss: tensor(6.8583)\n",
      "425 Traning Loss: tensor(6.8436)\n",
      "426 Traning Loss: tensor(6.8290)\n",
      "427 Traning Loss: tensor(6.8144)\n",
      "428 Traning Loss: tensor(6.7998)\n",
      "429 Traning Loss: tensor(6.7854)\n",
      "430 Traning Loss: tensor(6.7709)\n",
      "431 Traning Loss: tensor(6.7566)\n",
      "432 Traning Loss: tensor(6.7422)\n",
      "433 Traning Loss: tensor(6.7280)\n",
      "434 Traning Loss: tensor(6.7138)\n",
      "435 Traning Loss: tensor(6.6996)\n",
      "436 Traning Loss: tensor(6.6856)\n",
      "437 Traning Loss: tensor(6.6715)\n",
      "438 Traning Loss: tensor(6.6575)\n",
      "439 Traning Loss: tensor(6.6436)\n",
      "440 Traning Loss: tensor(6.6298)\n",
      "441 Traning Loss: tensor(6.6159)\n",
      "442 Traning Loss: tensor(6.6022)\n",
      "443 Traning Loss: tensor(6.5885)\n",
      "444 Traning Loss: tensor(6.5748)\n",
      "445 Traning Loss: tensor(6.5612)\n",
      "446 Traning Loss: tensor(6.5477)\n",
      "447 Traning Loss: tensor(6.5342)\n",
      "448 Traning Loss: tensor(6.5207)\n",
      "449 Traning Loss: tensor(6.5074)\n",
      "450 Traning Loss: tensor(6.4940)\n",
      "451 Traning Loss: tensor(6.4807)\n",
      "452 Traning Loss: tensor(6.4675)\n",
      "453 Traning Loss: tensor(6.4543)\n",
      "454 Traning Loss: tensor(6.4412)\n",
      "455 Traning Loss: tensor(6.4281)\n",
      "456 Traning Loss: tensor(6.4151)\n",
      "457 Traning Loss: tensor(6.4021)\n",
      "458 Traning Loss: tensor(6.3892)\n",
      "459 Traning Loss: tensor(6.3763)\n",
      "460 Traning Loss: tensor(6.3635)\n",
      "461 Traning Loss: tensor(6.3508)\n",
      "462 Traning Loss: tensor(6.3380)\n",
      "463 Traning Loss: tensor(6.3254)\n",
      "464 Traning Loss: tensor(6.3127)\n",
      "465 Traning Loss: tensor(6.3002)\n",
      "466 Traning Loss: tensor(6.2876)\n",
      "467 Traning Loss: tensor(6.2752)\n",
      "468 Traning Loss: tensor(6.2627)\n",
      "469 Traning Loss: tensor(6.2504)\n",
      "470 Traning Loss: tensor(6.2380)\n",
      "471 Traning Loss: tensor(6.2258)\n",
      "472 Traning Loss: tensor(6.2135)\n",
      "473 Traning Loss: tensor(6.2014)\n",
      "474 Traning Loss: tensor(6.1892)\n",
      "475 Traning Loss: tensor(6.1771)\n",
      "476 Traning Loss: tensor(6.1651)\n",
      "477 Traning Loss: tensor(6.1531)\n",
      "478 Traning Loss: tensor(6.1412)\n",
      "479 Traning Loss: tensor(6.1293)\n",
      "480 Traning Loss: tensor(6.1174)\n",
      "481 Traning Loss: tensor(6.1056)\n",
      "482 Traning Loss: tensor(6.0938)\n",
      "483 Traning Loss: tensor(6.0821)\n",
      "484 Traning Loss: tensor(6.0704)\n",
      "485 Traning Loss: tensor(6.0588)\n",
      "486 Traning Loss: tensor(6.0473)\n",
      "487 Traning Loss: tensor(6.0357)\n",
      "488 Traning Loss: tensor(6.0242)\n",
      "489 Traning Loss: tensor(6.0128)\n",
      "490 Traning Loss: tensor(6.0014)\n",
      "491 Traning Loss: tensor(5.9900)\n",
      "492 Traning Loss: tensor(5.9787)\n",
      "493 Traning Loss: tensor(5.9675)\n",
      "494 Traning Loss: tensor(5.9562)\n",
      "495 Traning Loss: tensor(5.9451)\n",
      "496 Traning Loss: tensor(5.9339)\n",
      "497 Traning Loss: tensor(5.9229)\n",
      "498 Traning Loss: tensor(5.9118)\n",
      "499 Traning Loss: tensor(5.9008)\n",
      "500 Traning Loss: tensor(5.8898)\n",
      "501 Traning Loss: tensor(5.8789)\n",
      "502 Traning Loss: tensor(5.8681)\n",
      "503 Traning Loss: tensor(5.8572)\n",
      "504 Traning Loss: tensor(5.8464)\n",
      "505 Traning Loss: tensor(5.8357)\n",
      "506 Traning Loss: tensor(5.8250)\n",
      "507 Traning Loss: tensor(5.8143)\n",
      "508 Traning Loss: tensor(5.8037)\n",
      "509 Traning Loss: tensor(5.7931)\n",
      "510 Traning Loss: tensor(5.7826)\n",
      "511 Traning Loss: tensor(5.7721)\n",
      "512 Traning Loss: tensor(5.7616)\n",
      "513 Traning Loss: tensor(5.7512)\n",
      "514 Traning Loss: tensor(5.7409)\n",
      "515 Traning Loss: tensor(5.7305)\n",
      "516 Traning Loss: tensor(5.7202)\n",
      "517 Traning Loss: tensor(5.7100)\n",
      "518 Traning Loss: tensor(5.6998)\n",
      "519 Traning Loss: tensor(5.6896)\n",
      "520 Traning Loss: tensor(5.6795)\n",
      "521 Traning Loss: tensor(5.6694)\n",
      "522 Traning Loss: tensor(5.6593)\n",
      "523 Traning Loss: tensor(5.6493)\n",
      "524 Traning Loss: tensor(5.6393)\n",
      "525 Traning Loss: tensor(5.6294)\n",
      "526 Traning Loss: tensor(5.6195)\n",
      "527 Traning Loss: tensor(5.6096)\n",
      "528 Traning Loss: tensor(5.5998)\n",
      "529 Traning Loss: tensor(5.5900)\n",
      "530 Traning Loss: tensor(5.5803)\n",
      "531 Traning Loss: tensor(5.5706)\n",
      "532 Traning Loss: tensor(5.5609)\n",
      "533 Traning Loss: tensor(5.5513)\n",
      "534 Traning Loss: tensor(5.5417)\n",
      "535 Traning Loss: tensor(5.5322)\n",
      "536 Traning Loss: tensor(5.5227)\n",
      "537 Traning Loss: tensor(5.5132)\n",
      "538 Traning Loss: tensor(5.5037)\n",
      "539 Traning Loss: tensor(5.4943)\n",
      "540 Traning Loss: tensor(5.4850)\n",
      "541 Traning Loss: tensor(5.4756)\n",
      "542 Traning Loss: tensor(5.4663)\n",
      "543 Traning Loss: tensor(5.4571)\n",
      "544 Traning Loss: tensor(5.4479)\n",
      "545 Traning Loss: tensor(5.4387)\n",
      "546 Traning Loss: tensor(5.4295)\n",
      "547 Traning Loss: tensor(5.4204)\n",
      "548 Traning Loss: tensor(5.4113)\n",
      "549 Traning Loss: tensor(5.4023)\n",
      "550 Traning Loss: tensor(5.3933)\n",
      "551 Traning Loss: tensor(5.3843)\n",
      "552 Traning Loss: tensor(5.3754)\n",
      "553 Traning Loss: tensor(5.3665)\n",
      "554 Traning Loss: tensor(5.3576)\n",
      "555 Traning Loss: tensor(5.3488)\n",
      "556 Traning Loss: tensor(5.3400)\n",
      "557 Traning Loss: tensor(5.3313)\n",
      "558 Traning Loss: tensor(5.3225)\n",
      "559 Traning Loss: tensor(5.3138)\n",
      "560 Traning Loss: tensor(5.3052)\n",
      "561 Traning Loss: tensor(5.2966)\n",
      "562 Traning Loss: tensor(5.2880)\n",
      "563 Traning Loss: tensor(5.2794)\n",
      "564 Traning Loss: tensor(5.2709)\n",
      "565 Traning Loss: tensor(5.2624)\n",
      "566 Traning Loss: tensor(5.2540)\n",
      "567 Traning Loss: tensor(5.2455)\n",
      "568 Traning Loss: tensor(5.2371)\n",
      "569 Traning Loss: tensor(5.2288)\n",
      "570 Traning Loss: tensor(5.2205)\n",
      "571 Traning Loss: tensor(5.2122)\n",
      "572 Traning Loss: tensor(5.2039)\n",
      "573 Traning Loss: tensor(5.1957)\n",
      "574 Traning Loss: tensor(5.1875)\n",
      "575 Traning Loss: tensor(5.1794)\n",
      "576 Traning Loss: tensor(5.1712)\n",
      "577 Traning Loss: tensor(5.1631)\n",
      "578 Traning Loss: tensor(5.1551)\n",
      "579 Traning Loss: tensor(5.1470)\n",
      "580 Traning Loss: tensor(5.1390)\n",
      "581 Traning Loss: tensor(5.1311)\n",
      "582 Traning Loss: tensor(5.1231)\n",
      "583 Traning Loss: tensor(5.1152)\n",
      "584 Traning Loss: tensor(5.1074)\n",
      "585 Traning Loss: tensor(5.0995)\n",
      "586 Traning Loss: tensor(5.0917)\n",
      "587 Traning Loss: tensor(5.0839)\n",
      "588 Traning Loss: tensor(5.0762)\n",
      "589 Traning Loss: tensor(5.0685)\n",
      "590 Traning Loss: tensor(5.0608)\n",
      "591 Traning Loss: tensor(5.0531)\n",
      "592 Traning Loss: tensor(5.0455)\n",
      "593 Traning Loss: tensor(5.0379)\n",
      "594 Traning Loss: tensor(5.0303)\n",
      "595 Traning Loss: tensor(5.0228)\n",
      "596 Traning Loss: tensor(5.0153)\n",
      "597 Traning Loss: tensor(5.0078)\n",
      "598 Traning Loss: tensor(5.0004)\n",
      "599 Traning Loss: tensor(4.9930)\n",
      "600 Traning Loss: tensor(4.9856)\n",
      "601 Traning Loss: tensor(4.9782)\n",
      "602 Traning Loss: tensor(4.9709)\n",
      "603 Traning Loss: tensor(4.9636)\n",
      "604 Traning Loss: tensor(4.9563)\n",
      "605 Traning Loss: tensor(4.9491)\n",
      "606 Traning Loss: tensor(4.9419)\n",
      "607 Traning Loss: tensor(4.9347)\n",
      "608 Traning Loss: tensor(4.9275)\n",
      "609 Traning Loss: tensor(4.9204)\n",
      "610 Traning Loss: tensor(4.9133)\n",
      "611 Traning Loss: tensor(4.9062)\n",
      "612 Traning Loss: tensor(4.8992)\n",
      "613 Traning Loss: tensor(4.8922)\n",
      "614 Traning Loss: tensor(4.8852)\n",
      "615 Traning Loss: tensor(4.8782)\n",
      "616 Traning Loss: tensor(4.8713)\n",
      "617 Traning Loss: tensor(4.8644)\n",
      "618 Traning Loss: tensor(4.8575)\n",
      "619 Traning Loss: tensor(4.8507)\n",
      "620 Traning Loss: tensor(4.8438)\n",
      "621 Traning Loss: tensor(4.8371)\n",
      "622 Traning Loss: tensor(4.8303)\n",
      "623 Traning Loss: tensor(4.8235)\n",
      "624 Traning Loss: tensor(4.8168)\n",
      "625 Traning Loss: tensor(4.8102)\n",
      "626 Traning Loss: tensor(4.8035)\n",
      "627 Traning Loss: tensor(4.7969)\n",
      "628 Traning Loss: tensor(4.7903)\n",
      "629 Traning Loss: tensor(4.7837)\n",
      "630 Traning Loss: tensor(4.7771)\n",
      "631 Traning Loss: tensor(4.7706)\n",
      "632 Traning Loss: tensor(4.7641)\n",
      "633 Traning Loss: tensor(4.7576)\n",
      "634 Traning Loss: tensor(4.7512)\n",
      "635 Traning Loss: tensor(4.7448)\n",
      "636 Traning Loss: tensor(4.7384)\n",
      "637 Traning Loss: tensor(4.7320)\n",
      "638 Traning Loss: tensor(4.7257)\n",
      "639 Traning Loss: tensor(4.7193)\n",
      "640 Traning Loss: tensor(4.7130)\n",
      "641 Traning Loss: tensor(4.7068)\n",
      "642 Traning Loss: tensor(4.7005)\n",
      "643 Traning Loss: tensor(4.6943)\n",
      "644 Traning Loss: tensor(4.6881)\n",
      "645 Traning Loss: tensor(4.6820)\n",
      "646 Traning Loss: tensor(4.6758)\n",
      "647 Traning Loss: tensor(4.6697)\n",
      "648 Traning Loss: tensor(4.6636)\n",
      "649 Traning Loss: tensor(4.6575)\n",
      "650 Traning Loss: tensor(4.6515)\n",
      "651 Traning Loss: tensor(4.6455)\n",
      "652 Traning Loss: tensor(4.6395)\n",
      "653 Traning Loss: tensor(4.6335)\n",
      "654 Traning Loss: tensor(4.6276)\n",
      "655 Traning Loss: tensor(4.6216)\n",
      "656 Traning Loss: tensor(4.6157)\n",
      "657 Traning Loss: tensor(4.6099)\n",
      "658 Traning Loss: tensor(4.6040)\n",
      "659 Traning Loss: tensor(4.5982)\n",
      "660 Traning Loss: tensor(4.5924)\n",
      "661 Traning Loss: tensor(4.5866)\n",
      "662 Traning Loss: tensor(4.5809)\n",
      "663 Traning Loss: tensor(4.5751)\n",
      "664 Traning Loss: tensor(4.5694)\n",
      "665 Traning Loss: tensor(4.5637)\n",
      "666 Traning Loss: tensor(4.5581)\n",
      "667 Traning Loss: tensor(4.5524)\n",
      "668 Traning Loss: tensor(4.5468)\n",
      "669 Traning Loss: tensor(4.5412)\n",
      "670 Traning Loss: tensor(4.5356)\n",
      "671 Traning Loss: tensor(4.5301)\n",
      "672 Traning Loss: tensor(4.5246)\n",
      "673 Traning Loss: tensor(4.5191)\n",
      "674 Traning Loss: tensor(4.5136)\n",
      "675 Traning Loss: tensor(4.5081)\n",
      "676 Traning Loss: tensor(4.5027)\n",
      "677 Traning Loss: tensor(4.4973)\n",
      "678 Traning Loss: tensor(4.4919)\n",
      "679 Traning Loss: tensor(4.4865)\n",
      "680 Traning Loss: tensor(4.4812)\n",
      "681 Traning Loss: tensor(4.4758)\n",
      "682 Traning Loss: tensor(4.4705)\n",
      "683 Traning Loss: tensor(4.4653)\n",
      "684 Traning Loss: tensor(4.4600)\n",
      "685 Traning Loss: tensor(4.4548)\n",
      "686 Traning Loss: tensor(4.4495)\n",
      "687 Traning Loss: tensor(4.4444)\n",
      "688 Traning Loss: tensor(4.4392)\n",
      "689 Traning Loss: tensor(4.4340)\n",
      "690 Traning Loss: tensor(4.4289)\n",
      "691 Traning Loss: tensor(4.4238)\n",
      "692 Traning Loss: tensor(4.4187)\n",
      "693 Traning Loss: tensor(4.4136)\n",
      "694 Traning Loss: tensor(4.4086)\n",
      "695 Traning Loss: tensor(4.4036)\n",
      "696 Traning Loss: tensor(4.3985)\n",
      "697 Traning Loss: tensor(4.3936)\n",
      "698 Traning Loss: tensor(4.3886)\n",
      "699 Traning Loss: tensor(4.3837)\n",
      "700 Traning Loss: tensor(4.3787)\n",
      "701 Traning Loss: tensor(4.3738)\n",
      "702 Traning Loss: tensor(4.3689)\n",
      "703 Traning Loss: tensor(4.3641)\n",
      "704 Traning Loss: tensor(4.3592)\n",
      "705 Traning Loss: tensor(4.3544)\n",
      "706 Traning Loss: tensor(4.3496)\n",
      "707 Traning Loss: tensor(4.3448)\n",
      "708 Traning Loss: tensor(4.3401)\n",
      "709 Traning Loss: tensor(4.3353)\n",
      "710 Traning Loss: tensor(4.3306)\n",
      "711 Traning Loss: tensor(4.3259)\n",
      "712 Traning Loss: tensor(4.3212)\n",
      "713 Traning Loss: tensor(4.3166)\n",
      "714 Traning Loss: tensor(4.3119)\n",
      "715 Traning Loss: tensor(4.3073)\n",
      "716 Traning Loss: tensor(4.3027)\n",
      "717 Traning Loss: tensor(4.2981)\n",
      "718 Traning Loss: tensor(4.2935)\n",
      "719 Traning Loss: tensor(4.2890)\n",
      "720 Traning Loss: tensor(4.2844)\n",
      "721 Traning Loss: tensor(4.2799)\n",
      "722 Traning Loss: tensor(4.2754)\n",
      "723 Traning Loss: tensor(4.2710)\n",
      "724 Traning Loss: tensor(4.2665)\n",
      "725 Traning Loss: tensor(4.2621)\n",
      "726 Traning Loss: tensor(4.2577)\n",
      "727 Traning Loss: tensor(4.2533)\n",
      "728 Traning Loss: tensor(4.2489)\n",
      "729 Traning Loss: tensor(4.2445)\n",
      "730 Traning Loss: tensor(4.2402)\n",
      "731 Traning Loss: tensor(4.2359)\n",
      "732 Traning Loss: tensor(4.2315)\n",
      "733 Traning Loss: tensor(4.2273)\n",
      "734 Traning Loss: tensor(4.2230)\n",
      "735 Traning Loss: tensor(4.2187)\n",
      "736 Traning Loss: tensor(4.2145)\n",
      "737 Traning Loss: tensor(4.2103)\n",
      "738 Traning Loss: tensor(4.2061)\n",
      "739 Traning Loss: tensor(4.2019)\n",
      "740 Traning Loss: tensor(4.1977)\n",
      "741 Traning Loss: tensor(4.1936)\n",
      "742 Traning Loss: tensor(4.1895)\n",
      "743 Traning Loss: tensor(4.1854)\n",
      "744 Traning Loss: tensor(4.1813)\n",
      "745 Traning Loss: tensor(4.1772)\n",
      "746 Traning Loss: tensor(4.1731)\n",
      "747 Traning Loss: tensor(4.1691)\n",
      "748 Traning Loss: tensor(4.1651)\n",
      "749 Traning Loss: tensor(4.1611)\n",
      "750 Traning Loss: tensor(4.1571)\n",
      "751 Traning Loss: tensor(4.1531)\n",
      "752 Traning Loss: tensor(4.1491)\n",
      "753 Traning Loss: tensor(4.1452)\n",
      "754 Traning Loss: tensor(4.1413)\n",
      "755 Traning Loss: tensor(4.1374)\n",
      "756 Traning Loss: tensor(4.1335)\n",
      "757 Traning Loss: tensor(4.1296)\n",
      "758 Traning Loss: tensor(4.1258)\n",
      "759 Traning Loss: tensor(4.1219)\n",
      "760 Traning Loss: tensor(4.1181)\n",
      "761 Traning Loss: tensor(4.1143)\n",
      "762 Traning Loss: tensor(4.1105)\n",
      "763 Traning Loss: tensor(4.1067)\n",
      "764 Traning Loss: tensor(4.1030)\n",
      "765 Traning Loss: tensor(4.0992)\n",
      "766 Traning Loss: tensor(4.0955)\n",
      "767 Traning Loss: tensor(4.0918)\n",
      "768 Traning Loss: tensor(4.0881)\n",
      "769 Traning Loss: tensor(4.0844)\n",
      "770 Traning Loss: tensor(4.0808)\n",
      "771 Traning Loss: tensor(4.0771)\n",
      "772 Traning Loss: tensor(4.0735)\n",
      "773 Traning Loss: tensor(4.0699)\n",
      "774 Traning Loss: tensor(4.0663)\n",
      "775 Traning Loss: tensor(4.0627)\n",
      "776 Traning Loss: tensor(4.0591)\n",
      "777 Traning Loss: tensor(4.0556)\n",
      "778 Traning Loss: tensor(4.0520)\n",
      "779 Traning Loss: tensor(4.0485)\n",
      "780 Traning Loss: tensor(4.0450)\n",
      "781 Traning Loss: tensor(4.0415)\n",
      "782 Traning Loss: tensor(4.0380)\n",
      "783 Traning Loss: tensor(4.0346)\n",
      "784 Traning Loss: tensor(4.0311)\n",
      "785 Traning Loss: tensor(4.0277)\n",
      "786 Traning Loss: tensor(4.0243)\n",
      "787 Traning Loss: tensor(4.0209)\n",
      "788 Traning Loss: tensor(4.0175)\n",
      "789 Traning Loss: tensor(4.0141)\n",
      "790 Traning Loss: tensor(4.0108)\n",
      "791 Traning Loss: tensor(4.0074)\n",
      "792 Traning Loss: tensor(4.0041)\n",
      "793 Traning Loss: tensor(4.0008)\n",
      "794 Traning Loss: tensor(3.9975)\n",
      "795 Traning Loss: tensor(3.9942)\n",
      "796 Traning Loss: tensor(3.9909)\n",
      "797 Traning Loss: tensor(3.9877)\n",
      "798 Traning Loss: tensor(3.9844)\n",
      "799 Traning Loss: tensor(3.9812)\n",
      "800 Traning Loss: tensor(3.9780)\n",
      "801 Traning Loss: tensor(3.9748)\n",
      "802 Traning Loss: tensor(3.9716)\n",
      "803 Traning Loss: tensor(3.9684)\n",
      "804 Traning Loss: tensor(3.9653)\n",
      "805 Traning Loss: tensor(3.9621)\n",
      "806 Traning Loss: tensor(3.9590)\n",
      "807 Traning Loss: tensor(3.9559)\n",
      "808 Traning Loss: tensor(3.9528)\n",
      "809 Traning Loss: tensor(3.9497)\n",
      "810 Traning Loss: tensor(3.9466)\n",
      "811 Traning Loss: tensor(3.9436)\n",
      "812 Traning Loss: tensor(3.9405)\n",
      "813 Traning Loss: tensor(3.9375)\n",
      "814 Traning Loss: tensor(3.9345)\n",
      "815 Traning Loss: tensor(3.9315)\n",
      "816 Traning Loss: tensor(3.9285)\n",
      "817 Traning Loss: tensor(3.9255)\n",
      "818 Traning Loss: tensor(3.9225)\n",
      "819 Traning Loss: tensor(3.9196)\n",
      "820 Traning Loss: tensor(3.9166)\n",
      "821 Traning Loss: tensor(3.9137)\n",
      "822 Traning Loss: tensor(3.9108)\n",
      "823 Traning Loss: tensor(3.9079)\n",
      "824 Traning Loss: tensor(3.9050)\n",
      "825 Traning Loss: tensor(3.9021)\n",
      "826 Traning Loss: tensor(3.8993)\n",
      "827 Traning Loss: tensor(3.8964)\n",
      "828 Traning Loss: tensor(3.8936)\n",
      "829 Traning Loss: tensor(3.8908)\n",
      "830 Traning Loss: tensor(3.8880)\n",
      "831 Traning Loss: tensor(3.8852)\n",
      "832 Traning Loss: tensor(3.8824)\n",
      "833 Traning Loss: tensor(3.8796)\n",
      "834 Traning Loss: tensor(3.8768)\n",
      "835 Traning Loss: tensor(3.8741)\n",
      "836 Traning Loss: tensor(3.8714)\n",
      "837 Traning Loss: tensor(3.8686)\n",
      "838 Traning Loss: tensor(3.8659)\n",
      "839 Traning Loss: tensor(3.8632)\n",
      "840 Traning Loss: tensor(3.8605)\n",
      "841 Traning Loss: tensor(3.8579)\n",
      "842 Traning Loss: tensor(3.8552)\n",
      "843 Traning Loss: tensor(3.8526)\n",
      "844 Traning Loss: tensor(3.8499)\n",
      "845 Traning Loss: tensor(3.8473)\n",
      "846 Traning Loss: tensor(3.8447)\n",
      "847 Traning Loss: tensor(3.8421)\n",
      "848 Traning Loss: tensor(3.8395)\n",
      "849 Traning Loss: tensor(3.8369)\n",
      "850 Traning Loss: tensor(3.8343)\n",
      "851 Traning Loss: tensor(3.8318)\n",
      "852 Traning Loss: tensor(3.8292)\n",
      "853 Traning Loss: tensor(3.8267)\n",
      "854 Traning Loss: tensor(3.8242)\n",
      "855 Traning Loss: tensor(3.8217)\n",
      "856 Traning Loss: tensor(3.8192)\n",
      "857 Traning Loss: tensor(3.8167)\n",
      "858 Traning Loss: tensor(3.8142)\n",
      "859 Traning Loss: tensor(3.8117)\n",
      "860 Traning Loss: tensor(3.8093)\n",
      "861 Traning Loss: tensor(3.8069)\n",
      "862 Traning Loss: tensor(3.8044)\n",
      "863 Traning Loss: tensor(3.8020)\n",
      "864 Traning Loss: tensor(3.7996)\n",
      "865 Traning Loss: tensor(3.7972)\n",
      "866 Traning Loss: tensor(3.7948)\n",
      "867 Traning Loss: tensor(3.7924)\n",
      "868 Traning Loss: tensor(3.7901)\n",
      "869 Traning Loss: tensor(3.7877)\n",
      "870 Traning Loss: tensor(3.7854)\n",
      "871 Traning Loss: tensor(3.7831)\n",
      "872 Traning Loss: tensor(3.7807)\n",
      "873 Traning Loss: tensor(3.7784)\n",
      "874 Traning Loss: tensor(3.7761)\n",
      "875 Traning Loss: tensor(3.7738)\n",
      "876 Traning Loss: tensor(3.7716)\n",
      "877 Traning Loss: tensor(3.7693)\n",
      "878 Traning Loss: tensor(3.7670)\n",
      "879 Traning Loss: tensor(3.7648)\n",
      "880 Traning Loss: tensor(3.7626)\n",
      "881 Traning Loss: tensor(3.7603)\n",
      "882 Traning Loss: tensor(3.7581)\n",
      "883 Traning Loss: tensor(3.7559)\n",
      "884 Traning Loss: tensor(3.7537)\n",
      "885 Traning Loss: tensor(3.7515)\n",
      "886 Traning Loss: tensor(3.7494)\n",
      "887 Traning Loss: tensor(3.7472)\n",
      "888 Traning Loss: tensor(3.7450)\n",
      "889 Traning Loss: tensor(3.7429)\n",
      "890 Traning Loss: tensor(3.7408)\n",
      "891 Traning Loss: tensor(3.7386)\n",
      "892 Traning Loss: tensor(3.7365)\n",
      "893 Traning Loss: tensor(3.7344)\n",
      "894 Traning Loss: tensor(3.7323)\n",
      "895 Traning Loss: tensor(3.7303)\n",
      "896 Traning Loss: tensor(3.7282)\n",
      "897 Traning Loss: tensor(3.7261)\n",
      "898 Traning Loss: tensor(3.7241)\n",
      "899 Traning Loss: tensor(3.7220)\n",
      "900 Traning Loss: tensor(3.7200)\n",
      "901 Traning Loss: tensor(3.7180)\n",
      "902 Traning Loss: tensor(3.7159)\n",
      "903 Traning Loss: tensor(3.7139)\n",
      "904 Traning Loss: tensor(3.7119)\n",
      "905 Traning Loss: tensor(3.7100)\n",
      "906 Traning Loss: tensor(3.7080)\n",
      "907 Traning Loss: tensor(3.7060)\n",
      "908 Traning Loss: tensor(3.7040)\n",
      "909 Traning Loss: tensor(3.7021)\n",
      "910 Traning Loss: tensor(3.7002)\n",
      "911 Traning Loss: tensor(3.6982)\n",
      "912 Traning Loss: tensor(3.6963)\n",
      "913 Traning Loss: tensor(3.6944)\n",
      "914 Traning Loss: tensor(3.6925)\n",
      "915 Traning Loss: tensor(3.6906)\n",
      "916 Traning Loss: tensor(3.6887)\n",
      "917 Traning Loss: tensor(3.6868)\n",
      "918 Traning Loss: tensor(3.6850)\n",
      "919 Traning Loss: tensor(3.6831)\n",
      "920 Traning Loss: tensor(3.6813)\n",
      "921 Traning Loss: tensor(3.6794)\n",
      "922 Traning Loss: tensor(3.6776)\n",
      "923 Traning Loss: tensor(3.6758)\n",
      "924 Traning Loss: tensor(3.6740)\n",
      "925 Traning Loss: tensor(3.6721)\n",
      "926 Traning Loss: tensor(3.6704)\n",
      "927 Traning Loss: tensor(3.6686)\n",
      "928 Traning Loss: tensor(3.6668)\n",
      "929 Traning Loss: tensor(3.6650)\n",
      "930 Traning Loss: tensor(3.6633)\n",
      "931 Traning Loss: tensor(3.6615)\n",
      "932 Traning Loss: tensor(3.6598)\n",
      "933 Traning Loss: tensor(3.6580)\n",
      "934 Traning Loss: tensor(3.6563)\n",
      "935 Traning Loss: tensor(3.6546)\n",
      "936 Traning Loss: tensor(3.6529)\n",
      "937 Traning Loss: tensor(3.6512)\n",
      "938 Traning Loss: tensor(3.6495)\n",
      "939 Traning Loss: tensor(3.6478)\n",
      "940 Traning Loss: tensor(3.6461)\n",
      "941 Traning Loss: tensor(3.6444)\n",
      "942 Traning Loss: tensor(3.6428)\n",
      "943 Traning Loss: tensor(3.6411)\n",
      "944 Traning Loss: tensor(3.6395)\n",
      "945 Traning Loss: tensor(3.6378)\n",
      "946 Traning Loss: tensor(3.6362)\n",
      "947 Traning Loss: tensor(3.6346)\n",
      "948 Traning Loss: tensor(3.6330)\n",
      "949 Traning Loss: tensor(3.6314)\n",
      "950 Traning Loss: tensor(3.6298)\n",
      "951 Traning Loss: tensor(3.6282)\n",
      "952 Traning Loss: tensor(3.6266)\n",
      "953 Traning Loss: tensor(3.6250)\n",
      "954 Traning Loss: tensor(3.6234)\n",
      "955 Traning Loss: tensor(3.6219)\n",
      "956 Traning Loss: tensor(3.6203)\n",
      "957 Traning Loss: tensor(3.6188)\n",
      "958 Traning Loss: tensor(3.6173)\n",
      "959 Traning Loss: tensor(3.6157)\n",
      "960 Traning Loss: tensor(3.6142)\n",
      "961 Traning Loss: tensor(3.6127)\n",
      "962 Traning Loss: tensor(3.6112)\n",
      "963 Traning Loss: tensor(3.6097)\n",
      "964 Traning Loss: tensor(3.6082)\n",
      "965 Traning Loss: tensor(3.6067)\n",
      "966 Traning Loss: tensor(3.6052)\n",
      "967 Traning Loss: tensor(3.6038)\n",
      "968 Traning Loss: tensor(3.6023)\n",
      "969 Traning Loss: tensor(3.6009)\n",
      "970 Traning Loss: tensor(3.5994)\n",
      "971 Traning Loss: tensor(3.5980)\n",
      "972 Traning Loss: tensor(3.5965)\n",
      "973 Traning Loss: tensor(3.5951)\n",
      "974 Traning Loss: tensor(3.5937)\n",
      "975 Traning Loss: tensor(3.5923)\n",
      "976 Traning Loss: tensor(3.5909)\n",
      "977 Traning Loss: tensor(3.5895)\n",
      "978 Traning Loss: tensor(3.5881)\n",
      "979 Traning Loss: tensor(3.5867)\n",
      "980 Traning Loss: tensor(3.5853)\n",
      "981 Traning Loss: tensor(3.5840)\n",
      "982 Traning Loss: tensor(3.5826)\n",
      "983 Traning Loss: tensor(3.5813)\n",
      "984 Traning Loss: tensor(3.5799)\n",
      "985 Traning Loss: tensor(3.5786)\n",
      "986 Traning Loss: tensor(3.5772)\n",
      "987 Traning Loss: tensor(3.5759)\n",
      "988 Traning Loss: tensor(3.5746)\n",
      "989 Traning Loss: tensor(3.5733)\n",
      "990 Traning Loss: tensor(3.5720)\n",
      "991 Traning Loss: tensor(3.5707)\n",
      "992 Traning Loss: tensor(3.5694)\n",
      "993 Traning Loss: tensor(3.5681)\n",
      "994 Traning Loss: tensor(3.5668)\n",
      "995 Traning Loss: tensor(3.5655)\n",
      "996 Traning Loss: tensor(3.5643)\n",
      "997 Traning Loss: tensor(3.5630)\n",
      "998 Traning Loss: tensor(3.5617)\n",
      "999 Traning Loss: tensor(3.5605)\n",
      "1000 Traning Loss: tensor(3.5593)\n",
      "1001 Traning Loss: tensor(3.5580)\n",
      "1002 Traning Loss: tensor(3.5568)\n",
      "1003 Traning Loss: tensor(3.5556)\n",
      "1004 Traning Loss: tensor(3.5544)\n",
      "1005 Traning Loss: tensor(3.5531)\n",
      "1006 Traning Loss: tensor(3.5519)\n",
      "1007 Traning Loss: tensor(3.5507)\n",
      "1008 Traning Loss: tensor(3.5495)\n",
      "1009 Traning Loss: tensor(3.5484)\n",
      "1010 Traning Loss: tensor(3.5472)\n",
      "1011 Traning Loss: tensor(3.5460)\n",
      "1012 Traning Loss: tensor(3.5448)\n",
      "1013 Traning Loss: tensor(3.5437)\n",
      "1014 Traning Loss: tensor(3.5425)\n",
      "1015 Traning Loss: tensor(3.5414)\n",
      "1016 Traning Loss: tensor(3.5402)\n",
      "1017 Traning Loss: tensor(3.5391)\n",
      "1018 Traning Loss: tensor(3.5380)\n",
      "1019 Traning Loss: tensor(3.5368)\n",
      "1020 Traning Loss: tensor(3.5357)\n",
      "1021 Traning Loss: tensor(3.5346)\n",
      "1022 Traning Loss: tensor(3.5335)\n",
      "1023 Traning Loss: tensor(3.5324)\n",
      "1024 Traning Loss: tensor(3.5313)\n",
      "1025 Traning Loss: tensor(3.5302)\n",
      "1026 Traning Loss: tensor(3.5291)\n",
      "1027 Traning Loss: tensor(3.5280)\n",
      "1028 Traning Loss: tensor(3.5270)\n",
      "1029 Traning Loss: tensor(3.5259)\n",
      "1030 Traning Loss: tensor(3.5248)\n",
      "1031 Traning Loss: tensor(3.5238)\n",
      "1032 Traning Loss: tensor(3.5227)\n",
      "1033 Traning Loss: tensor(3.5217)\n",
      "1034 Traning Loss: tensor(3.5206)\n",
      "1035 Traning Loss: tensor(3.5196)\n",
      "1036 Traning Loss: tensor(3.5186)\n",
      "1037 Traning Loss: tensor(3.5176)\n",
      "1038 Traning Loss: tensor(3.5165)\n",
      "1039 Traning Loss: tensor(3.5155)\n",
      "1040 Traning Loss: tensor(3.5145)\n",
      "1041 Traning Loss: tensor(3.5135)\n",
      "1042 Traning Loss: tensor(3.5125)\n",
      "1043 Traning Loss: tensor(3.5115)\n",
      "1044 Traning Loss: tensor(3.5105)\n",
      "1045 Traning Loss: tensor(3.5096)\n",
      "1046 Traning Loss: tensor(3.5086)\n",
      "1047 Traning Loss: tensor(3.5076)\n",
      "1048 Traning Loss: tensor(3.5066)\n",
      "1049 Traning Loss: tensor(3.5057)\n",
      "1050 Traning Loss: tensor(3.5047)\n",
      "1051 Traning Loss: tensor(3.5038)\n",
      "1052 Traning Loss: tensor(3.5028)\n",
      "1053 Traning Loss: tensor(3.5019)\n",
      "1054 Traning Loss: tensor(3.5010)\n",
      "1055 Traning Loss: tensor(3.5000)\n",
      "1056 Traning Loss: tensor(3.4991)\n",
      "1057 Traning Loss: tensor(3.4982)\n",
      "1058 Traning Loss: tensor(3.4973)\n",
      "1059 Traning Loss: tensor(3.4964)\n",
      "1060 Traning Loss: tensor(3.4955)\n",
      "1061 Traning Loss: tensor(3.4946)\n",
      "1062 Traning Loss: tensor(3.4937)\n",
      "1063 Traning Loss: tensor(3.4928)\n",
      "1064 Traning Loss: tensor(3.4919)\n",
      "1065 Traning Loss: tensor(3.4910)\n",
      "1066 Traning Loss: tensor(3.4901)\n",
      "1067 Traning Loss: tensor(3.4893)\n",
      "1068 Traning Loss: tensor(3.4884)\n",
      "1069 Traning Loss: tensor(3.4875)\n",
      "1070 Traning Loss: tensor(3.4867)\n",
      "1071 Traning Loss: tensor(3.4858)\n",
      "1072 Traning Loss: tensor(3.4850)\n",
      "1073 Traning Loss: tensor(3.4841)\n",
      "1074 Traning Loss: tensor(3.4833)\n",
      "1075 Traning Loss: tensor(3.4824)\n",
      "1076 Traning Loss: tensor(3.4816)\n",
      "1077 Traning Loss: tensor(3.4808)\n",
      "1078 Traning Loss: tensor(3.4800)\n",
      "1079 Traning Loss: tensor(3.4792)\n",
      "1080 Traning Loss: tensor(3.4783)\n",
      "1081 Traning Loss: tensor(3.4775)\n",
      "1082 Traning Loss: tensor(3.4767)\n",
      "1083 Traning Loss: tensor(3.4759)\n",
      "1084 Traning Loss: tensor(3.4751)\n",
      "1085 Traning Loss: tensor(3.4744)\n",
      "1086 Traning Loss: tensor(3.4736)\n",
      "1087 Traning Loss: tensor(3.4728)\n",
      "1088 Traning Loss: tensor(3.4720)\n",
      "1089 Traning Loss: tensor(3.4712)\n",
      "1090 Traning Loss: tensor(3.4705)\n",
      "1091 Traning Loss: tensor(3.4697)\n",
      "1092 Traning Loss: tensor(3.4689)\n",
      "1093 Traning Loss: tensor(3.4682)\n",
      "1094 Traning Loss: tensor(3.4674)\n",
      "1095 Traning Loss: tensor(3.4667)\n",
      "1096 Traning Loss: tensor(3.4660)\n",
      "1097 Traning Loss: tensor(3.4652)\n",
      "1098 Traning Loss: tensor(3.4645)\n",
      "1099 Traning Loss: tensor(3.4637)\n",
      "1100 Traning Loss: tensor(3.4630)\n",
      "1101 Traning Loss: tensor(3.4623)\n",
      "1102 Traning Loss: tensor(3.4616)\n",
      "1103 Traning Loss: tensor(3.4609)\n",
      "1104 Traning Loss: tensor(3.4602)\n",
      "1105 Traning Loss: tensor(3.4595)\n",
      "1106 Traning Loss: tensor(3.4587)\n",
      "1107 Traning Loss: tensor(3.4580)\n",
      "1108 Traning Loss: tensor(3.4574)\n",
      "1109 Traning Loss: tensor(3.4567)\n",
      "1110 Traning Loss: tensor(3.4560)\n",
      "1111 Traning Loss: tensor(3.4553)\n",
      "1112 Traning Loss: tensor(3.4546)\n",
      "1113 Traning Loss: tensor(3.4539)\n",
      "1114 Traning Loss: tensor(3.4533)\n",
      "1115 Traning Loss: tensor(3.4526)\n",
      "1116 Traning Loss: tensor(3.4519)\n",
      "1117 Traning Loss: tensor(3.4513)\n",
      "1118 Traning Loss: tensor(3.4506)\n",
      "1119 Traning Loss: tensor(3.4500)\n",
      "1120 Traning Loss: tensor(3.4493)\n",
      "1121 Traning Loss: tensor(3.4487)\n",
      "1122 Traning Loss: tensor(3.4480)\n",
      "1123 Traning Loss: tensor(3.4474)\n",
      "1124 Traning Loss: tensor(3.4468)\n",
      "1125 Traning Loss: tensor(3.4461)\n",
      "1126 Traning Loss: tensor(3.4455)\n",
      "1127 Traning Loss: tensor(3.4449)\n",
      "1128 Traning Loss: tensor(3.4443)\n",
      "1129 Traning Loss: tensor(3.4436)\n",
      "1130 Traning Loss: tensor(3.4430)\n",
      "1131 Traning Loss: tensor(3.4424)\n",
      "1132 Traning Loss: tensor(3.4418)\n",
      "1133 Traning Loss: tensor(3.4412)\n",
      "1134 Traning Loss: tensor(3.4406)\n",
      "1135 Traning Loss: tensor(3.4400)\n",
      "1136 Traning Loss: tensor(3.4394)\n",
      "1137 Traning Loss: tensor(3.4388)\n",
      "1138 Traning Loss: tensor(3.4383)\n",
      "1139 Traning Loss: tensor(3.4377)\n",
      "1140 Traning Loss: tensor(3.4371)\n",
      "1141 Traning Loss: tensor(3.4365)\n",
      "1142 Traning Loss: tensor(3.4359)\n",
      "1143 Traning Loss: tensor(3.4354)\n",
      "1144 Traning Loss: tensor(3.4348)\n",
      "1145 Traning Loss: tensor(3.4343)\n",
      "1146 Traning Loss: tensor(3.4337)\n",
      "1147 Traning Loss: tensor(3.4331)\n",
      "1148 Traning Loss: tensor(3.4326)\n",
      "1149 Traning Loss: tensor(3.4320)\n",
      "1150 Traning Loss: tensor(3.4315)\n",
      "1151 Traning Loss: tensor(3.4309)\n",
      "1152 Traning Loss: tensor(3.4304)\n",
      "1153 Traning Loss: tensor(3.4299)\n",
      "1154 Traning Loss: tensor(3.4293)\n",
      "1155 Traning Loss: tensor(3.4288)\n",
      "1156 Traning Loss: tensor(3.4283)\n",
      "1157 Traning Loss: tensor(3.4278)\n",
      "1158 Traning Loss: tensor(3.4272)\n",
      "1159 Traning Loss: tensor(3.4267)\n",
      "1160 Traning Loss: tensor(3.4262)\n",
      "1161 Traning Loss: tensor(3.4257)\n",
      "1162 Traning Loss: tensor(3.4252)\n",
      "1163 Traning Loss: tensor(3.4247)\n",
      "1164 Traning Loss: tensor(3.4242)\n",
      "1165 Traning Loss: tensor(3.4237)\n",
      "1166 Traning Loss: tensor(3.4232)\n",
      "1167 Traning Loss: tensor(3.4227)\n",
      "1168 Traning Loss: tensor(3.4222)\n",
      "1169 Traning Loss: tensor(3.4217)\n",
      "1170 Traning Loss: tensor(3.4212)\n",
      "1171 Traning Loss: tensor(3.4207)\n",
      "1172 Traning Loss: tensor(3.4203)\n",
      "1173 Traning Loss: tensor(3.4198)\n",
      "1174 Traning Loss: tensor(3.4193)\n",
      "1175 Traning Loss: tensor(3.4188)\n",
      "1176 Traning Loss: tensor(3.4184)\n",
      "1177 Traning Loss: tensor(3.4179)\n",
      "1178 Traning Loss: tensor(3.4174)\n",
      "1179 Traning Loss: tensor(3.4170)\n",
      "1180 Traning Loss: tensor(3.4165)\n",
      "1181 Traning Loss: tensor(3.4161)\n",
      "1182 Traning Loss: tensor(3.4156)\n",
      "1183 Traning Loss: tensor(3.4152)\n",
      "1184 Traning Loss: tensor(3.4147)\n",
      "1185 Traning Loss: tensor(3.4143)\n",
      "1186 Traning Loss: tensor(3.4138)\n",
      "1187 Traning Loss: tensor(3.4134)\n",
      "1188 Traning Loss: tensor(3.4130)\n",
      "1189 Traning Loss: tensor(3.4125)\n",
      "1190 Traning Loss: tensor(3.4121)\n",
      "1191 Traning Loss: tensor(3.4117)\n",
      "1192 Traning Loss: tensor(3.4113)\n",
      "1193 Traning Loss: tensor(3.4108)\n",
      "1194 Traning Loss: tensor(3.4104)\n",
      "1195 Traning Loss: tensor(3.4100)\n",
      "1196 Traning Loss: tensor(3.4096)\n",
      "1197 Traning Loss: tensor(3.4092)\n",
      "1198 Traning Loss: tensor(3.4088)\n",
      "1199 Traning Loss: tensor(3.4083)\n",
      "1200 Traning Loss: tensor(3.4079)\n",
      "1201 Traning Loss: tensor(3.4075)\n",
      "1202 Traning Loss: tensor(3.4071)\n",
      "1203 Traning Loss: tensor(3.4067)\n",
      "1204 Traning Loss: tensor(3.4063)\n",
      "1205 Traning Loss: tensor(3.4060)\n",
      "1206 Traning Loss: tensor(3.4056)\n",
      "1207 Traning Loss: tensor(3.4052)\n",
      "1208 Traning Loss: tensor(3.4048)\n",
      "1209 Traning Loss: tensor(3.4044)\n",
      "1210 Traning Loss: tensor(3.4040)\n",
      "1211 Traning Loss: tensor(3.4036)\n",
      "1212 Traning Loss: tensor(3.4033)\n",
      "1213 Traning Loss: tensor(3.4029)\n",
      "1214 Traning Loss: tensor(3.4025)\n",
      "1215 Traning Loss: tensor(3.4022)\n",
      "1216 Traning Loss: tensor(3.4018)\n",
      "1217 Traning Loss: tensor(3.4014)\n",
      "1218 Traning Loss: tensor(3.4011)\n",
      "1219 Traning Loss: tensor(3.4007)\n",
      "1220 Traning Loss: tensor(3.4003)\n",
      "1221 Traning Loss: tensor(3.4000)\n",
      "1222 Traning Loss: tensor(3.3996)\n",
      "1223 Traning Loss: tensor(3.3993)\n",
      "1224 Traning Loss: tensor(3.3989)\n",
      "1225 Traning Loss: tensor(3.3986)\n",
      "1226 Traning Loss: tensor(3.3982)\n",
      "1227 Traning Loss: tensor(3.3979)\n",
      "1228 Traning Loss: tensor(3.3976)\n",
      "1229 Traning Loss: tensor(3.3972)\n",
      "1230 Traning Loss: tensor(3.3969)\n",
      "1231 Traning Loss: tensor(3.3965)\n",
      "1232 Traning Loss: tensor(3.3962)\n",
      "1233 Traning Loss: tensor(3.3959)\n",
      "1234 Traning Loss: tensor(3.3956)\n",
      "1235 Traning Loss: tensor(3.3952)\n",
      "1236 Traning Loss: tensor(3.3949)\n",
      "1237 Traning Loss: tensor(3.3946)\n",
      "1238 Traning Loss: tensor(3.3943)\n",
      "1239 Traning Loss: tensor(3.3939)\n",
      "1240 Traning Loss: tensor(3.3936)\n",
      "1241 Traning Loss: tensor(3.3933)\n",
      "1242 Traning Loss: tensor(3.3930)\n",
      "1243 Traning Loss: tensor(3.3927)\n",
      "1244 Traning Loss: tensor(3.3924)\n",
      "1245 Traning Loss: tensor(3.3921)\n",
      "1246 Traning Loss: tensor(3.3918)\n",
      "1247 Traning Loss: tensor(3.3915)\n",
      "1248 Traning Loss: tensor(3.3912)\n",
      "1249 Traning Loss: tensor(3.3909)\n",
      "1250 Traning Loss: tensor(3.3906)\n",
      "1251 Traning Loss: tensor(3.3903)\n",
      "1252 Traning Loss: tensor(3.3900)\n",
      "1253 Traning Loss: tensor(3.3897)\n",
      "1254 Traning Loss: tensor(3.3894)\n",
      "1255 Traning Loss: tensor(3.3891)\n",
      "1256 Traning Loss: tensor(3.3888)\n",
      "1257 Traning Loss: tensor(3.3886)\n",
      "1258 Traning Loss: tensor(3.3883)\n",
      "1259 Traning Loss: tensor(3.3880)\n",
      "1260 Traning Loss: tensor(3.3877)\n",
      "1261 Traning Loss: tensor(3.3874)\n",
      "1262 Traning Loss: tensor(3.3872)\n",
      "1263 Traning Loss: tensor(3.3869)\n",
      "1264 Traning Loss: tensor(3.3866)\n",
      "1265 Traning Loss: tensor(3.3863)\n",
      "1266 Traning Loss: tensor(3.3861)\n",
      "1267 Traning Loss: tensor(3.3858)\n",
      "1268 Traning Loss: tensor(3.3855)\n",
      "1269 Traning Loss: tensor(3.3853)\n",
      "1270 Traning Loss: tensor(3.3850)\n",
      "1271 Traning Loss: tensor(3.3848)\n",
      "1272 Traning Loss: tensor(3.3845)\n",
      "1273 Traning Loss: tensor(3.3843)\n",
      "1274 Traning Loss: tensor(3.3840)\n",
      "1275 Traning Loss: tensor(3.3837)\n",
      "1276 Traning Loss: tensor(3.3835)\n",
      "1277 Traning Loss: tensor(3.3832)\n",
      "1278 Traning Loss: tensor(3.3830)\n",
      "1279 Traning Loss: tensor(3.3828)\n",
      "1280 Traning Loss: tensor(3.3825)\n",
      "1281 Traning Loss: tensor(3.3823)\n",
      "1282 Traning Loss: tensor(3.3820)\n",
      "1283 Traning Loss: tensor(3.3818)\n",
      "1284 Traning Loss: tensor(3.3815)\n",
      "1285 Traning Loss: tensor(3.3813)\n",
      "1286 Traning Loss: tensor(3.3811)\n",
      "1287 Traning Loss: tensor(3.3808)\n",
      "1288 Traning Loss: tensor(3.3806)\n",
      "1289 Traning Loss: tensor(3.3804)\n",
      "1290 Traning Loss: tensor(3.3801)\n",
      "1291 Traning Loss: tensor(3.3799)\n",
      "1292 Traning Loss: tensor(3.3797)\n",
      "1293 Traning Loss: tensor(3.3795)\n",
      "1294 Traning Loss: tensor(3.3792)\n",
      "1295 Traning Loss: tensor(3.3790)\n",
      "1296 Traning Loss: tensor(3.3788)\n",
      "1297 Traning Loss: tensor(3.3786)\n",
      "1298 Traning Loss: tensor(3.3784)\n",
      "1299 Traning Loss: tensor(3.3782)\n",
      "1300 Traning Loss: tensor(3.3779)\n",
      "1301 Traning Loss: tensor(3.3777)\n",
      "1302 Traning Loss: tensor(3.3775)\n",
      "1303 Traning Loss: tensor(3.3773)\n",
      "1304 Traning Loss: tensor(3.3771)\n",
      "1305 Traning Loss: tensor(3.3769)\n",
      "1306 Traning Loss: tensor(3.3767)\n",
      "1307 Traning Loss: tensor(3.3765)\n",
      "1308 Traning Loss: tensor(3.3763)\n",
      "1309 Traning Loss: tensor(3.3761)\n",
      "1310 Traning Loss: tensor(3.3759)\n",
      "1311 Traning Loss: tensor(3.3757)\n",
      "1312 Traning Loss: tensor(3.3755)\n",
      "1313 Traning Loss: tensor(3.3753)\n",
      "1314 Traning Loss: tensor(3.3751)\n",
      "1315 Traning Loss: tensor(3.3749)\n",
      "1316 Traning Loss: tensor(3.3747)\n",
      "1317 Traning Loss: tensor(3.3745)\n",
      "1318 Traning Loss: tensor(3.3743)\n",
      "1319 Traning Loss: tensor(3.3741)\n",
      "1320 Traning Loss: tensor(3.3739)\n",
      "1321 Traning Loss: tensor(3.3738)\n",
      "1322 Traning Loss: tensor(3.3736)\n",
      "1323 Traning Loss: tensor(3.3734)\n",
      "1324 Traning Loss: tensor(3.3732)\n",
      "1325 Traning Loss: tensor(3.3730)\n",
      "1326 Traning Loss: tensor(3.3728)\n",
      "1327 Traning Loss: tensor(3.3727)\n",
      "1328 Traning Loss: tensor(3.3725)\n",
      "1329 Traning Loss: tensor(3.3723)\n",
      "1330 Traning Loss: tensor(3.3721)\n",
      "1331 Traning Loss: tensor(3.3720)\n",
      "1332 Traning Loss: tensor(3.3718)\n",
      "1333 Traning Loss: tensor(3.3716)\n",
      "1334 Traning Loss: tensor(3.3714)\n",
      "1335 Traning Loss: tensor(3.3713)\n",
      "1336 Traning Loss: tensor(3.3711)\n",
      "1337 Traning Loss: tensor(3.3709)\n",
      "1338 Traning Loss: tensor(3.3708)\n",
      "1339 Traning Loss: tensor(3.3706)\n",
      "1340 Traning Loss: tensor(3.3704)\n",
      "1341 Traning Loss: tensor(3.3703)\n",
      "1342 Traning Loss: tensor(3.3701)\n",
      "1343 Traning Loss: tensor(3.3700)\n",
      "1344 Traning Loss: tensor(3.3698)\n",
      "1345 Traning Loss: tensor(3.3696)\n",
      "1346 Traning Loss: tensor(3.3695)\n",
      "1347 Traning Loss: tensor(3.3693)\n",
      "1348 Traning Loss: tensor(3.3692)\n",
      "1349 Traning Loss: tensor(3.3690)\n",
      "1350 Traning Loss: tensor(3.3689)\n",
      "1351 Traning Loss: tensor(3.3687)\n",
      "1352 Traning Loss: tensor(3.3686)\n",
      "1353 Traning Loss: tensor(3.3684)\n",
      "1354 Traning Loss: tensor(3.3683)\n",
      "1355 Traning Loss: tensor(3.3681)\n",
      "1356 Traning Loss: tensor(3.3680)\n",
      "1357 Traning Loss: tensor(3.3678)\n",
      "1358 Traning Loss: tensor(3.3677)\n",
      "1359 Traning Loss: tensor(3.3675)\n",
      "1360 Traning Loss: tensor(3.3674)\n",
      "1361 Traning Loss: tensor(3.3673)\n",
      "1362 Traning Loss: tensor(3.3671)\n",
      "1363 Traning Loss: tensor(3.3670)\n",
      "1364 Traning Loss: tensor(3.3668)\n",
      "1365 Traning Loss: tensor(3.3667)\n",
      "1366 Traning Loss: tensor(3.3666)\n",
      "1367 Traning Loss: tensor(3.3664)\n",
      "1368 Traning Loss: tensor(3.3663)\n",
      "1369 Traning Loss: tensor(3.3662)\n",
      "1370 Traning Loss: tensor(3.3660)\n",
      "1371 Traning Loss: tensor(3.3659)\n",
      "1372 Traning Loss: tensor(3.3658)\n",
      "1373 Traning Loss: tensor(3.3656)\n",
      "1374 Traning Loss: tensor(3.3655)\n",
      "1375 Traning Loss: tensor(3.3654)\n",
      "1376 Traning Loss: tensor(3.3652)\n",
      "1377 Traning Loss: tensor(3.3651)\n",
      "1378 Traning Loss: tensor(3.3650)\n",
      "1379 Traning Loss: tensor(3.3649)\n",
      "1380 Traning Loss: tensor(3.3647)\n",
      "1381 Traning Loss: tensor(3.3646)\n",
      "1382 Traning Loss: tensor(3.3645)\n",
      "1383 Traning Loss: tensor(3.3644)\n",
      "1384 Traning Loss: tensor(3.3643)\n",
      "1385 Traning Loss: tensor(3.3641)\n",
      "1386 Traning Loss: tensor(3.3640)\n",
      "1387 Traning Loss: tensor(3.3639)\n",
      "1388 Traning Loss: tensor(3.3638)\n",
      "1389 Traning Loss: tensor(3.3637)\n",
      "1390 Traning Loss: tensor(3.3636)\n",
      "1391 Traning Loss: tensor(3.3634)\n",
      "1392 Traning Loss: tensor(3.3633)\n",
      "1393 Traning Loss: tensor(3.3632)\n",
      "1394 Traning Loss: tensor(3.3631)\n",
      "1395 Traning Loss: tensor(3.3630)\n",
      "1396 Traning Loss: tensor(3.3629)\n",
      "1397 Traning Loss: tensor(3.3628)\n",
      "1398 Traning Loss: tensor(3.3627)\n",
      "1399 Traning Loss: tensor(3.3626)\n",
      "1400 Traning Loss: tensor(3.3624)\n",
      "1401 Traning Loss: tensor(3.3623)\n",
      "1402 Traning Loss: tensor(3.3622)\n",
      "1403 Traning Loss: tensor(3.3621)\n",
      "1404 Traning Loss: tensor(3.3620)\n",
      "1405 Traning Loss: tensor(3.3619)\n",
      "1406 Traning Loss: tensor(3.3618)\n",
      "1407 Traning Loss: tensor(3.3617)\n",
      "1408 Traning Loss: tensor(3.3616)\n",
      "1409 Traning Loss: tensor(3.3615)\n",
      "1410 Traning Loss: tensor(3.3614)\n",
      "1411 Traning Loss: tensor(3.3613)\n",
      "1412 Traning Loss: tensor(3.3612)\n",
      "1413 Traning Loss: tensor(3.3611)\n",
      "1414 Traning Loss: tensor(3.3610)\n",
      "1415 Traning Loss: tensor(3.3609)\n",
      "1416 Traning Loss: tensor(3.3608)\n",
      "1417 Traning Loss: tensor(3.3607)\n",
      "1418 Traning Loss: tensor(3.3606)\n",
      "1419 Traning Loss: tensor(3.3605)\n",
      "1420 Traning Loss: tensor(3.3605)\n",
      "1421 Traning Loss: tensor(3.3604)\n",
      "1422 Traning Loss: tensor(3.3603)\n",
      "1423 Traning Loss: tensor(3.3602)\n",
      "1424 Traning Loss: tensor(3.3601)\n",
      "1425 Traning Loss: tensor(3.3600)\n",
      "1426 Traning Loss: tensor(3.3599)\n",
      "1427 Traning Loss: tensor(3.3598)\n",
      "1428 Traning Loss: tensor(3.3597)\n",
      "1429 Traning Loss: tensor(3.3596)\n",
      "1430 Traning Loss: tensor(3.3596)\n",
      "1431 Traning Loss: tensor(3.3595)\n",
      "1432 Traning Loss: tensor(3.3594)\n",
      "1433 Traning Loss: tensor(3.3593)\n",
      "1434 Traning Loss: tensor(3.3592)\n",
      "1435 Traning Loss: tensor(3.3591)\n",
      "1436 Traning Loss: tensor(3.3591)\n",
      "1437 Traning Loss: tensor(3.3590)\n",
      "1438 Traning Loss: tensor(3.3589)\n",
      "1439 Traning Loss: tensor(3.3588)\n",
      "1440 Traning Loss: tensor(3.3587)\n",
      "1441 Traning Loss: tensor(3.3587)\n",
      "1442 Traning Loss: tensor(3.3586)\n",
      "1443 Traning Loss: tensor(3.3585)\n",
      "1444 Traning Loss: tensor(3.3584)\n",
      "1445 Traning Loss: tensor(3.3583)\n",
      "1446 Traning Loss: tensor(3.3583)\n",
      "1447 Traning Loss: tensor(3.3582)\n",
      "1448 Traning Loss: tensor(3.3581)\n",
      "1449 Traning Loss: tensor(3.3580)\n",
      "1450 Traning Loss: tensor(3.3580)\n",
      "1451 Traning Loss: tensor(3.3579)\n",
      "1452 Traning Loss: tensor(3.3578)\n",
      "1453 Traning Loss: tensor(3.3577)\n",
      "1454 Traning Loss: tensor(3.3577)\n",
      "1455 Traning Loss: tensor(3.3576)\n",
      "1456 Traning Loss: tensor(3.3575)\n",
      "1457 Traning Loss: tensor(3.3575)\n",
      "1458 Traning Loss: tensor(3.3574)\n",
      "1459 Traning Loss: tensor(3.3573)\n",
      "1460 Traning Loss: tensor(3.3573)\n",
      "1461 Traning Loss: tensor(3.3572)\n",
      "1462 Traning Loss: tensor(3.3571)\n",
      "1463 Traning Loss: tensor(3.3570)\n",
      "1464 Traning Loss: tensor(3.3570)\n",
      "1465 Traning Loss: tensor(3.3569)\n",
      "1466 Traning Loss: tensor(3.3568)\n",
      "1467 Traning Loss: tensor(3.3568)\n",
      "1468 Traning Loss: tensor(3.3567)\n",
      "1469 Traning Loss: tensor(3.3567)\n",
      "1470 Traning Loss: tensor(3.3566)\n",
      "1471 Traning Loss: tensor(3.3565)\n",
      "1472 Traning Loss: tensor(3.3565)\n",
      "1473 Traning Loss: tensor(3.3564)\n",
      "1474 Traning Loss: tensor(3.3563)\n",
      "1475 Traning Loss: tensor(3.3563)\n",
      "1476 Traning Loss: tensor(3.3562)\n",
      "1477 Traning Loss: tensor(3.3562)\n",
      "1478 Traning Loss: tensor(3.3561)\n",
      "1479 Traning Loss: tensor(3.3560)\n",
      "1480 Traning Loss: tensor(3.3560)\n",
      "1481 Traning Loss: tensor(3.3559)\n",
      "1482 Traning Loss: tensor(3.3559)\n",
      "1483 Traning Loss: tensor(3.3558)\n",
      "1484 Traning Loss: tensor(3.3557)\n",
      "1485 Traning Loss: tensor(3.3557)\n",
      "1486 Traning Loss: tensor(3.3556)\n",
      "1487 Traning Loss: tensor(3.3556)\n",
      "1488 Traning Loss: tensor(3.3555)\n",
      "1489 Traning Loss: tensor(3.3555)\n",
      "1490 Traning Loss: tensor(3.3554)\n",
      "1491 Traning Loss: tensor(3.3554)\n",
      "1492 Traning Loss: tensor(3.3553)\n",
      "1493 Traning Loss: tensor(3.3552)\n",
      "1494 Traning Loss: tensor(3.3552)\n",
      "1495 Traning Loss: tensor(3.3551)\n",
      "1496 Traning Loss: tensor(3.3551)\n",
      "1497 Traning Loss: tensor(3.3550)\n",
      "1498 Traning Loss: tensor(3.3550)\n",
      "1499 Traning Loss: tensor(3.3549)\n",
      "1500 Traning Loss: tensor(3.3549)\n",
      "1501 Traning Loss: tensor(3.3548)\n",
      "1502 Traning Loss: tensor(3.3548)\n",
      "1503 Traning Loss: tensor(3.3547)\n",
      "1504 Traning Loss: tensor(3.3547)\n",
      "1505 Traning Loss: tensor(3.3546)\n",
      "1506 Traning Loss: tensor(3.3546)\n",
      "1507 Traning Loss: tensor(3.3545)\n",
      "1508 Traning Loss: tensor(3.3545)\n",
      "1509 Traning Loss: tensor(3.3544)\n",
      "1510 Traning Loss: tensor(3.3544)\n",
      "1511 Traning Loss: tensor(3.3544)\n",
      "1512 Traning Loss: tensor(3.3543)\n",
      "1513 Traning Loss: tensor(3.3543)\n",
      "1514 Traning Loss: tensor(3.3542)\n",
      "1515 Traning Loss: tensor(3.3542)\n",
      "1516 Traning Loss: tensor(3.3541)\n",
      "1517 Traning Loss: tensor(3.3541)\n",
      "1518 Traning Loss: tensor(3.3540)\n",
      "1519 Traning Loss: tensor(3.3540)\n",
      "1520 Traning Loss: tensor(3.3539)\n",
      "1521 Traning Loss: tensor(3.3539)\n",
      "1522 Traning Loss: tensor(3.3539)\n",
      "1523 Traning Loss: tensor(3.3538)\n",
      "1524 Traning Loss: tensor(3.3538)\n",
      "1525 Traning Loss: tensor(3.3537)\n",
      "1526 Traning Loss: tensor(3.3537)\n",
      "1527 Traning Loss: tensor(3.3537)\n",
      "1528 Traning Loss: tensor(3.3536)\n",
      "1529 Traning Loss: tensor(3.3536)\n",
      "1530 Traning Loss: tensor(3.3535)\n",
      "1531 Traning Loss: tensor(3.3535)\n",
      "1532 Traning Loss: tensor(3.3535)\n",
      "1533 Traning Loss: tensor(3.3534)\n",
      "1534 Traning Loss: tensor(3.3534)\n",
      "1535 Traning Loss: tensor(3.3533)\n",
      "1536 Traning Loss: tensor(3.3533)\n",
      "1537 Traning Loss: tensor(3.3533)\n",
      "1538 Traning Loss: tensor(3.3532)\n",
      "1539 Traning Loss: tensor(3.3532)\n",
      "1540 Traning Loss: tensor(3.3532)\n",
      "1541 Traning Loss: tensor(3.3531)\n",
      "1542 Traning Loss: tensor(3.3531)\n",
      "1543 Traning Loss: tensor(3.3530)\n",
      "1544 Traning Loss: tensor(3.3530)\n",
      "1545 Traning Loss: tensor(3.3530)\n",
      "1546 Traning Loss: tensor(3.3529)\n",
      "1547 Traning Loss: tensor(3.3529)\n",
      "1548 Traning Loss: tensor(3.3529)\n",
      "1549 Traning Loss: tensor(3.3528)\n",
      "1550 Traning Loss: tensor(3.3528)\n",
      "1551 Traning Loss: tensor(3.3528)\n",
      "1552 Traning Loss: tensor(3.3527)\n",
      "1553 Traning Loss: tensor(3.3527)\n",
      "1554 Traning Loss: tensor(3.3527)\n",
      "1555 Traning Loss: tensor(3.3526)\n",
      "1556 Traning Loss: tensor(3.3526)\n",
      "1557 Traning Loss: tensor(3.3526)\n",
      "1558 Traning Loss: tensor(3.3525)\n",
      "1559 Traning Loss: tensor(3.3525)\n",
      "1560 Traning Loss: tensor(3.3525)\n",
      "1561 Traning Loss: tensor(3.3524)\n",
      "1562 Traning Loss: tensor(3.3524)\n",
      "1563 Traning Loss: tensor(3.3524)\n",
      "1564 Traning Loss: tensor(3.3523)\n",
      "1565 Traning Loss: tensor(3.3523)\n",
      "1566 Traning Loss: tensor(3.3523)\n",
      "1567 Traning Loss: tensor(3.3523)\n",
      "1568 Traning Loss: tensor(3.3522)\n",
      "1569 Traning Loss: tensor(3.3522)\n",
      "1570 Traning Loss: tensor(3.3522)\n",
      "1571 Traning Loss: tensor(3.3521)\n",
      "1572 Traning Loss: tensor(3.3521)\n",
      "1573 Traning Loss: tensor(3.3521)\n",
      "1574 Traning Loss: tensor(3.3521)\n",
      "1575 Traning Loss: tensor(3.3520)\n",
      "1576 Traning Loss: tensor(3.3520)\n",
      "1577 Traning Loss: tensor(3.3520)\n",
      "1578 Traning Loss: tensor(3.3519)\n",
      "1579 Traning Loss: tensor(3.3519)\n",
      "1580 Traning Loss: tensor(3.3519)\n",
      "1581 Traning Loss: tensor(3.3519)\n",
      "1582 Traning Loss: tensor(3.3518)\n",
      "1583 Traning Loss: tensor(3.3518)\n",
      "1584 Traning Loss: tensor(3.3518)\n",
      "1585 Traning Loss: tensor(3.3518)\n",
      "1586 Traning Loss: tensor(3.3517)\n",
      "1587 Traning Loss: tensor(3.3517)\n",
      "1588 Traning Loss: tensor(3.3517)\n",
      "1589 Traning Loss: tensor(3.3517)\n",
      "1590 Traning Loss: tensor(3.3516)\n",
      "1591 Traning Loss: tensor(3.3516)\n",
      "1592 Traning Loss: tensor(3.3516)\n",
      "1593 Traning Loss: tensor(3.3516)\n",
      "1594 Traning Loss: tensor(3.3515)\n",
      "1595 Traning Loss: tensor(3.3515)\n",
      "1596 Traning Loss: tensor(3.3515)\n",
      "1597 Traning Loss: tensor(3.3515)\n",
      "1598 Traning Loss: tensor(3.3515)\n",
      "1599 Traning Loss: tensor(3.3514)\n",
      "1600 Traning Loss: tensor(3.3514)\n",
      "1601 Traning Loss: tensor(3.3514)\n",
      "1602 Traning Loss: tensor(3.3514)\n",
      "1603 Traning Loss: tensor(3.3513)\n",
      "1604 Traning Loss: tensor(3.3513)\n",
      "1605 Traning Loss: tensor(3.3513)\n",
      "1606 Traning Loss: tensor(3.3513)\n",
      "1607 Traning Loss: tensor(3.3513)\n",
      "1608 Traning Loss: tensor(3.3512)\n",
      "1609 Traning Loss: tensor(3.3512)\n",
      "1610 Traning Loss: tensor(3.3512)\n",
      "1611 Traning Loss: tensor(3.3512)\n",
      "1612 Traning Loss: tensor(3.3511)\n",
      "1613 Traning Loss: tensor(3.3511)\n",
      "1614 Traning Loss: tensor(3.3511)\n",
      "1615 Traning Loss: tensor(3.3511)\n",
      "1616 Traning Loss: tensor(3.3511)\n",
      "1617 Traning Loss: tensor(3.3510)\n",
      "1618 Traning Loss: tensor(3.3510)\n",
      "1619 Traning Loss: tensor(3.3510)\n",
      "1620 Traning Loss: tensor(3.3510)\n",
      "1621 Traning Loss: tensor(3.3510)\n",
      "1622 Traning Loss: tensor(3.3510)\n",
      "1623 Traning Loss: tensor(3.3509)\n",
      "1624 Traning Loss: tensor(3.3509)\n",
      "1625 Traning Loss: tensor(3.3509)\n",
      "1626 Traning Loss: tensor(3.3509)\n",
      "1627 Traning Loss: tensor(3.3509)\n",
      "1628 Traning Loss: tensor(3.3508)\n",
      "1629 Traning Loss: tensor(3.3508)\n",
      "1630 Traning Loss: tensor(3.3508)\n",
      "1631 Traning Loss: tensor(3.3508)\n",
      "1632 Traning Loss: tensor(3.3508)\n",
      "1633 Traning Loss: tensor(3.3508)\n",
      "1634 Traning Loss: tensor(3.3507)\n",
      "1635 Traning Loss: tensor(3.3507)\n",
      "1636 Traning Loss: tensor(3.3507)\n",
      "1637 Traning Loss: tensor(3.3507)\n",
      "1638 Traning Loss: tensor(3.3507)\n",
      "1639 Traning Loss: tensor(3.3507)\n",
      "1640 Traning Loss: tensor(3.3506)\n",
      "1641 Traning Loss: tensor(3.3506)\n",
      "1642 Traning Loss: tensor(3.3506)\n",
      "1643 Traning Loss: tensor(3.3506)\n",
      "1644 Traning Loss: tensor(3.3506)\n",
      "1645 Traning Loss: tensor(3.3506)\n",
      "1646 Traning Loss: tensor(3.3505)\n",
      "1647 Traning Loss: tensor(3.3505)\n",
      "1648 Traning Loss: tensor(3.3505)\n",
      "1649 Traning Loss: tensor(3.3505)\n",
      "1650 Traning Loss: tensor(3.3505)\n",
      "1651 Traning Loss: tensor(3.3505)\n",
      "1652 Traning Loss: tensor(3.3505)\n",
      "1653 Traning Loss: tensor(3.3504)\n",
      "1654 Traning Loss: tensor(3.3504)\n",
      "1655 Traning Loss: tensor(3.3504)\n",
      "1656 Traning Loss: tensor(3.3504)\n",
      "1657 Traning Loss: tensor(3.3504)\n",
      "1658 Traning Loss: tensor(3.3504)\n",
      "1659 Traning Loss: tensor(3.3504)\n",
      "1660 Traning Loss: tensor(3.3504)\n",
      "1661 Traning Loss: tensor(3.3503)\n",
      "1662 Traning Loss: tensor(3.3503)\n",
      "1663 Traning Loss: tensor(3.3503)\n",
      "1664 Traning Loss: tensor(3.3503)\n",
      "1665 Traning Loss: tensor(3.3503)\n",
      "1666 Traning Loss: tensor(3.3503)\n",
      "1667 Traning Loss: tensor(3.3503)\n",
      "1668 Traning Loss: tensor(3.3502)\n",
      "1669 Traning Loss: tensor(3.3502)\n",
      "1670 Traning Loss: tensor(3.3502)\n",
      "1671 Traning Loss: tensor(3.3502)\n",
      "1672 Traning Loss: tensor(3.3502)\n",
      "1673 Traning Loss: tensor(3.3502)\n",
      "1674 Traning Loss: tensor(3.3502)\n",
      "1675 Traning Loss: tensor(3.3502)\n",
      "1676 Traning Loss: tensor(3.3502)\n",
      "1677 Traning Loss: tensor(3.3501)\n",
      "1678 Traning Loss: tensor(3.3501)\n",
      "1679 Traning Loss: tensor(3.3501)\n",
      "1680 Traning Loss: tensor(3.3501)\n",
      "1681 Traning Loss: tensor(3.3501)\n",
      "1682 Traning Loss: tensor(3.3501)\n",
      "1683 Traning Loss: tensor(3.3501)\n",
      "1684 Traning Loss: tensor(3.3501)\n",
      "1685 Traning Loss: tensor(3.3500)\n",
      "1686 Traning Loss: tensor(3.3500)\n",
      "1687 Traning Loss: tensor(3.3500)\n",
      "1688 Traning Loss: tensor(3.3500)\n",
      "1689 Traning Loss: tensor(3.3500)\n",
      "1690 Traning Loss: tensor(3.3500)\n",
      "1691 Traning Loss: tensor(3.3500)\n",
      "1692 Traning Loss: tensor(3.3500)\n",
      "1693 Traning Loss: tensor(3.3500)\n",
      "1694 Traning Loss: tensor(3.3500)\n",
      "1695 Traning Loss: tensor(3.3499)\n",
      "1696 Traning Loss: tensor(3.3499)\n",
      "1697 Traning Loss: tensor(3.3499)\n",
      "1698 Traning Loss: tensor(3.3499)\n",
      "1699 Traning Loss: tensor(3.3499)\n",
      "1700 Traning Loss: tensor(3.3499)\n",
      "1701 Traning Loss: tensor(3.3499)\n",
      "1702 Traning Loss: tensor(3.3499)\n",
      "1703 Traning Loss: tensor(3.3499)\n",
      "1704 Traning Loss: tensor(3.3499)\n",
      "1705 Traning Loss: tensor(3.3499)\n",
      "1706 Traning Loss: tensor(3.3498)\n",
      "1707 Traning Loss: tensor(3.3498)\n",
      "1708 Traning Loss: tensor(3.3498)\n",
      "1709 Traning Loss: tensor(3.3498)\n",
      "1710 Traning Loss: tensor(3.3498)\n",
      "1711 Traning Loss: tensor(3.3498)\n",
      "1712 Traning Loss: tensor(3.3498)\n",
      "1713 Traning Loss: tensor(3.3498)\n",
      "1714 Traning Loss: tensor(3.3498)\n",
      "1715 Traning Loss: tensor(3.3498)\n",
      "1716 Traning Loss: tensor(3.3498)\n",
      "1717 Traning Loss: tensor(3.3498)\n",
      "1718 Traning Loss: tensor(3.3497)\n",
      "1719 Traning Loss: tensor(3.3497)\n",
      "1720 Traning Loss: tensor(3.3497)\n",
      "1721 Traning Loss: tensor(3.3497)\n",
      "1722 Traning Loss: tensor(3.3497)\n",
      "1723 Traning Loss: tensor(3.3497)\n",
      "1724 Traning Loss: tensor(3.3497)\n",
      "1725 Traning Loss: tensor(3.3497)\n",
      "1726 Traning Loss: tensor(3.3497)\n",
      "1727 Traning Loss: tensor(3.3497)\n",
      "1728 Traning Loss: tensor(3.3497)\n",
      "1729 Traning Loss: tensor(3.3497)\n",
      "1730 Traning Loss: tensor(3.3497)\n",
      "1731 Traning Loss: tensor(3.3496)\n",
      "1732 Traning Loss: tensor(3.3496)\n",
      "1733 Traning Loss: tensor(3.3496)\n",
      "1734 Traning Loss: tensor(3.3496)\n",
      "1735 Traning Loss: tensor(3.3496)\n",
      "1736 Traning Loss: tensor(3.3496)\n",
      "1737 Traning Loss: tensor(3.3496)\n",
      "1738 Traning Loss: tensor(3.3496)\n",
      "1739 Traning Loss: tensor(3.3496)\n",
      "1740 Traning Loss: tensor(3.3496)\n",
      "1741 Traning Loss: tensor(3.3496)\n",
      "1742 Traning Loss: tensor(3.3496)\n",
      "1743 Traning Loss: tensor(3.3496)\n",
      "1744 Traning Loss: tensor(3.3496)\n",
      "1745 Traning Loss: tensor(3.3496)\n",
      "1746 Traning Loss: tensor(3.3495)\n",
      "1747 Traning Loss: tensor(3.3495)\n",
      "1748 Traning Loss: tensor(3.3495)\n",
      "1749 Traning Loss: tensor(3.3495)\n",
      "1750 Traning Loss: tensor(3.3495)\n",
      "1751 Traning Loss: tensor(3.3495)\n",
      "1752 Traning Loss: tensor(3.3495)\n",
      "1753 Traning Loss: tensor(3.3495)\n",
      "1754 Traning Loss: tensor(3.3495)\n",
      "1755 Traning Loss: tensor(3.3495)\n",
      "1756 Traning Loss: tensor(3.3495)\n",
      "1757 Traning Loss: tensor(3.3495)\n",
      "1758 Traning Loss: tensor(3.3495)\n",
      "1759 Traning Loss: tensor(3.3495)\n",
      "1760 Traning Loss: tensor(3.3495)\n",
      "1761 Traning Loss: tensor(3.3495)\n",
      "1762 Traning Loss: tensor(3.3495)\n",
      "1763 Traning Loss: tensor(3.3494)\n",
      "1764 Traning Loss: tensor(3.3494)\n",
      "1765 Traning Loss: tensor(3.3494)\n",
      "1766 Traning Loss: tensor(3.3494)\n",
      "1767 Traning Loss: tensor(3.3494)\n",
      "1768 Traning Loss: tensor(3.3494)\n",
      "1769 Traning Loss: tensor(3.3494)\n",
      "1770 Traning Loss: tensor(3.3494)\n",
      "1771 Traning Loss: tensor(3.3494)\n",
      "1772 Traning Loss: tensor(3.3494)\n",
      "1773 Traning Loss: tensor(3.3494)\n",
      "1774 Traning Loss: tensor(3.3494)\n",
      "1775 Traning Loss: tensor(3.3494)\n",
      "1776 Traning Loss: tensor(3.3494)\n",
      "1777 Traning Loss: tensor(3.3494)\n",
      "1778 Traning Loss: tensor(3.3494)\n",
      "1779 Traning Loss: tensor(3.3494)\n",
      "1780 Traning Loss: tensor(3.3494)\n",
      "1781 Traning Loss: tensor(3.3494)\n",
      "1782 Traning Loss: tensor(3.3494)\n",
      "1783 Traning Loss: tensor(3.3494)\n",
      "1784 Traning Loss: tensor(3.3494)\n",
      "1785 Traning Loss: tensor(3.3493)\n",
      "1786 Traning Loss: tensor(3.3493)\n",
      "1787 Traning Loss: tensor(3.3493)\n",
      "1788 Traning Loss: tensor(3.3493)\n",
      "1789 Traning Loss: tensor(3.3493)\n",
      "1790 Traning Loss: tensor(3.3493)\n",
      "1791 Traning Loss: tensor(3.3493)\n",
      "1792 Traning Loss: tensor(3.3493)\n",
      "1793 Traning Loss: tensor(3.3493)\n",
      "1794 Traning Loss: tensor(3.3493)\n",
      "1795 Traning Loss: tensor(3.3493)\n",
      "1796 Traning Loss: tensor(3.3493)\n",
      "1797 Traning Loss: tensor(3.3493)\n",
      "1798 Traning Loss: tensor(3.3493)\n",
      "1799 Traning Loss: tensor(3.3493)\n",
      "1800 Traning Loss: tensor(3.3493)\n",
      "1801 Traning Loss: tensor(3.3493)\n",
      "1802 Traning Loss: tensor(3.3493)\n",
      "1803 Traning Loss: tensor(3.3493)\n",
      "1804 Traning Loss: tensor(3.3493)\n",
      "1805 Traning Loss: tensor(3.3493)\n",
      "1806 Traning Loss: tensor(3.3493)\n",
      "1807 Traning Loss: tensor(3.3493)\n",
      "1808 Traning Loss: tensor(3.3493)\n",
      "1809 Traning Loss: tensor(3.3493)\n",
      "1810 Traning Loss: tensor(3.3493)\n",
      "1811 Traning Loss: tensor(3.3492)\n",
      "1812 Traning Loss: tensor(3.3492)\n",
      "1813 Traning Loss: tensor(3.3492)\n",
      "1814 Traning Loss: tensor(3.3492)\n",
      "1815 Traning Loss: tensor(3.3492)\n",
      "1816 Traning Loss: tensor(3.3492)\n",
      "1817 Traning Loss: tensor(3.3492)\n",
      "1818 Traning Loss: tensor(3.3492)\n",
      "1819 Traning Loss: tensor(3.3492)\n",
      "1820 Traning Loss: tensor(3.3492)\n",
      "1821 Traning Loss: tensor(3.3492)\n",
      "1822 Traning Loss: tensor(3.3492)\n",
      "1823 Traning Loss: tensor(3.3492)\n",
      "1824 Traning Loss: tensor(3.3492)\n",
      "1825 Traning Loss: tensor(3.3492)\n",
      "1826 Traning Loss: tensor(3.3492)\n",
      "1827 Traning Loss: tensor(3.3492)\n",
      "1828 Traning Loss: tensor(3.3492)\n",
      "1829 Traning Loss: tensor(3.3492)\n",
      "1830 Traning Loss: tensor(3.3492)\n",
      "1831 Traning Loss: tensor(3.3492)\n",
      "1832 Traning Loss: tensor(3.3492)\n",
      "1833 Traning Loss: tensor(3.3492)\n",
      "1834 Traning Loss: tensor(3.3492)\n",
      "1835 Traning Loss: tensor(3.3492)\n",
      "1836 Traning Loss: tensor(3.3492)\n",
      "1837 Traning Loss: tensor(3.3492)\n",
      "1838 Traning Loss: tensor(3.3492)\n",
      "1839 Traning Loss: tensor(3.3492)\n",
      "1840 Traning Loss: tensor(3.3492)\n",
      "1841 Traning Loss: tensor(3.3492)\n",
      "1842 Traning Loss: tensor(3.3492)\n",
      "1843 Traning Loss: tensor(3.3492)\n",
      "1844 Traning Loss: tensor(3.3492)\n",
      "1845 Traning Loss: tensor(3.3492)\n",
      "1846 Traning Loss: tensor(3.3492)\n",
      "1847 Traning Loss: tensor(3.3491)\n",
      "1848 Traning Loss: tensor(3.3491)\n",
      "1849 Traning Loss: tensor(3.3491)\n",
      "1850 Traning Loss: tensor(3.3491)\n",
      "1851 Traning Loss: tensor(3.3491)\n",
      "1852 Traning Loss: tensor(3.3491)\n",
      "1853 Traning Loss: tensor(3.3491)\n",
      "1854 Traning Loss: tensor(3.3491)\n",
      "1855 Traning Loss: tensor(3.3491)\n",
      "1856 Traning Loss: tensor(3.3491)\n",
      "1857 Traning Loss: tensor(3.3491)\n",
      "1858 Traning Loss: tensor(3.3491)\n",
      "1859 Traning Loss: tensor(3.3491)\n",
      "1860 Traning Loss: tensor(3.3491)\n",
      "1861 Traning Loss: tensor(3.3491)\n",
      "1862 Traning Loss: tensor(3.3491)\n",
      "1863 Traning Loss: tensor(3.3491)\n",
      "1864 Traning Loss: tensor(3.3491)\n",
      "1865 Traning Loss: tensor(3.3491)\n",
      "1866 Traning Loss: tensor(3.3491)\n",
      "1867 Traning Loss: tensor(3.3491)\n",
      "1868 Traning Loss: tensor(3.3491)\n",
      "1869 Traning Loss: tensor(3.3491)\n",
      "1870 Traning Loss: tensor(3.3491)\n",
      "1871 Traning Loss: tensor(3.3491)\n",
      "1872 Traning Loss: tensor(3.3491)\n",
      "1873 Traning Loss: tensor(3.3491)\n",
      "1874 Traning Loss: tensor(3.3491)\n",
      "1875 Traning Loss: tensor(3.3491)\n",
      "1876 Traning Loss: tensor(3.3491)\n",
      "1877 Traning Loss: tensor(3.3491)\n",
      "1878 Traning Loss: tensor(3.3491)\n",
      "1879 Traning Loss: tensor(3.3491)\n",
      "1880 Traning Loss: tensor(3.3491)\n",
      "1881 Traning Loss: tensor(3.3491)\n",
      "1882 Traning Loss: tensor(3.3491)\n",
      "1883 Traning Loss: tensor(3.3491)\n",
      "1884 Traning Loss: tensor(3.3491)\n",
      "1885 Traning Loss: tensor(3.3491)\n",
      "1886 Traning Loss: tensor(3.3491)\n",
      "1887 Traning Loss: tensor(3.3491)\n",
      "1888 Traning Loss: tensor(3.3491)\n",
      "1889 Traning Loss: tensor(3.3491)\n",
      "1890 Traning Loss: tensor(3.3491)\n",
      "1891 Traning Loss: tensor(3.3491)\n",
      "1892 Traning Loss: tensor(3.3491)\n",
      "1893 Traning Loss: tensor(3.3491)\n",
      "1894 Traning Loss: tensor(3.3491)\n",
      "1895 Traning Loss: tensor(3.3491)\n",
      "1896 Traning Loss: tensor(3.3491)\n",
      "1897 Traning Loss: tensor(3.3491)\n",
      "1898 Traning Loss: tensor(3.3491)\n",
      "1899 Traning Loss: tensor(3.3491)\n",
      "1900 Traning Loss: tensor(3.3491)\n",
      "1901 Traning Loss: tensor(3.3491)\n",
      "1902 Traning Loss: tensor(3.3491)\n",
      "1903 Traning Loss: tensor(3.3490)\n",
      "1904 Traning Loss: tensor(3.3490)\n",
      "1905 Traning Loss: tensor(3.3490)\n",
      "1906 Traning Loss: tensor(3.3490)\n",
      "1907 Traning Loss: tensor(3.3490)\n",
      "1908 Traning Loss: tensor(3.3490)\n",
      "1909 Traning Loss: tensor(3.3490)\n",
      "1910 Traning Loss: tensor(3.3490)\n",
      "1911 Traning Loss: tensor(3.3490)\n",
      "1912 Traning Loss: tensor(3.3490)\n",
      "1913 Traning Loss: tensor(3.3490)\n",
      "1914 Traning Loss: tensor(3.3490)\n",
      "1915 Traning Loss: tensor(3.3490)\n",
      "1916 Traning Loss: tensor(3.3490)\n",
      "1917 Traning Loss: tensor(3.3490)\n",
      "1918 Traning Loss: tensor(3.3490)\n",
      "1919 Traning Loss: tensor(3.3490)\n",
      "1920 Traning Loss: tensor(3.3490)\n",
      "1921 Traning Loss: tensor(3.3490)\n",
      "1922 Traning Loss: tensor(3.3490)\n",
      "1923 Traning Loss: tensor(3.3490)\n",
      "1924 Traning Loss: tensor(3.3490)\n",
      "1925 Traning Loss: tensor(3.3490)\n",
      "1926 Traning Loss: tensor(3.3490)\n",
      "1927 Traning Loss: tensor(3.3490)\n",
      "1928 Traning Loss: tensor(3.3490)\n",
      "1929 Traning Loss: tensor(3.3490)\n",
      "1930 Traning Loss: tensor(3.3490)\n",
      "1931 Traning Loss: tensor(3.3490)\n",
      "1932 Traning Loss: tensor(3.3490)\n",
      "1933 Traning Loss: tensor(3.3490)\n",
      "1934 Traning Loss: tensor(3.3490)\n",
      "1935 Traning Loss: tensor(3.3490)\n",
      "1936 Traning Loss: tensor(3.3490)\n",
      "1937 Traning Loss: tensor(3.3490)\n",
      "1938 Traning Loss: tensor(3.3490)\n",
      "1939 Traning Loss: tensor(3.3490)\n",
      "1940 Traning Loss: tensor(3.3490)\n",
      "1941 Traning Loss: tensor(3.3490)\n",
      "1942 Traning Loss: tensor(3.3490)\n",
      "1943 Traning Loss: tensor(3.3490)\n",
      "1944 Traning Loss: tensor(3.3490)\n",
      "1945 Traning Loss: tensor(3.3490)\n",
      "1946 Traning Loss: tensor(3.3490)\n",
      "1947 Traning Loss: tensor(3.3490)\n",
      "1948 Traning Loss: tensor(3.3490)\n",
      "1949 Traning Loss: tensor(3.3490)\n",
      "1950 Traning Loss: tensor(3.3490)\n",
      "1951 Traning Loss: tensor(3.3490)\n",
      "1952 Traning Loss: tensor(3.3490)\n",
      "1953 Traning Loss: tensor(3.3490)\n",
      "1954 Traning Loss: tensor(3.3490)\n",
      "1955 Traning Loss: tensor(3.3490)\n",
      "1956 Traning Loss: tensor(3.3490)\n",
      "1957 Traning Loss: tensor(3.3490)\n",
      "1958 Traning Loss: tensor(3.3490)\n",
      "1959 Traning Loss: tensor(3.3490)\n",
      "1960 Traning Loss: tensor(3.3490)\n",
      "1961 Traning Loss: tensor(3.3490)\n",
      "1962 Traning Loss: tensor(3.3490)\n",
      "1963 Traning Loss: tensor(3.3490)\n",
      "1964 Traning Loss: tensor(3.3490)\n",
      "1965 Traning Loss: tensor(3.3490)\n",
      "1966 Traning Loss: tensor(3.3490)\n",
      "1967 Traning Loss: tensor(3.3490)\n",
      "1968 Traning Loss: tensor(3.3490)\n",
      "1969 Traning Loss: tensor(3.3490)\n",
      "1970 Traning Loss: tensor(3.3490)\n",
      "1971 Traning Loss: tensor(3.3490)\n",
      "1972 Traning Loss: tensor(3.3490)\n",
      "1973 Traning Loss: tensor(3.3490)\n",
      "1974 Traning Loss: tensor(3.3490)\n",
      "1975 Traning Loss: tensor(3.3490)\n",
      "1976 Traning Loss: tensor(3.3490)\n",
      "1977 Traning Loss: tensor(3.3490)\n",
      "1978 Traning Loss: tensor(3.3490)\n",
      "1979 Traning Loss: tensor(3.3490)\n",
      "1980 Traning Loss: tensor(3.3490)\n",
      "1981 Traning Loss: tensor(3.3490)\n",
      "1982 Traning Loss: tensor(3.3490)\n",
      "1983 Traning Loss: tensor(3.3490)\n",
      "1984 Traning Loss: tensor(3.3490)\n",
      "1985 Traning Loss: tensor(3.3490)\n",
      "1986 Traning Loss: tensor(3.3490)\n",
      "1987 Traning Loss: tensor(3.3490)\n",
      "1988 Traning Loss: tensor(3.3490)\n",
      "1989 Traning Loss: tensor(3.3490)\n",
      "1990 Traning Loss: tensor(3.3490)\n",
      "1991 Traning Loss: tensor(3.3490)\n",
      "1992 Traning Loss: tensor(3.3490)\n",
      "1993 Traning Loss: tensor(3.3490)\n",
      "1994 Traning Loss: tensor(3.3490)\n",
      "1995 Traning Loss: tensor(3.3490)\n",
      "1996 Traning Loss: tensor(3.3490)\n",
      "1997 Traning Loss: tensor(3.3490)\n",
      "1998 Traning Loss: tensor(3.3490)\n",
      "1999 Traning Loss: tensor(3.3490)\n",
      "2000 Traning Loss: tensor(3.3490)\n",
      "2001 Traning Loss: tensor(3.3490)\n",
      "2002 Traning Loss: tensor(3.3490)\n",
      "2003 Traning Loss: tensor(3.3490)\n",
      "2004 Traning Loss: tensor(3.3490)\n",
      "2005 Traning Loss: tensor(3.3490)\n",
      "2006 Traning Loss: tensor(3.3490)\n",
      "2007 Traning Loss: tensor(3.3490)\n",
      "2008 Traning Loss: tensor(3.3490)\n",
      "2009 Traning Loss: tensor(3.3490)\n",
      "2010 Traning Loss: tensor(3.3490)\n",
      "2011 Traning Loss: tensor(3.3490)\n",
      "2012 Traning Loss: tensor(3.3490)\n",
      "2013 Traning Loss: tensor(3.3490)\n",
      "2014 Traning Loss: tensor(3.3490)\n",
      "2015 Traning Loss: tensor(3.3490)\n",
      "2016 Traning Loss: tensor(3.3490)\n",
      "2017 Traning Loss: tensor(3.3490)\n",
      "2018 Traning Loss: tensor(3.3490)\n",
      "2019 Traning Loss: tensor(3.3490)\n",
      "2020 Traning Loss: tensor(3.3490)\n",
      "2021 Traning Loss: tensor(3.3490)\n",
      "2022 Traning Loss: tensor(3.3490)\n",
      "2023 Traning Loss: tensor(3.3490)\n",
      "2024 Traning Loss: tensor(3.3490)\n",
      "2025 Traning Loss: tensor(3.3490)\n",
      "2026 Traning Loss: tensor(3.3490)\n",
      "2027 Traning Loss: tensor(3.3490)\n",
      "2028 Traning Loss: tensor(3.3490)\n",
      "2029 Traning Loss: tensor(3.3490)\n",
      "2030 Traning Loss: tensor(3.3490)\n",
      "2031 Traning Loss: tensor(3.3490)\n",
      "2032 Traning Loss: tensor(3.3490)\n",
      "2033 Traning Loss: tensor(3.3490)\n",
      "2034 Traning Loss: tensor(3.3490)\n",
      "2035 Traning Loss: tensor(3.3490)\n",
      "2036 Traning Loss: tensor(3.3490)\n",
      "2037 Traning Loss: tensor(3.3490)\n",
      "2038 Traning Loss: tensor(3.3490)\n",
      "2039 Traning Loss: tensor(3.3490)\n",
      "2040 Traning Loss: tensor(3.3490)\n",
      "2041 Traning Loss: tensor(3.3490)\n",
      "2042 Traning Loss: tensor(3.3490)\n",
      "2043 Traning Loss: tensor(3.3490)\n",
      "2044 Traning Loss: tensor(3.3490)\n",
      "2045 Traning Loss: tensor(3.3490)\n",
      "2046 Traning Loss: tensor(3.3490)\n",
      "2047 Traning Loss: tensor(3.3490)\n",
      "2048 Traning Loss: tensor(3.3490)\n",
      "2049 Traning Loss: tensor(3.3490)\n",
      "2050 Traning Loss: tensor(3.3490)\n",
      "2051 Traning Loss: tensor(3.3490)\n",
      "2052 Traning Loss: tensor(3.3490)\n",
      "2053 Traning Loss: tensor(3.3490)\n",
      "2054 Traning Loss: tensor(3.3490)\n",
      "2055 Traning Loss: tensor(3.3490)\n",
      "2056 Traning Loss: tensor(3.3490)\n",
      "2057 Traning Loss: tensor(3.3490)\n",
      "2058 Traning Loss: tensor(3.3490)\n",
      "2059 Traning Loss: tensor(3.3490)\n",
      "2060 Traning Loss: tensor(3.3490)\n",
      "2061 Traning Loss: tensor(3.3490)\n",
      "2062 Traning Loss: tensor(3.3490)\n",
      "2063 Traning Loss: tensor(3.3490)\n",
      "2064 Traning Loss: tensor(3.3490)\n",
      "2065 Traning Loss: tensor(3.3490)\n",
      "2066 Traning Loss: tensor(3.3489)\n",
      "2067 Traning Loss: tensor(3.3489)\n",
      "2068 Traning Loss: tensor(3.3489)\n",
      "2069 Traning Loss: tensor(3.3489)\n",
      "2070 Traning Loss: tensor(3.3489)\n",
      "2071 Traning Loss: tensor(3.3489)\n",
      "2072 Traning Loss: tensor(3.3489)\n",
      "2073 Traning Loss: tensor(3.3489)\n",
      "2074 Traning Loss: tensor(3.3489)\n",
      "2075 Traning Loss: tensor(3.3489)\n",
      "2076 Traning Loss: tensor(3.3489)\n",
      "2077 Traning Loss: tensor(3.3489)\n",
      "2078 Traning Loss: tensor(3.3489)\n",
      "2079 Traning Loss: tensor(3.3489)\n",
      "2080 Traning Loss: tensor(3.3489)\n",
      "2081 Traning Loss: tensor(3.3489)\n",
      "2082 Traning Loss: tensor(3.3489)\n",
      "2083 Traning Loss: tensor(3.3489)\n",
      "2084 Traning Loss: tensor(3.3489)\n",
      "2085 Traning Loss: tensor(3.3489)\n",
      "2086 Traning Loss: tensor(3.3489)\n",
      "2087 Traning Loss: tensor(3.3489)\n",
      "2088 Traning Loss: tensor(3.3489)\n",
      "2089 Traning Loss: tensor(3.3489)\n",
      "2090 Traning Loss: tensor(3.3489)\n",
      "2091 Traning Loss: tensor(3.3489)\n",
      "2092 Traning Loss: tensor(3.3489)\n",
      "2093 Traning Loss: tensor(3.3489)\n",
      "2094 Traning Loss: tensor(3.3489)\n",
      "2095 Traning Loss: tensor(3.3489)\n",
      "2096 Traning Loss: tensor(3.3489)\n",
      "2097 Traning Loss: tensor(3.3489)\n",
      "2098 Traning Loss: tensor(3.3489)\n",
      "2099 Traning Loss: tensor(3.3489)\n",
      "2100 Traning Loss: tensor(3.3489)\n",
      "2101 Traning Loss: tensor(3.3489)\n",
      "2102 Traning Loss: tensor(3.3489)\n",
      "2103 Traning Loss: tensor(3.3489)\n",
      "2104 Traning Loss: tensor(3.3489)\n",
      "2105 Traning Loss: tensor(3.3489)\n",
      "2106 Traning Loss: tensor(3.3489)\n",
      "2107 Traning Loss: tensor(3.3489)\n",
      "2108 Traning Loss: tensor(3.3489)\n",
      "2109 Traning Loss: tensor(3.3489)\n",
      "2110 Traning Loss: tensor(3.3489)\n",
      "2111 Traning Loss: tensor(3.3489)\n",
      "2112 Traning Loss: tensor(3.3489)\n",
      "2113 Traning Loss: tensor(3.3489)\n",
      "2114 Traning Loss: tensor(3.3489)\n",
      "2115 Traning Loss: tensor(3.3489)\n",
      "2116 Traning Loss: tensor(3.3489)\n",
      "2117 Traning Loss: tensor(3.3489)\n",
      "2118 Traning Loss: tensor(3.3489)\n",
      "2119 Traning Loss: tensor(3.3489)\n",
      "2120 Traning Loss: tensor(3.3489)\n",
      "2121 Traning Loss: tensor(3.3489)\n",
      "2122 Traning Loss: tensor(3.3489)\n",
      "2123 Traning Loss: tensor(3.3489)\n",
      "2124 Traning Loss: tensor(3.3489)\n",
      "2125 Traning Loss: tensor(3.3489)\n",
      "2126 Traning Loss: tensor(3.3489)\n",
      "2127 Traning Loss: tensor(3.3489)\n",
      "2128 Traning Loss: tensor(3.3489)\n",
      "2129 Traning Loss: tensor(3.3489)\n",
      "2130 Traning Loss: tensor(3.3489)\n",
      "2131 Traning Loss: tensor(3.3489)\n",
      "2132 Traning Loss: tensor(3.3489)\n",
      "2133 Traning Loss: tensor(3.3489)\n",
      "2134 Traning Loss: tensor(3.3489)\n",
      "2135 Traning Loss: tensor(3.3489)\n",
      "2136 Traning Loss: tensor(3.3489)\n",
      "2137 Traning Loss: tensor(3.3489)\n",
      "2138 Traning Loss: tensor(3.3489)\n",
      "2139 Traning Loss: tensor(3.3489)\n",
      "2140 Traning Loss: tensor(3.3489)\n",
      "2141 Traning Loss: tensor(3.3489)\n",
      "2142 Traning Loss: tensor(3.3489)\n",
      "2143 Traning Loss: tensor(3.3489)\n",
      "2144 Traning Loss: tensor(3.3489)\n",
      "2145 Traning Loss: tensor(3.3489)\n",
      "2146 Traning Loss: tensor(3.3489)\n",
      "2147 Traning Loss: tensor(3.3489)\n",
      "2148 Traning Loss: tensor(3.3489)\n",
      "2149 Traning Loss: tensor(3.3489)\n",
      "2150 Traning Loss: tensor(3.3489)\n",
      "2151 Traning Loss: tensor(3.3489)\n",
      "2152 Traning Loss: tensor(3.3489)\n",
      "2153 Traning Loss: tensor(3.3489)\n",
      "2154 Traning Loss: tensor(3.3489)\n",
      "2155 Traning Loss: tensor(3.3489)\n",
      "2156 Traning Loss: tensor(3.3489)\n",
      "2157 Traning Loss: tensor(3.3489)\n",
      "2158 Traning Loss: tensor(3.3489)\n",
      "2159 Traning Loss: tensor(3.3489)\n",
      "2160 Traning Loss: tensor(3.3489)\n",
      "2161 Traning Loss: tensor(3.3489)\n",
      "2162 Traning Loss: tensor(3.3489)\n",
      "2163 Traning Loss: tensor(3.3489)\n",
      "2164 Traning Loss: tensor(3.3489)\n",
      "2165 Traning Loss: tensor(3.3489)\n",
      "2166 Traning Loss: tensor(3.3489)\n",
      "2167 Traning Loss: tensor(3.3489)\n",
      "2168 Traning Loss: tensor(3.3489)\n",
      "2169 Traning Loss: tensor(3.3489)\n",
      "2170 Traning Loss: tensor(3.3489)\n",
      "2171 Traning Loss: tensor(3.3489)\n",
      "2172 Traning Loss: tensor(3.3489)\n",
      "2173 Traning Loss: tensor(3.3489)\n",
      "2174 Traning Loss: tensor(3.3489)\n",
      "2175 Traning Loss: tensor(3.3489)\n",
      "2176 Traning Loss: tensor(3.3489)\n",
      "2177 Traning Loss: tensor(3.3489)\n",
      "2178 Traning Loss: tensor(3.3489)\n",
      "2179 Traning Loss: tensor(3.3489)\n",
      "2180 Traning Loss: tensor(3.3489)\n",
      "2181 Traning Loss: tensor(3.3489)\n",
      "2182 Traning Loss: tensor(3.3489)\n",
      "2183 Traning Loss: tensor(3.3489)\n",
      "2184 Traning Loss: tensor(3.3489)\n",
      "2185 Traning Loss: tensor(3.3489)\n",
      "2186 Traning Loss: tensor(3.3489)\n",
      "2187 Traning Loss: tensor(3.3489)\n",
      "2188 Traning Loss: tensor(3.3489)\n",
      "2189 Traning Loss: tensor(3.3489)\n",
      "2190 Traning Loss: tensor(3.3489)\n",
      "2191 Traning Loss: tensor(3.3489)\n",
      "2192 Traning Loss: tensor(3.3489)\n",
      "2193 Traning Loss: tensor(3.3489)\n",
      "2194 Traning Loss: tensor(3.3489)\n",
      "2195 Traning Loss: tensor(3.3489)\n",
      "2196 Traning Loss: tensor(3.3489)\n",
      "2197 Traning Loss: tensor(3.3489)\n",
      "2198 Traning Loss: tensor(3.3489)\n",
      "2199 Traning Loss: tensor(3.3489)\n",
      "2200 Traning Loss: tensor(3.3489)\n",
      "2201 Traning Loss: tensor(3.3489)\n",
      "2202 Traning Loss: tensor(3.3489)\n",
      "2203 Traning Loss: tensor(3.3489)\n",
      "2204 Traning Loss: tensor(3.3489)\n",
      "2205 Traning Loss: tensor(3.3489)\n",
      "2206 Traning Loss: tensor(3.3489)\n",
      "2207 Traning Loss: tensor(3.3489)\n",
      "2208 Traning Loss: tensor(3.3489)\n",
      "2209 Traning Loss: tensor(3.3489)\n",
      "2210 Traning Loss: tensor(3.3489)\n",
      "2211 Traning Loss: tensor(3.3489)\n",
      "2212 Traning Loss: tensor(3.3489)\n",
      "2213 Traning Loss: tensor(3.3489)\n",
      "2214 Traning Loss: tensor(3.3489)\n",
      "2215 Traning Loss: tensor(3.3489)\n",
      "2216 Traning Loss: tensor(3.3489)\n",
      "2217 Traning Loss: tensor(3.3489)\n",
      "2218 Traning Loss: tensor(3.3489)\n",
      "2219 Traning Loss: tensor(3.3489)\n",
      "2220 Traning Loss: tensor(3.3489)\n",
      "2221 Traning Loss: tensor(3.3489)\n",
      "2222 Traning Loss: tensor(3.3489)\n",
      "2223 Traning Loss: tensor(3.3489)\n",
      "2224 Traning Loss: tensor(3.3489)\n",
      "2225 Traning Loss: tensor(3.3489)\n",
      "2226 Traning Loss: tensor(3.3489)\n",
      "2227 Traning Loss: tensor(3.3489)\n",
      "2228 Traning Loss: tensor(3.3489)\n",
      "2229 Traning Loss: tensor(3.3489)\n",
      "2230 Traning Loss: tensor(3.3489)\n",
      "2231 Traning Loss: tensor(3.3489)\n",
      "2232 Traning Loss: tensor(3.3489)\n",
      "2233 Traning Loss: tensor(3.3489)\n",
      "2234 Traning Loss: tensor(3.3489)\n",
      "2235 Traning Loss: tensor(3.3489)\n",
      "2236 Traning Loss: tensor(3.3489)\n",
      "2237 Traning Loss: tensor(3.3489)\n",
      "2238 Traning Loss: tensor(3.3489)\n",
      "2239 Traning Loss: tensor(3.3489)\n",
      "2240 Traning Loss: tensor(3.3489)\n",
      "2241 Traning Loss: tensor(3.3489)\n",
      "2242 Traning Loss: tensor(3.3489)\n",
      "2243 Traning Loss: tensor(3.3489)\n",
      "2244 Traning Loss: tensor(3.3489)\n",
      "2245 Traning Loss: tensor(3.3489)\n",
      "2246 Traning Loss: tensor(3.3489)\n",
      "2247 Traning Loss: tensor(3.3489)\n",
      "2248 Traning Loss: tensor(3.3489)\n",
      "2249 Traning Loss: tensor(3.3489)\n",
      "2250 Traning Loss: tensor(3.3489)\n",
      "2251 Traning Loss: tensor(3.3489)\n",
      "2252 Traning Loss: tensor(3.3489)\n",
      "2253 Traning Loss: tensor(3.3489)\n",
      "2254 Traning Loss: tensor(3.3489)\n",
      "2255 Traning Loss: tensor(3.3489)\n",
      "2256 Traning Loss: tensor(3.3489)\n",
      "2257 Traning Loss: tensor(3.3489)\n",
      "2258 Traning Loss: tensor(3.3489)\n",
      "2259 Traning Loss: tensor(3.3489)\n",
      "2260 Traning Loss: tensor(3.3489)\n",
      "2261 Traning Loss: tensor(3.3489)\n",
      "2262 Traning Loss: tensor(3.3489)\n",
      "2263 Traning Loss: tensor(3.3489)\n",
      "2264 Traning Loss: tensor(3.3489)\n",
      "2265 Traning Loss: tensor(3.3489)\n",
      "2266 Traning Loss: tensor(3.3489)\n",
      "2267 Traning Loss: tensor(3.3489)\n",
      "2268 Traning Loss: tensor(3.3489)\n",
      "2269 Traning Loss: tensor(3.3489)\n",
      "2270 Traning Loss: tensor(3.3489)\n",
      "2271 Traning Loss: tensor(3.3489)\n",
      "2272 Traning Loss: tensor(3.3489)\n",
      "2273 Traning Loss: tensor(3.3489)\n",
      "2274 Traning Loss: tensor(3.3489)\n",
      "2275 Traning Loss: tensor(3.3489)\n",
      "2276 Traning Loss: tensor(3.3489)\n",
      "2277 Traning Loss: tensor(3.3489)\n",
      "2278 Traning Loss: tensor(3.3489)\n",
      "2279 Traning Loss: tensor(3.3489)\n",
      "2280 Traning Loss: tensor(3.3489)\n",
      "2281 Traning Loss: tensor(3.3489)\n",
      "2282 Traning Loss: tensor(3.3489)\n",
      "2283 Traning Loss: tensor(3.3489)\n",
      "2284 Traning Loss: tensor(3.3489)\n",
      "2285 Traning Loss: tensor(3.3489)\n",
      "2286 Traning Loss: tensor(3.3489)\n",
      "2287 Traning Loss: tensor(3.3489)\n",
      "2288 Traning Loss: tensor(3.3489)\n",
      "2289 Traning Loss: tensor(3.3489)\n",
      "2290 Traning Loss: tensor(3.3489)\n",
      "2291 Traning Loss: tensor(3.3489)\n",
      "2292 Traning Loss: tensor(3.3489)\n",
      "2293 Traning Loss: tensor(3.3489)\n",
      "2294 Traning Loss: tensor(3.3489)\n",
      "2295 Traning Loss: tensor(3.3489)\n",
      "2296 Traning Loss: tensor(3.3489)\n",
      "2297 Traning Loss: tensor(3.3489)\n",
      "2298 Traning Loss: tensor(3.3489)\n",
      "2299 Traning Loss: tensor(3.3489)\n",
      "2300 Traning Loss: tensor(3.3489)\n",
      "2301 Traning Loss: tensor(3.3489)\n",
      "2302 Traning Loss: tensor(3.3489)\n",
      "2303 Traning Loss: tensor(3.3489)\n",
      "2304 Traning Loss: tensor(3.3489)\n",
      "2305 Traning Loss: tensor(3.3489)\n",
      "2306 Traning Loss: tensor(3.3489)\n",
      "2307 Traning Loss: tensor(3.3489)\n",
      "2308 Traning Loss: tensor(3.3489)\n",
      "2309 Traning Loss: tensor(3.3489)\n",
      "2310 Traning Loss: tensor(3.3489)\n",
      "2311 Traning Loss: tensor(3.3489)\n",
      "2312 Traning Loss: tensor(3.3489)\n",
      "2313 Traning Loss: tensor(3.3489)\n",
      "2314 Traning Loss: tensor(3.3489)\n",
      "2315 Traning Loss: tensor(3.3489)\n",
      "2316 Traning Loss: tensor(3.3489)\n",
      "2317 Traning Loss: tensor(3.3489)\n",
      "2318 Traning Loss: tensor(3.3489)\n",
      "2319 Traning Loss: tensor(3.3489)\n",
      "2320 Traning Loss: tensor(3.3489)\n",
      "2321 Traning Loss: tensor(3.3489)\n",
      "2322 Traning Loss: tensor(3.3489)\n",
      "2323 Traning Loss: tensor(3.3489)\n",
      "2324 Traning Loss: tensor(3.3489)\n",
      "2325 Traning Loss: tensor(3.3489)\n",
      "2326 Traning Loss: tensor(3.3489)\n",
      "2327 Traning Loss: tensor(3.3489)\n",
      "2328 Traning Loss: tensor(3.3489)\n",
      "2329 Traning Loss: tensor(3.3489)\n",
      "2330 Traning Loss: tensor(3.3489)\n",
      "2331 Traning Loss: tensor(3.3489)\n",
      "2332 Traning Loss: tensor(3.3489)\n",
      "2333 Traning Loss: tensor(3.3489)\n",
      "2334 Traning Loss: tensor(3.3489)\n",
      "2335 Traning Loss: tensor(3.3489)\n",
      "2336 Traning Loss: tensor(3.3489)\n",
      "2337 Traning Loss: tensor(3.3489)\n",
      "2338 Traning Loss: tensor(3.3489)\n",
      "2339 Traning Loss: tensor(3.3489)\n",
      "2340 Traning Loss: tensor(3.3489)\n",
      "2341 Traning Loss: tensor(3.3489)\n",
      "2342 Traning Loss: tensor(3.3489)\n",
      "2343 Traning Loss: tensor(3.3489)\n",
      "2344 Traning Loss: tensor(3.3489)\n",
      "2345 Traning Loss: tensor(3.3489)\n",
      "2346 Traning Loss: tensor(3.3489)\n",
      "2347 Traning Loss: tensor(3.3489)\n",
      "2348 Traning Loss: tensor(3.3489)\n",
      "2349 Traning Loss: tensor(3.3489)\n",
      "2350 Traning Loss: tensor(3.3489)\n",
      "2351 Traning Loss: tensor(3.3489)\n",
      "2352 Traning Loss: tensor(3.3489)\n",
      "2353 Traning Loss: tensor(3.3489)\n",
      "2354 Traning Loss: tensor(3.3489)\n",
      "2355 Traning Loss: tensor(3.3489)\n",
      "2356 Traning Loss: tensor(3.3489)\n",
      "2357 Traning Loss: tensor(3.3489)\n",
      "2358 Traning Loss: tensor(3.3489)\n",
      "2359 Traning Loss: tensor(3.3489)\n",
      "2360 Traning Loss: tensor(3.3489)\n",
      "2361 Traning Loss: tensor(3.3489)\n",
      "2362 Traning Loss: tensor(3.3489)\n",
      "2363 Traning Loss: tensor(3.3489)\n",
      "2364 Traning Loss: tensor(3.3489)\n",
      "2365 Traning Loss: tensor(3.3489)\n",
      "2366 Traning Loss: tensor(3.3489)\n",
      "2367 Traning Loss: tensor(3.3489)\n",
      "2368 Traning Loss: tensor(3.3489)\n",
      "2369 Traning Loss: tensor(3.3489)\n",
      "2370 Traning Loss: tensor(3.3489)\n",
      "2371 Traning Loss: tensor(3.3489)\n",
      "2372 Traning Loss: tensor(3.3489)\n",
      "2373 Traning Loss: tensor(3.3489)\n",
      "2374 Traning Loss: tensor(3.3489)\n",
      "2375 Traning Loss: tensor(3.3489)\n",
      "2376 Traning Loss: tensor(3.3489)\n",
      "2377 Traning Loss: tensor(3.3489)\n",
      "2378 Traning Loss: tensor(3.3489)\n",
      "2379 Traning Loss: tensor(3.3489)\n",
      "2380 Traning Loss: tensor(3.3489)\n",
      "2381 Traning Loss: tensor(3.3489)\n",
      "2382 Traning Loss: tensor(3.3489)\n",
      "2383 Traning Loss: tensor(3.3489)\n",
      "2384 Traning Loss: tensor(3.3489)\n",
      "2385 Traning Loss: tensor(3.3489)\n",
      "2386 Traning Loss: tensor(3.3489)\n",
      "2387 Traning Loss: tensor(3.3489)\n",
      "2388 Traning Loss: tensor(3.3489)\n",
      "2389 Traning Loss: tensor(3.3489)\n",
      "2390 Traning Loss: tensor(3.3489)\n",
      "2391 Traning Loss: tensor(3.3489)\n",
      "2392 Traning Loss: tensor(3.3489)\n",
      "2393 Traning Loss: tensor(3.3489)\n",
      "2394 Traning Loss: tensor(3.3489)\n",
      "2395 Traning Loss: tensor(3.3489)\n",
      "2396 Traning Loss: tensor(3.3489)\n",
      "2397 Traning Loss: tensor(3.3489)\n",
      "2398 Traning Loss: tensor(3.3489)\n",
      "2399 Traning Loss: tensor(3.3489)\n",
      "2400 Traning Loss: tensor(3.3489)\n",
      "2401 Traning Loss: tensor(3.3489)\n",
      "2402 Traning Loss: tensor(3.3489)\n",
      "2403 Traning Loss: tensor(3.3489)\n",
      "2404 Traning Loss: tensor(3.3489)\n",
      "2405 Traning Loss: tensor(3.3489)\n",
      "2406 Traning Loss: tensor(3.3489)\n",
      "2407 Traning Loss: tensor(3.3489)\n",
      "2408 Traning Loss: tensor(3.3489)\n",
      "2409 Traning Loss: tensor(3.3489)\n",
      "2410 Traning Loss: tensor(3.3489)\n",
      "2411 Traning Loss: tensor(3.3489)\n",
      "2412 Traning Loss: tensor(3.3489)\n",
      "2413 Traning Loss: tensor(3.3489)\n",
      "2414 Traning Loss: tensor(3.3489)\n",
      "2415 Traning Loss: tensor(3.3489)\n",
      "2416 Traning Loss: tensor(3.3489)\n",
      "2417 Traning Loss: tensor(3.3489)\n",
      "2418 Traning Loss: tensor(3.3489)\n",
      "2419 Traning Loss: tensor(3.3489)\n",
      "2420 Traning Loss: tensor(3.3489)\n",
      "2421 Traning Loss: tensor(3.3489)\n",
      "2422 Traning Loss: tensor(3.3489)\n",
      "2423 Traning Loss: tensor(3.3489)\n",
      "2424 Traning Loss: tensor(3.3489)\n",
      "2425 Traning Loss: tensor(3.3489)\n",
      "2426 Traning Loss: tensor(3.3489)\n",
      "2427 Traning Loss: tensor(3.3489)\n",
      "2428 Traning Loss: tensor(3.3489)\n",
      "2429 Traning Loss: tensor(3.3489)\n",
      "2430 Traning Loss: tensor(3.3489)\n",
      "2431 Traning Loss: tensor(3.3489)\n",
      "2432 Traning Loss: tensor(3.3489)\n",
      "2433 Traning Loss: tensor(3.3489)\n",
      "2434 Traning Loss: tensor(3.3489)\n",
      "2435 Traning Loss: tensor(3.3489)\n",
      "2436 Traning Loss: tensor(3.3489)\n",
      "2437 Traning Loss: tensor(3.3489)\n",
      "2438 Traning Loss: tensor(3.3489)\n",
      "2439 Traning Loss: tensor(3.3489)\n",
      "2440 Traning Loss: tensor(3.3489)\n",
      "2441 Traning Loss: tensor(3.3489)\n",
      "2442 Traning Loss: tensor(3.3489)\n",
      "2443 Traning Loss: tensor(3.3489)\n",
      "2444 Traning Loss: tensor(3.3489)\n",
      "2445 Traning Loss: tensor(3.3489)\n",
      "2446 Traning Loss: tensor(3.3489)\n",
      "2447 Traning Loss: tensor(3.3489)\n",
      "2448 Traning Loss: tensor(3.3489)\n",
      "2449 Traning Loss: tensor(3.3489)\n",
      "2450 Traning Loss: tensor(3.3489)\n",
      "2451 Traning Loss: tensor(3.3489)\n",
      "2452 Traning Loss: tensor(3.3489)\n",
      "2453 Traning Loss: tensor(3.3489)\n",
      "2454 Traning Loss: tensor(3.3489)\n",
      "2455 Traning Loss: tensor(3.3489)\n",
      "2456 Traning Loss: tensor(3.3489)\n",
      "2457 Traning Loss: tensor(3.3489)\n",
      "2458 Traning Loss: tensor(3.3489)\n",
      "2459 Traning Loss: tensor(3.3489)\n",
      "2460 Traning Loss: tensor(3.3489)\n",
      "2461 Traning Loss: tensor(3.3489)\n",
      "2462 Traning Loss: tensor(3.3489)\n",
      "2463 Traning Loss: tensor(3.3489)\n",
      "2464 Traning Loss: tensor(3.3489)\n",
      "2465 Traning Loss: tensor(3.3489)\n",
      "2466 Traning Loss: tensor(3.3489)\n",
      "2467 Traning Loss: tensor(3.3489)\n",
      "2468 Traning Loss: tensor(3.3489)\n",
      "2469 Traning Loss: tensor(3.3489)\n",
      "2470 Traning Loss: tensor(3.3489)\n",
      "2471 Traning Loss: tensor(3.3489)\n",
      "2472 Traning Loss: tensor(3.3489)\n",
      "2473 Traning Loss: tensor(3.3489)\n",
      "2474 Traning Loss: tensor(3.3489)\n",
      "2475 Traning Loss: tensor(3.3489)\n",
      "2476 Traning Loss: tensor(3.3489)\n",
      "2477 Traning Loss: tensor(3.3489)\n",
      "2478 Traning Loss: tensor(3.3489)\n",
      "2479 Traning Loss: tensor(3.3489)\n",
      "2480 Traning Loss: tensor(3.3489)\n",
      "2481 Traning Loss: tensor(3.3489)\n",
      "2482 Traning Loss: tensor(3.3489)\n",
      "2483 Traning Loss: tensor(3.3489)\n",
      "2484 Traning Loss: tensor(3.3489)\n",
      "2485 Traning Loss: tensor(3.3489)\n",
      "2486 Traning Loss: tensor(3.3489)\n",
      "2487 Traning Loss: tensor(3.3489)\n",
      "2488 Traning Loss: tensor(3.3489)\n",
      "2489 Traning Loss: tensor(3.3489)\n",
      "2490 Traning Loss: tensor(3.3489)\n",
      "2491 Traning Loss: tensor(3.3489)\n",
      "2492 Traning Loss: tensor(3.3489)\n",
      "2493 Traning Loss: tensor(3.3489)\n",
      "2494 Traning Loss: tensor(3.3489)\n",
      "2495 Traning Loss: tensor(3.3489)\n",
      "2496 Traning Loss: tensor(3.3489)\n",
      "2497 Traning Loss: tensor(3.3489)\n",
      "2498 Traning Loss: tensor(3.3489)\n",
      "2499 Traning Loss: tensor(3.3489)\n",
      "2500 Traning Loss: tensor(3.3489)\n",
      "2501 Traning Loss: tensor(3.3489)\n",
      "2502 Traning Loss: tensor(3.3489)\n",
      "2503 Traning Loss: tensor(3.3489)\n",
      "2504 Traning Loss: tensor(3.3489)\n",
      "2505 Traning Loss: tensor(3.3489)\n",
      "2506 Traning Loss: tensor(3.3489)\n",
      "2507 Traning Loss: tensor(3.3489)\n",
      "2508 Traning Loss: tensor(3.3489)\n",
      "2509 Traning Loss: tensor(3.3489)\n",
      "2510 Traning Loss: tensor(3.3489)\n",
      "2511 Traning Loss: tensor(3.3489)\n",
      "2512 Traning Loss: tensor(3.3489)\n",
      "2513 Traning Loss: tensor(3.3489)\n",
      "2514 Traning Loss: tensor(3.3489)\n",
      "2515 Traning Loss: tensor(3.3489)\n",
      "2516 Traning Loss: tensor(3.3489)\n",
      "2517 Traning Loss: tensor(3.3489)\n",
      "2518 Traning Loss: tensor(3.3489)\n",
      "2519 Traning Loss: tensor(3.3489)\n",
      "2520 Traning Loss: tensor(3.3489)\n",
      "2521 Traning Loss: tensor(3.3489)\n",
      "2522 Traning Loss: tensor(3.3489)\n",
      "2523 Traning Loss: tensor(3.3489)\n",
      "2524 Traning Loss: tensor(3.3489)\n",
      "2525 Traning Loss: tensor(3.3489)\n",
      "2526 Traning Loss: tensor(3.3489)\n",
      "2527 Traning Loss: tensor(3.3489)\n",
      "2528 Traning Loss: tensor(3.3489)\n",
      "2529 Traning Loss: tensor(3.3489)\n",
      "2530 Traning Loss: tensor(3.3489)\n",
      "2531 Traning Loss: tensor(3.3489)\n",
      "2532 Traning Loss: tensor(3.3489)\n",
      "2533 Traning Loss: tensor(3.3489)\n",
      "2534 Traning Loss: tensor(3.3489)\n",
      "2535 Traning Loss: tensor(3.3489)\n",
      "2536 Traning Loss: tensor(3.3489)\n",
      "2537 Traning Loss: tensor(3.3489)\n",
      "2538 Traning Loss: tensor(3.3489)\n",
      "2539 Traning Loss: tensor(3.3489)\n",
      "2540 Traning Loss: tensor(3.3489)\n",
      "2541 Traning Loss: tensor(3.3489)\n",
      "2542 Traning Loss: tensor(3.3489)\n",
      "2543 Traning Loss: tensor(3.3489)\n",
      "2544 Traning Loss: tensor(3.3489)\n",
      "2545 Traning Loss: tensor(3.3489)\n",
      "2546 Traning Loss: tensor(3.3489)\n",
      "2547 Traning Loss: tensor(3.3489)\n",
      "2548 Traning Loss: tensor(3.3489)\n",
      "2549 Traning Loss: tensor(3.3489)\n",
      "2550 Traning Loss: tensor(3.3489)\n",
      "2551 Traning Loss: tensor(3.3489)\n",
      "2552 Traning Loss: tensor(3.3489)\n",
      "2553 Traning Loss: tensor(3.3489)\n",
      "2554 Traning Loss: tensor(3.3489)\n",
      "2555 Traning Loss: tensor(3.3489)\n",
      "2556 Traning Loss: tensor(3.3489)\n",
      "2557 Traning Loss: tensor(3.3489)\n",
      "2558 Traning Loss: tensor(3.3489)\n",
      "2559 Traning Loss: tensor(3.3489)\n",
      "2560 Traning Loss: tensor(3.3489)\n",
      "2561 Traning Loss: tensor(3.3489)\n",
      "2562 Traning Loss: tensor(3.3489)\n",
      "2563 Traning Loss: tensor(3.3489)\n",
      "2564 Traning Loss: tensor(3.3489)\n",
      "2565 Traning Loss: tensor(3.3489)\n",
      "2566 Traning Loss: tensor(3.3489)\n",
      "2567 Traning Loss: tensor(3.3489)\n",
      "2568 Traning Loss: tensor(3.3489)\n",
      "2569 Traning Loss: tensor(3.3489)\n",
      "2570 Traning Loss: tensor(3.3489)\n",
      "2571 Traning Loss: tensor(3.3489)\n",
      "2572 Traning Loss: tensor(3.3489)\n",
      "2573 Traning Loss: tensor(3.3489)\n",
      "2574 Traning Loss: tensor(3.3489)\n",
      "2575 Traning Loss: tensor(3.3489)\n",
      "2576 Traning Loss: tensor(3.3489)\n",
      "2577 Traning Loss: tensor(3.3489)\n",
      "2578 Traning Loss: tensor(3.3489)\n",
      "2579 Traning Loss: tensor(3.3489)\n",
      "2580 Traning Loss: tensor(3.3489)\n",
      "2581 Traning Loss: tensor(3.3489)\n",
      "2582 Traning Loss: tensor(3.3489)\n",
      "2583 Traning Loss: tensor(3.3489)\n",
      "2584 Traning Loss: tensor(3.3489)\n",
      "2585 Traning Loss: tensor(3.3489)\n",
      "2586 Traning Loss: tensor(3.3489)\n",
      "2587 Traning Loss: tensor(3.3489)\n",
      "2588 Traning Loss: tensor(3.3489)\n",
      "2589 Traning Loss: tensor(3.3489)\n",
      "2590 Traning Loss: tensor(3.3489)\n",
      "2591 Traning Loss: tensor(3.3489)\n",
      "2592 Traning Loss: tensor(3.3489)\n",
      "2593 Traning Loss: tensor(3.3489)\n",
      "2594 Traning Loss: tensor(3.3489)\n",
      "2595 Traning Loss: tensor(3.3489)\n",
      "2596 Traning Loss: tensor(3.3489)\n",
      "2597 Traning Loss: tensor(3.3489)\n",
      "2598 Traning Loss: tensor(3.3489)\n",
      "2599 Traning Loss: tensor(3.3489)\n",
      "2600 Traning Loss: tensor(3.3489)\n",
      "2601 Traning Loss: tensor(3.3489)\n",
      "2602 Traning Loss: tensor(3.3489)\n",
      "2603 Traning Loss: tensor(3.3489)\n",
      "2604 Traning Loss: tensor(3.3489)\n",
      "2605 Traning Loss: tensor(3.3489)\n",
      "2606 Traning Loss: tensor(3.3489)\n",
      "2607 Traning Loss: tensor(3.3489)\n",
      "2608 Traning Loss: tensor(3.3489)\n",
      "2609 Traning Loss: tensor(3.3489)\n",
      "2610 Traning Loss: tensor(3.3489)\n",
      "2611 Traning Loss: tensor(3.3489)\n",
      "2612 Traning Loss: tensor(3.3489)\n",
      "2613 Traning Loss: tensor(3.3489)\n",
      "2614 Traning Loss: tensor(3.3489)\n",
      "2615 Traning Loss: tensor(3.3489)\n",
      "2616 Traning Loss: tensor(3.3489)\n",
      "2617 Traning Loss: tensor(3.3489)\n",
      "2618 Traning Loss: tensor(3.3489)\n",
      "2619 Traning Loss: tensor(3.3489)\n",
      "2620 Traning Loss: tensor(3.3489)\n",
      "2621 Traning Loss: tensor(3.3489)\n",
      "2622 Traning Loss: tensor(3.3489)\n",
      "2623 Traning Loss: tensor(3.3489)\n",
      "2624 Traning Loss: tensor(3.3489)\n",
      "2625 Traning Loss: tensor(3.3489)\n",
      "2626 Traning Loss: tensor(3.3489)\n",
      "2627 Traning Loss: tensor(3.3489)\n",
      "2628 Traning Loss: tensor(3.3489)\n",
      "2629 Traning Loss: tensor(3.3489)\n",
      "2630 Traning Loss: tensor(3.3489)\n",
      "2631 Traning Loss: tensor(3.3489)\n",
      "2632 Traning Loss: tensor(3.3489)\n",
      "2633 Traning Loss: tensor(3.3489)\n",
      "2634 Traning Loss: tensor(3.3489)\n",
      "2635 Traning Loss: tensor(3.3489)\n",
      "2636 Traning Loss: tensor(3.3489)\n",
      "2637 Traning Loss: tensor(3.3489)\n",
      "2638 Traning Loss: tensor(3.3489)\n",
      "2639 Traning Loss: tensor(3.3489)\n",
      "2640 Traning Loss: tensor(3.3489)\n",
      "2641 Traning Loss: tensor(3.3489)\n",
      "2642 Traning Loss: tensor(3.3489)\n",
      "2643 Traning Loss: tensor(3.3489)\n",
      "2644 Traning Loss: tensor(3.3489)\n",
      "2645 Traning Loss: tensor(3.3489)\n",
      "2646 Traning Loss: tensor(3.3489)\n",
      "2647 Traning Loss: tensor(3.3489)\n",
      "2648 Traning Loss: tensor(3.3489)\n",
      "2649 Traning Loss: tensor(3.3489)\n",
      "2650 Traning Loss: tensor(3.3489)\n",
      "2651 Traning Loss: tensor(3.3489)\n",
      "2652 Traning Loss: tensor(3.3489)\n",
      "2653 Traning Loss: tensor(3.3489)\n",
      "2654 Traning Loss: tensor(3.3489)\n",
      "2655 Traning Loss: tensor(3.3489)\n",
      "2656 Traning Loss: tensor(3.3489)\n",
      "2657 Traning Loss: tensor(3.3489)\n",
      "2658 Traning Loss: tensor(3.3489)\n",
      "2659 Traning Loss: tensor(3.3489)\n",
      "2660 Traning Loss: tensor(3.3489)\n",
      "2661 Traning Loss: tensor(3.3489)\n",
      "2662 Traning Loss: tensor(3.3489)\n",
      "2663 Traning Loss: tensor(3.3489)\n",
      "2664 Traning Loss: tensor(3.3489)\n",
      "2665 Traning Loss: tensor(3.3489)\n",
      "2666 Traning Loss: tensor(3.3489)\n",
      "2667 Traning Loss: tensor(3.3489)\n",
      "2668 Traning Loss: tensor(3.3489)\n",
      "2669 Traning Loss: tensor(3.3489)\n",
      "2670 Traning Loss: tensor(3.3489)\n",
      "2671 Traning Loss: tensor(3.3489)\n",
      "2672 Traning Loss: tensor(3.3489)\n",
      "2673 Traning Loss: tensor(3.3489)\n",
      "2674 Traning Loss: tensor(3.3489)\n",
      "2675 Traning Loss: tensor(3.3489)\n",
      "2676 Traning Loss: tensor(3.3489)\n",
      "2677 Traning Loss: tensor(3.3489)\n",
      "2678 Traning Loss: tensor(3.3489)\n",
      "2679 Traning Loss: tensor(3.3489)\n",
      "2680 Traning Loss: tensor(3.3489)\n",
      "2681 Traning Loss: tensor(3.3489)\n",
      "2682 Traning Loss: tensor(3.3489)\n",
      "2683 Traning Loss: tensor(3.3489)\n",
      "2684 Traning Loss: tensor(3.3489)\n",
      "2685 Traning Loss: tensor(3.3489)\n",
      "2686 Traning Loss: tensor(3.3489)\n",
      "2687 Traning Loss: tensor(3.3489)\n",
      "2688 Traning Loss: tensor(3.3489)\n",
      "2689 Traning Loss: tensor(3.3489)\n",
      "2690 Traning Loss: tensor(3.3489)\n",
      "2691 Traning Loss: tensor(3.3489)\n",
      "2692 Traning Loss: tensor(3.3489)\n",
      "2693 Traning Loss: tensor(3.3489)\n",
      "2694 Traning Loss: tensor(3.3489)\n",
      "2695 Traning Loss: tensor(3.3489)\n",
      "2696 Traning Loss: tensor(3.3489)\n",
      "2697 Traning Loss: tensor(3.3489)\n",
      "2698 Traning Loss: tensor(3.3489)\n",
      "2699 Traning Loss: tensor(3.3489)\n",
      "2700 Traning Loss: tensor(3.3489)\n",
      "2701 Traning Loss: tensor(3.3489)\n",
      "2702 Traning Loss: tensor(3.3489)\n",
      "2703 Traning Loss: tensor(3.3489)\n",
      "2704 Traning Loss: tensor(3.3489)\n",
      "2705 Traning Loss: tensor(3.3489)\n",
      "2706 Traning Loss: tensor(3.3489)\n",
      "2707 Traning Loss: tensor(3.3489)\n",
      "2708 Traning Loss: tensor(3.3489)\n",
      "2709 Traning Loss: tensor(3.3489)\n",
      "2710 Traning Loss: tensor(3.3489)\n",
      "2711 Traning Loss: tensor(3.3489)\n",
      "2712 Traning Loss: tensor(3.3489)\n",
      "2713 Traning Loss: tensor(3.3489)\n",
      "2714 Traning Loss: tensor(3.3489)\n",
      "2715 Traning Loss: tensor(3.3489)\n",
      "2716 Traning Loss: tensor(3.3489)\n",
      "2717 Traning Loss: tensor(3.3489)\n",
      "2718 Traning Loss: tensor(3.3489)\n",
      "2719 Traning Loss: tensor(3.3489)\n",
      "2720 Traning Loss: tensor(3.3489)\n",
      "2721 Traning Loss: tensor(3.3489)\n",
      "2722 Traning Loss: tensor(3.3489)\n",
      "2723 Traning Loss: tensor(3.3489)\n",
      "2724 Traning Loss: tensor(3.3489)\n",
      "2725 Traning Loss: tensor(3.3489)\n",
      "2726 Traning Loss: tensor(3.3489)\n",
      "2727 Traning Loss: tensor(3.3489)\n",
      "2728 Traning Loss: tensor(3.3489)\n",
      "2729 Traning Loss: tensor(3.3489)\n",
      "2730 Traning Loss: tensor(3.3489)\n",
      "2731 Traning Loss: tensor(3.3489)\n",
      "2732 Traning Loss: tensor(3.3489)\n",
      "2733 Traning Loss: tensor(3.3489)\n",
      "2734 Traning Loss: tensor(3.3489)\n",
      "2735 Traning Loss: tensor(3.3489)\n",
      "2736 Traning Loss: tensor(3.3489)\n",
      "2737 Traning Loss: tensor(3.3489)\n",
      "2738 Traning Loss: tensor(3.3489)\n",
      "2739 Traning Loss: tensor(3.3489)\n",
      "2740 Traning Loss: tensor(3.3489)\n",
      "2741 Traning Loss: tensor(3.3489)\n",
      "2742 Traning Loss: tensor(3.3489)\n",
      "2743 Traning Loss: tensor(3.3489)\n",
      "2744 Traning Loss: tensor(3.3489)\n",
      "2745 Traning Loss: tensor(3.3489)\n",
      "2746 Traning Loss: tensor(3.3489)\n",
      "2747 Traning Loss: tensor(3.3489)\n",
      "2748 Traning Loss: tensor(3.3489)\n",
      "2749 Traning Loss: tensor(3.3489)\n",
      "2750 Traning Loss: tensor(3.3489)\n",
      "2751 Traning Loss: tensor(3.3489)\n",
      "2752 Traning Loss: tensor(3.3489)\n",
      "2753 Traning Loss: tensor(3.3489)\n",
      "2754 Traning Loss: tensor(3.3489)\n",
      "2755 Traning Loss: tensor(3.3489)\n",
      "2756 Traning Loss: tensor(3.3489)\n",
      "2757 Traning Loss: tensor(3.3489)\n",
      "2758 Traning Loss: tensor(3.3489)\n",
      "2759 Traning Loss: tensor(3.3489)\n",
      "2760 Traning Loss: tensor(3.3489)\n",
      "2761 Traning Loss: tensor(3.3489)\n",
      "2762 Traning Loss: tensor(3.3489)\n",
      "2763 Traning Loss: tensor(3.3489)\n",
      "2764 Traning Loss: tensor(3.3489)\n",
      "2765 Traning Loss: tensor(3.3489)\n",
      "2766 Traning Loss: tensor(3.3489)\n",
      "2767 Traning Loss: tensor(3.3489)\n",
      "2768 Traning Loss: tensor(3.3489)\n",
      "2769 Traning Loss: tensor(3.3489)\n",
      "2770 Traning Loss: tensor(3.3489)\n",
      "2771 Traning Loss: tensor(3.3489)\n",
      "2772 Traning Loss: tensor(3.3489)\n",
      "2773 Traning Loss: tensor(3.3489)\n",
      "2774 Traning Loss: tensor(3.3489)\n",
      "2775 Traning Loss: tensor(3.3489)\n",
      "2776 Traning Loss: tensor(3.3489)\n",
      "2777 Traning Loss: tensor(3.3489)\n",
      "2778 Traning Loss: tensor(3.3489)\n",
      "2779 Traning Loss: tensor(3.3489)\n",
      "2780 Traning Loss: tensor(3.3489)\n",
      "2781 Traning Loss: tensor(3.3489)\n",
      "2782 Traning Loss: tensor(3.3489)\n",
      "2783 Traning Loss: tensor(3.3489)\n",
      "2784 Traning Loss: tensor(3.3489)\n",
      "2785 Traning Loss: tensor(3.3489)\n",
      "2786 Traning Loss: tensor(3.3489)\n",
      "2787 Traning Loss: tensor(3.3489)\n",
      "2788 Traning Loss: tensor(3.3489)\n",
      "2789 Traning Loss: tensor(3.3489)\n",
      "2790 Traning Loss: tensor(3.3489)\n",
      "2791 Traning Loss: tensor(3.3489)\n",
      "2792 Traning Loss: tensor(3.3489)\n",
      "2793 Traning Loss: tensor(3.3489)\n",
      "2794 Traning Loss: tensor(3.3489)\n",
      "2795 Traning Loss: tensor(3.3489)\n",
      "2796 Traning Loss: tensor(3.3489)\n",
      "2797 Traning Loss: tensor(3.3489)\n",
      "2798 Traning Loss: tensor(3.3489)\n",
      "2799 Traning Loss: tensor(3.3489)\n",
      "2800 Traning Loss: tensor(3.3489)\n",
      "2801 Traning Loss: tensor(3.3489)\n",
      "2802 Traning Loss: tensor(3.3489)\n",
      "2803 Traning Loss: tensor(3.3489)\n",
      "2804 Traning Loss: tensor(3.3489)\n",
      "2805 Traning Loss: tensor(3.3489)\n",
      "2806 Traning Loss: tensor(3.3489)\n",
      "2807 Traning Loss: tensor(3.3489)\n",
      "2808 Traning Loss: tensor(3.3489)\n",
      "2809 Traning Loss: tensor(3.3489)\n",
      "2810 Traning Loss: tensor(3.3489)\n",
      "2811 Traning Loss: tensor(3.3489)\n",
      "2812 Traning Loss: tensor(3.3489)\n",
      "2813 Traning Loss: tensor(3.3489)\n",
      "2814 Traning Loss: tensor(3.3489)\n",
      "2815 Traning Loss: tensor(3.3489)\n",
      "2816 Traning Loss: tensor(3.3489)\n",
      "2817 Traning Loss: tensor(3.3489)\n",
      "2818 Traning Loss: tensor(3.3489)\n",
      "2819 Traning Loss: tensor(3.3489)\n",
      "2820 Traning Loss: tensor(3.3489)\n",
      "2821 Traning Loss: tensor(3.3489)\n",
      "2822 Traning Loss: tensor(3.3489)\n",
      "2823 Traning Loss: tensor(3.3489)\n",
      "2824 Traning Loss: tensor(3.3489)\n",
      "2825 Traning Loss: tensor(3.3489)\n",
      "2826 Traning Loss: tensor(3.3489)\n",
      "2827 Traning Loss: tensor(3.3489)\n",
      "2828 Traning Loss: tensor(3.3489)\n",
      "2829 Traning Loss: tensor(3.3489)\n",
      "2830 Traning Loss: tensor(3.3489)\n",
      "2831 Traning Loss: tensor(3.3489)\n",
      "2832 Traning Loss: tensor(3.3489)\n",
      "2833 Traning Loss: tensor(3.3489)\n",
      "2834 Traning Loss: tensor(3.3489)\n",
      "2835 Traning Loss: tensor(3.3489)\n",
      "2836 Traning Loss: tensor(3.3489)\n",
      "2837 Traning Loss: tensor(3.3489)\n",
      "2838 Traning Loss: tensor(3.3489)\n",
      "2839 Traning Loss: tensor(3.3489)\n",
      "2840 Traning Loss: tensor(3.3489)\n",
      "2841 Traning Loss: tensor(3.3489)\n",
      "2842 Traning Loss: tensor(3.3489)\n",
      "2843 Traning Loss: tensor(3.3489)\n",
      "2844 Traning Loss: tensor(3.3489)\n",
      "2845 Traning Loss: tensor(3.3489)\n",
      "2846 Traning Loss: tensor(3.3489)\n",
      "2847 Traning Loss: tensor(3.3489)\n",
      "2848 Traning Loss: tensor(3.3489)\n",
      "2849 Traning Loss: tensor(3.3489)\n",
      "2850 Traning Loss: tensor(3.3489)\n",
      "2851 Traning Loss: tensor(3.3489)\n",
      "2852 Traning Loss: tensor(3.3489)\n",
      "2853 Traning Loss: tensor(3.3489)\n",
      "2854 Traning Loss: tensor(3.3489)\n",
      "2855 Traning Loss: tensor(3.3489)\n",
      "2856 Traning Loss: tensor(3.3489)\n",
      "2857 Traning Loss: tensor(3.3489)\n",
      "2858 Traning Loss: tensor(3.3489)\n",
      "2859 Traning Loss: tensor(3.3489)\n",
      "2860 Traning Loss: tensor(3.3489)\n",
      "2861 Traning Loss: tensor(3.3489)\n",
      "2862 Traning Loss: tensor(3.3489)\n",
      "2863 Traning Loss: tensor(3.3489)\n",
      "2864 Traning Loss: tensor(3.3489)\n",
      "2865 Traning Loss: tensor(3.3489)\n",
      "2866 Traning Loss: tensor(3.3489)\n",
      "2867 Traning Loss: tensor(3.3489)\n",
      "2868 Traning Loss: tensor(3.3489)\n",
      "2869 Traning Loss: tensor(3.3489)\n",
      "2870 Traning Loss: tensor(3.3489)\n",
      "2871 Traning Loss: tensor(3.3489)\n",
      "2872 Traning Loss: tensor(3.3489)\n",
      "2873 Traning Loss: tensor(3.3489)\n",
      "2874 Traning Loss: tensor(3.3489)\n",
      "2875 Traning Loss: tensor(3.3489)\n",
      "2876 Traning Loss: tensor(3.3489)\n",
      "2877 Traning Loss: tensor(3.3489)\n",
      "2878 Traning Loss: tensor(3.3489)\n",
      "2879 Traning Loss: tensor(3.3489)\n",
      "2880 Traning Loss: tensor(3.3489)\n",
      "2881 Traning Loss: tensor(3.3489)\n",
      "2882 Traning Loss: tensor(3.3489)\n",
      "2883 Traning Loss: tensor(3.3489)\n",
      "2884 Traning Loss: tensor(3.3489)\n",
      "2885 Traning Loss: tensor(3.3489)\n",
      "2886 Traning Loss: tensor(3.3489)\n",
      "2887 Traning Loss: tensor(3.3489)\n",
      "2888 Traning Loss: tensor(3.3489)\n",
      "2889 Traning Loss: tensor(3.3489)\n",
      "2890 Traning Loss: tensor(3.3489)\n",
      "2891 Traning Loss: tensor(3.3489)\n",
      "2892 Traning Loss: tensor(3.3489)\n",
      "2893 Traning Loss: tensor(3.3489)\n",
      "2894 Traning Loss: tensor(3.3489)\n",
      "2895 Traning Loss: tensor(3.3489)\n",
      "2896 Traning Loss: tensor(3.3489)\n",
      "2897 Traning Loss: tensor(3.3489)\n",
      "2898 Traning Loss: tensor(3.3489)\n",
      "2899 Traning Loss: tensor(3.3489)\n",
      "2900 Traning Loss: tensor(3.3489)\n",
      "2901 Traning Loss: tensor(3.3489)\n",
      "2902 Traning Loss: tensor(3.3489)\n",
      "2903 Traning Loss: tensor(3.3489)\n",
      "2904 Traning Loss: tensor(3.3489)\n",
      "2905 Traning Loss: tensor(3.3489)\n",
      "2906 Traning Loss: tensor(3.3489)\n",
      "2907 Traning Loss: tensor(3.3489)\n",
      "2908 Traning Loss: tensor(3.3489)\n",
      "2909 Traning Loss: tensor(3.3489)\n",
      "2910 Traning Loss: tensor(3.3489)\n",
      "2911 Traning Loss: tensor(3.3489)\n",
      "2912 Traning Loss: tensor(3.3489)\n",
      "2913 Traning Loss: tensor(3.3489)\n",
      "2914 Traning Loss: tensor(3.3489)\n",
      "2915 Traning Loss: tensor(3.3489)\n",
      "2916 Traning Loss: tensor(3.3489)\n",
      "2917 Traning Loss: tensor(3.3489)\n",
      "2918 Traning Loss: tensor(3.3489)\n",
      "2919 Traning Loss: tensor(3.3489)\n",
      "2920 Traning Loss: tensor(3.3489)\n",
      "2921 Traning Loss: tensor(3.3489)\n",
      "2922 Traning Loss: tensor(3.3489)\n",
      "2923 Traning Loss: tensor(3.3489)\n",
      "2924 Traning Loss: tensor(3.3489)\n",
      "2925 Traning Loss: tensor(3.3489)\n",
      "2926 Traning Loss: tensor(3.3489)\n",
      "2927 Traning Loss: tensor(3.3489)\n",
      "2928 Traning Loss: tensor(3.3489)\n",
      "2929 Traning Loss: tensor(3.3489)\n",
      "2930 Traning Loss: tensor(3.3489)\n",
      "2931 Traning Loss: tensor(3.3489)\n",
      "2932 Traning Loss: tensor(3.3489)\n",
      "2933 Traning Loss: tensor(3.3489)\n",
      "2934 Traning Loss: tensor(3.3489)\n",
      "2935 Traning Loss: tensor(3.3489)\n",
      "2936 Traning Loss: tensor(3.3489)\n",
      "2937 Traning Loss: tensor(3.3489)\n",
      "2938 Traning Loss: tensor(3.3489)\n",
      "2939 Traning Loss: tensor(3.3489)\n",
      "2940 Traning Loss: tensor(3.3489)\n",
      "2941 Traning Loss: tensor(3.3489)\n",
      "2942 Traning Loss: tensor(3.3489)\n",
      "2943 Traning Loss: tensor(3.3489)\n",
      "2944 Traning Loss: tensor(3.3489)\n",
      "2945 Traning Loss: tensor(3.3489)\n",
      "2946 Traning Loss: tensor(3.3489)\n",
      "2947 Traning Loss: tensor(3.3489)\n",
      "2948 Traning Loss: tensor(3.3489)\n",
      "2949 Traning Loss: tensor(3.3489)\n",
      "2950 Traning Loss: tensor(3.3489)\n",
      "2951 Traning Loss: tensor(3.3489)\n",
      "2952 Traning Loss: tensor(3.3489)\n",
      "2953 Traning Loss: tensor(3.3489)\n",
      "2954 Traning Loss: tensor(3.3489)\n",
      "2955 Traning Loss: tensor(3.3489)\n",
      "2956 Traning Loss: tensor(3.3489)\n",
      "2957 Traning Loss: tensor(3.3489)\n",
      "2958 Traning Loss: tensor(3.3489)\n",
      "2959 Traning Loss: tensor(3.3489)\n",
      "2960 Traning Loss: tensor(3.3489)\n",
      "2961 Traning Loss: tensor(3.3489)\n",
      "2962 Traning Loss: tensor(3.3489)\n",
      "2963 Traning Loss: tensor(3.3489)\n",
      "2964 Traning Loss: tensor(3.3489)\n",
      "2965 Traning Loss: tensor(3.3489)\n",
      "2966 Traning Loss: tensor(3.3489)\n",
      "2967 Traning Loss: tensor(3.3489)\n",
      "2968 Traning Loss: tensor(3.3489)\n",
      "2969 Traning Loss: tensor(3.3489)\n",
      "2970 Traning Loss: tensor(3.3489)\n",
      "2971 Traning Loss: tensor(3.3489)\n",
      "2972 Traning Loss: tensor(3.3489)\n",
      "2973 Traning Loss: tensor(3.3489)\n",
      "2974 Traning Loss: tensor(3.3489)\n",
      "2975 Traning Loss: tensor(3.3489)\n",
      "2976 Traning Loss: tensor(3.3489)\n",
      "2977 Traning Loss: tensor(3.3489)\n",
      "2978 Traning Loss: tensor(3.3489)\n",
      "2979 Traning Loss: tensor(3.3489)\n",
      "2980 Traning Loss: tensor(3.3489)\n",
      "2981 Traning Loss: tensor(3.3489)\n",
      "2982 Traning Loss: tensor(3.3489)\n",
      "2983 Traning Loss: tensor(3.3489)\n",
      "2984 Traning Loss: tensor(3.3489)\n",
      "2985 Traning Loss: tensor(3.3489)\n",
      "2986 Traning Loss: tensor(3.3489)\n",
      "2987 Traning Loss: tensor(3.3489)\n",
      "2988 Traning Loss: tensor(3.3489)\n",
      "2989 Traning Loss: tensor(3.3489)\n",
      "2990 Traning Loss: tensor(3.3489)\n",
      "2991 Traning Loss: tensor(3.3489)\n",
      "2992 Traning Loss: tensor(3.3489)\n",
      "2993 Traning Loss: tensor(3.3489)\n",
      "2994 Traning Loss: tensor(3.3489)\n",
      "2995 Traning Loss: tensor(3.3489)\n",
      "2996 Traning Loss: tensor(3.3489)\n",
      "2997 Traning Loss: tensor(3.3489)\n",
      "2998 Traning Loss: tensor(3.3489)\n",
      "2999 Traning Loss: tensor(3.3489)\n",
      "3000 Traning Loss: tensor(3.3489)\n",
      "3001 Traning Loss: tensor(3.3489)\n",
      "3002 Traning Loss: tensor(3.3489)\n",
      "3003 Traning Loss: tensor(3.3489)\n",
      "3004 Traning Loss: tensor(3.3489)\n",
      "3005 Traning Loss: tensor(3.3489)\n",
      "3006 Traning Loss: tensor(3.3489)\n",
      "3007 Traning Loss: tensor(3.3489)\n",
      "3008 Traning Loss: tensor(3.3489)\n",
      "3009 Traning Loss: tensor(3.3489)\n",
      "3010 Traning Loss: tensor(3.3489)\n",
      "3011 Traning Loss: tensor(3.3489)\n",
      "3012 Traning Loss: tensor(3.3489)\n",
      "3013 Traning Loss: tensor(3.3489)\n",
      "3014 Traning Loss: tensor(3.3489)\n",
      "3015 Traning Loss: tensor(3.3489)\n",
      "3016 Traning Loss: tensor(3.3489)\n",
      "3017 Traning Loss: tensor(3.3489)\n",
      "3018 Traning Loss: tensor(3.3489)\n",
      "3019 Traning Loss: tensor(3.3489)\n",
      "3020 Traning Loss: tensor(3.3489)\n",
      "3021 Traning Loss: tensor(3.3489)\n",
      "3022 Traning Loss: tensor(3.3489)\n",
      "3023 Traning Loss: tensor(3.3489)\n",
      "3024 Traning Loss: tensor(3.3489)\n",
      "3025 Traning Loss: tensor(3.3489)\n",
      "3026 Traning Loss: tensor(3.3489)\n",
      "3027 Traning Loss: tensor(3.3489)\n",
      "3028 Traning Loss: tensor(3.3489)\n",
      "3029 Traning Loss: tensor(3.3489)\n",
      "3030 Traning Loss: tensor(3.3489)\n",
      "3031 Traning Loss: tensor(3.3489)\n",
      "3032 Traning Loss: tensor(3.3489)\n",
      "3033 Traning Loss: tensor(3.3489)\n",
      "3034 Traning Loss: tensor(3.3489)\n",
      "3035 Traning Loss: tensor(3.3489)\n",
      "3036 Traning Loss: tensor(3.3489)\n",
      "3037 Traning Loss: tensor(3.3489)\n",
      "3038 Traning Loss: tensor(3.3489)\n",
      "3039 Traning Loss: tensor(3.3489)\n",
      "3040 Traning Loss: tensor(3.3489)\n",
      "3041 Traning Loss: tensor(3.3489)\n",
      "3042 Traning Loss: tensor(3.3489)\n",
      "3043 Traning Loss: tensor(3.3489)\n",
      "3044 Traning Loss: tensor(3.3489)\n",
      "3045 Traning Loss: tensor(3.3489)\n",
      "3046 Traning Loss: tensor(3.3489)\n",
      "3047 Traning Loss: tensor(3.3489)\n",
      "3048 Traning Loss: tensor(3.3489)\n",
      "3049 Traning Loss: tensor(3.3489)\n",
      "3050 Traning Loss: tensor(3.3489)\n",
      "3051 Traning Loss: tensor(3.3489)\n",
      "3052 Traning Loss: tensor(3.3489)\n",
      "3053 Traning Loss: tensor(3.3489)\n",
      "3054 Traning Loss: tensor(3.3489)\n",
      "3055 Traning Loss: tensor(3.3489)\n",
      "3056 Traning Loss: tensor(3.3489)\n",
      "3057 Traning Loss: tensor(3.3489)\n",
      "3058 Traning Loss: tensor(3.3489)\n",
      "3059 Traning Loss: tensor(3.3489)\n",
      "3060 Traning Loss: tensor(3.3489)\n",
      "3061 Traning Loss: tensor(3.3489)\n",
      "3062 Traning Loss: tensor(3.3489)\n",
      "3063 Traning Loss: tensor(3.3489)\n",
      "3064 Traning Loss: tensor(3.3489)\n",
      "3065 Traning Loss: tensor(3.3489)\n",
      "3066 Traning Loss: tensor(3.3489)\n",
      "3067 Traning Loss: tensor(3.3489)\n",
      "3068 Traning Loss: tensor(3.3489)\n",
      "3069 Traning Loss: tensor(3.3489)\n",
      "3070 Traning Loss: tensor(3.3489)\n",
      "3071 Traning Loss: tensor(3.3489)\n",
      "3072 Traning Loss: tensor(3.3489)\n",
      "3073 Traning Loss: tensor(3.3489)\n",
      "3074 Traning Loss: tensor(3.3489)\n",
      "3075 Traning Loss: tensor(3.3489)\n",
      "3076 Traning Loss: tensor(3.3489)\n",
      "3077 Traning Loss: tensor(3.3489)\n",
      "3078 Traning Loss: tensor(3.3489)\n",
      "3079 Traning Loss: tensor(3.3489)\n",
      "3080 Traning Loss: tensor(3.3489)\n",
      "3081 Traning Loss: tensor(3.3489)\n",
      "3082 Traning Loss: tensor(3.3489)\n",
      "3083 Traning Loss: tensor(3.3489)\n",
      "3084 Traning Loss: tensor(3.3489)\n",
      "3085 Traning Loss: tensor(3.3489)\n",
      "3086 Traning Loss: tensor(3.3489)\n",
      "3087 Traning Loss: tensor(3.3489)\n",
      "3088 Traning Loss: tensor(3.3489)\n",
      "3089 Traning Loss: tensor(3.3489)\n",
      "3090 Traning Loss: tensor(3.3489)\n",
      "3091 Traning Loss: tensor(3.3489)\n",
      "3092 Traning Loss: tensor(3.3489)\n",
      "3093 Traning Loss: tensor(3.3489)\n",
      "3094 Traning Loss: tensor(3.3489)\n",
      "3095 Traning Loss: tensor(3.3489)\n",
      "3096 Traning Loss: tensor(3.3489)\n",
      "3097 Traning Loss: tensor(3.3489)\n",
      "3098 Traning Loss: tensor(3.3489)\n",
      "3099 Traning Loss: tensor(3.3489)\n",
      "3100 Traning Loss: tensor(3.3489)\n",
      "3101 Traning Loss: tensor(3.3489)\n",
      "3102 Traning Loss: tensor(3.3489)\n",
      "3103 Traning Loss: tensor(3.3489)\n",
      "3104 Traning Loss: tensor(3.3489)\n",
      "3105 Traning Loss: tensor(3.3489)\n",
      "3106 Traning Loss: tensor(3.3489)\n",
      "3107 Traning Loss: tensor(3.3489)\n",
      "3108 Traning Loss: tensor(3.3489)\n",
      "3109 Traning Loss: tensor(3.3489)\n",
      "3110 Traning Loss: tensor(3.3489)\n",
      "3111 Traning Loss: tensor(3.3489)\n",
      "3112 Traning Loss: tensor(3.3489)\n",
      "3113 Traning Loss: tensor(3.3489)\n",
      "3114 Traning Loss: tensor(3.3489)\n",
      "3115 Traning Loss: tensor(3.3489)\n",
      "3116 Traning Loss: tensor(3.3489)\n",
      "3117 Traning Loss: tensor(3.3489)\n",
      "3118 Traning Loss: tensor(3.3489)\n",
      "3119 Traning Loss: tensor(3.3489)\n",
      "3120 Traning Loss: tensor(3.3489)\n",
      "3121 Traning Loss: tensor(3.3489)\n",
      "3122 Traning Loss: tensor(3.3489)\n",
      "3123 Traning Loss: tensor(3.3489)\n",
      "3124 Traning Loss: tensor(3.3489)\n",
      "3125 Traning Loss: tensor(3.3489)\n",
      "3126 Traning Loss: tensor(3.3489)\n",
      "3127 Traning Loss: tensor(3.3489)\n",
      "3128 Traning Loss: tensor(3.3489)\n",
      "3129 Traning Loss: tensor(3.3489)\n",
      "3130 Traning Loss: tensor(3.3489)\n",
      "3131 Traning Loss: tensor(3.3489)\n",
      "3132 Traning Loss: tensor(3.3489)\n",
      "3133 Traning Loss: tensor(3.3489)\n",
      "3134 Traning Loss: tensor(3.3489)\n",
      "3135 Traning Loss: tensor(3.3489)\n",
      "3136 Traning Loss: tensor(3.3489)\n",
      "3137 Traning Loss: tensor(3.3489)\n",
      "3138 Traning Loss: tensor(3.3489)\n",
      "3139 Traning Loss: tensor(3.3489)\n",
      "3140 Traning Loss: tensor(3.3489)\n",
      "3141 Traning Loss: tensor(3.3489)\n",
      "3142 Traning Loss: tensor(3.3489)\n",
      "3143 Traning Loss: tensor(3.3489)\n",
      "3144 Traning Loss: tensor(3.3489)\n",
      "3145 Traning Loss: tensor(3.3489)\n",
      "3146 Traning Loss: tensor(3.3489)\n",
      "3147 Traning Loss: tensor(3.3489)\n",
      "3148 Traning Loss: tensor(3.3489)\n",
      "3149 Traning Loss: tensor(3.3489)\n",
      "3150 Traning Loss: tensor(3.3489)\n",
      "3151 Traning Loss: tensor(3.3489)\n",
      "3152 Traning Loss: tensor(3.3489)\n",
      "3153 Traning Loss: tensor(3.3489)\n",
      "3154 Traning Loss: tensor(3.3489)\n",
      "3155 Traning Loss: tensor(3.3489)\n",
      "3156 Traning Loss: tensor(3.3489)\n",
      "3157 Traning Loss: tensor(3.3489)\n",
      "3158 Traning Loss: tensor(3.3489)\n",
      "3159 Traning Loss: tensor(3.3489)\n",
      "3160 Traning Loss: tensor(3.3489)\n",
      "3161 Traning Loss: tensor(3.3489)\n",
      "3162 Traning Loss: tensor(3.3489)\n",
      "3163 Traning Loss: tensor(3.3489)\n",
      "3164 Traning Loss: tensor(3.3489)\n",
      "3165 Traning Loss: tensor(3.3489)\n",
      "3166 Traning Loss: tensor(3.3489)\n",
      "3167 Traning Loss: tensor(3.3489)\n",
      "3168 Traning Loss: tensor(3.3489)\n",
      "3169 Traning Loss: tensor(3.3489)\n",
      "3170 Traning Loss: tensor(3.3489)\n",
      "3171 Traning Loss: tensor(3.3489)\n",
      "3172 Traning Loss: tensor(3.3489)\n",
      "3173 Traning Loss: tensor(3.3489)\n",
      "3174 Traning Loss: tensor(3.3489)\n",
      "3175 Traning Loss: tensor(3.3489)\n",
      "3176 Traning Loss: tensor(3.3489)\n",
      "3177 Traning Loss: tensor(3.3489)\n",
      "3178 Traning Loss: tensor(3.3489)\n",
      "3179 Traning Loss: tensor(3.3489)\n",
      "3180 Traning Loss: tensor(3.3489)\n",
      "3181 Traning Loss: tensor(3.3489)\n",
      "3182 Traning Loss: tensor(3.3489)\n",
      "3183 Traning Loss: tensor(3.3489)\n",
      "3184 Traning Loss: tensor(3.3489)\n",
      "3185 Traning Loss: tensor(3.3489)\n",
      "3186 Traning Loss: tensor(3.3489)\n",
      "3187 Traning Loss: tensor(3.3489)\n",
      "3188 Traning Loss: tensor(3.3489)\n",
      "3189 Traning Loss: tensor(3.3489)\n",
      "3190 Traning Loss: tensor(3.3489)\n",
      "3191 Traning Loss: tensor(3.3489)\n",
      "3192 Traning Loss: tensor(3.3489)\n",
      "3193 Traning Loss: tensor(3.3489)\n",
      "3194 Traning Loss: tensor(3.3489)\n",
      "3195 Traning Loss: tensor(3.3489)\n",
      "3196 Traning Loss: tensor(3.3489)\n",
      "3197 Traning Loss: tensor(3.3489)\n",
      "3198 Traning Loss: tensor(3.3489)\n",
      "3199 Traning Loss: tensor(3.3489)\n",
      "3200 Traning Loss: tensor(3.3489)\n",
      "3201 Traning Loss: tensor(3.3489)\n",
      "3202 Traning Loss: tensor(3.3489)\n",
      "3203 Traning Loss: tensor(3.3489)\n",
      "3204 Traning Loss: tensor(3.3489)\n",
      "3205 Traning Loss: tensor(3.3489)\n",
      "3206 Traning Loss: tensor(3.3489)\n",
      "3207 Traning Loss: tensor(3.3489)\n",
      "3208 Traning Loss: tensor(3.3489)\n",
      "3209 Traning Loss: tensor(3.3489)\n",
      "3210 Traning Loss: tensor(3.3489)\n",
      "3211 Traning Loss: tensor(3.3489)\n",
      "3212 Traning Loss: tensor(3.3489)\n",
      "3213 Traning Loss: tensor(3.3489)\n",
      "3214 Traning Loss: tensor(3.3489)\n",
      "3215 Traning Loss: tensor(3.3489)\n",
      "3216 Traning Loss: tensor(3.3489)\n",
      "3217 Traning Loss: tensor(3.3489)\n",
      "3218 Traning Loss: tensor(3.3489)\n",
      "3219 Traning Loss: tensor(3.3489)\n",
      "3220 Traning Loss: tensor(3.3489)\n",
      "3221 Traning Loss: tensor(3.3489)\n",
      "3222 Traning Loss: tensor(3.3489)\n",
      "3223 Traning Loss: tensor(3.3489)\n",
      "3224 Traning Loss: tensor(3.3489)\n",
      "3225 Traning Loss: tensor(3.3489)\n",
      "3226 Traning Loss: tensor(3.3489)\n",
      "3227 Traning Loss: tensor(3.3489)\n",
      "3228 Traning Loss: tensor(3.3489)\n",
      "3229 Traning Loss: tensor(3.3489)\n",
      "3230 Traning Loss: tensor(3.3489)\n",
      "3231 Traning Loss: tensor(3.3489)\n",
      "3232 Traning Loss: tensor(3.3489)\n",
      "3233 Traning Loss: tensor(3.3489)\n",
      "3234 Traning Loss: tensor(3.3489)\n",
      "3235 Traning Loss: tensor(3.3489)\n",
      "3236 Traning Loss: tensor(3.3489)\n",
      "3237 Traning Loss: tensor(3.3489)\n",
      "3238 Traning Loss: tensor(3.3489)\n",
      "3239 Traning Loss: tensor(3.3489)\n",
      "3240 Traning Loss: tensor(3.3489)\n",
      "3241 Traning Loss: tensor(3.3489)\n",
      "3242 Traning Loss: tensor(3.3489)\n",
      "3243 Traning Loss: tensor(3.3489)\n",
      "3244 Traning Loss: tensor(3.3489)\n",
      "3245 Traning Loss: tensor(3.3489)\n",
      "3246 Traning Loss: tensor(3.3489)\n",
      "3247 Traning Loss: tensor(3.3489)\n",
      "3248 Traning Loss: tensor(3.3489)\n",
      "3249 Traning Loss: tensor(3.3489)\n",
      "3250 Traning Loss: tensor(3.3489)\n",
      "3251 Traning Loss: tensor(3.3489)\n",
      "3252 Traning Loss: tensor(3.3489)\n",
      "3253 Traning Loss: tensor(3.3489)\n",
      "3254 Traning Loss: tensor(3.3489)\n",
      "3255 Traning Loss: tensor(3.3489)\n",
      "3256 Traning Loss: tensor(3.3489)\n",
      "3257 Traning Loss: tensor(3.3489)\n",
      "3258 Traning Loss: tensor(3.3489)\n",
      "3259 Traning Loss: tensor(3.3489)\n",
      "3260 Traning Loss: tensor(3.3489)\n",
      "3261 Traning Loss: tensor(3.3489)\n",
      "3262 Traning Loss: tensor(3.3489)\n",
      "3263 Traning Loss: tensor(3.3489)\n",
      "3264 Traning Loss: tensor(3.3489)\n",
      "3265 Traning Loss: tensor(3.3489)\n",
      "3266 Traning Loss: tensor(3.3489)\n",
      "3267 Traning Loss: tensor(3.3489)\n",
      "3268 Traning Loss: tensor(3.3489)\n",
      "3269 Traning Loss: tensor(3.3489)\n",
      "3270 Traning Loss: tensor(3.3489)\n",
      "3271 Traning Loss: tensor(3.3489)\n",
      "3272 Traning Loss: tensor(3.3489)\n",
      "3273 Traning Loss: tensor(3.3489)\n",
      "3274 Traning Loss: tensor(3.3489)\n",
      "3275 Traning Loss: tensor(3.3489)\n",
      "3276 Traning Loss: tensor(3.3489)\n",
      "3277 Traning Loss: tensor(3.3489)\n",
      "3278 Traning Loss: tensor(3.3489)\n",
      "3279 Traning Loss: tensor(3.3489)\n",
      "3280 Traning Loss: tensor(3.3489)\n",
      "3281 Traning Loss: tensor(3.3489)\n",
      "3282 Traning Loss: tensor(3.3489)\n",
      "3283 Traning Loss: tensor(3.3489)\n",
      "3284 Traning Loss: tensor(3.3489)\n",
      "3285 Traning Loss: tensor(3.3489)\n",
      "3286 Traning Loss: tensor(3.3489)\n",
      "3287 Traning Loss: tensor(3.3489)\n",
      "3288 Traning Loss: tensor(3.3489)\n",
      "3289 Traning Loss: tensor(3.3489)\n",
      "3290 Traning Loss: tensor(3.3489)\n",
      "3291 Traning Loss: tensor(3.3489)\n",
      "3292 Traning Loss: tensor(3.3489)\n",
      "3293 Traning Loss: tensor(3.3489)\n",
      "3294 Traning Loss: tensor(3.3489)\n",
      "3295 Traning Loss: tensor(3.3489)\n",
      "3296 Traning Loss: tensor(3.3489)\n",
      "3297 Traning Loss: tensor(3.3489)\n",
      "3298 Traning Loss: tensor(3.3489)\n",
      "3299 Traning Loss: tensor(3.3489)\n",
      "3300 Traning Loss: tensor(3.3489)\n",
      "3301 Traning Loss: tensor(3.3489)\n",
      "3302 Traning Loss: tensor(3.3489)\n",
      "3303 Traning Loss: tensor(3.3489)\n",
      "3304 Traning Loss: tensor(3.3489)\n",
      "3305 Traning Loss: tensor(3.3489)\n",
      "3306 Traning Loss: tensor(3.3489)\n",
      "3307 Traning Loss: tensor(3.3489)\n",
      "3308 Traning Loss: tensor(3.3489)\n",
      "3309 Traning Loss: tensor(3.3489)\n",
      "3310 Traning Loss: tensor(3.3489)\n",
      "3311 Traning Loss: tensor(3.3489)\n",
      "3312 Traning Loss: tensor(3.3489)\n",
      "3313 Traning Loss: tensor(3.3489)\n",
      "3314 Traning Loss: tensor(3.3489)\n",
      "3315 Traning Loss: tensor(3.3489)\n",
      "3316 Traning Loss: tensor(3.3489)\n",
      "3317 Traning Loss: tensor(3.3489)\n",
      "3318 Traning Loss: tensor(3.3489)\n",
      "3319 Traning Loss: tensor(3.3489)\n",
      "3320 Traning Loss: tensor(3.3489)\n",
      "3321 Traning Loss: tensor(3.3489)\n",
      "3322 Traning Loss: tensor(3.3489)\n",
      "3323 Traning Loss: tensor(3.3489)\n",
      "3324 Traning Loss: tensor(3.3489)\n",
      "3325 Traning Loss: tensor(3.3489)\n",
      "3326 Traning Loss: tensor(3.3489)\n",
      "3327 Traning Loss: tensor(3.3489)\n",
      "3328 Traning Loss: tensor(3.3489)\n",
      "3329 Traning Loss: tensor(3.3489)\n",
      "3330 Traning Loss: tensor(3.3489)\n",
      "3331 Traning Loss: tensor(3.3489)\n",
      "3332 Traning Loss: tensor(3.3489)\n",
      "3333 Traning Loss: tensor(3.3489)\n",
      "3334 Traning Loss: tensor(3.3489)\n",
      "3335 Traning Loss: tensor(3.3489)\n",
      "3336 Traning Loss: tensor(3.3489)\n",
      "3337 Traning Loss: tensor(3.3489)\n",
      "3338 Traning Loss: tensor(3.3489)\n",
      "3339 Traning Loss: tensor(3.3489)\n",
      "3340 Traning Loss: tensor(3.3489)\n",
      "3341 Traning Loss: tensor(3.3489)\n",
      "3342 Traning Loss: tensor(3.3489)\n",
      "3343 Traning Loss: tensor(3.3489)\n",
      "3344 Traning Loss: tensor(3.3489)\n",
      "3345 Traning Loss: tensor(3.3489)\n",
      "3346 Traning Loss: tensor(3.3489)\n",
      "3347 Traning Loss: tensor(3.3489)\n",
      "3348 Traning Loss: tensor(3.3489)\n",
      "3349 Traning Loss: tensor(3.3489)\n",
      "3350 Traning Loss: tensor(3.3489)\n",
      "3351 Traning Loss: tensor(3.3489)\n",
      "3352 Traning Loss: tensor(3.3489)\n",
      "3353 Traning Loss: tensor(3.3489)\n",
      "3354 Traning Loss: tensor(3.3489)\n",
      "3355 Traning Loss: tensor(3.3489)\n",
      "3356 Traning Loss: tensor(3.3489)\n",
      "3357 Traning Loss: tensor(3.3489)\n",
      "3358 Traning Loss: tensor(3.3489)\n",
      "3359 Traning Loss: tensor(3.3489)\n",
      "3360 Traning Loss: tensor(3.3489)\n",
      "3361 Traning Loss: tensor(3.3489)\n",
      "3362 Traning Loss: tensor(3.3489)\n",
      "3363 Traning Loss: tensor(3.3489)\n",
      "3364 Traning Loss: tensor(3.3489)\n",
      "3365 Traning Loss: tensor(3.3489)\n",
      "3366 Traning Loss: tensor(3.3489)\n",
      "3367 Traning Loss: tensor(3.3489)\n",
      "3368 Traning Loss: tensor(3.3489)\n",
      "3369 Traning Loss: tensor(3.3489)\n",
      "3370 Traning Loss: tensor(3.3489)\n",
      "3371 Traning Loss: tensor(3.3489)\n",
      "3372 Traning Loss: tensor(3.3489)\n",
      "3373 Traning Loss: tensor(3.3489)\n",
      "3374 Traning Loss: tensor(3.3489)\n",
      "3375 Traning Loss: tensor(3.3489)\n",
      "3376 Traning Loss: tensor(3.3489)\n",
      "3377 Traning Loss: tensor(3.3489)\n",
      "3378 Traning Loss: tensor(3.3489)\n",
      "3379 Traning Loss: tensor(3.3489)\n",
      "3380 Traning Loss: tensor(3.3489)\n",
      "3381 Traning Loss: tensor(3.3489)\n",
      "3382 Traning Loss: tensor(3.3489)\n",
      "3383 Traning Loss: tensor(3.3489)\n",
      "3384 Traning Loss: tensor(3.3489)\n",
      "3385 Traning Loss: tensor(3.3489)\n",
      "3386 Traning Loss: tensor(3.3489)\n",
      "3387 Traning Loss: tensor(3.3489)\n",
      "3388 Traning Loss: tensor(3.3489)\n",
      "3389 Traning Loss: tensor(3.3489)\n",
      "3390 Traning Loss: tensor(3.3489)\n",
      "3391 Traning Loss: tensor(3.3489)\n",
      "3392 Traning Loss: tensor(3.3489)\n",
      "3393 Traning Loss: tensor(3.3489)\n",
      "3394 Traning Loss: tensor(3.3489)\n",
      "3395 Traning Loss: tensor(3.3489)\n",
      "3396 Traning Loss: tensor(3.3489)\n",
      "3397 Traning Loss: tensor(3.3489)\n",
      "3398 Traning Loss: tensor(3.3489)\n",
      "3399 Traning Loss: tensor(3.3489)\n",
      "3400 Traning Loss: tensor(3.3489)\n",
      "3401 Traning Loss: tensor(3.3489)\n",
      "3402 Traning Loss: tensor(3.3489)\n",
      "3403 Traning Loss: tensor(3.3489)\n",
      "3404 Traning Loss: tensor(3.3489)\n",
      "3405 Traning Loss: tensor(3.3489)\n",
      "3406 Traning Loss: tensor(3.3489)\n",
      "3407 Traning Loss: tensor(3.3489)\n",
      "3408 Traning Loss: tensor(3.3489)\n",
      "3409 Traning Loss: tensor(3.3489)\n",
      "3410 Traning Loss: tensor(3.3489)\n",
      "3411 Traning Loss: tensor(3.3489)\n",
      "3412 Traning Loss: tensor(3.3489)\n",
      "3413 Traning Loss: tensor(3.3489)\n",
      "3414 Traning Loss: tensor(3.3489)\n",
      "3415 Traning Loss: tensor(3.3489)\n",
      "3416 Traning Loss: tensor(3.3489)\n",
      "3417 Traning Loss: tensor(3.3489)\n",
      "3418 Traning Loss: tensor(3.3489)\n",
      "3419 Traning Loss: tensor(3.3489)\n",
      "3420 Traning Loss: tensor(3.3489)\n",
      "3421 Traning Loss: tensor(3.3489)\n",
      "3422 Traning Loss: tensor(3.3489)\n",
      "3423 Traning Loss: tensor(3.3489)\n",
      "3424 Traning Loss: tensor(3.3489)\n",
      "3425 Traning Loss: tensor(3.3489)\n",
      "3426 Traning Loss: tensor(3.3489)\n",
      "3427 Traning Loss: tensor(3.3489)\n",
      "3428 Traning Loss: tensor(3.3489)\n",
      "3429 Traning Loss: tensor(3.3489)\n",
      "3430 Traning Loss: tensor(3.3489)\n",
      "3431 Traning Loss: tensor(3.3489)\n",
      "3432 Traning Loss: tensor(3.3489)\n",
      "3433 Traning Loss: tensor(3.3489)\n",
      "3434 Traning Loss: tensor(3.3489)\n",
      "3435 Traning Loss: tensor(3.3489)\n",
      "3436 Traning Loss: tensor(3.3489)\n",
      "3437 Traning Loss: tensor(3.3489)\n",
      "3438 Traning Loss: tensor(3.3489)\n",
      "3439 Traning Loss: tensor(3.3489)\n",
      "3440 Traning Loss: tensor(3.3489)\n",
      "3441 Traning Loss: tensor(3.3489)\n",
      "3442 Traning Loss: tensor(3.3489)\n",
      "3443 Traning Loss: tensor(3.3489)\n",
      "3444 Traning Loss: tensor(3.3489)\n",
      "3445 Traning Loss: tensor(3.3489)\n",
      "3446 Traning Loss: tensor(3.3489)\n",
      "3447 Traning Loss: tensor(3.3489)\n",
      "3448 Traning Loss: tensor(3.3489)\n",
      "3449 Traning Loss: tensor(3.3489)\n",
      "3450 Traning Loss: tensor(3.3489)\n",
      "3451 Traning Loss: tensor(3.3489)\n",
      "3452 Traning Loss: tensor(3.3489)\n",
      "3453 Traning Loss: tensor(3.3489)\n",
      "3454 Traning Loss: tensor(3.3489)\n",
      "3455 Traning Loss: tensor(3.3489)\n",
      "3456 Traning Loss: tensor(3.3489)\n",
      "3457 Traning Loss: tensor(3.3489)\n",
      "3458 Traning Loss: tensor(3.3489)\n",
      "3459 Traning Loss: tensor(3.3489)\n",
      "3460 Traning Loss: tensor(3.3489)\n",
      "3461 Traning Loss: tensor(3.3489)\n",
      "3462 Traning Loss: tensor(3.3489)\n",
      "3463 Traning Loss: tensor(3.3489)\n",
      "3464 Traning Loss: tensor(3.3489)\n",
      "3465 Traning Loss: tensor(3.3489)\n",
      "3466 Traning Loss: tensor(3.3489)\n",
      "3467 Traning Loss: tensor(3.3489)\n",
      "3468 Traning Loss: tensor(3.3489)\n",
      "3469 Traning Loss: tensor(3.3489)\n",
      "3470 Traning Loss: tensor(3.3489)\n",
      "3471 Traning Loss: tensor(3.3489)\n",
      "3472 Traning Loss: tensor(3.3489)\n",
      "3473 Traning Loss: tensor(3.3489)\n",
      "3474 Traning Loss: tensor(3.3489)\n",
      "3475 Traning Loss: tensor(3.3489)\n",
      "3476 Traning Loss: tensor(3.3489)\n",
      "3477 Traning Loss: tensor(3.3489)\n",
      "3478 Traning Loss: tensor(3.3489)\n",
      "3479 Traning Loss: tensor(3.3489)\n",
      "3480 Traning Loss: tensor(3.3489)\n",
      "3481 Traning Loss: tensor(3.3489)\n",
      "3482 Traning Loss: tensor(3.3489)\n",
      "3483 Traning Loss: tensor(3.3489)\n",
      "3484 Traning Loss: tensor(3.3489)\n",
      "3485 Traning Loss: tensor(3.3489)\n",
      "3486 Traning Loss: tensor(3.3489)\n",
      "3487 Traning Loss: tensor(3.3489)\n",
      "3488 Traning Loss: tensor(3.3489)\n",
      "3489 Traning Loss: tensor(3.3489)\n",
      "3490 Traning Loss: tensor(3.3489)\n",
      "3491 Traning Loss: tensor(3.3489)\n",
      "3492 Traning Loss: tensor(3.3489)\n",
      "3493 Traning Loss: tensor(3.3489)\n",
      "3494 Traning Loss: tensor(3.3489)\n",
      "3495 Traning Loss: tensor(3.3489)\n",
      "3496 Traning Loss: tensor(3.3489)\n",
      "3497 Traning Loss: tensor(3.3489)\n",
      "3498 Traning Loss: tensor(3.3489)\n",
      "3499 Traning Loss: tensor(3.3489)\n",
      "3500 Traning Loss: tensor(3.3489)\n",
      "3501 Traning Loss: tensor(3.3489)\n",
      "3502 Traning Loss: tensor(3.3489)\n",
      "3503 Traning Loss: tensor(3.3489)\n",
      "3504 Traning Loss: tensor(3.3489)\n",
      "3505 Traning Loss: tensor(3.3489)\n",
      "3506 Traning Loss: tensor(3.3489)\n",
      "3507 Traning Loss: tensor(3.3489)\n",
      "3508 Traning Loss: tensor(3.3489)\n",
      "3509 Traning Loss: tensor(3.3489)\n",
      "3510 Traning Loss: tensor(3.3489)\n",
      "3511 Traning Loss: tensor(3.3489)\n",
      "3512 Traning Loss: tensor(3.3489)\n",
      "3513 Traning Loss: tensor(3.3489)\n",
      "3514 Traning Loss: tensor(3.3489)\n",
      "3515 Traning Loss: tensor(3.3489)\n",
      "3516 Traning Loss: tensor(3.3489)\n",
      "3517 Traning Loss: tensor(3.3489)\n",
      "3518 Traning Loss: tensor(3.3489)\n",
      "3519 Traning Loss: tensor(3.3489)\n",
      "3520 Traning Loss: tensor(3.3489)\n",
      "3521 Traning Loss: tensor(3.3489)\n",
      "3522 Traning Loss: tensor(3.3489)\n",
      "3523 Traning Loss: tensor(3.3489)\n",
      "3524 Traning Loss: tensor(3.3489)\n",
      "3525 Traning Loss: tensor(3.3489)\n",
      "3526 Traning Loss: tensor(3.3489)\n",
      "3527 Traning Loss: tensor(3.3489)\n",
      "3528 Traning Loss: tensor(3.3489)\n",
      "3529 Traning Loss: tensor(3.3489)\n",
      "3530 Traning Loss: tensor(3.3489)\n",
      "3531 Traning Loss: tensor(3.3489)\n",
      "3532 Traning Loss: tensor(3.3489)\n",
      "3533 Traning Loss: tensor(3.3489)\n",
      "3534 Traning Loss: tensor(3.3489)\n",
      "3535 Traning Loss: tensor(3.3489)\n",
      "3536 Traning Loss: tensor(3.3489)\n",
      "3537 Traning Loss: tensor(3.3489)\n",
      "3538 Traning Loss: tensor(3.3489)\n",
      "3539 Traning Loss: tensor(3.3489)\n",
      "3540 Traning Loss: tensor(3.3489)\n",
      "3541 Traning Loss: tensor(3.3489)\n",
      "3542 Traning Loss: tensor(3.3489)\n",
      "3543 Traning Loss: tensor(3.3489)\n",
      "3544 Traning Loss: tensor(3.3489)\n",
      "3545 Traning Loss: tensor(3.3489)\n",
      "3546 Traning Loss: tensor(3.3489)\n",
      "3547 Traning Loss: tensor(3.3489)\n",
      "3548 Traning Loss: tensor(3.3489)\n",
      "3549 Traning Loss: tensor(3.3489)\n",
      "3550 Traning Loss: tensor(3.3489)\n",
      "3551 Traning Loss: tensor(3.3489)\n",
      "3552 Traning Loss: tensor(3.3489)\n",
      "3553 Traning Loss: tensor(3.3489)\n",
      "3554 Traning Loss: tensor(3.3489)\n",
      "3555 Traning Loss: tensor(3.3489)\n",
      "3556 Traning Loss: tensor(3.3489)\n",
      "3557 Traning Loss: tensor(3.3489)\n",
      "3558 Traning Loss: tensor(3.3489)\n",
      "3559 Traning Loss: tensor(3.3489)\n",
      "3560 Traning Loss: tensor(3.3489)\n",
      "3561 Traning Loss: tensor(3.3489)\n",
      "3562 Traning Loss: tensor(3.3489)\n",
      "3563 Traning Loss: tensor(3.3489)\n",
      "3564 Traning Loss: tensor(3.3489)\n",
      "3565 Traning Loss: tensor(3.3489)\n",
      "3566 Traning Loss: tensor(3.3489)\n",
      "3567 Traning Loss: tensor(3.3489)\n",
      "3568 Traning Loss: tensor(3.3489)\n",
      "3569 Traning Loss: tensor(3.3489)\n",
      "3570 Traning Loss: tensor(3.3489)\n",
      "3571 Traning Loss: tensor(3.3489)\n",
      "3572 Traning Loss: tensor(3.3489)\n",
      "3573 Traning Loss: tensor(3.3489)\n",
      "3574 Traning Loss: tensor(3.3489)\n",
      "3575 Traning Loss: tensor(3.3489)\n",
      "3576 Traning Loss: tensor(3.3489)\n",
      "3577 Traning Loss: tensor(3.3489)\n",
      "3578 Traning Loss: tensor(3.3489)\n",
      "3579 Traning Loss: tensor(3.3489)\n",
      "3580 Traning Loss: tensor(3.3489)\n",
      "3581 Traning Loss: tensor(3.3489)\n",
      "3582 Traning Loss: tensor(3.3489)\n",
      "3583 Traning Loss: tensor(3.3489)\n",
      "3584 Traning Loss: tensor(3.3489)\n",
      "3585 Traning Loss: tensor(3.3489)\n",
      "3586 Traning Loss: tensor(3.3489)\n",
      "3587 Traning Loss: tensor(3.3489)\n",
      "3588 Traning Loss: tensor(3.3489)\n",
      "3589 Traning Loss: tensor(3.3489)\n",
      "3590 Traning Loss: tensor(3.3489)\n",
      "3591 Traning Loss: tensor(3.3489)\n",
      "3592 Traning Loss: tensor(3.3489)\n",
      "3593 Traning Loss: tensor(3.3489)\n",
      "3594 Traning Loss: tensor(3.3489)\n",
      "3595 Traning Loss: tensor(3.3489)\n",
      "3596 Traning Loss: tensor(3.3489)\n",
      "3597 Traning Loss: tensor(3.3489)\n",
      "3598 Traning Loss: tensor(3.3489)\n",
      "3599 Traning Loss: tensor(3.3489)\n",
      "3600 Traning Loss: tensor(3.3489)\n",
      "3601 Traning Loss: tensor(3.3489)\n",
      "3602 Traning Loss: tensor(3.3489)\n",
      "3603 Traning Loss: tensor(3.3489)\n",
      "3604 Traning Loss: tensor(3.3489)\n",
      "3605 Traning Loss: tensor(3.3489)\n",
      "3606 Traning Loss: tensor(3.3489)\n",
      "3607 Traning Loss: tensor(3.3489)\n",
      "3608 Traning Loss: tensor(3.3489)\n",
      "3609 Traning Loss: tensor(3.3489)\n",
      "3610 Traning Loss: tensor(3.3489)\n",
      "3611 Traning Loss: tensor(3.3489)\n",
      "3612 Traning Loss: tensor(3.3489)\n",
      "3613 Traning Loss: tensor(3.3489)\n",
      "3614 Traning Loss: tensor(3.3489)\n",
      "3615 Traning Loss: tensor(3.3489)\n",
      "3616 Traning Loss: tensor(3.3489)\n",
      "3617 Traning Loss: tensor(3.3489)\n",
      "3618 Traning Loss: tensor(3.3489)\n",
      "3619 Traning Loss: tensor(3.3489)\n",
      "3620 Traning Loss: tensor(3.3489)\n",
      "3621 Traning Loss: tensor(3.3489)\n",
      "3622 Traning Loss: tensor(3.3489)\n",
      "3623 Traning Loss: tensor(3.3489)\n",
      "3624 Traning Loss: tensor(3.3489)\n",
      "3625 Traning Loss: tensor(3.3489)\n",
      "3626 Traning Loss: tensor(3.3489)\n",
      "3627 Traning Loss: tensor(3.3489)\n",
      "3628 Traning Loss: tensor(3.3489)\n",
      "3629 Traning Loss: tensor(3.3489)\n",
      "3630 Traning Loss: tensor(3.3489)\n",
      "3631 Traning Loss: tensor(3.3489)\n",
      "3632 Traning Loss: tensor(3.3489)\n",
      "3633 Traning Loss: tensor(3.3489)\n",
      "3634 Traning Loss: tensor(3.3489)\n",
      "3635 Traning Loss: tensor(3.3489)\n",
      "3636 Traning Loss: tensor(3.3489)\n",
      "3637 Traning Loss: tensor(3.3489)\n",
      "3638 Traning Loss: tensor(3.3489)\n",
      "3639 Traning Loss: tensor(3.3489)\n",
      "3640 Traning Loss: tensor(3.3489)\n",
      "3641 Traning Loss: tensor(3.3489)\n",
      "3642 Traning Loss: tensor(3.3489)\n",
      "3643 Traning Loss: tensor(3.3489)\n",
      "3644 Traning Loss: tensor(3.3489)\n",
      "3645 Traning Loss: tensor(3.3489)\n",
      "3646 Traning Loss: tensor(3.3489)\n",
      "3647 Traning Loss: tensor(3.3489)\n",
      "3648 Traning Loss: tensor(3.3489)\n",
      "3649 Traning Loss: tensor(3.3489)\n",
      "3650 Traning Loss: tensor(3.3489)\n",
      "3651 Traning Loss: tensor(3.3489)\n",
      "3652 Traning Loss: tensor(3.3489)\n",
      "3653 Traning Loss: tensor(3.3489)\n",
      "3654 Traning Loss: tensor(3.3489)\n",
      "3655 Traning Loss: tensor(3.3489)\n",
      "3656 Traning Loss: tensor(3.3489)\n",
      "3657 Traning Loss: tensor(3.3489)\n",
      "3658 Traning Loss: tensor(3.3489)\n",
      "3659 Traning Loss: tensor(3.3489)\n",
      "3660 Traning Loss: tensor(3.3489)\n",
      "3661 Traning Loss: tensor(3.3489)\n",
      "3662 Traning Loss: tensor(3.3489)\n",
      "3663 Traning Loss: tensor(3.3489)\n",
      "3664 Traning Loss: tensor(3.3489)\n",
      "3665 Traning Loss: tensor(3.3489)\n",
      "3666 Traning Loss: tensor(3.3489)\n",
      "3667 Traning Loss: tensor(3.3489)\n",
      "3668 Traning Loss: tensor(3.3489)\n",
      "3669 Traning Loss: tensor(3.3489)\n",
      "3670 Traning Loss: tensor(3.3489)\n",
      "3671 Traning Loss: tensor(3.3489)\n",
      "3672 Traning Loss: tensor(3.3489)\n",
      "3673 Traning Loss: tensor(3.3489)\n",
      "3674 Traning Loss: tensor(3.3489)\n",
      "3675 Traning Loss: tensor(3.3489)\n",
      "3676 Traning Loss: tensor(3.3489)\n",
      "3677 Traning Loss: tensor(3.3489)\n",
      "3678 Traning Loss: tensor(3.3489)\n",
      "3679 Traning Loss: tensor(3.3489)\n",
      "3680 Traning Loss: tensor(3.3489)\n",
      "3681 Traning Loss: tensor(3.3489)\n",
      "3682 Traning Loss: tensor(3.3489)\n",
      "3683 Traning Loss: tensor(3.3489)\n",
      "3684 Traning Loss: tensor(3.3489)\n",
      "3685 Traning Loss: tensor(3.3489)\n",
      "3686 Traning Loss: tensor(3.3489)\n",
      "3687 Traning Loss: tensor(3.3489)\n",
      "3688 Traning Loss: tensor(3.3489)\n",
      "3689 Traning Loss: tensor(3.3489)\n",
      "3690 Traning Loss: tensor(3.3489)\n",
      "3691 Traning Loss: tensor(3.3489)\n",
      "3692 Traning Loss: tensor(3.3489)\n",
      "3693 Traning Loss: tensor(3.3489)\n",
      "3694 Traning Loss: tensor(3.3489)\n",
      "3695 Traning Loss: tensor(3.3489)\n",
      "3696 Traning Loss: tensor(3.3489)\n",
      "3697 Traning Loss: tensor(3.3489)\n",
      "3698 Traning Loss: tensor(3.3489)\n",
      "3699 Traning Loss: tensor(3.3489)\n",
      "3700 Traning Loss: tensor(3.3489)\n",
      "3701 Traning Loss: tensor(3.3489)\n",
      "3702 Traning Loss: tensor(3.3489)\n",
      "3703 Traning Loss: tensor(3.3489)\n",
      "3704 Traning Loss: tensor(3.3489)\n",
      "3705 Traning Loss: tensor(3.3489)\n",
      "3706 Traning Loss: tensor(3.3489)\n",
      "3707 Traning Loss: tensor(3.3489)\n",
      "3708 Traning Loss: tensor(3.3489)\n",
      "3709 Traning Loss: tensor(3.3489)\n",
      "3710 Traning Loss: tensor(3.3489)\n",
      "3711 Traning Loss: tensor(3.3489)\n",
      "3712 Traning Loss: tensor(3.3489)\n",
      "3713 Traning Loss: tensor(3.3489)\n",
      "3714 Traning Loss: tensor(3.3489)\n",
      "3715 Traning Loss: tensor(3.3489)\n",
      "3716 Traning Loss: tensor(3.3489)\n",
      "3717 Traning Loss: tensor(3.3489)\n",
      "3718 Traning Loss: tensor(3.3489)\n",
      "3719 Traning Loss: tensor(3.3489)\n",
      "3720 Traning Loss: tensor(3.3489)\n",
      "3721 Traning Loss: tensor(3.3489)\n",
      "3722 Traning Loss: tensor(3.3489)\n",
      "3723 Traning Loss: tensor(3.3489)\n",
      "3724 Traning Loss: tensor(3.3489)\n",
      "3725 Traning Loss: tensor(3.3489)\n",
      "3726 Traning Loss: tensor(3.3489)\n",
      "3727 Traning Loss: tensor(3.3489)\n",
      "3728 Traning Loss: tensor(3.3489)\n",
      "3729 Traning Loss: tensor(3.3489)\n",
      "3730 Traning Loss: tensor(3.3489)\n",
      "3731 Traning Loss: tensor(3.3489)\n",
      "3732 Traning Loss: tensor(3.3489)\n",
      "3733 Traning Loss: tensor(3.3489)\n",
      "3734 Traning Loss: tensor(3.3489)\n",
      "3735 Traning Loss: tensor(3.3489)\n",
      "3736 Traning Loss: tensor(3.3489)\n",
      "3737 Traning Loss: tensor(3.3489)\n",
      "3738 Traning Loss: tensor(3.3489)\n",
      "3739 Traning Loss: tensor(3.3489)\n",
      "3740 Traning Loss: tensor(3.3489)\n",
      "3741 Traning Loss: tensor(3.3489)\n",
      "3742 Traning Loss: tensor(3.3489)\n",
      "3743 Traning Loss: tensor(3.3489)\n",
      "3744 Traning Loss: tensor(3.3489)\n",
      "3745 Traning Loss: tensor(3.3489)\n",
      "3746 Traning Loss: tensor(3.3489)\n",
      "3747 Traning Loss: tensor(3.3489)\n",
      "3748 Traning Loss: tensor(3.3489)\n",
      "3749 Traning Loss: tensor(3.3489)\n",
      "3750 Traning Loss: tensor(3.3489)\n",
      "3751 Traning Loss: tensor(3.3489)\n",
      "3752 Traning Loss: tensor(3.3489)\n",
      "3753 Traning Loss: tensor(3.3489)\n",
      "3754 Traning Loss: tensor(3.3489)\n",
      "3755 Traning Loss: tensor(3.3489)\n",
      "3756 Traning Loss: tensor(3.3489)\n",
      "3757 Traning Loss: tensor(3.3489)\n",
      "3758 Traning Loss: tensor(3.3489)\n",
      "3759 Traning Loss: tensor(3.3489)\n",
      "3760 Traning Loss: tensor(3.3489)\n",
      "3761 Traning Loss: tensor(3.3489)\n",
      "3762 Traning Loss: tensor(3.3489)\n",
      "3763 Traning Loss: tensor(3.3489)\n",
      "3764 Traning Loss: tensor(3.3489)\n",
      "3765 Traning Loss: tensor(3.3489)\n",
      "3766 Traning Loss: tensor(3.3489)\n",
      "3767 Traning Loss: tensor(3.3489)\n",
      "3768 Traning Loss: tensor(3.3489)\n",
      "3769 Traning Loss: tensor(3.3489)\n",
      "3770 Traning Loss: tensor(3.3489)\n",
      "3771 Traning Loss: tensor(3.3489)\n",
      "3772 Traning Loss: tensor(3.3489)\n",
      "3773 Traning Loss: tensor(3.3489)\n",
      "3774 Traning Loss: tensor(3.3489)\n",
      "3775 Traning Loss: tensor(3.3489)\n",
      "3776 Traning Loss: tensor(3.3489)\n",
      "3777 Traning Loss: tensor(3.3489)\n",
      "3778 Traning Loss: tensor(3.3489)\n",
      "3779 Traning Loss: tensor(3.3489)\n",
      "3780 Traning Loss: tensor(3.3489)\n",
      "3781 Traning Loss: tensor(3.3489)\n",
      "3782 Traning Loss: tensor(3.3489)\n",
      "3783 Traning Loss: tensor(3.3489)\n",
      "3784 Traning Loss: tensor(3.3489)\n",
      "3785 Traning Loss: tensor(3.3489)\n",
      "3786 Traning Loss: tensor(3.3489)\n",
      "3787 Traning Loss: tensor(3.3489)\n",
      "3788 Traning Loss: tensor(3.3489)\n",
      "3789 Traning Loss: tensor(3.3489)\n",
      "3790 Traning Loss: tensor(3.3489)\n",
      "3791 Traning Loss: tensor(3.3489)\n",
      "3792 Traning Loss: tensor(3.3489)\n",
      "3793 Traning Loss: tensor(3.3489)\n",
      "3794 Traning Loss: tensor(3.3489)\n",
      "3795 Traning Loss: tensor(3.3489)\n",
      "3796 Traning Loss: tensor(3.3489)\n",
      "3797 Traning Loss: tensor(3.3489)\n",
      "3798 Traning Loss: tensor(3.3489)\n",
      "3799 Traning Loss: tensor(3.3489)\n",
      "3800 Traning Loss: tensor(3.3489)\n",
      "3801 Traning Loss: tensor(3.3489)\n",
      "3802 Traning Loss: tensor(3.3489)\n",
      "3803 Traning Loss: tensor(3.3489)\n",
      "3804 Traning Loss: tensor(3.3489)\n",
      "3805 Traning Loss: tensor(3.3489)\n",
      "3806 Traning Loss: tensor(3.3489)\n",
      "3807 Traning Loss: tensor(3.3489)\n",
      "3808 Traning Loss: tensor(3.3489)\n",
      "3809 Traning Loss: tensor(3.3489)\n",
      "3810 Traning Loss: tensor(3.3489)\n",
      "3811 Traning Loss: tensor(3.3489)\n",
      "3812 Traning Loss: tensor(3.3489)\n",
      "3813 Traning Loss: tensor(3.3489)\n",
      "3814 Traning Loss: tensor(3.3489)\n",
      "3815 Traning Loss: tensor(3.3489)\n",
      "3816 Traning Loss: tensor(3.3489)\n",
      "3817 Traning Loss: tensor(3.3489)\n",
      "3818 Traning Loss: tensor(3.3489)\n",
      "3819 Traning Loss: tensor(3.3489)\n",
      "3820 Traning Loss: tensor(3.3489)\n",
      "3821 Traning Loss: tensor(3.3489)\n",
      "3822 Traning Loss: tensor(3.3489)\n",
      "3823 Traning Loss: tensor(3.3489)\n",
      "3824 Traning Loss: tensor(3.3489)\n",
      "3825 Traning Loss: tensor(3.3489)\n",
      "3826 Traning Loss: tensor(3.3489)\n",
      "3827 Traning Loss: tensor(3.3489)\n",
      "3828 Traning Loss: tensor(3.3489)\n",
      "3829 Traning Loss: tensor(3.3489)\n",
      "3830 Traning Loss: tensor(3.3489)\n",
      "3831 Traning Loss: tensor(3.3489)\n",
      "3832 Traning Loss: tensor(3.3489)\n",
      "3833 Traning Loss: tensor(3.3489)\n",
      "3834 Traning Loss: tensor(3.3489)\n",
      "3835 Traning Loss: tensor(3.3489)\n",
      "3836 Traning Loss: tensor(3.3489)\n",
      "3837 Traning Loss: tensor(3.3489)\n",
      "3838 Traning Loss: tensor(3.3489)\n",
      "3839 Traning Loss: tensor(3.3489)\n",
      "3840 Traning Loss: tensor(3.3489)\n",
      "3841 Traning Loss: tensor(3.3489)\n",
      "3842 Traning Loss: tensor(3.3489)\n",
      "3843 Traning Loss: tensor(3.3489)\n",
      "3844 Traning Loss: tensor(3.3489)\n",
      "3845 Traning Loss: tensor(3.3489)\n",
      "3846 Traning Loss: tensor(3.3489)\n",
      "3847 Traning Loss: tensor(3.3489)\n",
      "3848 Traning Loss: tensor(3.3489)\n",
      "3849 Traning Loss: tensor(3.3489)\n",
      "3850 Traning Loss: tensor(3.3489)\n",
      "3851 Traning Loss: tensor(3.3489)\n",
      "3852 Traning Loss: tensor(3.3489)\n",
      "3853 Traning Loss: tensor(3.3489)\n",
      "3854 Traning Loss: tensor(3.3489)\n",
      "3855 Traning Loss: tensor(3.3489)\n",
      "3856 Traning Loss: tensor(3.3489)\n",
      "3857 Traning Loss: tensor(3.3489)\n",
      "3858 Traning Loss: tensor(3.3489)\n",
      "3859 Traning Loss: tensor(3.3489)\n",
      "3860 Traning Loss: tensor(3.3489)\n",
      "3861 Traning Loss: tensor(3.3489)\n",
      "3862 Traning Loss: tensor(3.3489)\n",
      "3863 Traning Loss: tensor(3.3489)\n",
      "3864 Traning Loss: tensor(3.3489)\n",
      "3865 Traning Loss: tensor(3.3489)\n",
      "3866 Traning Loss: tensor(3.3489)\n",
      "3867 Traning Loss: tensor(3.3489)\n",
      "3868 Traning Loss: tensor(3.3489)\n",
      "3869 Traning Loss: tensor(3.3489)\n",
      "3870 Traning Loss: tensor(3.3489)\n",
      "3871 Traning Loss: tensor(3.3489)\n",
      "3872 Traning Loss: tensor(3.3489)\n",
      "3873 Traning Loss: tensor(3.3489)\n",
      "3874 Traning Loss: tensor(3.3489)\n",
      "3875 Traning Loss: tensor(3.3489)\n",
      "3876 Traning Loss: tensor(3.3489)\n",
      "3877 Traning Loss: tensor(3.3489)\n",
      "3878 Traning Loss: tensor(3.3489)\n",
      "3879 Traning Loss: tensor(3.3489)\n",
      "3880 Traning Loss: tensor(3.3489)\n",
      "3881 Traning Loss: tensor(3.3489)\n",
      "3882 Traning Loss: tensor(3.3489)\n",
      "3883 Traning Loss: tensor(3.3489)\n",
      "3884 Traning Loss: tensor(3.3489)\n",
      "3885 Traning Loss: tensor(3.3489)\n",
      "3886 Traning Loss: tensor(3.3489)\n",
      "3887 Traning Loss: tensor(3.3489)\n",
      "3888 Traning Loss: tensor(3.3489)\n",
      "3889 Traning Loss: tensor(3.3489)\n",
      "3890 Traning Loss: tensor(3.3489)\n",
      "3891 Traning Loss: tensor(3.3489)\n",
      "3892 Traning Loss: tensor(3.3489)\n",
      "3893 Traning Loss: tensor(3.3489)\n",
      "3894 Traning Loss: tensor(3.3489)\n",
      "3895 Traning Loss: tensor(3.3489)\n",
      "3896 Traning Loss: tensor(3.3489)\n",
      "3897 Traning Loss: tensor(3.3489)\n",
      "3898 Traning Loss: tensor(3.3489)\n",
      "3899 Traning Loss: tensor(3.3489)\n",
      "3900 Traning Loss: tensor(3.3489)\n",
      "3901 Traning Loss: tensor(3.3489)\n",
      "3902 Traning Loss: tensor(3.3489)\n",
      "3903 Traning Loss: tensor(3.3489)\n",
      "3904 Traning Loss: tensor(3.3489)\n",
      "3905 Traning Loss: tensor(3.3489)\n",
      "3906 Traning Loss: tensor(3.3489)\n",
      "3907 Traning Loss: tensor(3.3489)\n",
      "3908 Traning Loss: tensor(3.3489)\n",
      "3909 Traning Loss: tensor(3.3489)\n",
      "3910 Traning Loss: tensor(3.3489)\n",
      "3911 Traning Loss: tensor(3.3489)\n",
      "3912 Traning Loss: tensor(3.3489)\n",
      "3913 Traning Loss: tensor(3.3489)\n",
      "3914 Traning Loss: tensor(3.3489)\n",
      "3915 Traning Loss: tensor(3.3489)\n",
      "3916 Traning Loss: tensor(3.3489)\n",
      "3917 Traning Loss: tensor(3.3489)\n",
      "3918 Traning Loss: tensor(3.3489)\n",
      "3919 Traning Loss: tensor(3.3489)\n",
      "3920 Traning Loss: tensor(3.3489)\n",
      "3921 Traning Loss: tensor(3.3489)\n",
      "3922 Traning Loss: tensor(3.3489)\n",
      "3923 Traning Loss: tensor(3.3489)\n",
      "3924 Traning Loss: tensor(3.3489)\n",
      "3925 Traning Loss: tensor(3.3489)\n",
      "3926 Traning Loss: tensor(3.3489)\n",
      "3927 Traning Loss: tensor(3.3489)\n",
      "3928 Traning Loss: tensor(3.3489)\n",
      "3929 Traning Loss: tensor(3.3489)\n",
      "3930 Traning Loss: tensor(3.3489)\n",
      "3931 Traning Loss: tensor(3.3489)\n",
      "3932 Traning Loss: tensor(3.3489)\n",
      "3933 Traning Loss: tensor(3.3489)\n",
      "3934 Traning Loss: tensor(3.3489)\n",
      "3935 Traning Loss: tensor(3.3489)\n",
      "3936 Traning Loss: tensor(3.3489)\n",
      "3937 Traning Loss: tensor(3.3489)\n",
      "3938 Traning Loss: tensor(3.3489)\n",
      "3939 Traning Loss: tensor(3.3489)\n",
      "3940 Traning Loss: tensor(3.3489)\n",
      "3941 Traning Loss: tensor(3.3489)\n",
      "3942 Traning Loss: tensor(3.3489)\n",
      "3943 Traning Loss: tensor(3.3489)\n",
      "3944 Traning Loss: tensor(3.3489)\n",
      "3945 Traning Loss: tensor(3.3489)\n",
      "3946 Traning Loss: tensor(3.3489)\n",
      "3947 Traning Loss: tensor(3.3489)\n",
      "3948 Traning Loss: tensor(3.3489)\n",
      "3949 Traning Loss: tensor(3.3489)\n",
      "3950 Traning Loss: tensor(3.3489)\n",
      "3951 Traning Loss: tensor(3.3489)\n",
      "3952 Traning Loss: tensor(3.3489)\n",
      "3953 Traning Loss: tensor(3.3489)\n",
      "3954 Traning Loss: tensor(3.3489)\n",
      "3955 Traning Loss: tensor(3.3489)\n",
      "3956 Traning Loss: tensor(3.3489)\n",
      "3957 Traning Loss: tensor(3.3489)\n",
      "3958 Traning Loss: tensor(3.3489)\n",
      "3959 Traning Loss: tensor(3.3489)\n",
      "3960 Traning Loss: tensor(3.3489)\n",
      "3961 Traning Loss: tensor(3.3489)\n",
      "3962 Traning Loss: tensor(3.3489)\n",
      "3963 Traning Loss: tensor(3.3489)\n",
      "3964 Traning Loss: tensor(3.3489)\n",
      "3965 Traning Loss: tensor(3.3489)\n",
      "3966 Traning Loss: tensor(3.3489)\n",
      "3967 Traning Loss: tensor(3.3489)\n",
      "3968 Traning Loss: tensor(3.3489)\n",
      "3969 Traning Loss: tensor(3.3489)\n",
      "3970 Traning Loss: tensor(3.3489)\n",
      "3971 Traning Loss: tensor(3.3489)\n",
      "3972 Traning Loss: tensor(3.3489)\n",
      "3973 Traning Loss: tensor(3.3489)\n",
      "3974 Traning Loss: tensor(3.3489)\n",
      "3975 Traning Loss: tensor(3.3489)\n",
      "3976 Traning Loss: tensor(3.3489)\n",
      "3977 Traning Loss: tensor(3.3489)\n",
      "3978 Traning Loss: tensor(3.3489)\n",
      "3979 Traning Loss: tensor(3.3489)\n",
      "3980 Traning Loss: tensor(3.3489)\n",
      "3981 Traning Loss: tensor(3.3489)\n",
      "3982 Traning Loss: tensor(3.3489)\n",
      "3983 Traning Loss: tensor(3.3489)\n",
      "3984 Traning Loss: tensor(3.3489)\n",
      "3985 Traning Loss: tensor(3.3489)\n",
      "3986 Traning Loss: tensor(3.3489)\n",
      "3987 Traning Loss: tensor(3.3489)\n",
      "3988 Traning Loss: tensor(3.3489)\n",
      "3989 Traning Loss: tensor(3.3489)\n",
      "3990 Traning Loss: tensor(3.3489)\n",
      "3991 Traning Loss: tensor(3.3489)\n",
      "3992 Traning Loss: tensor(3.3489)\n",
      "3993 Traning Loss: tensor(3.3489)\n",
      "3994 Traning Loss: tensor(3.3489)\n",
      "3995 Traning Loss: tensor(3.3489)\n",
      "3996 Traning Loss: tensor(3.3489)\n",
      "3997 Traning Loss: tensor(3.3489)\n",
      "3998 Traning Loss: tensor(3.3489)\n",
      "3999 Traning Loss: tensor(3.3489)\n",
      "4000 Traning Loss: tensor(3.3489)\n",
      "4001 Traning Loss: tensor(3.3489)\n",
      "4002 Traning Loss: tensor(3.3489)\n",
      "4003 Traning Loss: tensor(3.3489)\n",
      "4004 Traning Loss: tensor(3.3489)\n",
      "4005 Traning Loss: tensor(3.3489)\n",
      "4006 Traning Loss: tensor(3.3489)\n",
      "4007 Traning Loss: tensor(3.3489)\n",
      "4008 Traning Loss: tensor(3.3489)\n",
      "4009 Traning Loss: tensor(3.3489)\n",
      "4010 Traning Loss: tensor(3.3489)\n",
      "4011 Traning Loss: tensor(3.3489)\n",
      "4012 Traning Loss: tensor(3.3489)\n",
      "4013 Traning Loss: tensor(3.3489)\n",
      "4014 Traning Loss: tensor(3.3489)\n",
      "4015 Traning Loss: tensor(3.3489)\n",
      "4016 Traning Loss: tensor(3.3489)\n",
      "4017 Traning Loss: tensor(3.3489)\n",
      "4018 Traning Loss: tensor(3.3489)\n",
      "4019 Traning Loss: tensor(3.3489)\n",
      "4020 Traning Loss: tensor(3.3489)\n",
      "4021 Traning Loss: tensor(3.3489)\n",
      "4022 Traning Loss: tensor(3.3489)\n",
      "4023 Traning Loss: tensor(3.3489)\n",
      "4024 Traning Loss: tensor(3.3489)\n",
      "4025 Traning Loss: tensor(3.3489)\n",
      "4026 Traning Loss: tensor(3.3489)\n",
      "4027 Traning Loss: tensor(3.3489)\n",
      "4028 Traning Loss: tensor(3.3489)\n",
      "4029 Traning Loss: tensor(3.3489)\n",
      "4030 Traning Loss: tensor(3.3489)\n",
      "4031 Traning Loss: tensor(3.3489)\n",
      "4032 Traning Loss: tensor(3.3489)\n",
      "4033 Traning Loss: tensor(3.3489)\n",
      "4034 Traning Loss: tensor(3.3489)\n",
      "4035 Traning Loss: tensor(3.3489)\n",
      "4036 Traning Loss: tensor(3.3489)\n",
      "4037 Traning Loss: tensor(3.3489)\n",
      "4038 Traning Loss: tensor(3.3489)\n",
      "4039 Traning Loss: tensor(3.3489)\n",
      "4040 Traning Loss: tensor(3.3489)\n",
      "4041 Traning Loss: tensor(3.3489)\n",
      "4042 Traning Loss: tensor(3.3489)\n",
      "4043 Traning Loss: tensor(3.3489)\n",
      "4044 Traning Loss: tensor(3.3489)\n",
      "4045 Traning Loss: tensor(3.3489)\n",
      "4046 Traning Loss: tensor(3.3489)\n",
      "4047 Traning Loss: tensor(3.3489)\n",
      "4048 Traning Loss: tensor(3.3489)\n",
      "4049 Traning Loss: tensor(3.3489)\n",
      "4050 Traning Loss: tensor(3.3489)\n",
      "4051 Traning Loss: tensor(3.3489)\n",
      "4052 Traning Loss: tensor(3.3489)\n",
      "4053 Traning Loss: tensor(3.3489)\n",
      "4054 Traning Loss: tensor(3.3489)\n",
      "4055 Traning Loss: tensor(3.3489)\n",
      "4056 Traning Loss: tensor(3.3489)\n",
      "4057 Traning Loss: tensor(3.3489)\n",
      "4058 Traning Loss: tensor(3.3489)\n",
      "4059 Traning Loss: tensor(3.3489)\n",
      "4060 Traning Loss: tensor(3.3489)\n",
      "4061 Traning Loss: tensor(3.3489)\n",
      "4062 Traning Loss: tensor(3.3489)\n",
      "4063 Traning Loss: tensor(3.3489)\n",
      "4064 Traning Loss: tensor(3.3489)\n",
      "4065 Traning Loss: tensor(3.3489)\n",
      "4066 Traning Loss: tensor(3.3489)\n",
      "4067 Traning Loss: tensor(3.3489)\n",
      "4068 Traning Loss: tensor(3.3489)\n",
      "4069 Traning Loss: tensor(3.3489)\n",
      "4070 Traning Loss: tensor(3.3489)\n",
      "4071 Traning Loss: tensor(3.3489)\n",
      "4072 Traning Loss: tensor(3.3489)\n",
      "4073 Traning Loss: tensor(3.3489)\n",
      "4074 Traning Loss: tensor(3.3489)\n",
      "4075 Traning Loss: tensor(3.3489)\n",
      "4076 Traning Loss: tensor(3.3489)\n",
      "4077 Traning Loss: tensor(3.3489)\n",
      "4078 Traning Loss: tensor(3.3489)\n",
      "4079 Traning Loss: tensor(3.3489)\n",
      "4080 Traning Loss: tensor(3.3489)\n",
      "4081 Traning Loss: tensor(3.3489)\n",
      "4082 Traning Loss: tensor(3.3489)\n",
      "4083 Traning Loss: tensor(3.3489)\n",
      "4084 Traning Loss: tensor(3.3489)\n",
      "4085 Traning Loss: tensor(3.3489)\n",
      "4086 Traning Loss: tensor(3.3489)\n",
      "4087 Traning Loss: tensor(3.3489)\n",
      "4088 Traning Loss: tensor(3.3489)\n",
      "4089 Traning Loss: tensor(3.3489)\n",
      "4090 Traning Loss: tensor(3.3489)\n",
      "4091 Traning Loss: tensor(3.3489)\n",
      "4092 Traning Loss: tensor(3.3489)\n",
      "4093 Traning Loss: tensor(3.3489)\n",
      "4094 Traning Loss: tensor(3.3489)\n",
      "4095 Traning Loss: tensor(3.3489)\n",
      "4096 Traning Loss: tensor(3.3489)\n",
      "4097 Traning Loss: tensor(3.3489)\n",
      "4098 Traning Loss: tensor(3.3489)\n",
      "4099 Traning Loss: tensor(3.3489)\n",
      "4100 Traning Loss: tensor(3.3489)\n",
      "4101 Traning Loss: tensor(3.3489)\n",
      "4102 Traning Loss: tensor(3.3489)\n",
      "4103 Traning Loss: tensor(3.3489)\n",
      "4104 Traning Loss: tensor(3.3489)\n",
      "4105 Traning Loss: tensor(3.3489)\n",
      "4106 Traning Loss: tensor(3.3489)\n",
      "4107 Traning Loss: tensor(3.3489)\n",
      "4108 Traning Loss: tensor(3.3489)\n",
      "4109 Traning Loss: tensor(3.3489)\n",
      "4110 Traning Loss: tensor(3.3489)\n",
      "4111 Traning Loss: tensor(3.3489)\n",
      "4112 Traning Loss: tensor(3.3489)\n",
      "4113 Traning Loss: tensor(3.3489)\n",
      "4114 Traning Loss: tensor(3.3489)\n",
      "4115 Traning Loss: tensor(3.3489)\n",
      "4116 Traning Loss: tensor(3.3489)\n",
      "4117 Traning Loss: tensor(3.3489)\n",
      "4118 Traning Loss: tensor(3.3489)\n",
      "4119 Traning Loss: tensor(3.3489)\n",
      "4120 Traning Loss: tensor(3.3489)\n",
      "4121 Traning Loss: tensor(3.3489)\n",
      "4122 Traning Loss: tensor(3.3489)\n",
      "4123 Traning Loss: tensor(3.3489)\n",
      "4124 Traning Loss: tensor(3.3489)\n",
      "4125 Traning Loss: tensor(3.3489)\n",
      "4126 Traning Loss: tensor(3.3489)\n",
      "4127 Traning Loss: tensor(3.3489)\n",
      "4128 Traning Loss: tensor(3.3489)\n",
      "4129 Traning Loss: tensor(3.3489)\n",
      "4130 Traning Loss: tensor(3.3489)\n",
      "4131 Traning Loss: tensor(3.3489)\n",
      "4132 Traning Loss: tensor(3.3489)\n",
      "4133 Traning Loss: tensor(3.3489)\n",
      "4134 Traning Loss: tensor(3.3489)\n",
      "4135 Traning Loss: tensor(3.3489)\n",
      "4136 Traning Loss: tensor(3.3489)\n",
      "4137 Traning Loss: tensor(3.3489)\n",
      "4138 Traning Loss: tensor(3.3489)\n",
      "4139 Traning Loss: tensor(3.3489)\n",
      "4140 Traning Loss: tensor(3.3489)\n",
      "4141 Traning Loss: tensor(3.3489)\n",
      "4142 Traning Loss: tensor(3.3489)\n",
      "4143 Traning Loss: tensor(3.3489)\n",
      "4144 Traning Loss: tensor(3.3489)\n",
      "4145 Traning Loss: tensor(3.3489)\n",
      "4146 Traning Loss: tensor(3.3489)\n",
      "4147 Traning Loss: tensor(3.3489)\n",
      "4148 Traning Loss: tensor(3.3489)\n",
      "4149 Traning Loss: tensor(3.3489)\n",
      "4150 Traning Loss: tensor(3.3489)\n",
      "4151 Traning Loss: tensor(3.3489)\n",
      "4152 Traning Loss: tensor(3.3489)\n",
      "4153 Traning Loss: tensor(3.3489)\n",
      "4154 Traning Loss: tensor(3.3489)\n",
      "4155 Traning Loss: tensor(3.3489)\n",
      "4156 Traning Loss: tensor(3.3489)\n",
      "4157 Traning Loss: tensor(3.3489)\n",
      "4158 Traning Loss: tensor(3.3489)\n",
      "4159 Traning Loss: tensor(3.3489)\n",
      "4160 Traning Loss: tensor(3.3489)\n",
      "4161 Traning Loss: tensor(3.3489)\n",
      "4162 Traning Loss: tensor(3.3489)\n",
      "4163 Traning Loss: tensor(3.3489)\n",
      "4164 Traning Loss: tensor(3.3489)\n",
      "4165 Traning Loss: tensor(3.3489)\n",
      "4166 Traning Loss: tensor(3.3489)\n",
      "4167 Traning Loss: tensor(3.3489)\n",
      "4168 Traning Loss: tensor(3.3489)\n",
      "4169 Traning Loss: tensor(3.3489)\n",
      "4170 Traning Loss: tensor(3.3489)\n",
      "4171 Traning Loss: tensor(3.3489)\n",
      "4172 Traning Loss: tensor(3.3489)\n",
      "4173 Traning Loss: tensor(3.3489)\n",
      "4174 Traning Loss: tensor(3.3489)\n",
      "4175 Traning Loss: tensor(3.3489)\n",
      "4176 Traning Loss: tensor(3.3489)\n",
      "4177 Traning Loss: tensor(3.3489)\n",
      "4178 Traning Loss: tensor(3.3489)\n",
      "4179 Traning Loss: tensor(3.3489)\n",
      "4180 Traning Loss: tensor(3.3489)\n",
      "4181 Traning Loss: tensor(3.3489)\n",
      "4182 Traning Loss: tensor(3.3489)\n",
      "4183 Traning Loss: tensor(3.3489)\n",
      "4184 Traning Loss: tensor(3.3489)\n",
      "4185 Traning Loss: tensor(3.3489)\n",
      "4186 Traning Loss: tensor(3.3489)\n",
      "4187 Traning Loss: tensor(3.3489)\n",
      "4188 Traning Loss: tensor(3.3489)\n",
      "4189 Traning Loss: tensor(3.3489)\n",
      "4190 Traning Loss: tensor(3.3489)\n",
      "4191 Traning Loss: tensor(3.3489)\n",
      "4192 Traning Loss: tensor(3.3489)\n",
      "4193 Traning Loss: tensor(3.3489)\n",
      "4194 Traning Loss: tensor(3.3489)\n",
      "4195 Traning Loss: tensor(3.3489)\n",
      "4196 Traning Loss: tensor(3.3489)\n",
      "4197 Traning Loss: tensor(3.3489)\n",
      "4198 Traning Loss: tensor(3.3489)\n",
      "4199 Traning Loss: tensor(3.3489)\n",
      "4200 Traning Loss: tensor(3.3489)\n",
      "4201 Traning Loss: tensor(3.3489)\n",
      "4202 Traning Loss: tensor(3.3489)\n",
      "4203 Traning Loss: tensor(3.3489)\n",
      "4204 Traning Loss: tensor(3.3489)\n",
      "4205 Traning Loss: tensor(3.3489)\n",
      "4206 Traning Loss: tensor(3.3489)\n",
      "4207 Traning Loss: tensor(3.3489)\n",
      "4208 Traning Loss: tensor(3.3489)\n",
      "4209 Traning Loss: tensor(3.3489)\n",
      "4210 Traning Loss: tensor(3.3489)\n",
      "4211 Traning Loss: tensor(3.3489)\n",
      "4212 Traning Loss: tensor(3.3489)\n",
      "4213 Traning Loss: tensor(3.3489)\n",
      "4214 Traning Loss: tensor(3.3489)\n",
      "4215 Traning Loss: tensor(3.3489)\n",
      "4216 Traning Loss: tensor(3.3489)\n",
      "4217 Traning Loss: tensor(3.3489)\n",
      "4218 Traning Loss: tensor(3.3489)\n",
      "4219 Traning Loss: tensor(3.3489)\n",
      "4220 Traning Loss: tensor(3.3489)\n",
      "4221 Traning Loss: tensor(3.3489)\n",
      "4222 Traning Loss: tensor(3.3489)\n",
      "4223 Traning Loss: tensor(3.3489)\n",
      "4224 Traning Loss: tensor(3.3489)\n",
      "4225 Traning Loss: tensor(3.3489)\n",
      "4226 Traning Loss: tensor(3.3489)\n",
      "4227 Traning Loss: tensor(3.3489)\n",
      "4228 Traning Loss: tensor(3.3489)\n",
      "4229 Traning Loss: tensor(3.3489)\n",
      "4230 Traning Loss: tensor(3.3489)\n",
      "4231 Traning Loss: tensor(3.3489)\n",
      "4232 Traning Loss: tensor(3.3489)\n",
      "4233 Traning Loss: tensor(3.3489)\n",
      "4234 Traning Loss: tensor(3.3489)\n",
      "4235 Traning Loss: tensor(3.3489)\n",
      "4236 Traning Loss: tensor(3.3489)\n",
      "4237 Traning Loss: tensor(3.3489)\n",
      "4238 Traning Loss: tensor(3.3489)\n",
      "4239 Traning Loss: tensor(3.3489)\n",
      "4240 Traning Loss: tensor(3.3489)\n",
      "4241 Traning Loss: tensor(3.3489)\n",
      "4242 Traning Loss: tensor(3.3489)\n",
      "4243 Traning Loss: tensor(3.3489)\n",
      "4244 Traning Loss: tensor(3.3489)\n",
      "4245 Traning Loss: tensor(3.3489)\n",
      "4246 Traning Loss: tensor(3.3489)\n",
      "4247 Traning Loss: tensor(3.3489)\n",
      "4248 Traning Loss: tensor(3.3489)\n",
      "4249 Traning Loss: tensor(3.3489)\n",
      "4250 Traning Loss: tensor(3.3489)\n",
      "4251 Traning Loss: tensor(3.3489)\n",
      "4252 Traning Loss: tensor(3.3489)\n",
      "4253 Traning Loss: tensor(3.3489)\n",
      "4254 Traning Loss: tensor(3.3489)\n",
      "4255 Traning Loss: tensor(3.3489)\n",
      "4256 Traning Loss: tensor(3.3489)\n",
      "4257 Traning Loss: tensor(3.3489)\n",
      "4258 Traning Loss: tensor(3.3489)\n",
      "4259 Traning Loss: tensor(3.3489)\n",
      "4260 Traning Loss: tensor(3.3489)\n",
      "4261 Traning Loss: tensor(3.3489)\n",
      "4262 Traning Loss: tensor(3.3489)\n",
      "4263 Traning Loss: tensor(3.3489)\n",
      "4264 Traning Loss: tensor(3.3489)\n",
      "4265 Traning Loss: tensor(3.3489)\n",
      "4266 Traning Loss: tensor(3.3489)\n",
      "4267 Traning Loss: tensor(3.3489)\n",
      "4268 Traning Loss: tensor(3.3489)\n",
      "4269 Traning Loss: tensor(3.3489)\n",
      "4270 Traning Loss: tensor(3.3489)\n",
      "4271 Traning Loss: tensor(3.3489)\n",
      "4272 Traning Loss: tensor(3.3489)\n",
      "4273 Traning Loss: tensor(3.3489)\n",
      "4274 Traning Loss: tensor(3.3489)\n",
      "4275 Traning Loss: tensor(3.3489)\n",
      "4276 Traning Loss: tensor(3.3489)\n",
      "4277 Traning Loss: tensor(3.3489)\n",
      "4278 Traning Loss: tensor(3.3489)\n",
      "4279 Traning Loss: tensor(3.3489)\n",
      "4280 Traning Loss: tensor(3.3489)\n",
      "4281 Traning Loss: tensor(3.3489)\n",
      "4282 Traning Loss: tensor(3.3489)\n",
      "4283 Traning Loss: tensor(3.3489)\n",
      "4284 Traning Loss: tensor(3.3489)\n",
      "4285 Traning Loss: tensor(3.3489)\n",
      "4286 Traning Loss: tensor(3.3489)\n",
      "4287 Traning Loss: tensor(3.3489)\n",
      "4288 Traning Loss: tensor(3.3489)\n",
      "4289 Traning Loss: tensor(3.3489)\n",
      "4290 Traning Loss: tensor(3.3489)\n",
      "4291 Traning Loss: tensor(3.3489)\n",
      "4292 Traning Loss: tensor(3.3489)\n",
      "4293 Traning Loss: tensor(3.3489)\n",
      "4294 Traning Loss: tensor(3.3489)\n",
      "4295 Traning Loss: tensor(3.3489)\n",
      "4296 Traning Loss: tensor(3.3489)\n",
      "4297 Traning Loss: tensor(3.3489)\n",
      "4298 Traning Loss: tensor(3.3489)\n",
      "4299 Traning Loss: tensor(3.3489)\n",
      "4300 Traning Loss: tensor(3.3489)\n",
      "4301 Traning Loss: tensor(3.3489)\n",
      "4302 Traning Loss: tensor(3.3489)\n",
      "4303 Traning Loss: tensor(3.3489)\n",
      "4304 Traning Loss: tensor(3.3489)\n",
      "4305 Traning Loss: tensor(3.3489)\n",
      "4306 Traning Loss: tensor(3.3489)\n",
      "4307 Traning Loss: tensor(3.3489)\n",
      "4308 Traning Loss: tensor(3.3489)\n",
      "4309 Traning Loss: tensor(3.3489)\n",
      "4310 Traning Loss: tensor(3.3489)\n",
      "4311 Traning Loss: tensor(3.3489)\n",
      "4312 Traning Loss: tensor(3.3489)\n",
      "4313 Traning Loss: tensor(3.3489)\n",
      "4314 Traning Loss: tensor(3.3489)\n",
      "4315 Traning Loss: tensor(3.3489)\n",
      "4316 Traning Loss: tensor(3.3489)\n",
      "4317 Traning Loss: tensor(3.3489)\n",
      "4318 Traning Loss: tensor(3.3489)\n",
      "4319 Traning Loss: tensor(3.3489)\n",
      "4320 Traning Loss: tensor(3.3489)\n",
      "4321 Traning Loss: tensor(3.3489)\n",
      "4322 Traning Loss: tensor(3.3489)\n",
      "4323 Traning Loss: tensor(3.3489)\n",
      "4324 Traning Loss: tensor(3.3489)\n",
      "4325 Traning Loss: tensor(3.3489)\n",
      "4326 Traning Loss: tensor(3.3489)\n",
      "4327 Traning Loss: tensor(3.3489)\n",
      "4328 Traning Loss: tensor(3.3489)\n",
      "4329 Traning Loss: tensor(3.3489)\n",
      "4330 Traning Loss: tensor(3.3489)\n",
      "4331 Traning Loss: tensor(3.3489)\n",
      "4332 Traning Loss: tensor(3.3489)\n",
      "4333 Traning Loss: tensor(3.3489)\n",
      "4334 Traning Loss: tensor(3.3489)\n",
      "4335 Traning Loss: tensor(3.3489)\n",
      "4336 Traning Loss: tensor(3.3489)\n",
      "4337 Traning Loss: tensor(3.3489)\n",
      "4338 Traning Loss: tensor(3.3489)\n",
      "4339 Traning Loss: tensor(3.3489)\n",
      "4340 Traning Loss: tensor(3.3489)\n",
      "4341 Traning Loss: tensor(3.3489)\n",
      "4342 Traning Loss: tensor(3.3489)\n",
      "4343 Traning Loss: tensor(3.3489)\n",
      "4344 Traning Loss: tensor(3.3489)\n",
      "4345 Traning Loss: tensor(3.3489)\n",
      "4346 Traning Loss: tensor(3.3489)\n",
      "4347 Traning Loss: tensor(3.3489)\n",
      "4348 Traning Loss: tensor(3.3489)\n",
      "4349 Traning Loss: tensor(3.3489)\n",
      "4350 Traning Loss: tensor(3.3489)\n",
      "4351 Traning Loss: tensor(3.3489)\n",
      "4352 Traning Loss: tensor(3.3489)\n",
      "4353 Traning Loss: tensor(3.3489)\n",
      "4354 Traning Loss: tensor(3.3489)\n",
      "4355 Traning Loss: tensor(3.3489)\n",
      "4356 Traning Loss: tensor(3.3489)\n",
      "4357 Traning Loss: tensor(3.3489)\n",
      "4358 Traning Loss: tensor(3.3489)\n",
      "4359 Traning Loss: tensor(3.3489)\n",
      "4360 Traning Loss: tensor(3.3489)\n",
      "4361 Traning Loss: tensor(3.3489)\n",
      "4362 Traning Loss: tensor(3.3489)\n",
      "4363 Traning Loss: tensor(3.3489)\n",
      "4364 Traning Loss: tensor(3.3489)\n",
      "4365 Traning Loss: tensor(3.3489)\n",
      "4366 Traning Loss: tensor(3.3489)\n",
      "4367 Traning Loss: tensor(3.3489)\n",
      "4368 Traning Loss: tensor(3.3489)\n",
      "4369 Traning Loss: tensor(3.3489)\n",
      "4370 Traning Loss: tensor(3.3489)\n",
      "4371 Traning Loss: tensor(3.3489)\n",
      "4372 Traning Loss: tensor(3.3489)\n",
      "4373 Traning Loss: tensor(3.3489)\n",
      "4374 Traning Loss: tensor(3.3489)\n",
      "4375 Traning Loss: tensor(3.3489)\n",
      "4376 Traning Loss: tensor(3.3489)\n",
      "4377 Traning Loss: tensor(3.3489)\n",
      "4378 Traning Loss: tensor(3.3489)\n",
      "4379 Traning Loss: tensor(3.3489)\n",
      "4380 Traning Loss: tensor(3.3489)\n",
      "4381 Traning Loss: tensor(3.3489)\n",
      "4382 Traning Loss: tensor(3.3489)\n",
      "4383 Traning Loss: tensor(3.3489)\n",
      "4384 Traning Loss: tensor(3.3489)\n",
      "4385 Traning Loss: tensor(3.3489)\n",
      "4386 Traning Loss: tensor(3.3489)\n",
      "4387 Traning Loss: tensor(3.3489)\n",
      "4388 Traning Loss: tensor(3.3489)\n",
      "4389 Traning Loss: tensor(3.3489)\n",
      "4390 Traning Loss: tensor(3.3489)\n",
      "4391 Traning Loss: tensor(3.3489)\n",
      "4392 Traning Loss: tensor(3.3489)\n",
      "4393 Traning Loss: tensor(3.3489)\n",
      "4394 Traning Loss: tensor(3.3489)\n",
      "4395 Traning Loss: tensor(3.3489)\n",
      "4396 Traning Loss: tensor(3.3489)\n",
      "4397 Traning Loss: tensor(3.3489)\n",
      "4398 Traning Loss: tensor(3.3489)\n",
      "4399 Traning Loss: tensor(3.3489)\n",
      "4400 Traning Loss: tensor(3.3489)\n",
      "4401 Traning Loss: tensor(3.3489)\n",
      "4402 Traning Loss: tensor(3.3489)\n",
      "4403 Traning Loss: tensor(3.3489)\n",
      "4404 Traning Loss: tensor(3.3489)\n",
      "4405 Traning Loss: tensor(3.3489)\n",
      "4406 Traning Loss: tensor(3.3489)\n",
      "4407 Traning Loss: tensor(3.3489)\n",
      "4408 Traning Loss: tensor(3.3489)\n",
      "4409 Traning Loss: tensor(3.3489)\n",
      "4410 Traning Loss: tensor(3.3489)\n",
      "4411 Traning Loss: tensor(3.3489)\n",
      "4412 Traning Loss: tensor(3.3489)\n",
      "4413 Traning Loss: tensor(3.3489)\n",
      "4414 Traning Loss: tensor(3.3489)\n",
      "4415 Traning Loss: tensor(3.3489)\n",
      "4416 Traning Loss: tensor(3.3489)\n",
      "4417 Traning Loss: tensor(3.3489)\n",
      "4418 Traning Loss: tensor(3.3489)\n",
      "4419 Traning Loss: tensor(3.3489)\n",
      "4420 Traning Loss: tensor(3.3489)\n",
      "4421 Traning Loss: tensor(3.3489)\n",
      "4422 Traning Loss: tensor(3.3489)\n",
      "4423 Traning Loss: tensor(3.3489)\n",
      "4424 Traning Loss: tensor(3.3489)\n",
      "4425 Traning Loss: tensor(3.3489)\n",
      "4426 Traning Loss: tensor(3.3489)\n",
      "4427 Traning Loss: tensor(3.3489)\n",
      "4428 Traning Loss: tensor(3.3489)\n",
      "4429 Traning Loss: tensor(3.3489)\n",
      "4430 Traning Loss: tensor(3.3489)\n",
      "4431 Traning Loss: tensor(3.3489)\n",
      "4432 Traning Loss: tensor(3.3489)\n",
      "4433 Traning Loss: tensor(3.3489)\n",
      "4434 Traning Loss: tensor(3.3489)\n",
      "4435 Traning Loss: tensor(3.3489)\n",
      "4436 Traning Loss: tensor(3.3489)\n",
      "4437 Traning Loss: tensor(3.3489)\n",
      "4438 Traning Loss: tensor(3.3489)\n",
      "4439 Traning Loss: tensor(3.3489)\n",
      "4440 Traning Loss: tensor(3.3489)\n",
      "4441 Traning Loss: tensor(3.3489)\n",
      "4442 Traning Loss: tensor(3.3489)\n",
      "4443 Traning Loss: tensor(3.3489)\n",
      "4444 Traning Loss: tensor(3.3489)\n",
      "4445 Traning Loss: tensor(3.3489)\n",
      "4446 Traning Loss: tensor(3.3489)\n",
      "4447 Traning Loss: tensor(3.3489)\n",
      "4448 Traning Loss: tensor(3.3489)\n",
      "4449 Traning Loss: tensor(3.3489)\n",
      "4450 Traning Loss: tensor(3.3489)\n",
      "4451 Traning Loss: tensor(3.3489)\n",
      "4452 Traning Loss: tensor(3.3489)\n",
      "4453 Traning Loss: tensor(3.3489)\n",
      "4454 Traning Loss: tensor(3.3489)\n",
      "4455 Traning Loss: tensor(3.3489)\n",
      "4456 Traning Loss: tensor(3.3489)\n",
      "4457 Traning Loss: tensor(3.3489)\n",
      "4458 Traning Loss: tensor(3.3489)\n",
      "4459 Traning Loss: tensor(3.3489)\n",
      "4460 Traning Loss: tensor(3.3489)\n",
      "4461 Traning Loss: tensor(3.3489)\n",
      "4462 Traning Loss: tensor(3.3489)\n",
      "4463 Traning Loss: tensor(3.3489)\n",
      "4464 Traning Loss: tensor(3.3489)\n",
      "4465 Traning Loss: tensor(3.3489)\n",
      "4466 Traning Loss: tensor(3.3489)\n",
      "4467 Traning Loss: tensor(3.3489)\n",
      "4468 Traning Loss: tensor(3.3489)\n",
      "4469 Traning Loss: tensor(3.3489)\n",
      "4470 Traning Loss: tensor(3.3489)\n",
      "4471 Traning Loss: tensor(3.3489)\n",
      "4472 Traning Loss: tensor(3.3489)\n",
      "4473 Traning Loss: tensor(3.3489)\n",
      "4474 Traning Loss: tensor(3.3489)\n",
      "4475 Traning Loss: tensor(3.3489)\n",
      "4476 Traning Loss: tensor(3.3489)\n",
      "4477 Traning Loss: tensor(3.3489)\n",
      "4478 Traning Loss: tensor(3.3489)\n",
      "4479 Traning Loss: tensor(3.3489)\n",
      "4480 Traning Loss: tensor(3.3489)\n",
      "4481 Traning Loss: tensor(3.3489)\n",
      "4482 Traning Loss: tensor(3.3489)\n",
      "4483 Traning Loss: tensor(3.3489)\n",
      "4484 Traning Loss: tensor(3.3489)\n",
      "4485 Traning Loss: tensor(3.3489)\n",
      "4486 Traning Loss: tensor(3.3489)\n",
      "4487 Traning Loss: tensor(3.3489)\n",
      "4488 Traning Loss: tensor(3.3489)\n",
      "4489 Traning Loss: tensor(3.3489)\n",
      "4490 Traning Loss: tensor(3.3489)\n",
      "4491 Traning Loss: tensor(3.3489)\n",
      "4492 Traning Loss: tensor(3.3489)\n",
      "4493 Traning Loss: tensor(3.3489)\n",
      "4494 Traning Loss: tensor(3.3489)\n",
      "4495 Traning Loss: tensor(3.3489)\n",
      "4496 Traning Loss: tensor(3.3489)\n",
      "4497 Traning Loss: tensor(3.3489)\n",
      "4498 Traning Loss: tensor(3.3489)\n",
      "4499 Traning Loss: tensor(3.3489)\n",
      "4500 Traning Loss: tensor(3.3489)\n",
      "4501 Traning Loss: tensor(3.3489)\n",
      "4502 Traning Loss: tensor(3.3489)\n",
      "4503 Traning Loss: tensor(3.3489)\n",
      "4504 Traning Loss: tensor(3.3489)\n",
      "4505 Traning Loss: tensor(3.3489)\n",
      "4506 Traning Loss: tensor(3.3489)\n",
      "4507 Traning Loss: tensor(3.3489)\n",
      "4508 Traning Loss: tensor(3.3489)\n",
      "4509 Traning Loss: tensor(3.3489)\n",
      "4510 Traning Loss: tensor(3.3489)\n",
      "4511 Traning Loss: tensor(3.3489)\n",
      "4512 Traning Loss: tensor(3.3489)\n",
      "4513 Traning Loss: tensor(3.3489)\n",
      "4514 Traning Loss: tensor(3.3489)\n",
      "4515 Traning Loss: tensor(3.3489)\n",
      "4516 Traning Loss: tensor(3.3489)\n",
      "4517 Traning Loss: tensor(3.3489)\n",
      "4518 Traning Loss: tensor(3.3489)\n",
      "4519 Traning Loss: tensor(3.3489)\n",
      "4520 Traning Loss: tensor(3.3489)\n",
      "4521 Traning Loss: tensor(3.3489)\n",
      "4522 Traning Loss: tensor(3.3489)\n",
      "4523 Traning Loss: tensor(3.3489)\n",
      "4524 Traning Loss: tensor(3.3489)\n",
      "4525 Traning Loss: tensor(3.3489)\n",
      "4526 Traning Loss: tensor(3.3489)\n",
      "4527 Traning Loss: tensor(3.3489)\n",
      "4528 Traning Loss: tensor(3.3489)\n",
      "4529 Traning Loss: tensor(3.3489)\n",
      "4530 Traning Loss: tensor(3.3489)\n",
      "4531 Traning Loss: tensor(3.3489)\n",
      "4532 Traning Loss: tensor(3.3489)\n",
      "4533 Traning Loss: tensor(3.3489)\n",
      "4534 Traning Loss: tensor(3.3489)\n",
      "4535 Traning Loss: tensor(3.3489)\n",
      "4536 Traning Loss: tensor(3.3489)\n",
      "4537 Traning Loss: tensor(3.3489)\n",
      "4538 Traning Loss: tensor(3.3489)\n",
      "4539 Traning Loss: tensor(3.3489)\n",
      "4540 Traning Loss: tensor(3.3489)\n",
      "4541 Traning Loss: tensor(3.3489)\n",
      "4542 Traning Loss: tensor(3.3489)\n",
      "4543 Traning Loss: tensor(3.3489)\n",
      "4544 Traning Loss: tensor(3.3489)\n",
      "4545 Traning Loss: tensor(3.3489)\n",
      "4546 Traning Loss: tensor(3.3489)\n",
      "4547 Traning Loss: tensor(3.3489)\n",
      "4548 Traning Loss: tensor(3.3489)\n",
      "4549 Traning Loss: tensor(3.3489)\n",
      "4550 Traning Loss: tensor(3.3489)\n",
      "4551 Traning Loss: tensor(3.3489)\n",
      "4552 Traning Loss: tensor(3.3489)\n",
      "4553 Traning Loss: tensor(3.3489)\n",
      "4554 Traning Loss: tensor(3.3489)\n",
      "4555 Traning Loss: tensor(3.3489)\n",
      "4556 Traning Loss: tensor(3.3489)\n",
      "4557 Traning Loss: tensor(3.3489)\n",
      "4558 Traning Loss: tensor(3.3489)\n",
      "4559 Traning Loss: tensor(3.3489)\n",
      "4560 Traning Loss: tensor(3.3489)\n",
      "4561 Traning Loss: tensor(3.3489)\n",
      "4562 Traning Loss: tensor(3.3489)\n",
      "4563 Traning Loss: tensor(3.3489)\n",
      "4564 Traning Loss: tensor(3.3489)\n",
      "4565 Traning Loss: tensor(3.3489)\n",
      "4566 Traning Loss: tensor(3.3489)\n",
      "4567 Traning Loss: tensor(3.3489)\n",
      "4568 Traning Loss: tensor(3.3489)\n",
      "4569 Traning Loss: tensor(3.3489)\n",
      "4570 Traning Loss: tensor(3.3489)\n",
      "4571 Traning Loss: tensor(3.3489)\n",
      "4572 Traning Loss: tensor(3.3489)\n",
      "4573 Traning Loss: tensor(3.3489)\n",
      "4574 Traning Loss: tensor(3.3489)\n",
      "4575 Traning Loss: tensor(3.3489)\n",
      "4576 Traning Loss: tensor(3.3489)\n",
      "4577 Traning Loss: tensor(3.3489)\n",
      "4578 Traning Loss: tensor(3.3489)\n",
      "4579 Traning Loss: tensor(3.3489)\n",
      "4580 Traning Loss: tensor(3.3489)\n",
      "4581 Traning Loss: tensor(3.3489)\n",
      "4582 Traning Loss: tensor(3.3489)\n",
      "4583 Traning Loss: tensor(3.3489)\n",
      "4584 Traning Loss: tensor(3.3489)\n",
      "4585 Traning Loss: tensor(3.3489)\n",
      "4586 Traning Loss: tensor(3.3489)\n",
      "4587 Traning Loss: tensor(3.3489)\n",
      "4588 Traning Loss: tensor(3.3489)\n",
      "4589 Traning Loss: tensor(3.3489)\n",
      "4590 Traning Loss: tensor(3.3489)\n",
      "4591 Traning Loss: tensor(3.3489)\n",
      "4592 Traning Loss: tensor(3.3489)\n",
      "4593 Traning Loss: tensor(3.3489)\n",
      "4594 Traning Loss: tensor(3.3489)\n",
      "4595 Traning Loss: tensor(3.3489)\n",
      "4596 Traning Loss: tensor(3.3489)\n",
      "4597 Traning Loss: tensor(3.3489)\n",
      "4598 Traning Loss: tensor(3.3489)\n",
      "4599 Traning Loss: tensor(3.3489)\n",
      "4600 Traning Loss: tensor(3.3489)\n",
      "4601 Traning Loss: tensor(3.3489)\n",
      "4602 Traning Loss: tensor(3.3489)\n",
      "4603 Traning Loss: tensor(3.3489)\n",
      "4604 Traning Loss: tensor(3.3489)\n",
      "4605 Traning Loss: tensor(3.3489)\n",
      "4606 Traning Loss: tensor(3.3489)\n",
      "4607 Traning Loss: tensor(3.3489)\n",
      "4608 Traning Loss: tensor(3.3489)\n",
      "4609 Traning Loss: tensor(3.3489)\n",
      "4610 Traning Loss: tensor(3.3489)\n",
      "4611 Traning Loss: tensor(3.3489)\n",
      "4612 Traning Loss: tensor(3.3489)\n",
      "4613 Traning Loss: tensor(3.3489)\n",
      "4614 Traning Loss: tensor(3.3489)\n",
      "4615 Traning Loss: tensor(3.3489)\n",
      "4616 Traning Loss: tensor(3.3489)\n",
      "4617 Traning Loss: tensor(3.3489)\n",
      "4618 Traning Loss: tensor(3.3489)\n",
      "4619 Traning Loss: tensor(3.3489)\n",
      "4620 Traning Loss: tensor(3.3489)\n",
      "4621 Traning Loss: tensor(3.3489)\n",
      "4622 Traning Loss: tensor(3.3489)\n",
      "4623 Traning Loss: tensor(3.3489)\n",
      "4624 Traning Loss: tensor(3.3489)\n",
      "4625 Traning Loss: tensor(3.3489)\n",
      "4626 Traning Loss: tensor(3.3489)\n",
      "4627 Traning Loss: tensor(3.3489)\n",
      "4628 Traning Loss: tensor(3.3489)\n",
      "4629 Traning Loss: tensor(3.3489)\n",
      "4630 Traning Loss: tensor(3.3489)\n",
      "4631 Traning Loss: tensor(3.3489)\n",
      "4632 Traning Loss: tensor(3.3489)\n",
      "4633 Traning Loss: tensor(3.3489)\n",
      "4634 Traning Loss: tensor(3.3489)\n",
      "4635 Traning Loss: tensor(3.3489)\n",
      "4636 Traning Loss: tensor(3.3489)\n",
      "4637 Traning Loss: tensor(3.3489)\n",
      "4638 Traning Loss: tensor(3.3489)\n",
      "4639 Traning Loss: tensor(3.3489)\n",
      "4640 Traning Loss: tensor(3.3489)\n",
      "4641 Traning Loss: tensor(3.3489)\n",
      "4642 Traning Loss: tensor(3.3489)\n",
      "4643 Traning Loss: tensor(3.3489)\n",
      "4644 Traning Loss: tensor(3.3489)\n",
      "4645 Traning Loss: tensor(3.3489)\n",
      "4646 Traning Loss: tensor(3.3489)\n",
      "4647 Traning Loss: tensor(3.3489)\n",
      "4648 Traning Loss: tensor(3.3489)\n",
      "4649 Traning Loss: tensor(3.3489)\n",
      "4650 Traning Loss: tensor(3.3489)\n",
      "4651 Traning Loss: tensor(3.3489)\n",
      "4652 Traning Loss: tensor(3.3489)\n",
      "4653 Traning Loss: tensor(3.3489)\n",
      "4654 Traning Loss: tensor(3.3489)\n",
      "4655 Traning Loss: tensor(3.3489)\n",
      "4656 Traning Loss: tensor(3.3489)\n",
      "4657 Traning Loss: tensor(3.3489)\n",
      "4658 Traning Loss: tensor(3.3489)\n",
      "4659 Traning Loss: tensor(3.3489)\n",
      "4660 Traning Loss: tensor(3.3489)\n",
      "4661 Traning Loss: tensor(3.3489)\n",
      "4662 Traning Loss: tensor(3.3489)\n",
      "4663 Traning Loss: tensor(3.3489)\n",
      "4664 Traning Loss: tensor(3.3489)\n",
      "4665 Traning Loss: tensor(3.3489)\n",
      "4666 Traning Loss: tensor(3.3489)\n",
      "4667 Traning Loss: tensor(3.3489)\n",
      "4668 Traning Loss: tensor(3.3489)\n",
      "4669 Traning Loss: tensor(3.3489)\n",
      "4670 Traning Loss: tensor(3.3489)\n",
      "4671 Traning Loss: tensor(3.3489)\n",
      "4672 Traning Loss: tensor(3.3489)\n",
      "4673 Traning Loss: tensor(3.3489)\n",
      "4674 Traning Loss: tensor(3.3489)\n",
      "4675 Traning Loss: tensor(3.3489)\n",
      "4676 Traning Loss: tensor(3.3489)\n",
      "4677 Traning Loss: tensor(3.3489)\n",
      "4678 Traning Loss: tensor(3.3489)\n",
      "4679 Traning Loss: tensor(3.3489)\n",
      "4680 Traning Loss: tensor(3.3489)\n",
      "4681 Traning Loss: tensor(3.3489)\n",
      "4682 Traning Loss: tensor(3.3489)\n",
      "4683 Traning Loss: tensor(3.3489)\n",
      "4684 Traning Loss: tensor(3.3489)\n",
      "4685 Traning Loss: tensor(3.3489)\n",
      "4686 Traning Loss: tensor(3.3489)\n",
      "4687 Traning Loss: tensor(3.3489)\n",
      "4688 Traning Loss: tensor(3.3489)\n",
      "4689 Traning Loss: tensor(3.3489)\n",
      "4690 Traning Loss: tensor(3.3489)\n",
      "4691 Traning Loss: tensor(3.3489)\n",
      "4692 Traning Loss: tensor(3.3489)\n",
      "4693 Traning Loss: tensor(3.3489)\n",
      "4694 Traning Loss: tensor(3.3489)\n",
      "4695 Traning Loss: tensor(3.3489)\n",
      "4696 Traning Loss: tensor(3.3489)\n",
      "4697 Traning Loss: tensor(3.3489)\n",
      "4698 Traning Loss: tensor(3.3489)\n",
      "4699 Traning Loss: tensor(3.3489)\n",
      "4700 Traning Loss: tensor(3.3489)\n",
      "4701 Traning Loss: tensor(3.3489)\n",
      "4702 Traning Loss: tensor(3.3489)\n",
      "4703 Traning Loss: tensor(3.3489)\n",
      "4704 Traning Loss: tensor(3.3489)\n",
      "4705 Traning Loss: tensor(3.3489)\n",
      "4706 Traning Loss: tensor(3.3489)\n",
      "4707 Traning Loss: tensor(3.3489)\n",
      "4708 Traning Loss: tensor(3.3489)\n",
      "4709 Traning Loss: tensor(3.3489)\n",
      "4710 Traning Loss: tensor(3.3489)\n",
      "4711 Traning Loss: tensor(3.3489)\n",
      "4712 Traning Loss: tensor(3.3489)\n",
      "4713 Traning Loss: tensor(3.3489)\n",
      "4714 Traning Loss: tensor(3.3489)\n",
      "4715 Traning Loss: tensor(3.3489)\n",
      "4716 Traning Loss: tensor(3.3489)\n",
      "4717 Traning Loss: tensor(3.3489)\n",
      "4718 Traning Loss: tensor(3.3489)\n",
      "4719 Traning Loss: tensor(3.3489)\n",
      "4720 Traning Loss: tensor(3.3489)\n",
      "4721 Traning Loss: tensor(3.3489)\n",
      "4722 Traning Loss: tensor(3.3489)\n",
      "4723 Traning Loss: tensor(3.3489)\n",
      "4724 Traning Loss: tensor(3.3489)\n",
      "4725 Traning Loss: tensor(3.3489)\n",
      "4726 Traning Loss: tensor(3.3489)\n",
      "4727 Traning Loss: tensor(3.3489)\n",
      "4728 Traning Loss: tensor(3.3489)\n",
      "4729 Traning Loss: tensor(3.3489)\n",
      "4730 Traning Loss: tensor(3.3489)\n",
      "4731 Traning Loss: tensor(3.3489)\n",
      "4732 Traning Loss: tensor(3.3489)\n",
      "4733 Traning Loss: tensor(3.3489)\n",
      "4734 Traning Loss: tensor(3.3489)\n",
      "4735 Traning Loss: tensor(3.3489)\n",
      "4736 Traning Loss: tensor(3.3489)\n",
      "4737 Traning Loss: tensor(3.3489)\n",
      "4738 Traning Loss: tensor(3.3489)\n",
      "4739 Traning Loss: tensor(3.3489)\n",
      "4740 Traning Loss: tensor(3.3489)\n",
      "4741 Traning Loss: tensor(3.3489)\n",
      "4742 Traning Loss: tensor(3.3489)\n",
      "4743 Traning Loss: tensor(3.3489)\n",
      "4744 Traning Loss: tensor(3.3489)\n",
      "4745 Traning Loss: tensor(3.3489)\n",
      "4746 Traning Loss: tensor(3.3489)\n",
      "4747 Traning Loss: tensor(3.3489)\n",
      "4748 Traning Loss: tensor(3.3489)\n",
      "4749 Traning Loss: tensor(3.3489)\n",
      "4750 Traning Loss: tensor(3.3489)\n",
      "4751 Traning Loss: tensor(3.3489)\n",
      "4752 Traning Loss: tensor(3.3489)\n",
      "4753 Traning Loss: tensor(3.3489)\n",
      "4754 Traning Loss: tensor(3.3489)\n",
      "4755 Traning Loss: tensor(3.3489)\n",
      "4756 Traning Loss: tensor(3.3489)\n",
      "4757 Traning Loss: tensor(3.3489)\n",
      "4758 Traning Loss: tensor(3.3489)\n",
      "4759 Traning Loss: tensor(3.3489)\n",
      "4760 Traning Loss: tensor(3.3489)\n",
      "4761 Traning Loss: tensor(3.3489)\n",
      "4762 Traning Loss: tensor(3.3489)\n",
      "4763 Traning Loss: tensor(3.3489)\n",
      "4764 Traning Loss: tensor(3.3489)\n",
      "4765 Traning Loss: tensor(3.3489)\n",
      "4766 Traning Loss: tensor(3.3489)\n",
      "4767 Traning Loss: tensor(3.3489)\n",
      "4768 Traning Loss: tensor(3.3489)\n",
      "4769 Traning Loss: tensor(3.3489)\n",
      "4770 Traning Loss: tensor(3.3489)\n",
      "4771 Traning Loss: tensor(3.3489)\n",
      "4772 Traning Loss: tensor(3.3489)\n",
      "4773 Traning Loss: tensor(3.3489)\n",
      "4774 Traning Loss: tensor(3.3489)\n",
      "4775 Traning Loss: tensor(3.3489)\n",
      "4776 Traning Loss: tensor(3.3489)\n",
      "4777 Traning Loss: tensor(3.3489)\n",
      "4778 Traning Loss: tensor(3.3489)\n",
      "4779 Traning Loss: tensor(3.3489)\n",
      "4780 Traning Loss: tensor(3.3489)\n",
      "4781 Traning Loss: tensor(3.3489)\n",
      "4782 Traning Loss: tensor(3.3489)\n",
      "4783 Traning Loss: tensor(3.3489)\n",
      "4784 Traning Loss: tensor(3.3489)\n",
      "4785 Traning Loss: tensor(3.3489)\n",
      "4786 Traning Loss: tensor(3.3489)\n",
      "4787 Traning Loss: tensor(3.3489)\n",
      "4788 Traning Loss: tensor(3.3489)\n",
      "4789 Traning Loss: tensor(3.3489)\n",
      "4790 Traning Loss: tensor(3.3489)\n",
      "4791 Traning Loss: tensor(3.3489)\n",
      "4792 Traning Loss: tensor(3.3489)\n",
      "4793 Traning Loss: tensor(3.3489)\n",
      "4794 Traning Loss: tensor(3.3489)\n",
      "4795 Traning Loss: tensor(3.3489)\n",
      "4796 Traning Loss: tensor(3.3489)\n",
      "4797 Traning Loss: tensor(3.3489)\n",
      "4798 Traning Loss: tensor(3.3489)\n",
      "4799 Traning Loss: tensor(3.3489)\n",
      "4800 Traning Loss: tensor(3.3489)\n",
      "4801 Traning Loss: tensor(3.3489)\n",
      "4802 Traning Loss: tensor(3.3489)\n",
      "4803 Traning Loss: tensor(3.3489)\n",
      "4804 Traning Loss: tensor(3.3489)\n",
      "4805 Traning Loss: tensor(3.3489)\n",
      "4806 Traning Loss: tensor(3.3489)\n",
      "4807 Traning Loss: tensor(3.3489)\n",
      "4808 Traning Loss: tensor(3.3489)\n",
      "4809 Traning Loss: tensor(3.3489)\n",
      "4810 Traning Loss: tensor(3.3489)\n",
      "4811 Traning Loss: tensor(3.3489)\n",
      "4812 Traning Loss: tensor(3.3489)\n",
      "4813 Traning Loss: tensor(3.3489)\n",
      "4814 Traning Loss: tensor(3.3489)\n",
      "4815 Traning Loss: tensor(3.3489)\n",
      "4816 Traning Loss: tensor(3.3489)\n",
      "4817 Traning Loss: tensor(3.3489)\n",
      "4818 Traning Loss: tensor(3.3489)\n",
      "4819 Traning Loss: tensor(3.3489)\n",
      "4820 Traning Loss: tensor(3.3489)\n",
      "4821 Traning Loss: tensor(3.3489)\n",
      "4822 Traning Loss: tensor(3.3489)\n",
      "4823 Traning Loss: tensor(3.3489)\n",
      "4824 Traning Loss: tensor(3.3489)\n",
      "4825 Traning Loss: tensor(3.3489)\n",
      "4826 Traning Loss: tensor(3.3489)\n",
      "4827 Traning Loss: tensor(3.3489)\n",
      "4828 Traning Loss: tensor(3.3489)\n",
      "4829 Traning Loss: tensor(3.3489)\n",
      "4830 Traning Loss: tensor(3.3489)\n",
      "4831 Traning Loss: tensor(3.3489)\n",
      "4832 Traning Loss: tensor(3.3489)\n",
      "4833 Traning Loss: tensor(3.3489)\n",
      "4834 Traning Loss: tensor(3.3489)\n",
      "4835 Traning Loss: tensor(3.3489)\n",
      "4836 Traning Loss: tensor(3.3489)\n",
      "4837 Traning Loss: tensor(3.3489)\n",
      "4838 Traning Loss: tensor(3.3489)\n",
      "4839 Traning Loss: tensor(3.3489)\n",
      "4840 Traning Loss: tensor(3.3489)\n",
      "4841 Traning Loss: tensor(3.3489)\n",
      "4842 Traning Loss: tensor(3.3489)\n",
      "4843 Traning Loss: tensor(3.3489)\n",
      "4844 Traning Loss: tensor(3.3489)\n",
      "4845 Traning Loss: tensor(3.3489)\n",
      "4846 Traning Loss: tensor(3.3489)\n",
      "4847 Traning Loss: tensor(3.3489)\n",
      "4848 Traning Loss: tensor(3.3489)\n",
      "4849 Traning Loss: tensor(3.3489)\n",
      "4850 Traning Loss: tensor(3.3489)\n",
      "4851 Traning Loss: tensor(3.3489)\n",
      "4852 Traning Loss: tensor(3.3489)\n",
      "4853 Traning Loss: tensor(3.3489)\n",
      "4854 Traning Loss: tensor(3.3489)\n",
      "4855 Traning Loss: tensor(3.3489)\n",
      "4856 Traning Loss: tensor(3.3489)\n",
      "4857 Traning Loss: tensor(3.3489)\n",
      "4858 Traning Loss: tensor(3.3489)\n",
      "4859 Traning Loss: tensor(3.3489)\n",
      "4860 Traning Loss: tensor(3.3489)\n",
      "4861 Traning Loss: tensor(3.3489)\n",
      "4862 Traning Loss: tensor(3.3489)\n",
      "4863 Traning Loss: tensor(3.3489)\n",
      "4864 Traning Loss: tensor(3.3489)\n",
      "4865 Traning Loss: tensor(3.3489)\n",
      "4866 Traning Loss: tensor(3.3489)\n",
      "4867 Traning Loss: tensor(3.3489)\n",
      "4868 Traning Loss: tensor(3.3489)\n",
      "4869 Traning Loss: tensor(3.3489)\n",
      "4870 Traning Loss: tensor(3.3489)\n",
      "4871 Traning Loss: tensor(3.3489)\n",
      "4872 Traning Loss: tensor(3.3489)\n",
      "4873 Traning Loss: tensor(3.3489)\n",
      "4874 Traning Loss: tensor(3.3489)\n",
      "4875 Traning Loss: tensor(3.3489)\n",
      "4876 Traning Loss: tensor(3.3489)\n",
      "4877 Traning Loss: tensor(3.3489)\n",
      "4878 Traning Loss: tensor(3.3489)\n",
      "4879 Traning Loss: tensor(3.3489)\n",
      "4880 Traning Loss: tensor(3.3489)\n",
      "4881 Traning Loss: tensor(3.3489)\n",
      "4882 Traning Loss: tensor(3.3489)\n",
      "4883 Traning Loss: tensor(3.3489)\n",
      "4884 Traning Loss: tensor(3.3489)\n",
      "4885 Traning Loss: tensor(3.3489)\n",
      "4886 Traning Loss: tensor(3.3489)\n",
      "4887 Traning Loss: tensor(3.3489)\n",
      "4888 Traning Loss: tensor(3.3489)\n",
      "4889 Traning Loss: tensor(3.3489)\n",
      "4890 Traning Loss: tensor(3.3489)\n",
      "4891 Traning Loss: tensor(3.3489)\n",
      "4892 Traning Loss: tensor(3.3489)\n",
      "4893 Traning Loss: tensor(3.3489)\n",
      "4894 Traning Loss: tensor(3.3489)\n",
      "4895 Traning Loss: tensor(3.3489)\n",
      "4896 Traning Loss: tensor(3.3489)\n",
      "4897 Traning Loss: tensor(3.3489)\n",
      "4898 Traning Loss: tensor(3.3489)\n",
      "4899 Traning Loss: tensor(3.3489)\n",
      "4900 Traning Loss: tensor(3.3489)\n",
      "4901 Traning Loss: tensor(3.3489)\n",
      "4902 Traning Loss: tensor(3.3489)\n",
      "4903 Traning Loss: tensor(3.3489)\n",
      "4904 Traning Loss: tensor(3.3489)\n",
      "4905 Traning Loss: tensor(3.3489)\n",
      "4906 Traning Loss: tensor(3.3489)\n",
      "4907 Traning Loss: tensor(3.3489)\n",
      "4908 Traning Loss: tensor(3.3489)\n",
      "4909 Traning Loss: tensor(3.3489)\n",
      "4910 Traning Loss: tensor(3.3489)\n",
      "4911 Traning Loss: tensor(3.3489)\n",
      "4912 Traning Loss: tensor(3.3489)\n",
      "4913 Traning Loss: tensor(3.3489)\n",
      "4914 Traning Loss: tensor(3.3489)\n",
      "4915 Traning Loss: tensor(3.3489)\n",
      "4916 Traning Loss: tensor(3.3489)\n",
      "4917 Traning Loss: tensor(3.3489)\n",
      "4918 Traning Loss: tensor(3.3489)\n",
      "4919 Traning Loss: tensor(3.3489)\n",
      "4920 Traning Loss: tensor(3.3489)\n",
      "4921 Traning Loss: tensor(3.3489)\n",
      "4922 Traning Loss: tensor(3.3489)\n",
      "4923 Traning Loss: tensor(3.3489)\n",
      "4924 Traning Loss: tensor(3.3489)\n",
      "4925 Traning Loss: tensor(3.3489)\n",
      "4926 Traning Loss: tensor(3.3489)\n",
      "4927 Traning Loss: tensor(3.3489)\n",
      "4928 Traning Loss: tensor(3.3489)\n",
      "4929 Traning Loss: tensor(3.3489)\n",
      "4930 Traning Loss: tensor(3.3489)\n",
      "4931 Traning Loss: tensor(3.3489)\n",
      "4932 Traning Loss: tensor(3.3489)\n",
      "4933 Traning Loss: tensor(3.3489)\n",
      "4934 Traning Loss: tensor(3.3489)\n",
      "4935 Traning Loss: tensor(3.3489)\n",
      "4936 Traning Loss: tensor(3.3489)\n",
      "4937 Traning Loss: tensor(3.3489)\n",
      "4938 Traning Loss: tensor(3.3489)\n",
      "4939 Traning Loss: tensor(3.3489)\n",
      "4940 Traning Loss: tensor(3.3489)\n",
      "4941 Traning Loss: tensor(3.3489)\n",
      "4942 Traning Loss: tensor(3.3489)\n",
      "4943 Traning Loss: tensor(3.3489)\n",
      "4944 Traning Loss: tensor(3.3489)\n",
      "4945 Traning Loss: tensor(3.3489)\n",
      "4946 Traning Loss: tensor(3.3489)\n",
      "4947 Traning Loss: tensor(3.3489)\n",
      "4948 Traning Loss: tensor(3.3489)\n",
      "4949 Traning Loss: tensor(3.3489)\n",
      "4950 Traning Loss: tensor(3.3489)\n",
      "4951 Traning Loss: tensor(3.3489)\n",
      "4952 Traning Loss: tensor(3.3489)\n",
      "4953 Traning Loss: tensor(3.3489)\n",
      "4954 Traning Loss: tensor(3.3489)\n",
      "4955 Traning Loss: tensor(3.3489)\n",
      "4956 Traning Loss: tensor(3.3489)\n",
      "4957 Traning Loss: tensor(3.3489)\n",
      "4958 Traning Loss: tensor(3.3489)\n",
      "4959 Traning Loss: tensor(3.3489)\n",
      "4960 Traning Loss: tensor(3.3489)\n",
      "4961 Traning Loss: tensor(3.3489)\n",
      "4962 Traning Loss: tensor(3.3489)\n",
      "4963 Traning Loss: tensor(3.3489)\n",
      "4964 Traning Loss: tensor(3.3489)\n",
      "4965 Traning Loss: tensor(3.3489)\n",
      "4966 Traning Loss: tensor(3.3489)\n",
      "4967 Traning Loss: tensor(3.3489)\n",
      "4968 Traning Loss: tensor(3.3489)\n",
      "4969 Traning Loss: tensor(3.3489)\n",
      "4970 Traning Loss: tensor(3.3489)\n",
      "4971 Traning Loss: tensor(3.3489)\n",
      "4972 Traning Loss: tensor(3.3489)\n",
      "4973 Traning Loss: tensor(3.3489)\n",
      "4974 Traning Loss: tensor(3.3489)\n",
      "4975 Traning Loss: tensor(3.3489)\n",
      "4976 Traning Loss: tensor(3.3489)\n",
      "4977 Traning Loss: tensor(3.3489)\n",
      "4978 Traning Loss: tensor(3.3489)\n",
      "4979 Traning Loss: tensor(3.3489)\n",
      "4980 Traning Loss: tensor(3.3489)\n",
      "4981 Traning Loss: tensor(3.3489)\n",
      "4982 Traning Loss: tensor(3.3489)\n",
      "4983 Traning Loss: tensor(3.3489)\n",
      "4984 Traning Loss: tensor(3.3489)\n",
      "4985 Traning Loss: tensor(3.3489)\n",
      "4986 Traning Loss: tensor(3.3489)\n",
      "4987 Traning Loss: tensor(3.3489)\n",
      "4988 Traning Loss: tensor(3.3489)\n",
      "4989 Traning Loss: tensor(3.3489)\n",
      "4990 Traning Loss: tensor(3.3489)\n",
      "4991 Traning Loss: tensor(3.3489)\n",
      "4992 Traning Loss: tensor(3.3489)\n",
      "4993 Traning Loss: tensor(3.3489)\n",
      "4994 Traning Loss: tensor(3.3489)\n",
      "4995 Traning Loss: tensor(3.3489)\n",
      "4996 Traning Loss: tensor(3.3489)\n",
      "4997 Traning Loss: tensor(3.3489)\n",
      "4998 Traning Loss: tensor(3.3489)\n",
      "4999 Traning Loss: tensor(3.3489)\n",
      "5000 Traning Loss: tensor(3.3489)\n",
      "5001 Traning Loss: tensor(3.3489)\n",
      "5002 Traning Loss: tensor(3.3489)\n",
      "5003 Traning Loss: tensor(3.3489)\n",
      "5004 Traning Loss: tensor(3.3489)\n",
      "5005 Traning Loss: tensor(3.3489)\n",
      "5006 Traning Loss: tensor(3.3489)\n",
      "5007 Traning Loss: tensor(3.3489)\n",
      "5008 Traning Loss: tensor(3.3489)\n",
      "5009 Traning Loss: tensor(3.3489)\n",
      "5010 Traning Loss: tensor(3.3489)\n",
      "5011 Traning Loss: tensor(3.3489)\n",
      "5012 Traning Loss: tensor(3.3489)\n",
      "5013 Traning Loss: tensor(3.3489)\n",
      "5014 Traning Loss: tensor(3.3489)\n",
      "5015 Traning Loss: tensor(3.3489)\n",
      "5016 Traning Loss: tensor(3.3489)\n",
      "5017 Traning Loss: tensor(3.3489)\n",
      "5018 Traning Loss: tensor(3.3489)\n",
      "5019 Traning Loss: tensor(3.3489)\n",
      "5020 Traning Loss: tensor(3.3489)\n",
      "5021 Traning Loss: tensor(3.3489)\n",
      "5022 Traning Loss: tensor(3.3489)\n",
      "5023 Traning Loss: tensor(3.3489)\n",
      "5024 Traning Loss: tensor(3.3489)\n",
      "5025 Traning Loss: tensor(3.3489)\n",
      "5026 Traning Loss: tensor(3.3489)\n",
      "5027 Traning Loss: tensor(3.3489)\n",
      "5028 Traning Loss: tensor(3.3489)\n",
      "5029 Traning Loss: tensor(3.3489)\n",
      "5030 Traning Loss: tensor(3.3489)\n",
      "5031 Traning Loss: tensor(3.3489)\n",
      "5032 Traning Loss: tensor(3.3489)\n",
      "5033 Traning Loss: tensor(3.3489)\n",
      "5034 Traning Loss: tensor(3.3489)\n",
      "5035 Traning Loss: tensor(3.3489)\n",
      "5036 Traning Loss: tensor(3.3489)\n",
      "5037 Traning Loss: tensor(3.3489)\n",
      "5038 Traning Loss: tensor(3.3489)\n",
      "5039 Traning Loss: tensor(3.3489)\n",
      "5040 Traning Loss: tensor(3.3489)\n",
      "5041 Traning Loss: tensor(3.3489)\n",
      "5042 Traning Loss: tensor(3.3489)\n",
      "5043 Traning Loss: tensor(3.3489)\n",
      "5044 Traning Loss: tensor(3.3489)\n",
      "5045 Traning Loss: tensor(3.3489)\n",
      "5046 Traning Loss: tensor(3.3489)\n",
      "5047 Traning Loss: tensor(3.3489)\n",
      "5048 Traning Loss: tensor(3.3489)\n",
      "5049 Traning Loss: tensor(3.3489)\n",
      "5050 Traning Loss: tensor(3.3489)\n",
      "5051 Traning Loss: tensor(3.3489)\n",
      "5052 Traning Loss: tensor(3.3489)\n",
      "5053 Traning Loss: tensor(3.3489)\n",
      "5054 Traning Loss: tensor(3.3489)\n",
      "5055 Traning Loss: tensor(3.3489)\n",
      "5056 Traning Loss: tensor(3.3489)\n",
      "5057 Traning Loss: tensor(3.3489)\n",
      "5058 Traning Loss: tensor(3.3489)\n",
      "5059 Traning Loss: tensor(3.3489)\n",
      "5060 Traning Loss: tensor(3.3489)\n",
      "5061 Traning Loss: tensor(3.3489)\n",
      "5062 Traning Loss: tensor(3.3489)\n",
      "5063 Traning Loss: tensor(3.3489)\n",
      "5064 Traning Loss: tensor(3.3489)\n",
      "5065 Traning Loss: tensor(3.3489)\n",
      "5066 Traning Loss: tensor(3.3489)\n",
      "5067 Traning Loss: tensor(3.3489)\n",
      "5068 Traning Loss: tensor(3.3489)\n",
      "5069 Traning Loss: tensor(3.3489)\n",
      "5070 Traning Loss: tensor(3.3489)\n",
      "5071 Traning Loss: tensor(3.3489)\n",
      "5072 Traning Loss: tensor(3.3489)\n",
      "5073 Traning Loss: tensor(3.3489)\n",
      "5074 Traning Loss: tensor(3.3489)\n",
      "5075 Traning Loss: tensor(3.3489)\n",
      "5076 Traning Loss: tensor(3.3489)\n",
      "5077 Traning Loss: tensor(3.3489)\n",
      "5078 Traning Loss: tensor(3.3489)\n",
      "5079 Traning Loss: tensor(3.3489)\n",
      "5080 Traning Loss: tensor(3.3489)\n",
      "5081 Traning Loss: tensor(3.3489)\n",
      "5082 Traning Loss: tensor(3.3489)\n",
      "5083 Traning Loss: tensor(3.3489)\n",
      "5084 Traning Loss: tensor(3.3489)\n",
      "5085 Traning Loss: tensor(3.3489)\n",
      "5086 Traning Loss: tensor(3.3489)\n",
      "5087 Traning Loss: tensor(3.3489)\n",
      "5088 Traning Loss: tensor(3.3489)\n",
      "5089 Traning Loss: tensor(3.3489)\n",
      "5090 Traning Loss: tensor(3.3489)\n",
      "5091 Traning Loss: tensor(3.3489)\n",
      "5092 Traning Loss: tensor(3.3489)\n",
      "5093 Traning Loss: tensor(3.3489)\n",
      "5094 Traning Loss: tensor(3.3489)\n",
      "5095 Traning Loss: tensor(3.3489)\n",
      "5096 Traning Loss: tensor(3.3489)\n",
      "5097 Traning Loss: tensor(3.3489)\n",
      "5098 Traning Loss: tensor(3.3489)\n",
      "5099 Traning Loss: tensor(3.3489)\n",
      "5100 Traning Loss: tensor(3.3489)\n",
      "5101 Traning Loss: tensor(3.3489)\n",
      "5102 Traning Loss: tensor(3.3489)\n",
      "5103 Traning Loss: tensor(3.3489)\n",
      "5104 Traning Loss: tensor(3.3489)\n",
      "5105 Traning Loss: tensor(3.3489)\n",
      "5106 Traning Loss: tensor(3.3489)\n",
      "5107 Traning Loss: tensor(3.3489)\n",
      "5108 Traning Loss: tensor(3.3489)\n",
      "5109 Traning Loss: tensor(3.3489)\n",
      "5110 Traning Loss: tensor(3.3489)\n",
      "5111 Traning Loss: tensor(3.3489)\n",
      "5112 Traning Loss: tensor(3.3489)\n",
      "5113 Traning Loss: tensor(3.3489)\n",
      "5114 Traning Loss: tensor(3.3489)\n",
      "5115 Traning Loss: tensor(3.3489)\n",
      "5116 Traning Loss: tensor(3.3489)\n",
      "5117 Traning Loss: tensor(3.3489)\n",
      "5118 Traning Loss: tensor(3.3489)\n",
      "5119 Traning Loss: tensor(3.3489)\n",
      "5120 Traning Loss: tensor(3.3489)\n",
      "5121 Traning Loss: tensor(3.3489)\n",
      "5122 Traning Loss: tensor(3.3489)\n",
      "5123 Traning Loss: tensor(3.3489)\n",
      "5124 Traning Loss: tensor(3.3489)\n",
      "5125 Traning Loss: tensor(3.3489)\n",
      "5126 Traning Loss: tensor(3.3489)\n",
      "5127 Traning Loss: tensor(3.3489)\n",
      "5128 Traning Loss: tensor(3.3489)\n",
      "5129 Traning Loss: tensor(3.3489)\n",
      "5130 Traning Loss: tensor(3.3489)\n",
      "5131 Traning Loss: tensor(3.3489)\n",
      "5132 Traning Loss: tensor(3.3489)\n",
      "5133 Traning Loss: tensor(3.3489)\n",
      "5134 Traning Loss: tensor(3.3489)\n",
      "5135 Traning Loss: tensor(3.3489)\n",
      "5136 Traning Loss: tensor(3.3489)\n",
      "5137 Traning Loss: tensor(3.3489)\n",
      "5138 Traning Loss: tensor(3.3489)\n",
      "5139 Traning Loss: tensor(3.3489)\n",
      "5140 Traning Loss: tensor(3.3489)\n",
      "5141 Traning Loss: tensor(3.3489)\n",
      "5142 Traning Loss: tensor(3.3489)\n",
      "5143 Traning Loss: tensor(3.3489)\n",
      "5144 Traning Loss: tensor(3.3489)\n",
      "5145 Traning Loss: tensor(3.3489)\n",
      "5146 Traning Loss: tensor(3.3489)\n",
      "5147 Traning Loss: tensor(3.3489)\n",
      "5148 Traning Loss: tensor(3.3489)\n",
      "5149 Traning Loss: tensor(3.3489)\n",
      "5150 Traning Loss: tensor(3.3489)\n",
      "5151 Traning Loss: tensor(3.3489)\n",
      "5152 Traning Loss: tensor(3.3489)\n",
      "5153 Traning Loss: tensor(3.3489)\n",
      "5154 Traning Loss: tensor(3.3489)\n",
      "5155 Traning Loss: tensor(3.3489)\n",
      "5156 Traning Loss: tensor(3.3489)\n",
      "5157 Traning Loss: tensor(3.3489)\n",
      "5158 Traning Loss: tensor(3.3489)\n",
      "5159 Traning Loss: tensor(3.3489)\n",
      "5160 Traning Loss: tensor(3.3489)\n",
      "5161 Traning Loss: tensor(3.3489)\n",
      "5162 Traning Loss: tensor(3.3489)\n",
      "5163 Traning Loss: tensor(3.3489)\n",
      "5164 Traning Loss: tensor(3.3489)\n",
      "5165 Traning Loss: tensor(3.3489)\n",
      "5166 Traning Loss: tensor(3.3489)\n",
      "5167 Traning Loss: tensor(3.3489)\n",
      "5168 Traning Loss: tensor(3.3489)\n",
      "5169 Traning Loss: tensor(3.3489)\n",
      "5170 Traning Loss: tensor(3.3489)\n",
      "5171 Traning Loss: tensor(3.3489)\n",
      "5172 Traning Loss: tensor(3.3489)\n",
      "5173 Traning Loss: tensor(3.3489)\n",
      "5174 Traning Loss: tensor(3.3489)\n",
      "5175 Traning Loss: tensor(3.3489)\n",
      "5176 Traning Loss: tensor(3.3489)\n",
      "5177 Traning Loss: tensor(3.3489)\n",
      "5178 Traning Loss: tensor(3.3489)\n",
      "5179 Traning Loss: tensor(3.3489)\n",
      "5180 Traning Loss: tensor(3.3489)\n",
      "5181 Traning Loss: tensor(3.3489)\n",
      "5182 Traning Loss: tensor(3.3489)\n",
      "5183 Traning Loss: tensor(3.3489)\n",
      "5184 Traning Loss: tensor(3.3489)\n",
      "5185 Traning Loss: tensor(3.3489)\n",
      "5186 Traning Loss: tensor(3.3489)\n",
      "5187 Traning Loss: tensor(3.3489)\n",
      "5188 Traning Loss: tensor(3.3489)\n",
      "5189 Traning Loss: tensor(3.3489)\n",
      "5190 Traning Loss: tensor(3.3489)\n",
      "5191 Traning Loss: tensor(3.3489)\n",
      "5192 Traning Loss: tensor(3.3489)\n",
      "5193 Traning Loss: tensor(3.3489)\n",
      "5194 Traning Loss: tensor(3.3489)\n",
      "5195 Traning Loss: tensor(3.3489)\n",
      "5196 Traning Loss: tensor(3.3489)\n",
      "5197 Traning Loss: tensor(3.3489)\n",
      "5198 Traning Loss: tensor(3.3489)\n",
      "5199 Traning Loss: tensor(3.3489)\n",
      "5200 Traning Loss: tensor(3.3489)\n",
      "5201 Traning Loss: tensor(3.3489)\n",
      "5202 Traning Loss: tensor(3.3489)\n",
      "5203 Traning Loss: tensor(3.3489)\n",
      "5204 Traning Loss: tensor(3.3489)\n",
      "5205 Traning Loss: tensor(3.3489)\n",
      "5206 Traning Loss: tensor(3.3489)\n",
      "5207 Traning Loss: tensor(3.3489)\n",
      "5208 Traning Loss: tensor(3.3489)\n",
      "5209 Traning Loss: tensor(3.3489)\n",
      "5210 Traning Loss: tensor(3.3489)\n",
      "5211 Traning Loss: tensor(3.3489)\n",
      "5212 Traning Loss: tensor(3.3489)\n",
      "5213 Traning Loss: tensor(3.3489)\n",
      "5214 Traning Loss: tensor(3.3489)\n",
      "5215 Traning Loss: tensor(3.3489)\n",
      "5216 Traning Loss: tensor(3.3489)\n",
      "5217 Traning Loss: tensor(3.3489)\n",
      "5218 Traning Loss: tensor(3.3489)\n",
      "5219 Traning Loss: tensor(3.3489)\n",
      "5220 Traning Loss: tensor(3.3489)\n",
      "5221 Traning Loss: tensor(3.3489)\n",
      "5222 Traning Loss: tensor(3.3489)\n",
      "5223 Traning Loss: tensor(3.3489)\n",
      "5224 Traning Loss: tensor(3.3489)\n",
      "5225 Traning Loss: tensor(3.3489)\n",
      "5226 Traning Loss: tensor(3.3489)\n",
      "5227 Traning Loss: tensor(3.3489)\n",
      "5228 Traning Loss: tensor(3.3489)\n",
      "5229 Traning Loss: tensor(3.3489)\n",
      "5230 Traning Loss: tensor(3.3489)\n",
      "5231 Traning Loss: tensor(3.3489)\n",
      "5232 Traning Loss: tensor(3.3489)\n",
      "5233 Traning Loss: tensor(3.3489)\n",
      "5234 Traning Loss: tensor(3.3489)\n",
      "5235 Traning Loss: tensor(3.3489)\n",
      "5236 Traning Loss: tensor(3.3489)\n",
      "5237 Traning Loss: tensor(3.3489)\n",
      "5238 Traning Loss: tensor(3.3489)\n",
      "5239 Traning Loss: tensor(3.3489)\n",
      "5240 Traning Loss: tensor(3.3489)\n",
      "5241 Traning Loss: tensor(3.3489)\n",
      "5242 Traning Loss: tensor(3.3489)\n",
      "5243 Traning Loss: tensor(3.3489)\n",
      "5244 Traning Loss: tensor(3.3489)\n",
      "5245 Traning Loss: tensor(3.3489)\n",
      "5246 Traning Loss: tensor(3.3489)\n",
      "5247 Traning Loss: tensor(3.3489)\n",
      "5248 Traning Loss: tensor(3.3489)\n",
      "5249 Traning Loss: tensor(3.3489)\n",
      "5250 Traning Loss: tensor(3.3489)\n",
      "5251 Traning Loss: tensor(3.3489)\n",
      "5252 Traning Loss: tensor(3.3489)\n",
      "5253 Traning Loss: tensor(3.3489)\n",
      "5254 Traning Loss: tensor(3.3489)\n",
      "5255 Traning Loss: tensor(3.3489)\n",
      "5256 Traning Loss: tensor(3.3489)\n",
      "5257 Traning Loss: tensor(3.3489)\n",
      "5258 Traning Loss: tensor(3.3489)\n",
      "5259 Traning Loss: tensor(3.3489)\n",
      "5260 Traning Loss: tensor(3.3489)\n",
      "5261 Traning Loss: tensor(3.3489)\n",
      "5262 Traning Loss: tensor(3.3489)\n",
      "5263 Traning Loss: tensor(3.3489)\n",
      "5264 Traning Loss: tensor(3.3489)\n",
      "5265 Traning Loss: tensor(3.3489)\n",
      "5266 Traning Loss: tensor(3.3489)\n",
      "5267 Traning Loss: tensor(3.3489)\n",
      "5268 Traning Loss: tensor(3.3489)\n",
      "5269 Traning Loss: tensor(3.3489)\n",
      "5270 Traning Loss: tensor(3.3489)\n",
      "5271 Traning Loss: tensor(3.3489)\n",
      "5272 Traning Loss: tensor(3.3489)\n",
      "5273 Traning Loss: tensor(3.3489)\n",
      "5274 Traning Loss: tensor(3.3489)\n",
      "5275 Traning Loss: tensor(3.3489)\n",
      "5276 Traning Loss: tensor(3.3489)\n",
      "5277 Traning Loss: tensor(3.3489)\n",
      "5278 Traning Loss: tensor(3.3489)\n",
      "5279 Traning Loss: tensor(3.3489)\n",
      "5280 Traning Loss: tensor(3.3489)\n",
      "5281 Traning Loss: tensor(3.3489)\n",
      "5282 Traning Loss: tensor(3.3489)\n",
      "5283 Traning Loss: tensor(3.3489)\n",
      "5284 Traning Loss: tensor(3.3489)\n",
      "5285 Traning Loss: tensor(3.3489)\n",
      "5286 Traning Loss: tensor(3.3489)\n",
      "5287 Traning Loss: tensor(3.3489)\n",
      "5288 Traning Loss: tensor(3.3489)\n",
      "5289 Traning Loss: tensor(3.3489)\n",
      "5290 Traning Loss: tensor(3.3489)\n",
      "5291 Traning Loss: tensor(3.3489)\n",
      "5292 Traning Loss: tensor(3.3489)\n",
      "5293 Traning Loss: tensor(3.3489)\n",
      "5294 Traning Loss: tensor(3.3489)\n",
      "5295 Traning Loss: tensor(3.3489)\n",
      "5296 Traning Loss: tensor(3.3489)\n",
      "5297 Traning Loss: tensor(3.3489)\n",
      "5298 Traning Loss: tensor(3.3489)\n",
      "5299 Traning Loss: tensor(3.3489)\n",
      "5300 Traning Loss: tensor(3.3489)\n",
      "5301 Traning Loss: tensor(3.3489)\n",
      "5302 Traning Loss: tensor(3.3489)\n",
      "5303 Traning Loss: tensor(3.3489)\n",
      "5304 Traning Loss: tensor(3.3489)\n",
      "5305 Traning Loss: tensor(3.3489)\n",
      "5306 Traning Loss: tensor(3.3489)\n",
      "5307 Traning Loss: tensor(3.3489)\n",
      "5308 Traning Loss: tensor(3.3489)\n",
      "5309 Traning Loss: tensor(3.3489)\n",
      "5310 Traning Loss: tensor(3.3489)\n",
      "5311 Traning Loss: tensor(3.3489)\n",
      "5312 Traning Loss: tensor(3.3489)\n",
      "5313 Traning Loss: tensor(3.3489)\n",
      "5314 Traning Loss: tensor(3.3489)\n",
      "5315 Traning Loss: tensor(3.3489)\n",
      "5316 Traning Loss: tensor(3.3489)\n",
      "5317 Traning Loss: tensor(3.3489)\n",
      "5318 Traning Loss: tensor(3.3489)\n",
      "5319 Traning Loss: tensor(3.3489)\n",
      "5320 Traning Loss: tensor(3.3489)\n",
      "5321 Traning Loss: tensor(3.3489)\n",
      "5322 Traning Loss: tensor(3.3489)\n",
      "5323 Traning Loss: tensor(3.3489)\n",
      "5324 Traning Loss: tensor(3.3489)\n",
      "5325 Traning Loss: tensor(3.3489)\n",
      "5326 Traning Loss: tensor(3.3489)\n",
      "5327 Traning Loss: tensor(3.3489)\n",
      "5328 Traning Loss: tensor(3.3489)\n",
      "5329 Traning Loss: tensor(3.3489)\n",
      "5330 Traning Loss: tensor(3.3489)\n",
      "5331 Traning Loss: tensor(3.3489)\n",
      "5332 Traning Loss: tensor(3.3489)\n",
      "5333 Traning Loss: tensor(3.3489)\n",
      "5334 Traning Loss: tensor(3.3489)\n",
      "5335 Traning Loss: tensor(3.3489)\n",
      "5336 Traning Loss: tensor(3.3489)\n",
      "5337 Traning Loss: tensor(3.3489)\n",
      "5338 Traning Loss: tensor(3.3489)\n",
      "5339 Traning Loss: tensor(3.3489)\n",
      "5340 Traning Loss: tensor(3.3489)\n",
      "5341 Traning Loss: tensor(3.3489)\n",
      "5342 Traning Loss: tensor(3.3489)\n",
      "5343 Traning Loss: tensor(3.3489)\n",
      "5344 Traning Loss: tensor(3.3489)\n",
      "5345 Traning Loss: tensor(3.3489)\n",
      "5346 Traning Loss: tensor(3.3489)\n",
      "5347 Traning Loss: tensor(3.3489)\n",
      "5348 Traning Loss: tensor(3.3489)\n",
      "5349 Traning Loss: tensor(3.3489)\n",
      "5350 Traning Loss: tensor(3.3489)\n",
      "5351 Traning Loss: tensor(3.3489)\n",
      "5352 Traning Loss: tensor(3.3489)\n",
      "5353 Traning Loss: tensor(3.3489)\n",
      "5354 Traning Loss: tensor(3.3489)\n",
      "5355 Traning Loss: tensor(3.3489)\n",
      "5356 Traning Loss: tensor(3.3489)\n",
      "5357 Traning Loss: tensor(3.3489)\n",
      "5358 Traning Loss: tensor(3.3489)\n",
      "5359 Traning Loss: tensor(3.3489)\n",
      "5360 Traning Loss: tensor(3.3489)\n",
      "5361 Traning Loss: tensor(3.3489)\n",
      "5362 Traning Loss: tensor(3.3489)\n",
      "5363 Traning Loss: tensor(3.3489)\n",
      "5364 Traning Loss: tensor(3.3489)\n",
      "5365 Traning Loss: tensor(3.3489)\n",
      "5366 Traning Loss: tensor(3.3489)\n",
      "5367 Traning Loss: tensor(3.3489)\n",
      "5368 Traning Loss: tensor(3.3489)\n",
      "5369 Traning Loss: tensor(3.3489)\n",
      "5370 Traning Loss: tensor(3.3489)\n",
      "5371 Traning Loss: tensor(3.3489)\n",
      "5372 Traning Loss: tensor(3.3489)\n",
      "5373 Traning Loss: tensor(3.3489)\n",
      "5374 Traning Loss: tensor(3.3489)\n",
      "5375 Traning Loss: tensor(3.3489)\n",
      "5376 Traning Loss: tensor(3.3489)\n",
      "5377 Traning Loss: tensor(3.3489)\n",
      "5378 Traning Loss: tensor(3.3489)\n",
      "5379 Traning Loss: tensor(3.3489)\n",
      "5380 Traning Loss: tensor(3.3489)\n",
      "5381 Traning Loss: tensor(3.3489)\n",
      "5382 Traning Loss: tensor(3.3489)\n",
      "5383 Traning Loss: tensor(3.3489)\n",
      "5384 Traning Loss: tensor(3.3489)\n",
      "5385 Traning Loss: tensor(3.3489)\n",
      "5386 Traning Loss: tensor(3.3489)\n",
      "5387 Traning Loss: tensor(3.3489)\n",
      "5388 Traning Loss: tensor(3.3489)\n",
      "5389 Traning Loss: tensor(3.3489)\n",
      "5390 Traning Loss: tensor(3.3489)\n",
      "5391 Traning Loss: tensor(3.3489)\n",
      "5392 Traning Loss: tensor(3.3489)\n",
      "5393 Traning Loss: tensor(3.3489)\n",
      "5394 Traning Loss: tensor(3.3489)\n",
      "5395 Traning Loss: tensor(3.3489)\n",
      "5396 Traning Loss: tensor(3.3489)\n",
      "5397 Traning Loss: tensor(3.3489)\n",
      "5398 Traning Loss: tensor(3.3489)\n",
      "5399 Traning Loss: tensor(3.3489)\n",
      "5400 Traning Loss: tensor(3.3489)\n",
      "5401 Traning Loss: tensor(3.3489)\n",
      "5402 Traning Loss: tensor(3.3489)\n",
      "5403 Traning Loss: tensor(3.3489)\n",
      "5404 Traning Loss: tensor(3.3489)\n",
      "5405 Traning Loss: tensor(3.3489)\n",
      "5406 Traning Loss: tensor(3.3489)\n",
      "5407 Traning Loss: tensor(3.3489)\n",
      "5408 Traning Loss: tensor(3.3489)\n",
      "5409 Traning Loss: tensor(3.3489)\n",
      "5410 Traning Loss: tensor(3.3489)\n",
      "5411 Traning Loss: tensor(3.3489)\n",
      "5412 Traning Loss: tensor(3.3489)\n",
      "5413 Traning Loss: tensor(3.3489)\n",
      "5414 Traning Loss: tensor(3.3489)\n",
      "5415 Traning Loss: tensor(3.3489)\n",
      "5416 Traning Loss: tensor(3.3489)\n",
      "5417 Traning Loss: tensor(3.3489)\n",
      "5418 Traning Loss: tensor(3.3489)\n",
      "5419 Traning Loss: tensor(3.3489)\n",
      "5420 Traning Loss: tensor(3.3489)\n",
      "5421 Traning Loss: tensor(3.3489)\n",
      "5422 Traning Loss: tensor(3.3489)\n",
      "5423 Traning Loss: tensor(3.3489)\n",
      "5424 Traning Loss: tensor(3.3489)\n",
      "5425 Traning Loss: tensor(3.3489)\n",
      "5426 Traning Loss: tensor(3.3489)\n",
      "5427 Traning Loss: tensor(3.3489)\n",
      "5428 Traning Loss: tensor(3.3489)\n",
      "5429 Traning Loss: tensor(3.3489)\n",
      "5430 Traning Loss: tensor(3.3489)\n",
      "5431 Traning Loss: tensor(3.3489)\n",
      "5432 Traning Loss: tensor(3.3489)\n",
      "5433 Traning Loss: tensor(3.3489)\n",
      "5434 Traning Loss: tensor(3.3489)\n",
      "5435 Traning Loss: tensor(3.3489)\n",
      "5436 Traning Loss: tensor(3.3489)\n",
      "5437 Traning Loss: tensor(3.3489)\n",
      "5438 Traning Loss: tensor(3.3489)\n",
      "5439 Traning Loss: tensor(3.3489)\n",
      "5440 Traning Loss: tensor(3.3489)\n",
      "5441 Traning Loss: tensor(3.3489)\n",
      "5442 Traning Loss: tensor(3.3489)\n",
      "5443 Traning Loss: tensor(3.3489)\n",
      "5444 Traning Loss: tensor(3.3489)\n",
      "5445 Traning Loss: tensor(3.3489)\n",
      "5446 Traning Loss: tensor(3.3489)\n",
      "5447 Traning Loss: tensor(3.3489)\n",
      "5448 Traning Loss: tensor(3.3489)\n",
      "5449 Traning Loss: tensor(3.3489)\n",
      "5450 Traning Loss: tensor(3.3489)\n",
      "5451 Traning Loss: tensor(3.3489)\n",
      "5452 Traning Loss: tensor(3.3489)\n",
      "5453 Traning Loss: tensor(3.3489)\n",
      "5454 Traning Loss: tensor(3.3489)\n",
      "5455 Traning Loss: tensor(3.3489)\n",
      "5456 Traning Loss: tensor(3.3489)\n",
      "5457 Traning Loss: tensor(3.3489)\n",
      "5458 Traning Loss: tensor(3.3489)\n",
      "5459 Traning Loss: tensor(3.3489)\n",
      "5460 Traning Loss: tensor(3.3489)\n",
      "5461 Traning Loss: tensor(3.3489)\n",
      "5462 Traning Loss: tensor(3.3489)\n",
      "5463 Traning Loss: tensor(3.3489)\n",
      "5464 Traning Loss: tensor(3.3489)\n",
      "5465 Traning Loss: tensor(3.3489)\n",
      "5466 Traning Loss: tensor(3.3489)\n",
      "5467 Traning Loss: tensor(3.3489)\n",
      "5468 Traning Loss: tensor(3.3489)\n",
      "5469 Traning Loss: tensor(3.3489)\n",
      "5470 Traning Loss: tensor(3.3489)\n",
      "5471 Traning Loss: tensor(3.3489)\n",
      "5472 Traning Loss: tensor(3.3489)\n",
      "5473 Traning Loss: tensor(3.3489)\n",
      "5474 Traning Loss: tensor(3.3489)\n",
      "5475 Traning Loss: tensor(3.3489)\n",
      "5476 Traning Loss: tensor(3.3489)\n",
      "5477 Traning Loss: tensor(3.3489)\n",
      "5478 Traning Loss: tensor(3.3489)\n",
      "5479 Traning Loss: tensor(3.3489)\n",
      "5480 Traning Loss: tensor(3.3489)\n",
      "5481 Traning Loss: tensor(3.3489)\n",
      "5482 Traning Loss: tensor(3.3489)\n",
      "5483 Traning Loss: tensor(3.3489)\n",
      "5484 Traning Loss: tensor(3.3489)\n",
      "5485 Traning Loss: tensor(3.3489)\n",
      "5486 Traning Loss: tensor(3.3489)\n",
      "5487 Traning Loss: tensor(3.3489)\n",
      "5488 Traning Loss: tensor(3.3489)\n",
      "5489 Traning Loss: tensor(3.3489)\n",
      "5490 Traning Loss: tensor(3.3489)\n",
      "5491 Traning Loss: tensor(3.3489)\n",
      "5492 Traning Loss: tensor(3.3489)\n",
      "5493 Traning Loss: tensor(3.3489)\n",
      "5494 Traning Loss: tensor(3.3489)\n",
      "5495 Traning Loss: tensor(3.3489)\n",
      "5496 Traning Loss: tensor(3.3489)\n",
      "5497 Traning Loss: tensor(3.3489)\n",
      "5498 Traning Loss: tensor(3.3489)\n",
      "5499 Traning Loss: tensor(3.3489)\n",
      "5500 Traning Loss: tensor(3.3489)\n",
      "5501 Traning Loss: tensor(3.3489)\n",
      "5502 Traning Loss: tensor(3.3489)\n",
      "5503 Traning Loss: tensor(3.3489)\n",
      "5504 Traning Loss: tensor(3.3489)\n",
      "5505 Traning Loss: tensor(3.3489)\n",
      "5506 Traning Loss: tensor(3.3489)\n",
      "5507 Traning Loss: tensor(3.3489)\n",
      "5508 Traning Loss: tensor(3.3489)\n",
      "5509 Traning Loss: tensor(3.3489)\n",
      "5510 Traning Loss: tensor(3.3489)\n",
      "5511 Traning Loss: tensor(3.3489)\n",
      "5512 Traning Loss: tensor(3.3489)\n",
      "5513 Traning Loss: tensor(3.3489)\n",
      "5514 Traning Loss: tensor(3.3489)\n",
      "5515 Traning Loss: tensor(3.3489)\n",
      "5516 Traning Loss: tensor(3.3489)\n",
      "5517 Traning Loss: tensor(3.3489)\n",
      "5518 Traning Loss: tensor(3.3489)\n",
      "5519 Traning Loss: tensor(3.3489)\n",
      "5520 Traning Loss: tensor(3.3489)\n",
      "5521 Traning Loss: tensor(3.3489)\n",
      "5522 Traning Loss: tensor(3.3489)\n",
      "5523 Traning Loss: tensor(3.3489)\n",
      "5524 Traning Loss: tensor(3.3489)\n",
      "5525 Traning Loss: tensor(3.3489)\n",
      "5526 Traning Loss: tensor(3.3489)\n",
      "5527 Traning Loss: tensor(3.3489)\n",
      "5528 Traning Loss: tensor(3.3489)\n",
      "5529 Traning Loss: tensor(3.3489)\n",
      "5530 Traning Loss: tensor(3.3489)\n",
      "5531 Traning Loss: tensor(3.3489)\n",
      "5532 Traning Loss: tensor(3.3489)\n",
      "5533 Traning Loss: tensor(3.3489)\n",
      "5534 Traning Loss: tensor(3.3489)\n",
      "5535 Traning Loss: tensor(3.3489)\n",
      "5536 Traning Loss: tensor(3.3489)\n",
      "5537 Traning Loss: tensor(3.3489)\n",
      "5538 Traning Loss: tensor(3.3489)\n",
      "5539 Traning Loss: tensor(3.3489)\n",
      "5540 Traning Loss: tensor(3.3489)\n",
      "5541 Traning Loss: tensor(3.3489)\n",
      "5542 Traning Loss: tensor(3.3489)\n",
      "5543 Traning Loss: tensor(3.3489)\n",
      "5544 Traning Loss: tensor(3.3489)\n",
      "5545 Traning Loss: tensor(3.3489)\n",
      "5546 Traning Loss: tensor(3.3489)\n",
      "5547 Traning Loss: tensor(3.3489)\n",
      "5548 Traning Loss: tensor(3.3489)\n",
      "5549 Traning Loss: tensor(3.3489)\n",
      "5550 Traning Loss: tensor(3.3489)\n",
      "5551 Traning Loss: tensor(3.3489)\n",
      "5552 Traning Loss: tensor(3.3489)\n",
      "5553 Traning Loss: tensor(3.3489)\n",
      "5554 Traning Loss: tensor(3.3489)\n",
      "5555 Traning Loss: tensor(3.3489)\n",
      "5556 Traning Loss: tensor(3.3489)\n",
      "5557 Traning Loss: tensor(3.3489)\n",
      "5558 Traning Loss: tensor(3.3489)\n",
      "5559 Traning Loss: tensor(3.3489)\n",
      "5560 Traning Loss: tensor(3.3489)\n",
      "5561 Traning Loss: tensor(3.3489)\n",
      "5562 Traning Loss: tensor(3.3489)\n",
      "5563 Traning Loss: tensor(3.3489)\n",
      "5564 Traning Loss: tensor(3.3489)\n",
      "5565 Traning Loss: tensor(3.3489)\n",
      "5566 Traning Loss: tensor(3.3489)\n",
      "5567 Traning Loss: tensor(3.3489)\n",
      "5568 Traning Loss: tensor(3.3489)\n",
      "5569 Traning Loss: tensor(3.3489)\n",
      "5570 Traning Loss: tensor(3.3489)\n",
      "5571 Traning Loss: tensor(3.3489)\n",
      "5572 Traning Loss: tensor(3.3489)\n",
      "5573 Traning Loss: tensor(3.3489)\n",
      "5574 Traning Loss: tensor(3.3489)\n",
      "5575 Traning Loss: tensor(3.3489)\n",
      "5576 Traning Loss: tensor(3.3489)\n",
      "5577 Traning Loss: tensor(3.3489)\n",
      "5578 Traning Loss: tensor(3.3489)\n",
      "5579 Traning Loss: tensor(3.3489)\n",
      "5580 Traning Loss: tensor(3.3489)\n",
      "5581 Traning Loss: tensor(3.3489)\n",
      "5582 Traning Loss: tensor(3.3489)\n",
      "5583 Traning Loss: tensor(3.3489)\n",
      "5584 Traning Loss: tensor(3.3489)\n",
      "5585 Traning Loss: tensor(3.3489)\n",
      "5586 Traning Loss: tensor(3.3489)\n",
      "5587 Traning Loss: tensor(3.3489)\n",
      "5588 Traning Loss: tensor(3.3489)\n",
      "5589 Traning Loss: tensor(3.3489)\n",
      "5590 Traning Loss: tensor(3.3489)\n",
      "5591 Traning Loss: tensor(3.3489)\n",
      "5592 Traning Loss: tensor(3.3489)\n",
      "5593 Traning Loss: tensor(3.3489)\n",
      "5594 Traning Loss: tensor(3.3489)\n",
      "5595 Traning Loss: tensor(3.3489)\n",
      "5596 Traning Loss: tensor(3.3489)\n",
      "5597 Traning Loss: tensor(3.3489)\n",
      "5598 Traning Loss: tensor(3.3489)\n",
      "5599 Traning Loss: tensor(3.3489)\n",
      "5600 Traning Loss: tensor(3.3489)\n",
      "5601 Traning Loss: tensor(3.3489)\n",
      "5602 Traning Loss: tensor(3.3489)\n",
      "5603 Traning Loss: tensor(3.3489)\n",
      "5604 Traning Loss: tensor(3.3489)\n",
      "5605 Traning Loss: tensor(3.3489)\n",
      "5606 Traning Loss: tensor(3.3489)\n",
      "5607 Traning Loss: tensor(3.3489)\n",
      "5608 Traning Loss: tensor(3.3489)\n",
      "5609 Traning Loss: tensor(3.3489)\n",
      "5610 Traning Loss: tensor(3.3489)\n",
      "5611 Traning Loss: tensor(3.3489)\n",
      "5612 Traning Loss: tensor(3.3489)\n",
      "5613 Traning Loss: tensor(3.3489)\n",
      "5614 Traning Loss: tensor(3.3489)\n",
      "5615 Traning Loss: tensor(3.3489)\n",
      "5616 Traning Loss: tensor(3.3489)\n",
      "5617 Traning Loss: tensor(3.3489)\n",
      "5618 Traning Loss: tensor(3.3489)\n",
      "5619 Traning Loss: tensor(3.3489)\n",
      "5620 Traning Loss: tensor(3.3489)\n",
      "5621 Traning Loss: tensor(3.3489)\n",
      "5622 Traning Loss: tensor(3.3489)\n",
      "5623 Traning Loss: tensor(3.3489)\n",
      "5624 Traning Loss: tensor(3.3489)\n",
      "5625 Traning Loss: tensor(3.3489)\n",
      "5626 Traning Loss: tensor(3.3489)\n",
      "5627 Traning Loss: tensor(3.3489)\n",
      "5628 Traning Loss: tensor(3.3489)\n",
      "5629 Traning Loss: tensor(3.3489)\n",
      "5630 Traning Loss: tensor(3.3489)\n",
      "5631 Traning Loss: tensor(3.3489)\n",
      "5632 Traning Loss: tensor(3.3489)\n",
      "5633 Traning Loss: tensor(3.3489)\n",
      "5634 Traning Loss: tensor(3.3489)\n",
      "5635 Traning Loss: tensor(3.3489)\n",
      "5636 Traning Loss: tensor(3.3489)\n",
      "5637 Traning Loss: tensor(3.3489)\n",
      "5638 Traning Loss: tensor(3.3489)\n",
      "5639 Traning Loss: tensor(3.3489)\n",
      "5640 Traning Loss: tensor(3.3489)\n",
      "5641 Traning Loss: tensor(3.3489)\n",
      "5642 Traning Loss: tensor(3.3489)\n",
      "5643 Traning Loss: tensor(3.3489)\n",
      "5644 Traning Loss: tensor(3.3489)\n",
      "5645 Traning Loss: tensor(3.3489)\n",
      "5646 Traning Loss: tensor(3.3489)\n",
      "5647 Traning Loss: tensor(3.3489)\n",
      "5648 Traning Loss: tensor(3.3489)\n",
      "5649 Traning Loss: tensor(3.3489)\n",
      "5650 Traning Loss: tensor(3.3489)\n",
      "5651 Traning Loss: tensor(3.3489)\n",
      "5652 Traning Loss: tensor(3.3489)\n",
      "5653 Traning Loss: tensor(3.3489)\n",
      "5654 Traning Loss: tensor(3.3489)\n",
      "5655 Traning Loss: tensor(3.3489)\n",
      "5656 Traning Loss: tensor(3.3489)\n",
      "5657 Traning Loss: tensor(3.3489)\n",
      "5658 Traning Loss: tensor(3.3489)\n",
      "5659 Traning Loss: tensor(3.3489)\n",
      "5660 Traning Loss: tensor(3.3489)\n",
      "5661 Traning Loss: tensor(3.3489)\n",
      "5662 Traning Loss: tensor(3.3489)\n",
      "5663 Traning Loss: tensor(3.3489)\n",
      "5664 Traning Loss: tensor(3.3489)\n",
      "5665 Traning Loss: tensor(3.3489)\n",
      "5666 Traning Loss: tensor(3.3489)\n",
      "5667 Traning Loss: tensor(3.3489)\n",
      "5668 Traning Loss: tensor(3.3489)\n",
      "5669 Traning Loss: tensor(3.3489)\n",
      "5670 Traning Loss: tensor(3.3489)\n",
      "5671 Traning Loss: tensor(3.3489)\n",
      "5672 Traning Loss: tensor(3.3489)\n",
      "5673 Traning Loss: tensor(3.3489)\n",
      "5674 Traning Loss: tensor(3.3489)\n",
      "5675 Traning Loss: tensor(3.3489)\n",
      "5676 Traning Loss: tensor(3.3489)\n",
      "5677 Traning Loss: tensor(3.3489)\n",
      "5678 Traning Loss: tensor(3.3489)\n",
      "5679 Traning Loss: tensor(3.3489)\n",
      "5680 Traning Loss: tensor(3.3489)\n",
      "5681 Traning Loss: tensor(3.3489)\n",
      "5682 Traning Loss: tensor(3.3489)\n",
      "5683 Traning Loss: tensor(3.3489)\n",
      "5684 Traning Loss: tensor(3.3489)\n",
      "5685 Traning Loss: tensor(3.3489)\n",
      "5686 Traning Loss: tensor(3.3489)\n",
      "5687 Traning Loss: tensor(3.3489)\n",
      "5688 Traning Loss: tensor(3.3489)\n",
      "5689 Traning Loss: tensor(3.3489)\n",
      "5690 Traning Loss: tensor(3.3489)\n",
      "5691 Traning Loss: tensor(3.3489)\n",
      "5692 Traning Loss: tensor(3.3489)\n",
      "5693 Traning Loss: tensor(3.3489)\n",
      "5694 Traning Loss: tensor(3.3489)\n",
      "5695 Traning Loss: tensor(3.3489)\n",
      "5696 Traning Loss: tensor(3.3489)\n",
      "5697 Traning Loss: tensor(3.3489)\n",
      "5698 Traning Loss: tensor(3.3489)\n",
      "5699 Traning Loss: tensor(3.3489)\n",
      "5700 Traning Loss: tensor(3.3489)\n",
      "5701 Traning Loss: tensor(3.3489)\n",
      "5702 Traning Loss: tensor(3.3489)\n",
      "5703 Traning Loss: tensor(3.3489)\n",
      "5704 Traning Loss: tensor(3.3489)\n",
      "5705 Traning Loss: tensor(3.3489)\n",
      "5706 Traning Loss: tensor(3.3489)\n",
      "5707 Traning Loss: tensor(3.3489)\n",
      "5708 Traning Loss: tensor(3.3489)\n",
      "5709 Traning Loss: tensor(3.3489)\n",
      "5710 Traning Loss: tensor(3.3489)\n",
      "5711 Traning Loss: tensor(3.3489)\n",
      "5712 Traning Loss: tensor(3.3489)\n",
      "5713 Traning Loss: tensor(3.3489)\n",
      "5714 Traning Loss: tensor(3.3489)\n",
      "5715 Traning Loss: tensor(3.3489)\n",
      "5716 Traning Loss: tensor(3.3489)\n",
      "5717 Traning Loss: tensor(3.3489)\n",
      "5718 Traning Loss: tensor(3.3489)\n",
      "5719 Traning Loss: tensor(3.3489)\n",
      "5720 Traning Loss: tensor(3.3489)\n",
      "5721 Traning Loss: tensor(3.3489)\n",
      "5722 Traning Loss: tensor(3.3489)\n",
      "5723 Traning Loss: tensor(3.3489)\n",
      "5724 Traning Loss: tensor(3.3489)\n",
      "5725 Traning Loss: tensor(3.3489)\n",
      "5726 Traning Loss: tensor(3.3489)\n",
      "5727 Traning Loss: tensor(3.3489)\n",
      "5728 Traning Loss: tensor(3.3489)\n",
      "5729 Traning Loss: tensor(3.3489)\n",
      "5730 Traning Loss: tensor(3.3489)\n",
      "5731 Traning Loss: tensor(3.3489)\n",
      "5732 Traning Loss: tensor(3.3489)\n",
      "5733 Traning Loss: tensor(3.3489)\n",
      "5734 Traning Loss: tensor(3.3489)\n",
      "5735 Traning Loss: tensor(3.3489)\n",
      "5736 Traning Loss: tensor(3.3489)\n",
      "5737 Traning Loss: tensor(3.3489)\n",
      "5738 Traning Loss: tensor(3.3489)\n",
      "5739 Traning Loss: tensor(3.3489)\n",
      "5740 Traning Loss: tensor(3.3489)\n",
      "5741 Traning Loss: tensor(3.3489)\n",
      "5742 Traning Loss: tensor(3.3489)\n",
      "5743 Traning Loss: tensor(3.3489)\n",
      "5744 Traning Loss: tensor(3.3489)\n",
      "5745 Traning Loss: tensor(3.3489)\n",
      "5746 Traning Loss: tensor(3.3489)\n",
      "5747 Traning Loss: tensor(3.3489)\n",
      "5748 Traning Loss: tensor(3.3489)\n",
      "5749 Traning Loss: tensor(3.3489)\n",
      "5750 Traning Loss: tensor(3.3489)\n",
      "5751 Traning Loss: tensor(3.3489)\n",
      "5752 Traning Loss: tensor(3.3489)\n",
      "5753 Traning Loss: tensor(3.3489)\n",
      "5754 Traning Loss: tensor(3.3489)\n",
      "5755 Traning Loss: tensor(3.3489)\n",
      "5756 Traning Loss: tensor(3.3489)\n",
      "5757 Traning Loss: tensor(3.3489)\n",
      "5758 Traning Loss: tensor(3.3489)\n",
      "5759 Traning Loss: tensor(3.3489)\n",
      "5760 Traning Loss: tensor(3.3489)\n",
      "5761 Traning Loss: tensor(3.3489)\n",
      "5762 Traning Loss: tensor(3.3489)\n",
      "5763 Traning Loss: tensor(3.3489)\n",
      "5764 Traning Loss: tensor(3.3489)\n",
      "5765 Traning Loss: tensor(3.3489)\n",
      "5766 Traning Loss: tensor(3.3489)\n",
      "5767 Traning Loss: tensor(3.3489)\n",
      "5768 Traning Loss: tensor(3.3489)\n",
      "5769 Traning Loss: tensor(3.3489)\n",
      "5770 Traning Loss: tensor(3.3489)\n",
      "5771 Traning Loss: tensor(3.3489)\n",
      "5772 Traning Loss: tensor(3.3489)\n",
      "5773 Traning Loss: tensor(3.3489)\n",
      "5774 Traning Loss: tensor(3.3489)\n",
      "5775 Traning Loss: tensor(3.3489)\n",
      "5776 Traning Loss: tensor(3.3489)\n",
      "5777 Traning Loss: tensor(3.3489)\n",
      "5778 Traning Loss: tensor(3.3489)\n",
      "5779 Traning Loss: tensor(3.3489)\n",
      "5780 Traning Loss: tensor(3.3489)\n",
      "5781 Traning Loss: tensor(3.3489)\n",
      "5782 Traning Loss: tensor(3.3489)\n",
      "5783 Traning Loss: tensor(3.3489)\n",
      "5784 Traning Loss: tensor(3.3489)\n",
      "5785 Traning Loss: tensor(3.3489)\n",
      "5786 Traning Loss: tensor(3.3489)\n",
      "5787 Traning Loss: tensor(3.3489)\n",
      "5788 Traning Loss: tensor(3.3489)\n",
      "5789 Traning Loss: tensor(3.3489)\n",
      "5790 Traning Loss: tensor(3.3489)\n",
      "5791 Traning Loss: tensor(3.3489)\n",
      "5792 Traning Loss: tensor(3.3489)\n",
      "5793 Traning Loss: tensor(3.3489)\n",
      "5794 Traning Loss: tensor(3.3489)\n",
      "5795 Traning Loss: tensor(3.3489)\n",
      "5796 Traning Loss: tensor(3.3489)\n",
      "5797 Traning Loss: tensor(3.3489)\n",
      "5798 Traning Loss: tensor(3.3489)\n",
      "5799 Traning Loss: tensor(3.3489)\n",
      "5800 Traning Loss: tensor(3.3489)\n",
      "5801 Traning Loss: tensor(3.3489)\n",
      "5802 Traning Loss: tensor(3.3489)\n",
      "5803 Traning Loss: tensor(3.3489)\n",
      "5804 Traning Loss: tensor(3.3489)\n",
      "5805 Traning Loss: tensor(3.3489)\n",
      "5806 Traning Loss: tensor(3.3489)\n",
      "5807 Traning Loss: tensor(3.3489)\n",
      "5808 Traning Loss: tensor(3.3489)\n",
      "5809 Traning Loss: tensor(3.3489)\n",
      "5810 Traning Loss: tensor(3.3489)\n",
      "5811 Traning Loss: tensor(3.3489)\n",
      "5812 Traning Loss: tensor(3.3489)\n",
      "5813 Traning Loss: tensor(3.3489)\n",
      "5814 Traning Loss: tensor(3.3489)\n",
      "5815 Traning Loss: tensor(3.3489)\n",
      "5816 Traning Loss: tensor(3.3489)\n",
      "5817 Traning Loss: tensor(3.3489)\n",
      "5818 Traning Loss: tensor(3.3489)\n",
      "5819 Traning Loss: tensor(3.3489)\n",
      "5820 Traning Loss: tensor(3.3489)\n",
      "5821 Traning Loss: tensor(3.3489)\n",
      "5822 Traning Loss: tensor(3.3489)\n",
      "5823 Traning Loss: tensor(3.3489)\n",
      "5824 Traning Loss: tensor(3.3489)\n",
      "5825 Traning Loss: tensor(3.3489)\n",
      "5826 Traning Loss: tensor(3.3489)\n",
      "5827 Traning Loss: tensor(3.3489)\n",
      "5828 Traning Loss: tensor(3.3489)\n",
      "5829 Traning Loss: tensor(3.3489)\n",
      "5830 Traning Loss: tensor(3.3489)\n",
      "5831 Traning Loss: tensor(3.3489)\n",
      "5832 Traning Loss: tensor(3.3489)\n",
      "5833 Traning Loss: tensor(3.3489)\n",
      "5834 Traning Loss: tensor(3.3489)\n",
      "5835 Traning Loss: tensor(3.3489)\n",
      "5836 Traning Loss: tensor(3.3489)\n",
      "5837 Traning Loss: tensor(3.3489)\n",
      "5838 Traning Loss: tensor(3.3489)\n",
      "5839 Traning Loss: tensor(3.3489)\n",
      "5840 Traning Loss: tensor(3.3489)\n",
      "5841 Traning Loss: tensor(3.3489)\n",
      "5842 Traning Loss: tensor(3.3489)\n",
      "5843 Traning Loss: tensor(3.3489)\n",
      "5844 Traning Loss: tensor(3.3489)\n",
      "5845 Traning Loss: tensor(3.3489)\n",
      "5846 Traning Loss: tensor(3.3489)\n",
      "5847 Traning Loss: tensor(3.3489)\n",
      "5848 Traning Loss: tensor(3.3489)\n",
      "5849 Traning Loss: tensor(3.3489)\n",
      "5850 Traning Loss: tensor(3.3489)\n",
      "5851 Traning Loss: tensor(3.3489)\n",
      "5852 Traning Loss: tensor(3.3489)\n",
      "5853 Traning Loss: tensor(3.3489)\n",
      "5854 Traning Loss: tensor(3.3489)\n",
      "5855 Traning Loss: tensor(3.3489)\n",
      "5856 Traning Loss: tensor(3.3489)\n",
      "5857 Traning Loss: tensor(3.3489)\n",
      "5858 Traning Loss: tensor(3.3489)\n",
      "5859 Traning Loss: tensor(3.3489)\n",
      "5860 Traning Loss: tensor(3.3489)\n",
      "5861 Traning Loss: tensor(3.3489)\n",
      "5862 Traning Loss: tensor(3.3489)\n",
      "5863 Traning Loss: tensor(3.3489)\n",
      "5864 Traning Loss: tensor(3.3489)\n",
      "5865 Traning Loss: tensor(3.3489)\n",
      "5866 Traning Loss: tensor(3.3489)\n",
      "5867 Traning Loss: tensor(3.3489)\n",
      "5868 Traning Loss: tensor(3.3489)\n",
      "5869 Traning Loss: tensor(3.3489)\n",
      "5870 Traning Loss: tensor(3.3489)\n",
      "5871 Traning Loss: tensor(3.3489)\n",
      "5872 Traning Loss: tensor(3.3489)\n",
      "5873 Traning Loss: tensor(3.3489)\n",
      "5874 Traning Loss: tensor(3.3489)\n",
      "5875 Traning Loss: tensor(3.3489)\n",
      "5876 Traning Loss: tensor(3.3489)\n",
      "5877 Traning Loss: tensor(3.3489)\n",
      "5878 Traning Loss: tensor(3.3489)\n",
      "5879 Traning Loss: tensor(3.3489)\n",
      "5880 Traning Loss: tensor(3.3489)\n",
      "5881 Traning Loss: tensor(3.3489)\n",
      "5882 Traning Loss: tensor(3.3489)\n",
      "5883 Traning Loss: tensor(3.3489)\n",
      "5884 Traning Loss: tensor(3.3489)\n",
      "5885 Traning Loss: tensor(3.3489)\n",
      "5886 Traning Loss: tensor(3.3489)\n",
      "5887 Traning Loss: tensor(3.3489)\n",
      "5888 Traning Loss: tensor(3.3489)\n",
      "5889 Traning Loss: tensor(3.3489)\n",
      "5890 Traning Loss: tensor(3.3489)\n",
      "5891 Traning Loss: tensor(3.3489)\n",
      "5892 Traning Loss: tensor(3.3489)\n",
      "5893 Traning Loss: tensor(3.3489)\n",
      "5894 Traning Loss: tensor(3.3489)\n",
      "5895 Traning Loss: tensor(3.3489)\n",
      "5896 Traning Loss: tensor(3.3489)\n",
      "5897 Traning Loss: tensor(3.3489)\n",
      "5898 Traning Loss: tensor(3.3489)\n",
      "5899 Traning Loss: tensor(3.3489)\n",
      "5900 Traning Loss: tensor(3.3489)\n",
      "5901 Traning Loss: tensor(3.3489)\n",
      "5902 Traning Loss: tensor(3.3489)\n",
      "5903 Traning Loss: tensor(3.3489)\n",
      "5904 Traning Loss: tensor(3.3489)\n",
      "5905 Traning Loss: tensor(3.3489)\n",
      "5906 Traning Loss: tensor(3.3489)\n",
      "5907 Traning Loss: tensor(3.3489)\n",
      "5908 Traning Loss: tensor(3.3489)\n",
      "5909 Traning Loss: tensor(3.3489)\n",
      "5910 Traning Loss: tensor(3.3489)\n",
      "5911 Traning Loss: tensor(3.3489)\n",
      "5912 Traning Loss: tensor(3.3489)\n",
      "5913 Traning Loss: tensor(3.3489)\n",
      "5914 Traning Loss: tensor(3.3489)\n",
      "5915 Traning Loss: tensor(3.3489)\n",
      "5916 Traning Loss: tensor(3.3489)\n",
      "5917 Traning Loss: tensor(3.3489)\n",
      "5918 Traning Loss: tensor(3.3489)\n",
      "5919 Traning Loss: tensor(3.3489)\n",
      "5920 Traning Loss: tensor(3.3489)\n",
      "5921 Traning Loss: tensor(3.3489)\n",
      "5922 Traning Loss: tensor(3.3489)\n",
      "5923 Traning Loss: tensor(3.3489)\n",
      "5924 Traning Loss: tensor(3.3489)\n",
      "5925 Traning Loss: tensor(3.3489)\n",
      "5926 Traning Loss: tensor(3.3489)\n",
      "5927 Traning Loss: tensor(3.3489)\n",
      "5928 Traning Loss: tensor(3.3489)\n",
      "5929 Traning Loss: tensor(3.3489)\n",
      "5930 Traning Loss: tensor(3.3489)\n",
      "5931 Traning Loss: tensor(3.3489)\n",
      "5932 Traning Loss: tensor(3.3489)\n",
      "5933 Traning Loss: tensor(3.3489)\n",
      "5934 Traning Loss: tensor(3.3489)\n",
      "5935 Traning Loss: tensor(3.3489)\n",
      "5936 Traning Loss: tensor(3.3489)\n",
      "5937 Traning Loss: tensor(3.3489)\n",
      "5938 Traning Loss: tensor(3.3489)\n",
      "5939 Traning Loss: tensor(3.3489)\n",
      "5940 Traning Loss: tensor(3.3489)\n",
      "5941 Traning Loss: tensor(3.3489)\n",
      "5942 Traning Loss: tensor(3.3489)\n",
      "5943 Traning Loss: tensor(3.3489)\n",
      "5944 Traning Loss: tensor(3.3489)\n",
      "5945 Traning Loss: tensor(3.3489)\n",
      "5946 Traning Loss: tensor(3.3489)\n",
      "5947 Traning Loss: tensor(3.3489)\n",
      "5948 Traning Loss: tensor(3.3489)\n",
      "5949 Traning Loss: tensor(3.3489)\n",
      "5950 Traning Loss: tensor(3.3489)\n",
      "5951 Traning Loss: tensor(3.3489)\n",
      "5952 Traning Loss: tensor(3.3489)\n",
      "5953 Traning Loss: tensor(3.3489)\n",
      "5954 Traning Loss: tensor(3.3489)\n",
      "5955 Traning Loss: tensor(3.3489)\n",
      "5956 Traning Loss: tensor(3.3489)\n",
      "5957 Traning Loss: tensor(3.3489)\n",
      "5958 Traning Loss: tensor(3.3489)\n",
      "5959 Traning Loss: tensor(3.3489)\n",
      "5960 Traning Loss: tensor(3.3489)\n",
      "5961 Traning Loss: tensor(3.3489)\n",
      "5962 Traning Loss: tensor(3.3489)\n",
      "5963 Traning Loss: tensor(3.3489)\n",
      "5964 Traning Loss: tensor(3.3489)\n",
      "5965 Traning Loss: tensor(3.3489)\n",
      "5966 Traning Loss: tensor(3.3489)\n",
      "5967 Traning Loss: tensor(3.3489)\n",
      "5968 Traning Loss: tensor(3.3489)\n",
      "5969 Traning Loss: tensor(3.3489)\n",
      "5970 Traning Loss: tensor(3.3489)\n",
      "5971 Traning Loss: tensor(3.3489)\n",
      "5972 Traning Loss: tensor(3.3489)\n",
      "5973 Traning Loss: tensor(3.3489)\n",
      "5974 Traning Loss: tensor(3.3489)\n",
      "5975 Traning Loss: tensor(3.3489)\n",
      "5976 Traning Loss: tensor(3.3489)\n",
      "5977 Traning Loss: tensor(3.3489)\n",
      "5978 Traning Loss: tensor(3.3489)\n",
      "5979 Traning Loss: tensor(3.3489)\n",
      "5980 Traning Loss: tensor(3.3489)\n",
      "5981 Traning Loss: tensor(3.3489)\n",
      "5982 Traning Loss: tensor(3.3489)\n",
      "5983 Traning Loss: tensor(3.3489)\n",
      "5984 Traning Loss: tensor(3.3489)\n",
      "5985 Traning Loss: tensor(3.3489)\n",
      "5986 Traning Loss: tensor(3.3489)\n",
      "5987 Traning Loss: tensor(3.3489)\n",
      "5988 Traning Loss: tensor(3.3489)\n",
      "5989 Traning Loss: tensor(3.3489)\n",
      "5990 Traning Loss: tensor(3.3489)\n",
      "5991 Traning Loss: tensor(3.3489)\n",
      "5992 Traning Loss: tensor(3.3489)\n",
      "5993 Traning Loss: tensor(3.3489)\n",
      "5994 Traning Loss: tensor(3.3489)\n",
      "5995 Traning Loss: tensor(3.3489)\n",
      "5996 Traning Loss: tensor(3.3489)\n",
      "5997 Traning Loss: tensor(3.3489)\n",
      "5998 Traning Loss: tensor(3.3489)\n",
      "5999 Traning Loss: tensor(3.3489)\n",
      "6000 Traning Loss: tensor(3.3489)\n",
      "6001 Traning Loss: tensor(3.3489)\n",
      "6002 Traning Loss: tensor(3.3489)\n",
      "6003 Traning Loss: tensor(3.3489)\n",
      "6004 Traning Loss: tensor(3.3489)\n",
      "6005 Traning Loss: tensor(3.3489)\n",
      "6006 Traning Loss: tensor(3.3489)\n",
      "6007 Traning Loss: tensor(3.3489)\n",
      "6008 Traning Loss: tensor(3.3489)\n",
      "6009 Traning Loss: tensor(3.3489)\n",
      "6010 Traning Loss: tensor(3.3489)\n",
      "6011 Traning Loss: tensor(3.3489)\n",
      "6012 Traning Loss: tensor(3.3489)\n",
      "6013 Traning Loss: tensor(3.3489)\n",
      "6014 Traning Loss: tensor(3.3489)\n",
      "6015 Traning Loss: tensor(3.3489)\n",
      "6016 Traning Loss: tensor(3.3489)\n",
      "6017 Traning Loss: tensor(3.3489)\n",
      "6018 Traning Loss: tensor(3.3489)\n",
      "6019 Traning Loss: tensor(3.3489)\n",
      "6020 Traning Loss: tensor(3.3489)\n",
      "6021 Traning Loss: tensor(3.3489)\n",
      "6022 Traning Loss: tensor(3.3489)\n",
      "6023 Traning Loss: tensor(3.3489)\n",
      "6024 Traning Loss: tensor(3.3489)\n",
      "6025 Traning Loss: tensor(3.3489)\n",
      "6026 Traning Loss: tensor(3.3489)\n",
      "6027 Traning Loss: tensor(3.3489)\n",
      "6028 Traning Loss: tensor(3.3489)\n",
      "6029 Traning Loss: tensor(3.3489)\n",
      "6030 Traning Loss: tensor(3.3489)\n",
      "6031 Traning Loss: tensor(3.3489)\n",
      "6032 Traning Loss: tensor(3.3489)\n",
      "6033 Traning Loss: tensor(3.3489)\n",
      "6034 Traning Loss: tensor(3.3489)\n",
      "6035 Traning Loss: tensor(3.3489)\n",
      "6036 Traning Loss: tensor(3.3489)\n",
      "6037 Traning Loss: tensor(3.3489)\n",
      "6038 Traning Loss: tensor(3.3489)\n",
      "6039 Traning Loss: tensor(3.3489)\n",
      "6040 Traning Loss: tensor(3.3489)\n",
      "6041 Traning Loss: tensor(3.3489)\n",
      "6042 Traning Loss: tensor(3.3489)\n",
      "6043 Traning Loss: tensor(3.3489)\n",
      "6044 Traning Loss: tensor(3.3489)\n",
      "6045 Traning Loss: tensor(3.3489)\n",
      "6046 Traning Loss: tensor(3.3489)\n",
      "6047 Traning Loss: tensor(3.3489)\n",
      "6048 Traning Loss: tensor(3.3489)\n",
      "6049 Traning Loss: tensor(3.3489)\n",
      "6050 Traning Loss: tensor(3.3489)\n",
      "6051 Traning Loss: tensor(3.3489)\n",
      "6052 Traning Loss: tensor(3.3489)\n",
      "6053 Traning Loss: tensor(3.3489)\n",
      "6054 Traning Loss: tensor(3.3489)\n",
      "6055 Traning Loss: tensor(3.3489)\n",
      "6056 Traning Loss: tensor(3.3489)\n",
      "6057 Traning Loss: tensor(3.3489)\n",
      "6058 Traning Loss: tensor(3.3489)\n",
      "6059 Traning Loss: tensor(3.3489)\n",
      "6060 Traning Loss: tensor(3.3489)\n",
      "6061 Traning Loss: tensor(3.3489)\n",
      "6062 Traning Loss: tensor(3.3489)\n",
      "6063 Traning Loss: tensor(3.3489)\n",
      "6064 Traning Loss: tensor(3.3489)\n",
      "6065 Traning Loss: tensor(3.3489)\n",
      "6066 Traning Loss: tensor(3.3489)\n",
      "6067 Traning Loss: tensor(3.3489)\n",
      "6068 Traning Loss: tensor(3.3489)\n",
      "6069 Traning Loss: tensor(3.3489)\n",
      "6070 Traning Loss: tensor(3.3489)\n",
      "6071 Traning Loss: tensor(3.3489)\n",
      "6072 Traning Loss: tensor(3.3489)\n",
      "6073 Traning Loss: tensor(3.3489)\n",
      "6074 Traning Loss: tensor(3.3489)\n",
      "6075 Traning Loss: tensor(3.3489)\n",
      "6076 Traning Loss: tensor(3.3489)\n",
      "6077 Traning Loss: tensor(3.3489)\n",
      "6078 Traning Loss: tensor(3.3489)\n",
      "6079 Traning Loss: tensor(3.3489)\n",
      "6080 Traning Loss: tensor(3.3489)\n",
      "6081 Traning Loss: tensor(3.3489)\n",
      "6082 Traning Loss: tensor(3.3489)\n",
      "6083 Traning Loss: tensor(3.3489)\n",
      "6084 Traning Loss: tensor(3.3489)\n",
      "6085 Traning Loss: tensor(3.3489)\n",
      "6086 Traning Loss: tensor(3.3489)\n",
      "6087 Traning Loss: tensor(3.3489)\n",
      "6088 Traning Loss: tensor(3.3489)\n",
      "6089 Traning Loss: tensor(3.3489)\n",
      "6090 Traning Loss: tensor(3.3489)\n",
      "6091 Traning Loss: tensor(3.3489)\n",
      "6092 Traning Loss: tensor(3.3489)\n",
      "6093 Traning Loss: tensor(3.3489)\n",
      "6094 Traning Loss: tensor(3.3489)\n",
      "6095 Traning Loss: tensor(3.3489)\n",
      "6096 Traning Loss: tensor(3.3489)\n",
      "6097 Traning Loss: tensor(3.3489)\n",
      "6098 Traning Loss: tensor(3.3489)\n",
      "6099 Traning Loss: tensor(3.3489)\n",
      "6100 Traning Loss: tensor(3.3489)\n",
      "6101 Traning Loss: tensor(3.3489)\n",
      "6102 Traning Loss: tensor(3.3489)\n",
      "6103 Traning Loss: tensor(3.3489)\n",
      "6104 Traning Loss: tensor(3.3489)\n",
      "6105 Traning Loss: tensor(3.3489)\n",
      "6106 Traning Loss: tensor(3.3489)\n",
      "6107 Traning Loss: tensor(3.3489)\n",
      "6108 Traning Loss: tensor(3.3489)\n",
      "6109 Traning Loss: tensor(3.3489)\n",
      "6110 Traning Loss: tensor(3.3489)\n",
      "6111 Traning Loss: tensor(3.3489)\n",
      "6112 Traning Loss: tensor(3.3489)\n",
      "6113 Traning Loss: tensor(3.3489)\n",
      "6114 Traning Loss: tensor(3.3489)\n",
      "6115 Traning Loss: tensor(3.3489)\n",
      "6116 Traning Loss: tensor(3.3489)\n",
      "6117 Traning Loss: tensor(3.3489)\n",
      "6118 Traning Loss: tensor(3.3489)\n",
      "6119 Traning Loss: tensor(3.3489)\n",
      "6120 Traning Loss: tensor(3.3489)\n",
      "6121 Traning Loss: tensor(3.3489)\n",
      "6122 Traning Loss: tensor(3.3489)\n",
      "6123 Traning Loss: tensor(3.3489)\n",
      "6124 Traning Loss: tensor(3.3489)\n",
      "6125 Traning Loss: tensor(3.3489)\n",
      "6126 Traning Loss: tensor(3.3489)\n",
      "6127 Traning Loss: tensor(3.3489)\n",
      "6128 Traning Loss: tensor(3.3489)\n",
      "6129 Traning Loss: tensor(3.3489)\n",
      "6130 Traning Loss: tensor(3.3489)\n",
      "6131 Traning Loss: tensor(3.3489)\n",
      "6132 Traning Loss: tensor(3.3489)\n",
      "6133 Traning Loss: tensor(3.3489)\n",
      "6134 Traning Loss: tensor(3.3489)\n",
      "6135 Traning Loss: tensor(3.3489)\n",
      "6136 Traning Loss: tensor(3.3489)\n",
      "6137 Traning Loss: tensor(3.3489)\n",
      "6138 Traning Loss: tensor(3.3489)\n",
      "6139 Traning Loss: tensor(3.3489)\n",
      "6140 Traning Loss: tensor(3.3489)\n",
      "6141 Traning Loss: tensor(3.3489)\n",
      "6142 Traning Loss: tensor(3.3489)\n",
      "6143 Traning Loss: tensor(3.3489)\n",
      "6144 Traning Loss: tensor(3.3489)\n",
      "6145 Traning Loss: tensor(3.3489)\n",
      "6146 Traning Loss: tensor(3.3489)\n",
      "6147 Traning Loss: tensor(3.3489)\n",
      "6148 Traning Loss: tensor(3.3489)\n",
      "6149 Traning Loss: tensor(3.3489)\n",
      "6150 Traning Loss: tensor(3.3489)\n",
      "6151 Traning Loss: tensor(3.3489)\n",
      "6152 Traning Loss: tensor(3.3489)\n",
      "6153 Traning Loss: tensor(3.3489)\n",
      "6154 Traning Loss: tensor(3.3489)\n",
      "6155 Traning Loss: tensor(3.3489)\n",
      "6156 Traning Loss: tensor(3.3489)\n",
      "6157 Traning Loss: tensor(3.3489)\n",
      "6158 Traning Loss: tensor(3.3489)\n",
      "6159 Traning Loss: tensor(3.3489)\n",
      "6160 Traning Loss: tensor(3.3489)\n",
      "6161 Traning Loss: tensor(3.3489)\n",
      "6162 Traning Loss: tensor(3.3489)\n",
      "6163 Traning Loss: tensor(3.3489)\n",
      "6164 Traning Loss: tensor(3.3489)\n",
      "6165 Traning Loss: tensor(3.3489)\n",
      "6166 Traning Loss: tensor(3.3489)\n",
      "6167 Traning Loss: tensor(3.3489)\n",
      "6168 Traning Loss: tensor(3.3489)\n",
      "6169 Traning Loss: tensor(3.3489)\n",
      "6170 Traning Loss: tensor(3.3489)\n",
      "6171 Traning Loss: tensor(3.3489)\n",
      "6172 Traning Loss: tensor(3.3489)\n",
      "6173 Traning Loss: tensor(3.3489)\n",
      "6174 Traning Loss: tensor(3.3489)\n",
      "6175 Traning Loss: tensor(3.3489)\n",
      "6176 Traning Loss: tensor(3.3489)\n",
      "6177 Traning Loss: tensor(3.3489)\n",
      "6178 Traning Loss: tensor(3.3489)\n",
      "6179 Traning Loss: tensor(3.3489)\n",
      "6180 Traning Loss: tensor(3.3489)\n",
      "6181 Traning Loss: tensor(3.3489)\n",
      "6182 Traning Loss: tensor(3.3489)\n",
      "6183 Traning Loss: tensor(3.3489)\n",
      "6184 Traning Loss: tensor(3.3489)\n",
      "6185 Traning Loss: tensor(3.3489)\n",
      "6186 Traning Loss: tensor(3.3489)\n",
      "6187 Traning Loss: tensor(3.3489)\n",
      "6188 Traning Loss: tensor(3.3489)\n",
      "6189 Traning Loss: tensor(3.3489)\n",
      "6190 Traning Loss: tensor(3.3489)\n",
      "6191 Traning Loss: tensor(3.3489)\n",
      "6192 Traning Loss: tensor(3.3489)\n",
      "6193 Traning Loss: tensor(3.3489)\n",
      "6194 Traning Loss: tensor(3.3489)\n",
      "6195 Traning Loss: tensor(3.3489)\n",
      "6196 Traning Loss: tensor(3.3489)\n",
      "6197 Traning Loss: tensor(3.3489)\n",
      "6198 Traning Loss: tensor(3.3489)\n",
      "6199 Traning Loss: tensor(3.3489)\n",
      "6200 Traning Loss: tensor(3.3489)\n",
      "6201 Traning Loss: tensor(3.3489)\n",
      "6202 Traning Loss: tensor(3.3489)\n",
      "6203 Traning Loss: tensor(3.3489)\n",
      "6204 Traning Loss: tensor(3.3489)\n",
      "6205 Traning Loss: tensor(3.3489)\n",
      "6206 Traning Loss: tensor(3.3489)\n",
      "6207 Traning Loss: tensor(3.3489)\n",
      "6208 Traning Loss: tensor(3.3489)\n",
      "6209 Traning Loss: tensor(3.3489)\n",
      "6210 Traning Loss: tensor(3.3489)\n",
      "6211 Traning Loss: tensor(3.3489)\n",
      "6212 Traning Loss: tensor(3.3489)\n",
      "6213 Traning Loss: tensor(3.3489)\n",
      "6214 Traning Loss: tensor(3.3489)\n",
      "6215 Traning Loss: tensor(3.3489)\n",
      "6216 Traning Loss: tensor(3.3489)\n",
      "6217 Traning Loss: tensor(3.3489)\n",
      "6218 Traning Loss: tensor(3.3489)\n",
      "6219 Traning Loss: tensor(3.3489)\n",
      "6220 Traning Loss: tensor(3.3489)\n",
      "6221 Traning Loss: tensor(3.3489)\n",
      "6222 Traning Loss: tensor(3.3489)\n",
      "6223 Traning Loss: tensor(3.3489)\n",
      "6224 Traning Loss: tensor(3.3489)\n",
      "6225 Traning Loss: tensor(3.3489)\n",
      "6226 Traning Loss: tensor(3.3489)\n",
      "6227 Traning Loss: tensor(3.3489)\n",
      "6228 Traning Loss: tensor(3.3489)\n",
      "6229 Traning Loss: tensor(3.3489)\n",
      "6230 Traning Loss: tensor(3.3489)\n",
      "6231 Traning Loss: tensor(3.3489)\n",
      "6232 Traning Loss: tensor(3.3489)\n",
      "6233 Traning Loss: tensor(3.3489)\n",
      "6234 Traning Loss: tensor(3.3489)\n",
      "6235 Traning Loss: tensor(3.3489)\n",
      "6236 Traning Loss: tensor(3.3489)\n",
      "6237 Traning Loss: tensor(3.3489)\n",
      "6238 Traning Loss: tensor(3.3489)\n",
      "6239 Traning Loss: tensor(3.3489)\n",
      "6240 Traning Loss: tensor(3.3489)\n",
      "6241 Traning Loss: tensor(3.3489)\n",
      "6242 Traning Loss: tensor(3.3489)\n",
      "6243 Traning Loss: tensor(3.3489)\n",
      "6244 Traning Loss: tensor(3.3489)\n",
      "6245 Traning Loss: tensor(3.3489)\n",
      "6246 Traning Loss: tensor(3.3489)\n",
      "6247 Traning Loss: tensor(3.3489)\n",
      "6248 Traning Loss: tensor(3.3489)\n",
      "6249 Traning Loss: tensor(3.3489)\n",
      "6250 Traning Loss: tensor(3.3489)\n",
      "6251 Traning Loss: tensor(3.3489)\n",
      "6252 Traning Loss: tensor(3.3489)\n",
      "6253 Traning Loss: tensor(3.3489)\n",
      "6254 Traning Loss: tensor(3.3489)\n",
      "6255 Traning Loss: tensor(3.3489)\n",
      "6256 Traning Loss: tensor(3.3489)\n",
      "6257 Traning Loss: tensor(3.3489)\n",
      "6258 Traning Loss: tensor(3.3489)\n",
      "6259 Traning Loss: tensor(3.3489)\n",
      "6260 Traning Loss: tensor(3.3489)\n",
      "6261 Traning Loss: tensor(3.3489)\n",
      "6262 Traning Loss: tensor(3.3489)\n",
      "6263 Traning Loss: tensor(3.3489)\n",
      "6264 Traning Loss: tensor(3.3489)\n",
      "6265 Traning Loss: tensor(3.3489)\n",
      "6266 Traning Loss: tensor(3.3489)\n",
      "6267 Traning Loss: tensor(3.3489)\n",
      "6268 Traning Loss: tensor(3.3489)\n",
      "6269 Traning Loss: tensor(3.3489)\n",
      "6270 Traning Loss: tensor(3.3489)\n",
      "6271 Traning Loss: tensor(3.3489)\n",
      "6272 Traning Loss: tensor(3.3489)\n",
      "6273 Traning Loss: tensor(3.3489)\n",
      "6274 Traning Loss: tensor(3.3489)\n",
      "6275 Traning Loss: tensor(3.3489)\n",
      "6276 Traning Loss: tensor(3.3489)\n",
      "6277 Traning Loss: tensor(3.3489)\n",
      "6278 Traning Loss: tensor(3.3489)\n",
      "6279 Traning Loss: tensor(3.3489)\n",
      "6280 Traning Loss: tensor(3.3489)\n",
      "6281 Traning Loss: tensor(3.3489)\n",
      "6282 Traning Loss: tensor(3.3489)\n",
      "6283 Traning Loss: tensor(3.3489)\n",
      "6284 Traning Loss: tensor(3.3489)\n",
      "6285 Traning Loss: tensor(3.3489)\n",
      "6286 Traning Loss: tensor(3.3489)\n",
      "6287 Traning Loss: tensor(3.3489)\n",
      "6288 Traning Loss: tensor(3.3489)\n",
      "6289 Traning Loss: tensor(3.3489)\n",
      "6290 Traning Loss: tensor(3.3489)\n",
      "6291 Traning Loss: tensor(3.3489)\n",
      "6292 Traning Loss: tensor(3.3489)\n",
      "6293 Traning Loss: tensor(3.3489)\n",
      "6294 Traning Loss: tensor(3.3489)\n",
      "6295 Traning Loss: tensor(3.3489)\n",
      "6296 Traning Loss: tensor(3.3489)\n",
      "6297 Traning Loss: tensor(3.3489)\n",
      "6298 Traning Loss: tensor(3.3489)\n",
      "6299 Traning Loss: tensor(3.3489)\n",
      "6300 Traning Loss: tensor(3.3489)\n",
      "6301 Traning Loss: tensor(3.3489)\n",
      "6302 Traning Loss: tensor(3.3489)\n",
      "6303 Traning Loss: tensor(3.3489)\n",
      "6304 Traning Loss: tensor(3.3489)\n",
      "6305 Traning Loss: tensor(3.3489)\n",
      "6306 Traning Loss: tensor(3.3489)\n",
      "6307 Traning Loss: tensor(3.3489)\n",
      "6308 Traning Loss: tensor(3.3489)\n",
      "6309 Traning Loss: tensor(3.3489)\n",
      "6310 Traning Loss: tensor(3.3489)\n",
      "6311 Traning Loss: tensor(3.3489)\n",
      "6312 Traning Loss: tensor(3.3489)\n",
      "6313 Traning Loss: tensor(3.3489)\n",
      "6314 Traning Loss: tensor(3.3489)\n",
      "6315 Traning Loss: tensor(3.3489)\n",
      "6316 Traning Loss: tensor(3.3489)\n",
      "6317 Traning Loss: tensor(3.3489)\n",
      "6318 Traning Loss: tensor(3.3489)\n",
      "6319 Traning Loss: tensor(3.3489)\n",
      "6320 Traning Loss: tensor(3.3489)\n",
      "6321 Traning Loss: tensor(3.3489)\n",
      "6322 Traning Loss: tensor(3.3489)\n",
      "6323 Traning Loss: tensor(3.3489)\n",
      "6324 Traning Loss: tensor(3.3489)\n",
      "6325 Traning Loss: tensor(3.3489)\n",
      "6326 Traning Loss: tensor(3.3489)\n",
      "6327 Traning Loss: tensor(3.3489)\n",
      "6328 Traning Loss: tensor(3.3489)\n",
      "6329 Traning Loss: tensor(3.3489)\n",
      "6330 Traning Loss: tensor(3.3489)\n",
      "6331 Traning Loss: tensor(3.3489)\n",
      "6332 Traning Loss: tensor(3.3489)\n",
      "6333 Traning Loss: tensor(3.3489)\n",
      "6334 Traning Loss: tensor(3.3489)\n",
      "6335 Traning Loss: tensor(3.3489)\n",
      "6336 Traning Loss: tensor(3.3489)\n",
      "6337 Traning Loss: tensor(3.3489)\n",
      "6338 Traning Loss: tensor(3.3489)\n",
      "6339 Traning Loss: tensor(3.3489)\n",
      "6340 Traning Loss: tensor(3.3489)\n",
      "6341 Traning Loss: tensor(3.3489)\n",
      "6342 Traning Loss: tensor(3.3489)\n",
      "6343 Traning Loss: tensor(3.3489)\n",
      "6344 Traning Loss: tensor(3.3489)\n",
      "6345 Traning Loss: tensor(3.3489)\n",
      "6346 Traning Loss: tensor(3.3489)\n",
      "6347 Traning Loss: tensor(3.3489)\n",
      "6348 Traning Loss: tensor(3.3489)\n",
      "6349 Traning Loss: tensor(3.3489)\n",
      "6350 Traning Loss: tensor(3.3489)\n",
      "6351 Traning Loss: tensor(3.3489)\n",
      "6352 Traning Loss: tensor(3.3489)\n",
      "6353 Traning Loss: tensor(3.3489)\n",
      "6354 Traning Loss: tensor(3.3489)\n",
      "6355 Traning Loss: tensor(3.3489)\n",
      "6356 Traning Loss: tensor(3.3489)\n",
      "6357 Traning Loss: tensor(3.3489)\n",
      "6358 Traning Loss: tensor(3.3489)\n",
      "6359 Traning Loss: tensor(3.3489)\n",
      "6360 Traning Loss: tensor(3.3489)\n",
      "6361 Traning Loss: tensor(3.3489)\n",
      "6362 Traning Loss: tensor(3.3489)\n",
      "6363 Traning Loss: tensor(3.3489)\n",
      "6364 Traning Loss: tensor(3.3489)\n",
      "6365 Traning Loss: tensor(3.3489)\n",
      "6366 Traning Loss: tensor(3.3489)\n",
      "6367 Traning Loss: tensor(3.3489)\n",
      "6368 Traning Loss: tensor(3.3489)\n",
      "6369 Traning Loss: tensor(3.3489)\n",
      "6370 Traning Loss: tensor(3.3489)\n",
      "6371 Traning Loss: tensor(3.3489)\n",
      "6372 Traning Loss: tensor(3.3489)\n",
      "6373 Traning Loss: tensor(3.3489)\n",
      "6374 Traning Loss: tensor(3.3489)\n",
      "6375 Traning Loss: tensor(3.3489)\n",
      "6376 Traning Loss: tensor(3.3489)\n",
      "6377 Traning Loss: tensor(3.3489)\n",
      "6378 Traning Loss: tensor(3.3489)\n",
      "6379 Traning Loss: tensor(3.3489)\n",
      "6380 Traning Loss: tensor(3.3489)\n",
      "6381 Traning Loss: tensor(3.3489)\n",
      "6382 Traning Loss: tensor(3.3489)\n",
      "6383 Traning Loss: tensor(3.3489)\n",
      "6384 Traning Loss: tensor(3.3489)\n",
      "6385 Traning Loss: tensor(3.3489)\n",
      "6386 Traning Loss: tensor(3.3489)\n",
      "6387 Traning Loss: tensor(3.3489)\n",
      "6388 Traning Loss: tensor(3.3489)\n",
      "6389 Traning Loss: tensor(3.3489)\n",
      "6390 Traning Loss: tensor(3.3489)\n",
      "6391 Traning Loss: tensor(3.3489)\n",
      "6392 Traning Loss: tensor(3.3489)\n",
      "6393 Traning Loss: tensor(3.3489)\n",
      "6394 Traning Loss: tensor(3.3489)\n",
      "6395 Traning Loss: tensor(3.3489)\n",
      "6396 Traning Loss: tensor(3.3489)\n",
      "6397 Traning Loss: tensor(3.3489)\n",
      "6398 Traning Loss: tensor(3.3489)\n",
      "6399 Traning Loss: tensor(3.3489)\n",
      "6400 Traning Loss: tensor(3.3489)\n",
      "6401 Traning Loss: tensor(3.3489)\n",
      "6402 Traning Loss: tensor(3.3489)\n",
      "6403 Traning Loss: tensor(3.3489)\n",
      "6404 Traning Loss: tensor(3.3489)\n",
      "6405 Traning Loss: tensor(3.3489)\n",
      "6406 Traning Loss: tensor(3.3489)\n",
      "6407 Traning Loss: tensor(3.3489)\n",
      "6408 Traning Loss: tensor(3.3489)\n",
      "6409 Traning Loss: tensor(3.3489)\n",
      "6410 Traning Loss: tensor(3.3489)\n",
      "6411 Traning Loss: tensor(3.3489)\n",
      "6412 Traning Loss: tensor(3.3489)\n",
      "6413 Traning Loss: tensor(3.3489)\n",
      "6414 Traning Loss: tensor(3.3489)\n",
      "6415 Traning Loss: tensor(3.3489)\n",
      "6416 Traning Loss: tensor(3.3489)\n",
      "6417 Traning Loss: tensor(3.3489)\n",
      "6418 Traning Loss: tensor(3.3489)\n",
      "6419 Traning Loss: tensor(3.3489)\n",
      "6420 Traning Loss: tensor(3.3489)\n",
      "6421 Traning Loss: tensor(3.3489)\n",
      "6422 Traning Loss: tensor(3.3489)\n",
      "6423 Traning Loss: tensor(3.3489)\n",
      "6424 Traning Loss: tensor(3.3489)\n",
      "6425 Traning Loss: tensor(3.3489)\n",
      "6426 Traning Loss: tensor(3.3489)\n",
      "6427 Traning Loss: tensor(3.3489)\n",
      "6428 Traning Loss: tensor(3.3489)\n",
      "6429 Traning Loss: tensor(3.3489)\n",
      "6430 Traning Loss: tensor(3.3489)\n",
      "6431 Traning Loss: tensor(3.3489)\n",
      "6432 Traning Loss: tensor(3.3489)\n",
      "6433 Traning Loss: tensor(3.3489)\n",
      "6434 Traning Loss: tensor(3.3489)\n",
      "6435 Traning Loss: tensor(3.3489)\n",
      "6436 Traning Loss: tensor(3.3489)\n",
      "6437 Traning Loss: tensor(3.3489)\n",
      "6438 Traning Loss: tensor(3.3489)\n",
      "6439 Traning Loss: tensor(3.3489)\n",
      "6440 Traning Loss: tensor(3.3489)\n",
      "6441 Traning Loss: tensor(3.3489)\n",
      "6442 Traning Loss: tensor(3.3489)\n",
      "6443 Traning Loss: tensor(3.3489)\n",
      "6444 Traning Loss: tensor(3.3489)\n",
      "6445 Traning Loss: tensor(3.3489)\n",
      "6446 Traning Loss: tensor(3.3489)\n",
      "6447 Traning Loss: tensor(3.3489)\n",
      "6448 Traning Loss: tensor(3.3489)\n",
      "6449 Traning Loss: tensor(3.3489)\n",
      "6450 Traning Loss: tensor(3.3489)\n",
      "6451 Traning Loss: tensor(3.3489)\n",
      "6452 Traning Loss: tensor(3.3489)\n",
      "6453 Traning Loss: tensor(3.3489)\n",
      "6454 Traning Loss: tensor(3.3489)\n",
      "6455 Traning Loss: tensor(3.3489)\n",
      "6456 Traning Loss: tensor(3.3489)\n",
      "6457 Traning Loss: tensor(3.3489)\n",
      "6458 Traning Loss: tensor(3.3489)\n",
      "6459 Traning Loss: tensor(3.3489)\n",
      "6460 Traning Loss: tensor(3.3489)\n",
      "6461 Traning Loss: tensor(3.3489)\n",
      "6462 Traning Loss: tensor(3.3489)\n",
      "6463 Traning Loss: tensor(3.3489)\n",
      "6464 Traning Loss: tensor(3.3489)\n",
      "6465 Traning Loss: tensor(3.3489)\n",
      "6466 Traning Loss: tensor(3.3489)\n",
      "6467 Traning Loss: tensor(3.3489)\n",
      "6468 Traning Loss: tensor(3.3489)\n",
      "6469 Traning Loss: tensor(3.3489)\n",
      "6470 Traning Loss: tensor(3.3489)\n",
      "6471 Traning Loss: tensor(3.3489)\n",
      "6472 Traning Loss: tensor(3.3489)\n",
      "6473 Traning Loss: tensor(3.3489)\n",
      "6474 Traning Loss: tensor(3.3489)\n",
      "6475 Traning Loss: tensor(3.3489)\n",
      "6476 Traning Loss: tensor(3.3489)\n",
      "6477 Traning Loss: tensor(3.3489)\n",
      "6478 Traning Loss: tensor(3.3489)\n",
      "6479 Traning Loss: tensor(3.3489)\n",
      "6480 Traning Loss: tensor(3.3489)\n",
      "6481 Traning Loss: tensor(3.3489)\n",
      "6482 Traning Loss: tensor(3.3489)\n",
      "6483 Traning Loss: tensor(3.3489)\n",
      "6484 Traning Loss: tensor(3.3489)\n",
      "6485 Traning Loss: tensor(3.3489)\n",
      "6486 Traning Loss: tensor(3.3489)\n",
      "6487 Traning Loss: tensor(3.3489)\n",
      "6488 Traning Loss: tensor(3.3489)\n",
      "6489 Traning Loss: tensor(3.3489)\n",
      "6490 Traning Loss: tensor(3.3489)\n",
      "6491 Traning Loss: tensor(3.3489)\n",
      "6492 Traning Loss: tensor(3.3489)\n",
      "6493 Traning Loss: tensor(3.3489)\n",
      "6494 Traning Loss: tensor(3.3489)\n",
      "6495 Traning Loss: tensor(3.3489)\n",
      "6496 Traning Loss: tensor(3.3489)\n",
      "6497 Traning Loss: tensor(3.3489)\n",
      "6498 Traning Loss: tensor(3.3489)\n",
      "6499 Traning Loss: tensor(3.3489)\n",
      "6500 Traning Loss: tensor(3.3489)\n",
      "6501 Traning Loss: tensor(3.3489)\n",
      "6502 Traning Loss: tensor(3.3489)\n",
      "6503 Traning Loss: tensor(3.3489)\n",
      "6504 Traning Loss: tensor(3.3489)\n",
      "6505 Traning Loss: tensor(3.3489)\n",
      "6506 Traning Loss: tensor(3.3489)\n",
      "6507 Traning Loss: tensor(3.3489)\n",
      "6508 Traning Loss: tensor(3.3489)\n",
      "6509 Traning Loss: tensor(3.3489)\n",
      "6510 Traning Loss: tensor(3.3489)\n",
      "6511 Traning Loss: tensor(3.3489)\n",
      "6512 Traning Loss: tensor(3.3489)\n",
      "6513 Traning Loss: tensor(3.3489)\n",
      "6514 Traning Loss: tensor(3.3489)\n",
      "6515 Traning Loss: tensor(3.3489)\n",
      "6516 Traning Loss: tensor(3.3489)\n",
      "6517 Traning Loss: tensor(3.3489)\n",
      "6518 Traning Loss: tensor(3.3489)\n",
      "6519 Traning Loss: tensor(3.3489)\n",
      "6520 Traning Loss: tensor(3.3489)\n",
      "6521 Traning Loss: tensor(3.3489)\n",
      "6522 Traning Loss: tensor(3.3489)\n",
      "6523 Traning Loss: tensor(3.3489)\n",
      "6524 Traning Loss: tensor(3.3489)\n",
      "6525 Traning Loss: tensor(3.3489)\n",
      "6526 Traning Loss: tensor(3.3489)\n",
      "6527 Traning Loss: tensor(3.3489)\n",
      "6528 Traning Loss: tensor(3.3489)\n",
      "6529 Traning Loss: tensor(3.3489)\n",
      "6530 Traning Loss: tensor(3.3489)\n",
      "6531 Traning Loss: tensor(3.3489)\n",
      "6532 Traning Loss: tensor(3.3489)\n",
      "6533 Traning Loss: tensor(3.3489)\n",
      "6534 Traning Loss: tensor(3.3489)\n",
      "6535 Traning Loss: tensor(3.3489)\n",
      "6536 Traning Loss: tensor(3.3489)\n",
      "6537 Traning Loss: tensor(3.3489)\n",
      "6538 Traning Loss: tensor(3.3489)\n",
      "6539 Traning Loss: tensor(3.3489)\n",
      "6540 Traning Loss: tensor(3.3489)\n",
      "6541 Traning Loss: tensor(3.3489)\n",
      "6542 Traning Loss: tensor(3.3489)\n",
      "6543 Traning Loss: tensor(3.3489)\n",
      "6544 Traning Loss: tensor(3.3489)\n",
      "6545 Traning Loss: tensor(3.3489)\n",
      "6546 Traning Loss: tensor(3.3489)\n",
      "6547 Traning Loss: tensor(3.3489)\n",
      "6548 Traning Loss: tensor(3.3489)\n",
      "6549 Traning Loss: tensor(3.3489)\n",
      "6550 Traning Loss: tensor(3.3489)\n",
      "6551 Traning Loss: tensor(3.3489)\n",
      "6552 Traning Loss: tensor(3.3489)\n",
      "6553 Traning Loss: tensor(3.3489)\n",
      "6554 Traning Loss: tensor(3.3489)\n",
      "6555 Traning Loss: tensor(3.3489)\n",
      "6556 Traning Loss: tensor(3.3489)\n",
      "6557 Traning Loss: tensor(3.3489)\n",
      "6558 Traning Loss: tensor(3.3489)\n",
      "6559 Traning Loss: tensor(3.3489)\n",
      "6560 Traning Loss: tensor(3.3489)\n",
      "6561 Traning Loss: tensor(3.3489)\n",
      "6562 Traning Loss: tensor(3.3489)\n",
      "6563 Traning Loss: tensor(3.3489)\n",
      "6564 Traning Loss: tensor(3.3489)\n",
      "6565 Traning Loss: tensor(3.3489)\n",
      "6566 Traning Loss: tensor(3.3489)\n",
      "6567 Traning Loss: tensor(3.3489)\n",
      "6568 Traning Loss: tensor(3.3489)\n",
      "6569 Traning Loss: tensor(3.3489)\n",
      "6570 Traning Loss: tensor(3.3489)\n",
      "6571 Traning Loss: tensor(3.3489)\n",
      "6572 Traning Loss: tensor(3.3489)\n",
      "6573 Traning Loss: tensor(3.3489)\n",
      "6574 Traning Loss: tensor(3.3489)\n",
      "6575 Traning Loss: tensor(3.3489)\n",
      "6576 Traning Loss: tensor(3.3489)\n",
      "6577 Traning Loss: tensor(3.3489)\n",
      "6578 Traning Loss: tensor(3.3489)\n",
      "6579 Traning Loss: tensor(3.3489)\n",
      "6580 Traning Loss: tensor(3.3489)\n",
      "6581 Traning Loss: tensor(3.3489)\n",
      "6582 Traning Loss: tensor(3.3489)\n",
      "6583 Traning Loss: tensor(3.3489)\n",
      "6584 Traning Loss: tensor(3.3489)\n",
      "6585 Traning Loss: tensor(3.3489)\n",
      "6586 Traning Loss: tensor(3.3489)\n",
      "6587 Traning Loss: tensor(3.3489)\n",
      "6588 Traning Loss: tensor(3.3489)\n",
      "6589 Traning Loss: tensor(3.3489)\n",
      "6590 Traning Loss: tensor(3.3489)\n",
      "6591 Traning Loss: tensor(3.3489)\n",
      "6592 Traning Loss: tensor(3.3489)\n",
      "6593 Traning Loss: tensor(3.3489)\n",
      "6594 Traning Loss: tensor(3.3489)\n",
      "6595 Traning Loss: tensor(3.3489)\n",
      "6596 Traning Loss: tensor(3.3489)\n",
      "6597 Traning Loss: tensor(3.3489)\n",
      "6598 Traning Loss: tensor(3.3489)\n",
      "6599 Traning Loss: tensor(3.3489)\n",
      "6600 Traning Loss: tensor(3.3489)\n",
      "6601 Traning Loss: tensor(3.3489)\n",
      "6602 Traning Loss: tensor(3.3489)\n",
      "6603 Traning Loss: tensor(3.3489)\n",
      "6604 Traning Loss: tensor(3.3489)\n",
      "6605 Traning Loss: tensor(3.3489)\n",
      "6606 Traning Loss: tensor(3.3489)\n",
      "6607 Traning Loss: tensor(3.3489)\n",
      "6608 Traning Loss: tensor(3.3489)\n",
      "6609 Traning Loss: tensor(3.3489)\n",
      "6610 Traning Loss: tensor(3.3489)\n",
      "6611 Traning Loss: tensor(3.3489)\n",
      "6612 Traning Loss: tensor(3.3489)\n",
      "6613 Traning Loss: tensor(3.3489)\n",
      "6614 Traning Loss: tensor(3.3489)\n",
      "6615 Traning Loss: tensor(3.3489)\n",
      "6616 Traning Loss: tensor(3.3489)\n",
      "6617 Traning Loss: tensor(3.3489)\n",
      "6618 Traning Loss: tensor(3.3489)\n",
      "6619 Traning Loss: tensor(3.3489)\n",
      "6620 Traning Loss: tensor(3.3489)\n",
      "6621 Traning Loss: tensor(3.3489)\n",
      "6622 Traning Loss: tensor(3.3489)\n",
      "6623 Traning Loss: tensor(3.3489)\n",
      "6624 Traning Loss: tensor(3.3489)\n",
      "6625 Traning Loss: tensor(3.3489)\n",
      "6626 Traning Loss: tensor(3.3489)\n",
      "6627 Traning Loss: tensor(3.3489)\n",
      "6628 Traning Loss: tensor(3.3489)\n",
      "6629 Traning Loss: tensor(3.3489)\n",
      "6630 Traning Loss: tensor(3.3489)\n",
      "6631 Traning Loss: tensor(3.3489)\n",
      "6632 Traning Loss: tensor(3.3489)\n",
      "6633 Traning Loss: tensor(3.3489)\n",
      "6634 Traning Loss: tensor(3.3489)\n",
      "6635 Traning Loss: tensor(3.3489)\n",
      "6636 Traning Loss: tensor(3.3489)\n",
      "6637 Traning Loss: tensor(3.3489)\n",
      "6638 Traning Loss: tensor(3.3489)\n",
      "6639 Traning Loss: tensor(3.3489)\n",
      "6640 Traning Loss: tensor(3.3489)\n",
      "6641 Traning Loss: tensor(3.3489)\n",
      "6642 Traning Loss: tensor(3.3489)\n",
      "6643 Traning Loss: tensor(3.3489)\n",
      "6644 Traning Loss: tensor(3.3489)\n",
      "6645 Traning Loss: tensor(3.3489)\n",
      "6646 Traning Loss: tensor(3.3489)\n",
      "6647 Traning Loss: tensor(3.3489)\n",
      "6648 Traning Loss: tensor(3.3489)\n",
      "6649 Traning Loss: tensor(3.3489)\n",
      "6650 Traning Loss: tensor(3.3489)\n",
      "6651 Traning Loss: tensor(3.3489)\n",
      "6652 Traning Loss: tensor(3.3489)\n",
      "6653 Traning Loss: tensor(3.3489)\n",
      "6654 Traning Loss: tensor(3.3489)\n",
      "6655 Traning Loss: tensor(3.3489)\n",
      "6656 Traning Loss: tensor(3.3489)\n",
      "6657 Traning Loss: tensor(3.3489)\n",
      "6658 Traning Loss: tensor(3.3489)\n",
      "6659 Traning Loss: tensor(3.3489)\n",
      "6660 Traning Loss: tensor(3.3489)\n",
      "6661 Traning Loss: tensor(3.3489)\n",
      "6662 Traning Loss: tensor(3.3489)\n",
      "6663 Traning Loss: tensor(3.3489)\n",
      "6664 Traning Loss: tensor(3.3489)\n",
      "6665 Traning Loss: tensor(3.3489)\n",
      "6666 Traning Loss: tensor(3.3489)\n",
      "6667 Traning Loss: tensor(3.3489)\n",
      "6668 Traning Loss: tensor(3.3489)\n",
      "6669 Traning Loss: tensor(3.3489)\n",
      "6670 Traning Loss: tensor(3.3489)\n",
      "6671 Traning Loss: tensor(3.3489)\n",
      "6672 Traning Loss: tensor(3.3489)\n",
      "6673 Traning Loss: tensor(3.3489)\n",
      "6674 Traning Loss: tensor(3.3489)\n",
      "6675 Traning Loss: tensor(3.3489)\n",
      "6676 Traning Loss: tensor(3.3489)\n",
      "6677 Traning Loss: tensor(3.3489)\n",
      "6678 Traning Loss: tensor(3.3489)\n",
      "6679 Traning Loss: tensor(3.3489)\n",
      "6680 Traning Loss: tensor(3.3489)\n",
      "6681 Traning Loss: tensor(3.3489)\n",
      "6682 Traning Loss: tensor(3.3489)\n",
      "6683 Traning Loss: tensor(3.3489)\n",
      "6684 Traning Loss: tensor(3.3489)\n",
      "6685 Traning Loss: tensor(3.3489)\n",
      "6686 Traning Loss: tensor(3.3489)\n",
      "6687 Traning Loss: tensor(3.3489)\n",
      "6688 Traning Loss: tensor(3.3489)\n",
      "6689 Traning Loss: tensor(3.3489)\n",
      "6690 Traning Loss: tensor(3.3489)\n",
      "6691 Traning Loss: tensor(3.3489)\n",
      "6692 Traning Loss: tensor(3.3489)\n",
      "6693 Traning Loss: tensor(3.3489)\n",
      "6694 Traning Loss: tensor(3.3489)\n",
      "6695 Traning Loss: tensor(3.3489)\n",
      "6696 Traning Loss: tensor(3.3489)\n",
      "6697 Traning Loss: tensor(3.3489)\n",
      "6698 Traning Loss: tensor(3.3489)\n",
      "6699 Traning Loss: tensor(3.3489)\n",
      "6700 Traning Loss: tensor(3.3489)\n",
      "6701 Traning Loss: tensor(3.3489)\n",
      "6702 Traning Loss: tensor(3.3489)\n",
      "6703 Traning Loss: tensor(3.3489)\n",
      "6704 Traning Loss: tensor(3.3489)\n",
      "6705 Traning Loss: tensor(3.3489)\n",
      "6706 Traning Loss: tensor(3.3489)\n",
      "6707 Traning Loss: tensor(3.3489)\n",
      "6708 Traning Loss: tensor(3.3489)\n",
      "6709 Traning Loss: tensor(3.3489)\n",
      "6710 Traning Loss: tensor(3.3489)\n",
      "6711 Traning Loss: tensor(3.3489)\n",
      "6712 Traning Loss: tensor(3.3489)\n",
      "6713 Traning Loss: tensor(3.3489)\n",
      "6714 Traning Loss: tensor(3.3489)\n",
      "6715 Traning Loss: tensor(3.3489)\n",
      "6716 Traning Loss: tensor(3.3489)\n",
      "6717 Traning Loss: tensor(3.3489)\n",
      "6718 Traning Loss: tensor(3.3489)\n",
      "6719 Traning Loss: tensor(3.3489)\n",
      "6720 Traning Loss: tensor(3.3489)\n",
      "6721 Traning Loss: tensor(3.3489)\n",
      "6722 Traning Loss: tensor(3.3489)\n",
      "6723 Traning Loss: tensor(3.3489)\n",
      "6724 Traning Loss: tensor(3.3489)\n",
      "6725 Traning Loss: tensor(3.3489)\n",
      "6726 Traning Loss: tensor(3.3489)\n",
      "6727 Traning Loss: tensor(3.3489)\n",
      "6728 Traning Loss: tensor(3.3489)\n",
      "6729 Traning Loss: tensor(3.3489)\n",
      "6730 Traning Loss: tensor(3.3489)\n",
      "6731 Traning Loss: tensor(3.3489)\n",
      "6732 Traning Loss: tensor(3.3489)\n",
      "6733 Traning Loss: tensor(3.3489)\n",
      "6734 Traning Loss: tensor(3.3489)\n",
      "6735 Traning Loss: tensor(3.3489)\n",
      "6736 Traning Loss: tensor(3.3489)\n",
      "6737 Traning Loss: tensor(3.3489)\n",
      "6738 Traning Loss: tensor(3.3489)\n",
      "6739 Traning Loss: tensor(3.3489)\n",
      "6740 Traning Loss: tensor(3.3489)\n",
      "6741 Traning Loss: tensor(3.3489)\n",
      "6742 Traning Loss: tensor(3.3489)\n",
      "6743 Traning Loss: tensor(3.3489)\n",
      "6744 Traning Loss: tensor(3.3489)\n",
      "6745 Traning Loss: tensor(3.3489)\n",
      "6746 Traning Loss: tensor(3.3489)\n",
      "6747 Traning Loss: tensor(3.3489)\n",
      "6748 Traning Loss: tensor(3.3489)\n",
      "6749 Traning Loss: tensor(3.3489)\n",
      "6750 Traning Loss: tensor(3.3489)\n",
      "6751 Traning Loss: tensor(3.3489)\n",
      "6752 Traning Loss: tensor(3.3489)\n",
      "6753 Traning Loss: tensor(3.3489)\n",
      "6754 Traning Loss: tensor(3.3489)\n",
      "6755 Traning Loss: tensor(3.3489)\n",
      "6756 Traning Loss: tensor(3.3489)\n",
      "6757 Traning Loss: tensor(3.3489)\n",
      "6758 Traning Loss: tensor(3.3489)\n",
      "6759 Traning Loss: tensor(3.3489)\n",
      "6760 Traning Loss: tensor(3.3489)\n",
      "6761 Traning Loss: tensor(3.3489)\n",
      "6762 Traning Loss: tensor(3.3489)\n",
      "6763 Traning Loss: tensor(3.3489)\n",
      "6764 Traning Loss: tensor(3.3489)\n",
      "6765 Traning Loss: tensor(3.3489)\n",
      "6766 Traning Loss: tensor(3.3489)\n",
      "6767 Traning Loss: tensor(3.3489)\n",
      "6768 Traning Loss: tensor(3.3489)\n",
      "6769 Traning Loss: tensor(3.3489)\n",
      "6770 Traning Loss: tensor(3.3489)\n",
      "6771 Traning Loss: tensor(3.3489)\n",
      "6772 Traning Loss: tensor(3.3489)\n",
      "6773 Traning Loss: tensor(3.3489)\n",
      "6774 Traning Loss: tensor(3.3489)\n",
      "6775 Traning Loss: tensor(3.3489)\n",
      "6776 Traning Loss: tensor(3.3489)\n",
      "6777 Traning Loss: tensor(3.3489)\n",
      "6778 Traning Loss: tensor(3.3489)\n",
      "6779 Traning Loss: tensor(3.3489)\n",
      "6780 Traning Loss: tensor(3.3489)\n",
      "6781 Traning Loss: tensor(3.3489)\n",
      "6782 Traning Loss: tensor(3.3489)\n",
      "6783 Traning Loss: tensor(3.3489)\n",
      "6784 Traning Loss: tensor(3.3489)\n",
      "6785 Traning Loss: tensor(3.3489)\n",
      "6786 Traning Loss: tensor(3.3489)\n",
      "6787 Traning Loss: tensor(3.3489)\n",
      "6788 Traning Loss: tensor(3.3489)\n",
      "6789 Traning Loss: tensor(3.3489)\n",
      "6790 Traning Loss: tensor(3.3489)\n",
      "6791 Traning Loss: tensor(3.3489)\n",
      "6792 Traning Loss: tensor(3.3489)\n",
      "6793 Traning Loss: tensor(3.3489)\n",
      "6794 Traning Loss: tensor(3.3489)\n",
      "6795 Traning Loss: tensor(3.3489)\n",
      "6796 Traning Loss: tensor(3.3489)\n",
      "6797 Traning Loss: tensor(3.3489)\n",
      "6798 Traning Loss: tensor(3.3489)\n",
      "6799 Traning Loss: tensor(3.3489)\n",
      "6800 Traning Loss: tensor(3.3489)\n",
      "6801 Traning Loss: tensor(3.3489)\n",
      "6802 Traning Loss: tensor(3.3489)\n",
      "6803 Traning Loss: tensor(3.3489)\n",
      "6804 Traning Loss: tensor(3.3489)\n",
      "6805 Traning Loss: tensor(3.3489)\n",
      "6806 Traning Loss: tensor(3.3489)\n",
      "6807 Traning Loss: tensor(3.3489)\n",
      "6808 Traning Loss: tensor(3.3489)\n",
      "6809 Traning Loss: tensor(3.3489)\n",
      "6810 Traning Loss: tensor(3.3489)\n",
      "6811 Traning Loss: tensor(3.3489)\n",
      "6812 Traning Loss: tensor(3.3489)\n",
      "6813 Traning Loss: tensor(3.3489)\n",
      "6814 Traning Loss: tensor(3.3489)\n",
      "6815 Traning Loss: tensor(3.3489)\n",
      "6816 Traning Loss: tensor(3.3489)\n",
      "6817 Traning Loss: tensor(3.3489)\n",
      "6818 Traning Loss: tensor(3.3489)\n",
      "6819 Traning Loss: tensor(3.3489)\n",
      "6820 Traning Loss: tensor(3.3489)\n",
      "6821 Traning Loss: tensor(3.3489)\n",
      "6822 Traning Loss: tensor(3.3489)\n",
      "6823 Traning Loss: tensor(3.3489)\n",
      "6824 Traning Loss: tensor(3.3489)\n",
      "6825 Traning Loss: tensor(3.3489)\n",
      "6826 Traning Loss: tensor(3.3489)\n",
      "6827 Traning Loss: tensor(3.3489)\n",
      "6828 Traning Loss: tensor(3.3489)\n",
      "6829 Traning Loss: tensor(3.3489)\n",
      "6830 Traning Loss: tensor(3.3489)\n",
      "6831 Traning Loss: tensor(3.3489)\n",
      "6832 Traning Loss: tensor(3.3489)\n",
      "6833 Traning Loss: tensor(3.3489)\n",
      "6834 Traning Loss: tensor(3.3489)\n",
      "6835 Traning Loss: tensor(3.3489)\n",
      "6836 Traning Loss: tensor(3.3489)\n",
      "6837 Traning Loss: tensor(3.3489)\n",
      "6838 Traning Loss: tensor(3.3489)\n",
      "6839 Traning Loss: tensor(3.3489)\n",
      "6840 Traning Loss: tensor(3.3489)\n",
      "6841 Traning Loss: tensor(3.3489)\n",
      "6842 Traning Loss: tensor(3.3489)\n",
      "6843 Traning Loss: tensor(3.3489)\n",
      "6844 Traning Loss: tensor(3.3489)\n",
      "6845 Traning Loss: tensor(3.3489)\n",
      "6846 Traning Loss: tensor(3.3489)\n",
      "6847 Traning Loss: tensor(3.3489)\n",
      "6848 Traning Loss: tensor(3.3489)\n",
      "6849 Traning Loss: tensor(3.3489)\n",
      "6850 Traning Loss: tensor(3.3489)\n",
      "6851 Traning Loss: tensor(3.3489)\n",
      "6852 Traning Loss: tensor(3.3489)\n",
      "6853 Traning Loss: tensor(3.3489)\n",
      "6854 Traning Loss: tensor(3.3489)\n",
      "6855 Traning Loss: tensor(3.3489)\n",
      "6856 Traning Loss: tensor(3.3489)\n",
      "6857 Traning Loss: tensor(3.3489)\n",
      "6858 Traning Loss: tensor(3.3489)\n",
      "6859 Traning Loss: tensor(3.3489)\n",
      "6860 Traning Loss: tensor(3.3489)\n",
      "6861 Traning Loss: tensor(3.3489)\n",
      "6862 Traning Loss: tensor(3.3489)\n",
      "6863 Traning Loss: tensor(3.3489)\n",
      "6864 Traning Loss: tensor(3.3489)\n",
      "6865 Traning Loss: tensor(3.3489)\n",
      "6866 Traning Loss: tensor(3.3489)\n",
      "6867 Traning Loss: tensor(3.3489)\n",
      "6868 Traning Loss: tensor(3.3489)\n",
      "6869 Traning Loss: tensor(3.3489)\n",
      "6870 Traning Loss: tensor(3.3489)\n",
      "6871 Traning Loss: tensor(3.3489)\n",
      "6872 Traning Loss: tensor(3.3489)\n",
      "6873 Traning Loss: tensor(3.3489)\n",
      "6874 Traning Loss: tensor(3.3489)\n",
      "6875 Traning Loss: tensor(3.3489)\n",
      "6876 Traning Loss: tensor(3.3489)\n",
      "6877 Traning Loss: tensor(3.3489)\n",
      "6878 Traning Loss: tensor(3.3489)\n",
      "6879 Traning Loss: tensor(3.3489)\n",
      "6880 Traning Loss: tensor(3.3489)\n",
      "6881 Traning Loss: tensor(3.3489)\n",
      "6882 Traning Loss: tensor(3.3489)\n",
      "6883 Traning Loss: tensor(3.3489)\n",
      "6884 Traning Loss: tensor(3.3489)\n",
      "6885 Traning Loss: tensor(3.3489)\n",
      "6886 Traning Loss: tensor(3.3489)\n",
      "6887 Traning Loss: tensor(3.3489)\n",
      "6888 Traning Loss: tensor(3.3489)\n",
      "6889 Traning Loss: tensor(3.3489)\n",
      "6890 Traning Loss: tensor(3.3489)\n",
      "6891 Traning Loss: tensor(3.3489)\n",
      "6892 Traning Loss: tensor(3.3489)\n",
      "6893 Traning Loss: tensor(3.3489)\n",
      "6894 Traning Loss: tensor(3.3489)\n",
      "6895 Traning Loss: tensor(3.3489)\n",
      "6896 Traning Loss: tensor(3.3489)\n",
      "6897 Traning Loss: tensor(3.3489)\n",
      "6898 Traning Loss: tensor(3.3489)\n",
      "6899 Traning Loss: tensor(3.3489)\n",
      "6900 Traning Loss: tensor(3.3489)\n",
      "6901 Traning Loss: tensor(3.3489)\n",
      "6902 Traning Loss: tensor(3.3489)\n",
      "6903 Traning Loss: tensor(3.3489)\n",
      "6904 Traning Loss: tensor(3.3489)\n",
      "6905 Traning Loss: tensor(3.3489)\n",
      "6906 Traning Loss: tensor(3.3489)\n",
      "6907 Traning Loss: tensor(3.3489)\n",
      "6908 Traning Loss: tensor(3.3489)\n",
      "6909 Traning Loss: tensor(3.3489)\n",
      "6910 Traning Loss: tensor(3.3489)\n",
      "6911 Traning Loss: tensor(3.3489)\n",
      "6912 Traning Loss: tensor(3.3489)\n",
      "6913 Traning Loss: tensor(3.3489)\n",
      "6914 Traning Loss: tensor(3.3489)\n",
      "6915 Traning Loss: tensor(3.3489)\n",
      "6916 Traning Loss: tensor(3.3489)\n",
      "6917 Traning Loss: tensor(3.3489)\n",
      "6918 Traning Loss: tensor(3.3489)\n",
      "6919 Traning Loss: tensor(3.3489)\n",
      "6920 Traning Loss: tensor(3.3489)\n",
      "6921 Traning Loss: tensor(3.3489)\n",
      "6922 Traning Loss: tensor(3.3489)\n",
      "6923 Traning Loss: tensor(3.3489)\n",
      "6924 Traning Loss: tensor(3.3489)\n",
      "6925 Traning Loss: tensor(3.3489)\n",
      "6926 Traning Loss: tensor(3.3489)\n",
      "6927 Traning Loss: tensor(3.3489)\n",
      "6928 Traning Loss: tensor(3.3489)\n",
      "6929 Traning Loss: tensor(3.3489)\n",
      "6930 Traning Loss: tensor(3.3489)\n",
      "6931 Traning Loss: tensor(3.3489)\n",
      "6932 Traning Loss: tensor(3.3489)\n",
      "6933 Traning Loss: tensor(3.3489)\n",
      "6934 Traning Loss: tensor(3.3489)\n",
      "6935 Traning Loss: tensor(3.3489)\n",
      "6936 Traning Loss: tensor(3.3489)\n",
      "6937 Traning Loss: tensor(3.3489)\n",
      "6938 Traning Loss: tensor(3.3489)\n",
      "6939 Traning Loss: tensor(3.3489)\n",
      "6940 Traning Loss: tensor(3.3489)\n",
      "6941 Traning Loss: tensor(3.3489)\n",
      "6942 Traning Loss: tensor(3.3489)\n",
      "6943 Traning Loss: tensor(3.3489)\n",
      "6944 Traning Loss: tensor(3.3489)\n",
      "6945 Traning Loss: tensor(3.3489)\n",
      "6946 Traning Loss: tensor(3.3489)\n",
      "6947 Traning Loss: tensor(3.3489)\n",
      "6948 Traning Loss: tensor(3.3489)\n",
      "6949 Traning Loss: tensor(3.3489)\n",
      "6950 Traning Loss: tensor(3.3489)\n",
      "6951 Traning Loss: tensor(3.3489)\n",
      "6952 Traning Loss: tensor(3.3489)\n",
      "6953 Traning Loss: tensor(3.3489)\n",
      "6954 Traning Loss: tensor(3.3489)\n",
      "6955 Traning Loss: tensor(3.3489)\n",
      "6956 Traning Loss: tensor(3.3489)\n",
      "6957 Traning Loss: tensor(3.3489)\n",
      "6958 Traning Loss: tensor(3.3489)\n",
      "6959 Traning Loss: tensor(3.3489)\n",
      "6960 Traning Loss: tensor(3.3489)\n",
      "6961 Traning Loss: tensor(3.3489)\n",
      "6962 Traning Loss: tensor(3.3489)\n",
      "6963 Traning Loss: tensor(3.3489)\n",
      "6964 Traning Loss: tensor(3.3489)\n",
      "6965 Traning Loss: tensor(3.3489)\n",
      "6966 Traning Loss: tensor(3.3489)\n",
      "6967 Traning Loss: tensor(3.3489)\n",
      "6968 Traning Loss: tensor(3.3489)\n",
      "6969 Traning Loss: tensor(3.3489)\n",
      "6970 Traning Loss: tensor(3.3489)\n",
      "6971 Traning Loss: tensor(3.3489)\n",
      "6972 Traning Loss: tensor(3.3489)\n",
      "6973 Traning Loss: tensor(3.3489)\n",
      "6974 Traning Loss: tensor(3.3489)\n",
      "6975 Traning Loss: tensor(3.3489)\n",
      "6976 Traning Loss: tensor(3.3489)\n",
      "6977 Traning Loss: tensor(3.3489)\n",
      "6978 Traning Loss: tensor(3.3489)\n",
      "6979 Traning Loss: tensor(3.3489)\n",
      "6980 Traning Loss: tensor(3.3489)\n",
      "6981 Traning Loss: tensor(3.3489)\n",
      "6982 Traning Loss: tensor(3.3489)\n",
      "6983 Traning Loss: tensor(3.3489)\n",
      "6984 Traning Loss: tensor(3.3489)\n",
      "6985 Traning Loss: tensor(3.3489)\n",
      "6986 Traning Loss: tensor(3.3489)\n",
      "6987 Traning Loss: tensor(3.3489)\n",
      "6988 Traning Loss: tensor(3.3489)\n",
      "6989 Traning Loss: tensor(3.3489)\n",
      "6990 Traning Loss: tensor(3.3489)\n",
      "6991 Traning Loss: tensor(3.3489)\n",
      "6992 Traning Loss: tensor(3.3489)\n",
      "6993 Traning Loss: tensor(3.3489)\n",
      "6994 Traning Loss: tensor(3.3489)\n",
      "6995 Traning Loss: tensor(3.3489)\n",
      "6996 Traning Loss: tensor(3.3489)\n",
      "6997 Traning Loss: tensor(3.3489)\n",
      "6998 Traning Loss: tensor(3.3489)\n",
      "6999 Traning Loss: tensor(3.3489)\n",
      "7000 Traning Loss: tensor(3.3489)\n",
      "7001 Traning Loss: tensor(3.3489)\n",
      "7002 Traning Loss: tensor(3.3489)\n",
      "7003 Traning Loss: tensor(3.3489)\n",
      "7004 Traning Loss: tensor(3.3489)\n",
      "7005 Traning Loss: tensor(3.3489)\n",
      "7006 Traning Loss: tensor(3.3489)\n",
      "7007 Traning Loss: tensor(3.3489)\n",
      "7008 Traning Loss: tensor(3.3489)\n",
      "7009 Traning Loss: tensor(3.3489)\n",
      "7010 Traning Loss: tensor(3.3489)\n",
      "7011 Traning Loss: tensor(3.3489)\n",
      "7012 Traning Loss: tensor(3.3489)\n",
      "7013 Traning Loss: tensor(3.3489)\n",
      "7014 Traning Loss: tensor(3.3489)\n",
      "7015 Traning Loss: tensor(3.3489)\n",
      "7016 Traning Loss: tensor(3.3489)\n",
      "7017 Traning Loss: tensor(3.3489)\n",
      "7018 Traning Loss: tensor(3.3489)\n",
      "7019 Traning Loss: tensor(3.3489)\n",
      "7020 Traning Loss: tensor(3.3489)\n",
      "7021 Traning Loss: tensor(3.3489)\n",
      "7022 Traning Loss: tensor(3.3489)\n",
      "7023 Traning Loss: tensor(3.3489)\n",
      "7024 Traning Loss: tensor(3.3489)\n",
      "7025 Traning Loss: tensor(3.3489)\n",
      "7026 Traning Loss: tensor(3.3489)\n",
      "7027 Traning Loss: tensor(3.3489)\n",
      "7028 Traning Loss: tensor(3.3489)\n",
      "7029 Traning Loss: tensor(3.3489)\n",
      "7030 Traning Loss: tensor(3.3489)\n",
      "7031 Traning Loss: tensor(3.3489)\n",
      "7032 Traning Loss: tensor(3.3489)\n",
      "7033 Traning Loss: tensor(3.3489)\n",
      "7034 Traning Loss: tensor(3.3489)\n",
      "7035 Traning Loss: tensor(3.3489)\n",
      "7036 Traning Loss: tensor(3.3489)\n",
      "7037 Traning Loss: tensor(3.3489)\n",
      "7038 Traning Loss: tensor(3.3489)\n",
      "7039 Traning Loss: tensor(3.3489)\n",
      "7040 Traning Loss: tensor(3.3489)\n",
      "7041 Traning Loss: tensor(3.3489)\n",
      "7042 Traning Loss: tensor(3.3489)\n",
      "7043 Traning Loss: tensor(3.3489)\n",
      "7044 Traning Loss: tensor(3.3489)\n",
      "7045 Traning Loss: tensor(3.3489)\n",
      "7046 Traning Loss: tensor(3.3489)\n",
      "7047 Traning Loss: tensor(3.3489)\n",
      "7048 Traning Loss: tensor(3.3489)\n",
      "7049 Traning Loss: tensor(3.3489)\n",
      "7050 Traning Loss: tensor(3.3489)\n",
      "7051 Traning Loss: tensor(3.3489)\n",
      "7052 Traning Loss: tensor(3.3489)\n",
      "7053 Traning Loss: tensor(3.3489)\n",
      "7054 Traning Loss: tensor(3.3489)\n",
      "7055 Traning Loss: tensor(3.3489)\n",
      "7056 Traning Loss: tensor(3.3489)\n",
      "7057 Traning Loss: tensor(3.3489)\n",
      "7058 Traning Loss: tensor(3.3489)\n",
      "7059 Traning Loss: tensor(3.3489)\n",
      "7060 Traning Loss: tensor(3.3489)\n",
      "7061 Traning Loss: tensor(3.3489)\n",
      "7062 Traning Loss: tensor(3.3489)\n",
      "7063 Traning Loss: tensor(3.3489)\n",
      "7064 Traning Loss: tensor(3.3489)\n",
      "7065 Traning Loss: tensor(3.3489)\n",
      "7066 Traning Loss: tensor(3.3489)\n",
      "7067 Traning Loss: tensor(3.3489)\n",
      "7068 Traning Loss: tensor(3.3489)\n",
      "7069 Traning Loss: tensor(3.3489)\n",
      "7070 Traning Loss: tensor(3.3489)\n",
      "7071 Traning Loss: tensor(3.3489)\n",
      "7072 Traning Loss: tensor(3.3489)\n",
      "7073 Traning Loss: tensor(3.3489)\n",
      "7074 Traning Loss: tensor(3.3489)\n",
      "7075 Traning Loss: tensor(3.3489)\n",
      "7076 Traning Loss: tensor(3.3489)\n",
      "7077 Traning Loss: tensor(3.3489)\n",
      "7078 Traning Loss: tensor(3.3489)\n",
      "7079 Traning Loss: tensor(3.3489)\n",
      "7080 Traning Loss: tensor(3.3489)\n",
      "7081 Traning Loss: tensor(3.3489)\n",
      "7082 Traning Loss: tensor(3.3489)\n",
      "7083 Traning Loss: tensor(3.3489)\n",
      "7084 Traning Loss: tensor(3.3489)\n",
      "7085 Traning Loss: tensor(3.3489)\n",
      "7086 Traning Loss: tensor(3.3489)\n",
      "7087 Traning Loss: tensor(3.3489)\n",
      "7088 Traning Loss: tensor(3.3489)\n",
      "7089 Traning Loss: tensor(3.3489)\n",
      "7090 Traning Loss: tensor(3.3489)\n",
      "7091 Traning Loss: tensor(3.3489)\n",
      "7092 Traning Loss: tensor(3.3489)\n",
      "7093 Traning Loss: tensor(3.3489)\n",
      "7094 Traning Loss: tensor(3.3489)\n",
      "7095 Traning Loss: tensor(3.3489)\n",
      "7096 Traning Loss: tensor(3.3489)\n",
      "7097 Traning Loss: tensor(3.3489)\n",
      "7098 Traning Loss: tensor(3.3489)\n",
      "7099 Traning Loss: tensor(3.3489)\n",
      "7100 Traning Loss: tensor(3.3489)\n",
      "7101 Traning Loss: tensor(3.3489)\n",
      "7102 Traning Loss: tensor(3.3489)\n",
      "7103 Traning Loss: tensor(3.3489)\n",
      "7104 Traning Loss: tensor(3.3489)\n",
      "7105 Traning Loss: tensor(3.3489)\n",
      "7106 Traning Loss: tensor(3.3489)\n",
      "7107 Traning Loss: tensor(3.3489)\n",
      "7108 Traning Loss: tensor(3.3489)\n",
      "7109 Traning Loss: tensor(3.3489)\n",
      "7110 Traning Loss: tensor(3.3489)\n",
      "7111 Traning Loss: tensor(3.3489)\n",
      "7112 Traning Loss: tensor(3.3489)\n",
      "7113 Traning Loss: tensor(3.3489)\n",
      "7114 Traning Loss: tensor(3.3489)\n",
      "7115 Traning Loss: tensor(3.3489)\n",
      "7116 Traning Loss: tensor(3.3489)\n",
      "7117 Traning Loss: tensor(3.3489)\n",
      "7118 Traning Loss: tensor(3.3489)\n",
      "7119 Traning Loss: tensor(3.3489)\n",
      "7120 Traning Loss: tensor(3.3489)\n",
      "7121 Traning Loss: tensor(3.3489)\n",
      "7122 Traning Loss: tensor(3.3489)\n",
      "7123 Traning Loss: tensor(3.3489)\n",
      "7124 Traning Loss: tensor(3.3489)\n",
      "7125 Traning Loss: tensor(3.3489)\n",
      "7126 Traning Loss: tensor(3.3489)\n",
      "7127 Traning Loss: tensor(3.3489)\n",
      "7128 Traning Loss: tensor(3.3489)\n",
      "7129 Traning Loss: tensor(3.3489)\n",
      "7130 Traning Loss: tensor(3.3489)\n",
      "7131 Traning Loss: tensor(3.3489)\n",
      "7132 Traning Loss: tensor(3.3489)\n",
      "7133 Traning Loss: tensor(3.3489)\n",
      "7134 Traning Loss: tensor(3.3489)\n",
      "7135 Traning Loss: tensor(3.3489)\n",
      "7136 Traning Loss: tensor(3.3489)\n",
      "7137 Traning Loss: tensor(3.3489)\n",
      "7138 Traning Loss: tensor(3.3489)\n",
      "7139 Traning Loss: tensor(3.3489)\n",
      "7140 Traning Loss: tensor(3.3489)\n",
      "7141 Traning Loss: tensor(3.3489)\n",
      "7142 Traning Loss: tensor(3.3489)\n",
      "7143 Traning Loss: tensor(3.3489)\n",
      "7144 Traning Loss: tensor(3.3489)\n",
      "7145 Traning Loss: tensor(3.3489)\n",
      "7146 Traning Loss: tensor(3.3489)\n",
      "7147 Traning Loss: tensor(3.3489)\n",
      "7148 Traning Loss: tensor(3.3489)\n",
      "7149 Traning Loss: tensor(3.3489)\n",
      "7150 Traning Loss: tensor(3.3489)\n",
      "7151 Traning Loss: tensor(3.3489)\n",
      "7152 Traning Loss: tensor(3.3489)\n",
      "7153 Traning Loss: tensor(3.3489)\n",
      "7154 Traning Loss: tensor(3.3489)\n",
      "7155 Traning Loss: tensor(3.3489)\n",
      "7156 Traning Loss: tensor(3.3489)\n",
      "7157 Traning Loss: tensor(3.3489)\n",
      "7158 Traning Loss: tensor(3.3489)\n",
      "7159 Traning Loss: tensor(3.3489)\n",
      "7160 Traning Loss: tensor(3.3489)\n",
      "7161 Traning Loss: tensor(3.3489)\n",
      "7162 Traning Loss: tensor(3.3489)\n",
      "7163 Traning Loss: tensor(3.3489)\n",
      "7164 Traning Loss: tensor(3.3489)\n",
      "7165 Traning Loss: tensor(3.3489)\n",
      "7166 Traning Loss: tensor(3.3489)\n",
      "7167 Traning Loss: tensor(3.3489)\n",
      "7168 Traning Loss: tensor(3.3489)\n",
      "7169 Traning Loss: tensor(3.3489)\n",
      "7170 Traning Loss: tensor(3.3489)\n",
      "7171 Traning Loss: tensor(3.3489)\n",
      "7172 Traning Loss: tensor(3.3489)\n",
      "7173 Traning Loss: tensor(3.3489)\n",
      "7174 Traning Loss: tensor(3.3489)\n",
      "7175 Traning Loss: tensor(3.3489)\n",
      "7176 Traning Loss: tensor(3.3489)\n",
      "7177 Traning Loss: tensor(3.3489)\n",
      "7178 Traning Loss: tensor(3.3489)\n",
      "7179 Traning Loss: tensor(3.3489)\n",
      "7180 Traning Loss: tensor(3.3489)\n",
      "7181 Traning Loss: tensor(3.3489)\n",
      "7182 Traning Loss: tensor(3.3489)\n",
      "7183 Traning Loss: tensor(3.3489)\n",
      "7184 Traning Loss: tensor(3.3489)\n",
      "7185 Traning Loss: tensor(3.3489)\n",
      "7186 Traning Loss: tensor(3.3489)\n",
      "7187 Traning Loss: tensor(3.3489)\n",
      "7188 Traning Loss: tensor(3.3489)\n",
      "7189 Traning Loss: tensor(3.3489)\n",
      "7190 Traning Loss: tensor(3.3489)\n",
      "7191 Traning Loss: tensor(3.3489)\n",
      "7192 Traning Loss: tensor(3.3489)\n",
      "7193 Traning Loss: tensor(3.3489)\n",
      "7194 Traning Loss: tensor(3.3489)\n",
      "7195 Traning Loss: tensor(3.3489)\n",
      "7196 Traning Loss: tensor(3.3489)\n",
      "7197 Traning Loss: tensor(3.3489)\n",
      "7198 Traning Loss: tensor(3.3489)\n",
      "7199 Traning Loss: tensor(3.3489)\n",
      "7200 Traning Loss: tensor(3.3489)\n",
      "7201 Traning Loss: tensor(3.3489)\n",
      "7202 Traning Loss: tensor(3.3489)\n",
      "7203 Traning Loss: tensor(3.3489)\n",
      "7204 Traning Loss: tensor(3.3489)\n",
      "7205 Traning Loss: tensor(3.3489)\n",
      "7206 Traning Loss: tensor(3.3489)\n",
      "7207 Traning Loss: tensor(3.3489)\n",
      "7208 Traning Loss: tensor(3.3489)\n",
      "7209 Traning Loss: tensor(3.3489)\n",
      "7210 Traning Loss: tensor(3.3489)\n",
      "7211 Traning Loss: tensor(3.3489)\n",
      "7212 Traning Loss: tensor(3.3489)\n",
      "7213 Traning Loss: tensor(3.3489)\n",
      "7214 Traning Loss: tensor(3.3489)\n",
      "7215 Traning Loss: tensor(3.3489)\n",
      "7216 Traning Loss: tensor(3.3489)\n",
      "7217 Traning Loss: tensor(3.3489)\n",
      "7218 Traning Loss: tensor(3.3489)\n",
      "7219 Traning Loss: tensor(3.3489)\n",
      "7220 Traning Loss: tensor(3.3489)\n",
      "7221 Traning Loss: tensor(3.3489)\n",
      "7222 Traning Loss: tensor(3.3489)\n",
      "7223 Traning Loss: tensor(3.3489)\n",
      "7224 Traning Loss: tensor(3.3489)\n",
      "7225 Traning Loss: tensor(3.3489)\n",
      "7226 Traning Loss: tensor(3.3489)\n",
      "7227 Traning Loss: tensor(3.3489)\n",
      "7228 Traning Loss: tensor(3.3489)\n",
      "7229 Traning Loss: tensor(3.3489)\n",
      "7230 Traning Loss: tensor(3.3489)\n",
      "7231 Traning Loss: tensor(3.3489)\n",
      "7232 Traning Loss: tensor(3.3489)\n",
      "7233 Traning Loss: tensor(3.3489)\n",
      "7234 Traning Loss: tensor(3.3489)\n",
      "7235 Traning Loss: tensor(3.3489)\n",
      "7236 Traning Loss: tensor(3.3489)\n",
      "7237 Traning Loss: tensor(3.3489)\n",
      "7238 Traning Loss: tensor(3.3489)\n",
      "7239 Traning Loss: tensor(3.3489)\n",
      "7240 Traning Loss: tensor(3.3489)\n",
      "7241 Traning Loss: tensor(3.3489)\n",
      "7242 Traning Loss: tensor(3.3489)\n",
      "7243 Traning Loss: tensor(3.3489)\n",
      "7244 Traning Loss: tensor(3.3489)\n",
      "7245 Traning Loss: tensor(3.3489)\n",
      "7246 Traning Loss: tensor(3.3489)\n",
      "7247 Traning Loss: tensor(3.3489)\n",
      "7248 Traning Loss: tensor(3.3489)\n",
      "7249 Traning Loss: tensor(3.3489)\n",
      "7250 Traning Loss: tensor(3.3489)\n",
      "7251 Traning Loss: tensor(3.3489)\n",
      "7252 Traning Loss: tensor(3.3489)\n",
      "7253 Traning Loss: tensor(3.3489)\n",
      "7254 Traning Loss: tensor(3.3489)\n",
      "7255 Traning Loss: tensor(3.3489)\n",
      "7256 Traning Loss: tensor(3.3489)\n",
      "7257 Traning Loss: tensor(3.3489)\n",
      "7258 Traning Loss: tensor(3.3489)\n",
      "7259 Traning Loss: tensor(3.3489)\n",
      "7260 Traning Loss: tensor(3.3489)\n",
      "7261 Traning Loss: tensor(3.3489)\n",
      "7262 Traning Loss: tensor(3.3489)\n",
      "7263 Traning Loss: tensor(3.3489)\n",
      "7264 Traning Loss: tensor(3.3489)\n",
      "7265 Traning Loss: tensor(3.3489)\n",
      "7266 Traning Loss: tensor(3.3489)\n",
      "7267 Traning Loss: tensor(3.3489)\n",
      "7268 Traning Loss: tensor(3.3489)\n",
      "7269 Traning Loss: tensor(3.3489)\n",
      "7270 Traning Loss: tensor(3.3489)\n",
      "7271 Traning Loss: tensor(3.3489)\n",
      "7272 Traning Loss: tensor(3.3489)\n",
      "7273 Traning Loss: tensor(3.3489)\n",
      "7274 Traning Loss: tensor(3.3489)\n",
      "7275 Traning Loss: tensor(3.3489)\n",
      "7276 Traning Loss: tensor(3.3489)\n",
      "7277 Traning Loss: tensor(3.3489)\n",
      "7278 Traning Loss: tensor(3.3489)\n",
      "7279 Traning Loss: tensor(3.3489)\n",
      "7280 Traning Loss: tensor(3.3489)\n",
      "7281 Traning Loss: tensor(3.3489)\n",
      "7282 Traning Loss: tensor(3.3489)\n",
      "7283 Traning Loss: tensor(3.3489)\n",
      "7284 Traning Loss: tensor(3.3489)\n",
      "7285 Traning Loss: tensor(3.3489)\n",
      "7286 Traning Loss: tensor(3.3489)\n",
      "7287 Traning Loss: tensor(3.3489)\n",
      "7288 Traning Loss: tensor(3.3489)\n",
      "7289 Traning Loss: tensor(3.3489)\n",
      "7290 Traning Loss: tensor(3.3489)\n",
      "7291 Traning Loss: tensor(3.3489)\n",
      "7292 Traning Loss: tensor(3.3489)\n",
      "7293 Traning Loss: tensor(3.3489)\n",
      "7294 Traning Loss: tensor(3.3489)\n",
      "7295 Traning Loss: tensor(3.3489)\n",
      "7296 Traning Loss: tensor(3.3489)\n",
      "7297 Traning Loss: tensor(3.3489)\n",
      "7298 Traning Loss: tensor(3.3489)\n",
      "7299 Traning Loss: tensor(3.3489)\n",
      "7300 Traning Loss: tensor(3.3489)\n",
      "7301 Traning Loss: tensor(3.3489)\n",
      "7302 Traning Loss: tensor(3.3489)\n",
      "7303 Traning Loss: tensor(3.3489)\n",
      "7304 Traning Loss: tensor(3.3489)\n",
      "7305 Traning Loss: tensor(3.3488)\n",
      "7306 Traning Loss: tensor(3.3488)\n",
      "7307 Traning Loss: tensor(3.3488)\n",
      "7308 Traning Loss: tensor(3.3488)\n",
      "7309 Traning Loss: tensor(3.3488)\n",
      "7310 Traning Loss: tensor(3.3488)\n",
      "7311 Traning Loss: tensor(3.3488)\n",
      "7312 Traning Loss: tensor(3.3488)\n",
      "7313 Traning Loss: tensor(3.3488)\n",
      "7314 Traning Loss: tensor(3.3488)\n",
      "7315 Traning Loss: tensor(3.3488)\n",
      "7316 Traning Loss: tensor(3.3488)\n",
      "7317 Traning Loss: tensor(3.3488)\n",
      "7318 Traning Loss: tensor(3.3488)\n",
      "7319 Traning Loss: tensor(3.3488)\n",
      "7320 Traning Loss: tensor(3.3488)\n",
      "7321 Traning Loss: tensor(3.3488)\n",
      "7322 Traning Loss: tensor(3.3488)\n",
      "7323 Traning Loss: tensor(3.3488)\n",
      "7324 Traning Loss: tensor(3.3488)\n",
      "7325 Traning Loss: tensor(3.3488)\n",
      "7326 Traning Loss: tensor(3.3488)\n",
      "7327 Traning Loss: tensor(3.3488)\n",
      "7328 Traning Loss: tensor(3.3488)\n",
      "7329 Traning Loss: tensor(3.3488)\n",
      "7330 Traning Loss: tensor(3.3488)\n",
      "7331 Traning Loss: tensor(3.3488)\n",
      "7332 Traning Loss: tensor(3.3488)\n",
      "7333 Traning Loss: tensor(3.3488)\n",
      "7334 Traning Loss: tensor(3.3488)\n",
      "7335 Traning Loss: tensor(3.3488)\n",
      "7336 Traning Loss: tensor(3.3488)\n",
      "7337 Traning Loss: tensor(3.3488)\n",
      "7338 Traning Loss: tensor(3.3488)\n",
      "7339 Traning Loss: tensor(3.3488)\n",
      "7340 Traning Loss: tensor(3.3488)\n",
      "7341 Traning Loss: tensor(3.3488)\n",
      "7342 Traning Loss: tensor(3.3488)\n",
      "7343 Traning Loss: tensor(3.3488)\n",
      "7344 Traning Loss: tensor(3.3488)\n",
      "7345 Traning Loss: tensor(3.3488)\n",
      "7346 Traning Loss: tensor(3.3488)\n",
      "7347 Traning Loss: tensor(3.3488)\n",
      "7348 Traning Loss: tensor(3.3488)\n",
      "7349 Traning Loss: tensor(3.3488)\n",
      "7350 Traning Loss: tensor(3.3488)\n",
      "7351 Traning Loss: tensor(3.3488)\n",
      "7352 Traning Loss: tensor(3.3488)\n",
      "7353 Traning Loss: tensor(3.3488)\n",
      "7354 Traning Loss: tensor(3.3488)\n",
      "7355 Traning Loss: tensor(3.3488)\n",
      "7356 Traning Loss: tensor(3.3488)\n",
      "7357 Traning Loss: tensor(3.3488)\n",
      "7358 Traning Loss: tensor(3.3488)\n",
      "7359 Traning Loss: tensor(3.3488)\n",
      "7360 Traning Loss: tensor(3.3488)\n",
      "7361 Traning Loss: tensor(3.3488)\n",
      "7362 Traning Loss: tensor(3.3488)\n",
      "7363 Traning Loss: tensor(3.3488)\n",
      "7364 Traning Loss: tensor(3.3488)\n",
      "7365 Traning Loss: tensor(3.3488)\n",
      "7366 Traning Loss: tensor(3.3488)\n",
      "7367 Traning Loss: tensor(3.3488)\n",
      "7368 Traning Loss: tensor(3.3488)\n",
      "7369 Traning Loss: tensor(3.3488)\n",
      "7370 Traning Loss: tensor(3.3488)\n",
      "7371 Traning Loss: tensor(3.3488)\n",
      "7372 Traning Loss: tensor(3.3488)\n",
      "7373 Traning Loss: tensor(3.3488)\n",
      "7374 Traning Loss: tensor(3.3488)\n",
      "7375 Traning Loss: tensor(3.3488)\n",
      "7376 Traning Loss: tensor(3.3488)\n",
      "7377 Traning Loss: tensor(3.3488)\n",
      "7378 Traning Loss: tensor(3.3488)\n",
      "7379 Traning Loss: tensor(3.3488)\n",
      "7380 Traning Loss: tensor(3.3488)\n",
      "7381 Traning Loss: tensor(3.3488)\n",
      "7382 Traning Loss: tensor(3.3488)\n",
      "7383 Traning Loss: tensor(3.3488)\n",
      "7384 Traning Loss: tensor(3.3488)\n",
      "7385 Traning Loss: tensor(3.3488)\n",
      "7386 Traning Loss: tensor(3.3488)\n",
      "7387 Traning Loss: tensor(3.3488)\n",
      "7388 Traning Loss: tensor(3.3488)\n",
      "7389 Traning Loss: tensor(3.3488)\n",
      "7390 Traning Loss: tensor(3.3488)\n",
      "7391 Traning Loss: tensor(3.3488)\n",
      "7392 Traning Loss: tensor(3.3488)\n",
      "7393 Traning Loss: tensor(3.3488)\n",
      "7394 Traning Loss: tensor(3.3488)\n",
      "7395 Traning Loss: tensor(3.3488)\n",
      "7396 Traning Loss: tensor(3.3488)\n",
      "7397 Traning Loss: tensor(3.3488)\n",
      "7398 Traning Loss: tensor(3.3488)\n",
      "7399 Traning Loss: tensor(3.3488)\n",
      "7400 Traning Loss: tensor(3.3488)\n",
      "7401 Traning Loss: tensor(3.3488)\n",
      "7402 Traning Loss: tensor(3.3488)\n",
      "7403 Traning Loss: tensor(3.3488)\n",
      "7404 Traning Loss: tensor(3.3488)\n",
      "7405 Traning Loss: tensor(3.3488)\n",
      "7406 Traning Loss: tensor(3.3488)\n",
      "7407 Traning Loss: tensor(3.3488)\n",
      "7408 Traning Loss: tensor(3.3488)\n",
      "7409 Traning Loss: tensor(3.3488)\n",
      "7410 Traning Loss: tensor(3.3488)\n",
      "7411 Traning Loss: tensor(3.3488)\n",
      "7412 Traning Loss: tensor(3.3488)\n",
      "7413 Traning Loss: tensor(3.3488)\n",
      "7414 Traning Loss: tensor(3.3488)\n",
      "7415 Traning Loss: tensor(3.3488)\n",
      "7416 Traning Loss: tensor(3.3488)\n",
      "7417 Traning Loss: tensor(3.3488)\n",
      "7418 Traning Loss: tensor(3.3488)\n",
      "7419 Traning Loss: tensor(3.3488)\n",
      "7420 Traning Loss: tensor(3.3488)\n",
      "7421 Traning Loss: tensor(3.3488)\n",
      "7422 Traning Loss: tensor(3.3488)\n",
      "7423 Traning Loss: tensor(3.3488)\n",
      "7424 Traning Loss: tensor(3.3488)\n",
      "7425 Traning Loss: tensor(3.3488)\n",
      "7426 Traning Loss: tensor(3.3488)\n",
      "7427 Traning Loss: tensor(3.3488)\n",
      "7428 Traning Loss: tensor(3.3488)\n",
      "7429 Traning Loss: tensor(3.3488)\n",
      "7430 Traning Loss: tensor(3.3488)\n",
      "7431 Traning Loss: tensor(3.3488)\n",
      "7432 Traning Loss: tensor(3.3488)\n",
      "7433 Traning Loss: tensor(3.3488)\n",
      "7434 Traning Loss: tensor(3.3488)\n",
      "7435 Traning Loss: tensor(3.3488)\n",
      "7436 Traning Loss: tensor(3.3488)\n",
      "7437 Traning Loss: tensor(3.3488)\n",
      "7438 Traning Loss: tensor(3.3488)\n",
      "7439 Traning Loss: tensor(3.3488)\n",
      "7440 Traning Loss: tensor(3.3488)\n",
      "7441 Traning Loss: tensor(3.3488)\n",
      "7442 Traning Loss: tensor(3.3488)\n",
      "7443 Traning Loss: tensor(3.3488)\n",
      "7444 Traning Loss: tensor(3.3488)\n",
      "7445 Traning Loss: tensor(3.3488)\n",
      "7446 Traning Loss: tensor(3.3488)\n",
      "7447 Traning Loss: tensor(3.3488)\n",
      "7448 Traning Loss: tensor(3.3488)\n",
      "7449 Traning Loss: tensor(3.3488)\n",
      "7450 Traning Loss: tensor(3.3488)\n",
      "7451 Traning Loss: tensor(3.3488)\n",
      "7452 Traning Loss: tensor(3.3488)\n",
      "7453 Traning Loss: tensor(3.3488)\n",
      "7454 Traning Loss: tensor(3.3488)\n",
      "7455 Traning Loss: tensor(3.3488)\n",
      "7456 Traning Loss: tensor(3.3488)\n",
      "7457 Traning Loss: tensor(3.3488)\n",
      "7458 Traning Loss: tensor(3.3488)\n",
      "7459 Traning Loss: tensor(3.3488)\n",
      "7460 Traning Loss: tensor(3.3488)\n",
      "7461 Traning Loss: tensor(3.3488)\n",
      "7462 Traning Loss: tensor(3.3488)\n",
      "7463 Traning Loss: tensor(3.3488)\n",
      "7464 Traning Loss: tensor(3.3488)\n",
      "7465 Traning Loss: tensor(3.3488)\n",
      "7466 Traning Loss: tensor(3.3488)\n",
      "7467 Traning Loss: tensor(3.3488)\n",
      "7468 Traning Loss: tensor(3.3488)\n",
      "7469 Traning Loss: tensor(3.3488)\n",
      "7470 Traning Loss: tensor(3.3488)\n",
      "7471 Traning Loss: tensor(3.3488)\n",
      "7472 Traning Loss: tensor(3.3488)\n",
      "7473 Traning Loss: tensor(3.3488)\n",
      "7474 Traning Loss: tensor(3.3488)\n",
      "7475 Traning Loss: tensor(3.3488)\n",
      "7476 Traning Loss: tensor(3.3488)\n",
      "7477 Traning Loss: tensor(3.3488)\n",
      "7478 Traning Loss: tensor(3.3488)\n",
      "7479 Traning Loss: tensor(3.3488)\n",
      "7480 Traning Loss: tensor(3.3488)\n",
      "7481 Traning Loss: tensor(3.3488)\n",
      "7482 Traning Loss: tensor(3.3488)\n",
      "7483 Traning Loss: tensor(3.3488)\n",
      "7484 Traning Loss: tensor(3.3488)\n",
      "7485 Traning Loss: tensor(3.3488)\n",
      "7486 Traning Loss: tensor(3.3488)\n",
      "7487 Traning Loss: tensor(3.3488)\n",
      "7488 Traning Loss: tensor(3.3488)\n",
      "7489 Traning Loss: tensor(3.3488)\n",
      "7490 Traning Loss: tensor(3.3488)\n",
      "7491 Traning Loss: tensor(3.3488)\n",
      "7492 Traning Loss: tensor(3.3488)\n",
      "7493 Traning Loss: tensor(3.3488)\n",
      "7494 Traning Loss: tensor(3.3488)\n",
      "7495 Traning Loss: tensor(3.3488)\n",
      "7496 Traning Loss: tensor(3.3488)\n",
      "7497 Traning Loss: tensor(3.3488)\n",
      "7498 Traning Loss: tensor(3.3488)\n",
      "7499 Traning Loss: tensor(3.3488)\n",
      "7500 Traning Loss: tensor(3.3488)\n",
      "7501 Traning Loss: tensor(3.3488)\n",
      "7502 Traning Loss: tensor(3.3488)\n",
      "7503 Traning Loss: tensor(3.3488)\n",
      "7504 Traning Loss: tensor(3.3488)\n",
      "7505 Traning Loss: tensor(3.3488)\n",
      "7506 Traning Loss: tensor(3.3488)\n",
      "7507 Traning Loss: tensor(3.3488)\n",
      "7508 Traning Loss: tensor(3.3488)\n",
      "7509 Traning Loss: tensor(3.3488)\n",
      "7510 Traning Loss: tensor(3.3488)\n",
      "7511 Traning Loss: tensor(3.3488)\n",
      "7512 Traning Loss: tensor(3.3488)\n",
      "7513 Traning Loss: tensor(3.3488)\n",
      "7514 Traning Loss: tensor(3.3488)\n",
      "7515 Traning Loss: tensor(3.3488)\n",
      "7516 Traning Loss: tensor(3.3488)\n",
      "7517 Traning Loss: tensor(3.3488)\n",
      "7518 Traning Loss: tensor(3.3488)\n",
      "7519 Traning Loss: tensor(3.3488)\n",
      "7520 Traning Loss: tensor(3.3488)\n",
      "7521 Traning Loss: tensor(3.3488)\n",
      "7522 Traning Loss: tensor(3.3488)\n",
      "7523 Traning Loss: tensor(3.3488)\n",
      "7524 Traning Loss: tensor(3.3488)\n",
      "7525 Traning Loss: tensor(3.3488)\n",
      "7526 Traning Loss: tensor(3.3488)\n",
      "7527 Traning Loss: tensor(3.3488)\n",
      "7528 Traning Loss: tensor(3.3488)\n",
      "7529 Traning Loss: tensor(3.3488)\n",
      "7530 Traning Loss: tensor(3.3488)\n",
      "7531 Traning Loss: tensor(3.3488)\n",
      "7532 Traning Loss: tensor(3.3488)\n",
      "7533 Traning Loss: tensor(3.3488)\n",
      "7534 Traning Loss: tensor(3.3488)\n",
      "7535 Traning Loss: tensor(3.3488)\n",
      "7536 Traning Loss: tensor(3.3488)\n",
      "7537 Traning Loss: tensor(3.3488)\n",
      "7538 Traning Loss: tensor(3.3488)\n",
      "7539 Traning Loss: tensor(3.3488)\n",
      "7540 Traning Loss: tensor(3.3488)\n",
      "7541 Traning Loss: tensor(3.3488)\n",
      "7542 Traning Loss: tensor(3.3488)\n",
      "7543 Traning Loss: tensor(3.3488)\n",
      "7544 Traning Loss: tensor(3.3488)\n",
      "7545 Traning Loss: tensor(3.3488)\n",
      "7546 Traning Loss: tensor(3.3488)\n",
      "7547 Traning Loss: tensor(3.3488)\n",
      "7548 Traning Loss: tensor(3.3488)\n",
      "7549 Traning Loss: tensor(3.3488)\n",
      "7550 Traning Loss: tensor(3.3488)\n",
      "7551 Traning Loss: tensor(3.3488)\n",
      "7552 Traning Loss: tensor(3.3488)\n",
      "7553 Traning Loss: tensor(3.3488)\n",
      "7554 Traning Loss: tensor(3.3488)\n",
      "7555 Traning Loss: tensor(3.3488)\n",
      "7556 Traning Loss: tensor(3.3488)\n",
      "7557 Traning Loss: tensor(3.3488)\n",
      "7558 Traning Loss: tensor(3.3488)\n",
      "7559 Traning Loss: tensor(3.3488)\n",
      "7560 Traning Loss: tensor(3.3488)\n",
      "7561 Traning Loss: tensor(3.3488)\n",
      "7562 Traning Loss: tensor(3.3488)\n",
      "7563 Traning Loss: tensor(3.3488)\n",
      "7564 Traning Loss: tensor(3.3488)\n",
      "7565 Traning Loss: tensor(3.3488)\n",
      "7566 Traning Loss: tensor(3.3488)\n",
      "7567 Traning Loss: tensor(3.3488)\n",
      "7568 Traning Loss: tensor(3.3488)\n",
      "7569 Traning Loss: tensor(3.3488)\n",
      "7570 Traning Loss: tensor(3.3488)\n",
      "7571 Traning Loss: tensor(3.3488)\n",
      "7572 Traning Loss: tensor(3.3488)\n",
      "7573 Traning Loss: tensor(3.3488)\n",
      "7574 Traning Loss: tensor(3.3488)\n",
      "7575 Traning Loss: tensor(3.3488)\n",
      "7576 Traning Loss: tensor(3.3488)\n",
      "7577 Traning Loss: tensor(3.3488)\n",
      "7578 Traning Loss: tensor(3.3488)\n",
      "7579 Traning Loss: tensor(3.3488)\n",
      "7580 Traning Loss: tensor(3.3488)\n",
      "7581 Traning Loss: tensor(3.3488)\n",
      "7582 Traning Loss: tensor(3.3488)\n",
      "7583 Traning Loss: tensor(3.3488)\n",
      "7584 Traning Loss: tensor(3.3488)\n",
      "7585 Traning Loss: tensor(3.3488)\n",
      "7586 Traning Loss: tensor(3.3488)\n",
      "7587 Traning Loss: tensor(3.3488)\n",
      "7588 Traning Loss: tensor(3.3488)\n",
      "7589 Traning Loss: tensor(3.3488)\n",
      "7590 Traning Loss: tensor(3.3488)\n",
      "7591 Traning Loss: tensor(3.3488)\n",
      "7592 Traning Loss: tensor(3.3488)\n",
      "7593 Traning Loss: tensor(3.3488)\n",
      "7594 Traning Loss: tensor(3.3488)\n",
      "7595 Traning Loss: tensor(3.3488)\n",
      "7596 Traning Loss: tensor(3.3488)\n",
      "7597 Traning Loss: tensor(3.3488)\n",
      "7598 Traning Loss: tensor(3.3487)\n",
      "7599 Traning Loss: tensor(3.3487)\n",
      "7600 Traning Loss: tensor(3.3487)\n",
      "7601 Traning Loss: tensor(3.3487)\n",
      "7602 Traning Loss: tensor(3.3487)\n",
      "7603 Traning Loss: tensor(3.3487)\n",
      "7604 Traning Loss: tensor(3.3487)\n",
      "7605 Traning Loss: tensor(3.3487)\n",
      "7606 Traning Loss: tensor(3.3487)\n",
      "7607 Traning Loss: tensor(3.3487)\n",
      "7608 Traning Loss: tensor(3.3487)\n",
      "7609 Traning Loss: tensor(3.3487)\n",
      "7610 Traning Loss: tensor(3.3487)\n",
      "7611 Traning Loss: tensor(3.3487)\n",
      "7612 Traning Loss: tensor(3.3487)\n",
      "7613 Traning Loss: tensor(3.3487)\n",
      "7614 Traning Loss: tensor(3.3487)\n",
      "7615 Traning Loss: tensor(3.3487)\n",
      "7616 Traning Loss: tensor(3.3487)\n",
      "7617 Traning Loss: tensor(3.3487)\n",
      "7618 Traning Loss: tensor(3.3487)\n",
      "7619 Traning Loss: tensor(3.3487)\n",
      "7620 Traning Loss: tensor(3.3487)\n",
      "7621 Traning Loss: tensor(3.3487)\n",
      "7622 Traning Loss: tensor(3.3487)\n",
      "7623 Traning Loss: tensor(3.3487)\n",
      "7624 Traning Loss: tensor(3.3487)\n",
      "7625 Traning Loss: tensor(3.3487)\n",
      "7626 Traning Loss: tensor(3.3487)\n",
      "7627 Traning Loss: tensor(3.3487)\n",
      "7628 Traning Loss: tensor(3.3487)\n",
      "7629 Traning Loss: tensor(3.3487)\n",
      "7630 Traning Loss: tensor(3.3487)\n",
      "7631 Traning Loss: tensor(3.3487)\n",
      "7632 Traning Loss: tensor(3.3487)\n",
      "7633 Traning Loss: tensor(3.3487)\n",
      "7634 Traning Loss: tensor(3.3487)\n",
      "7635 Traning Loss: tensor(3.3487)\n",
      "7636 Traning Loss: tensor(3.3487)\n",
      "7637 Traning Loss: tensor(3.3487)\n",
      "7638 Traning Loss: tensor(3.3487)\n",
      "7639 Traning Loss: tensor(3.3487)\n",
      "7640 Traning Loss: tensor(3.3487)\n",
      "7641 Traning Loss: tensor(3.3487)\n",
      "7642 Traning Loss: tensor(3.3487)\n",
      "7643 Traning Loss: tensor(3.3487)\n",
      "7644 Traning Loss: tensor(3.3487)\n",
      "7645 Traning Loss: tensor(3.3487)\n",
      "7646 Traning Loss: tensor(3.3487)\n",
      "7647 Traning Loss: tensor(3.3487)\n",
      "7648 Traning Loss: tensor(3.3487)\n",
      "7649 Traning Loss: tensor(3.3487)\n",
      "7650 Traning Loss: tensor(3.3487)\n",
      "7651 Traning Loss: tensor(3.3487)\n",
      "7652 Traning Loss: tensor(3.3487)\n",
      "7653 Traning Loss: tensor(3.3487)\n",
      "7654 Traning Loss: tensor(3.3487)\n",
      "7655 Traning Loss: tensor(3.3487)\n",
      "7656 Traning Loss: tensor(3.3487)\n",
      "7657 Traning Loss: tensor(3.3487)\n",
      "7658 Traning Loss: tensor(3.3487)\n",
      "7659 Traning Loss: tensor(3.3487)\n",
      "7660 Traning Loss: tensor(3.3487)\n",
      "7661 Traning Loss: tensor(3.3487)\n",
      "7662 Traning Loss: tensor(3.3487)\n",
      "7663 Traning Loss: tensor(3.3487)\n",
      "7664 Traning Loss: tensor(3.3487)\n",
      "7665 Traning Loss: tensor(3.3487)\n",
      "7666 Traning Loss: tensor(3.3487)\n",
      "7667 Traning Loss: tensor(3.3487)\n",
      "7668 Traning Loss: tensor(3.3487)\n",
      "7669 Traning Loss: tensor(3.3487)\n",
      "7670 Traning Loss: tensor(3.3487)\n",
      "7671 Traning Loss: tensor(3.3487)\n",
      "7672 Traning Loss: tensor(3.3487)\n",
      "7673 Traning Loss: tensor(3.3487)\n",
      "7674 Traning Loss: tensor(3.3487)\n",
      "7675 Traning Loss: tensor(3.3487)\n",
      "7676 Traning Loss: tensor(3.3487)\n",
      "7677 Traning Loss: tensor(3.3487)\n",
      "7678 Traning Loss: tensor(3.3487)\n",
      "7679 Traning Loss: tensor(3.3487)\n",
      "7680 Traning Loss: tensor(3.3487)\n",
      "7681 Traning Loss: tensor(3.3487)\n",
      "7682 Traning Loss: tensor(3.3487)\n",
      "7683 Traning Loss: tensor(3.3487)\n",
      "7684 Traning Loss: tensor(3.3487)\n",
      "7685 Traning Loss: tensor(3.3487)\n",
      "7686 Traning Loss: tensor(3.3487)\n",
      "7687 Traning Loss: tensor(3.3487)\n",
      "7688 Traning Loss: tensor(3.3487)\n",
      "7689 Traning Loss: tensor(3.3487)\n",
      "7690 Traning Loss: tensor(3.3487)\n",
      "7691 Traning Loss: tensor(3.3487)\n",
      "7692 Traning Loss: tensor(3.3487)\n",
      "7693 Traning Loss: tensor(3.3487)\n",
      "7694 Traning Loss: tensor(3.3487)\n",
      "7695 Traning Loss: tensor(3.3487)\n",
      "7696 Traning Loss: tensor(3.3487)\n",
      "7697 Traning Loss: tensor(3.3487)\n",
      "7698 Traning Loss: tensor(3.3487)\n",
      "7699 Traning Loss: tensor(3.3487)\n",
      "7700 Traning Loss: tensor(3.3487)\n",
      "7701 Traning Loss: tensor(3.3487)\n",
      "7702 Traning Loss: tensor(3.3487)\n",
      "7703 Traning Loss: tensor(3.3487)\n",
      "7704 Traning Loss: tensor(3.3487)\n",
      "7705 Traning Loss: tensor(3.3487)\n",
      "7706 Traning Loss: tensor(3.3487)\n",
      "7707 Traning Loss: tensor(3.3487)\n",
      "7708 Traning Loss: tensor(3.3487)\n",
      "7709 Traning Loss: tensor(3.3487)\n",
      "7710 Traning Loss: tensor(3.3487)\n",
      "7711 Traning Loss: tensor(3.3487)\n",
      "7712 Traning Loss: tensor(3.3487)\n",
      "7713 Traning Loss: tensor(3.3486)\n",
      "7714 Traning Loss: tensor(3.3486)\n",
      "7715 Traning Loss: tensor(3.3486)\n",
      "7716 Traning Loss: tensor(3.3486)\n",
      "7717 Traning Loss: tensor(3.3486)\n",
      "7718 Traning Loss: tensor(3.3486)\n",
      "7719 Traning Loss: tensor(3.3486)\n",
      "7720 Traning Loss: tensor(3.3486)\n",
      "7721 Traning Loss: tensor(3.3486)\n",
      "7722 Traning Loss: tensor(3.3486)\n",
      "7723 Traning Loss: tensor(3.3486)\n",
      "7724 Traning Loss: tensor(3.3486)\n",
      "7725 Traning Loss: tensor(3.3486)\n",
      "7726 Traning Loss: tensor(3.3486)\n",
      "7727 Traning Loss: tensor(3.3486)\n",
      "7728 Traning Loss: tensor(3.3486)\n",
      "7729 Traning Loss: tensor(3.3486)\n",
      "7730 Traning Loss: tensor(3.3486)\n",
      "7731 Traning Loss: tensor(3.3486)\n",
      "7732 Traning Loss: tensor(3.3486)\n",
      "7733 Traning Loss: tensor(3.3486)\n",
      "7734 Traning Loss: tensor(3.3486)\n",
      "7735 Traning Loss: tensor(3.3486)\n",
      "7736 Traning Loss: tensor(3.3486)\n",
      "7737 Traning Loss: tensor(3.3486)\n",
      "7738 Traning Loss: tensor(3.3486)\n",
      "7739 Traning Loss: tensor(3.3486)\n",
      "7740 Traning Loss: tensor(3.3486)\n",
      "7741 Traning Loss: tensor(3.3486)\n",
      "7742 Traning Loss: tensor(3.3486)\n",
      "7743 Traning Loss: tensor(3.3486)\n",
      "7744 Traning Loss: tensor(3.3486)\n",
      "7745 Traning Loss: tensor(3.3486)\n",
      "7746 Traning Loss: tensor(3.3486)\n",
      "7747 Traning Loss: tensor(3.3486)\n",
      "7748 Traning Loss: tensor(3.3486)\n",
      "7749 Traning Loss: tensor(3.3486)\n",
      "7750 Traning Loss: tensor(3.3486)\n",
      "7751 Traning Loss: tensor(3.3486)\n",
      "7752 Traning Loss: tensor(3.3486)\n",
      "7753 Traning Loss: tensor(3.3486)\n",
      "7754 Traning Loss: tensor(3.3486)\n",
      "7755 Traning Loss: tensor(3.3486)\n",
      "7756 Traning Loss: tensor(3.3486)\n",
      "7757 Traning Loss: tensor(3.3486)\n",
      "7758 Traning Loss: tensor(3.3486)\n",
      "7759 Traning Loss: tensor(3.3486)\n",
      "7760 Traning Loss: tensor(3.3486)\n",
      "7761 Traning Loss: tensor(3.3486)\n",
      "7762 Traning Loss: tensor(3.3486)\n",
      "7763 Traning Loss: tensor(3.3486)\n",
      "7764 Traning Loss: tensor(3.3486)\n",
      "7765 Traning Loss: tensor(3.3486)\n",
      "7766 Traning Loss: tensor(3.3486)\n",
      "7767 Traning Loss: tensor(3.3486)\n",
      "7768 Traning Loss: tensor(3.3486)\n",
      "7769 Traning Loss: tensor(3.3486)\n",
      "7770 Traning Loss: tensor(3.3486)\n",
      "7771 Traning Loss: tensor(3.3486)\n",
      "7772 Traning Loss: tensor(3.3486)\n",
      "7773 Traning Loss: tensor(3.3486)\n",
      "7774 Traning Loss: tensor(3.3486)\n",
      "7775 Traning Loss: tensor(3.3486)\n",
      "7776 Traning Loss: tensor(3.3486)\n",
      "7777 Traning Loss: tensor(3.3486)\n",
      "7778 Traning Loss: tensor(3.3486)\n",
      "7779 Traning Loss: tensor(3.3485)\n",
      "7780 Traning Loss: tensor(3.3485)\n",
      "7781 Traning Loss: tensor(3.3485)\n",
      "7782 Traning Loss: tensor(3.3485)\n",
      "7783 Traning Loss: tensor(3.3485)\n",
      "7784 Traning Loss: tensor(3.3485)\n",
      "7785 Traning Loss: tensor(3.3485)\n",
      "7786 Traning Loss: tensor(3.3485)\n",
      "7787 Traning Loss: tensor(3.3485)\n",
      "7788 Traning Loss: tensor(3.3485)\n",
      "7789 Traning Loss: tensor(3.3485)\n",
      "7790 Traning Loss: tensor(3.3485)\n",
      "7791 Traning Loss: tensor(3.3485)\n",
      "7792 Traning Loss: tensor(3.3485)\n",
      "7793 Traning Loss: tensor(3.3485)\n",
      "7794 Traning Loss: tensor(3.3485)\n",
      "7795 Traning Loss: tensor(3.3485)\n",
      "7796 Traning Loss: tensor(3.3485)\n",
      "7797 Traning Loss: tensor(3.3485)\n",
      "7798 Traning Loss: tensor(3.3485)\n",
      "7799 Traning Loss: tensor(3.3485)\n",
      "7800 Traning Loss: tensor(3.3485)\n",
      "7801 Traning Loss: tensor(3.3485)\n",
      "7802 Traning Loss: tensor(3.3485)\n",
      "7803 Traning Loss: tensor(3.3485)\n",
      "7804 Traning Loss: tensor(3.3485)\n",
      "7805 Traning Loss: tensor(3.3485)\n",
      "7806 Traning Loss: tensor(3.3485)\n",
      "7807 Traning Loss: tensor(3.3485)\n",
      "7808 Traning Loss: tensor(3.3485)\n",
      "7809 Traning Loss: tensor(3.3485)\n",
      "7810 Traning Loss: tensor(3.3485)\n",
      "7811 Traning Loss: tensor(3.3485)\n",
      "7812 Traning Loss: tensor(3.3485)\n",
      "7813 Traning Loss: tensor(3.3485)\n",
      "7814 Traning Loss: tensor(3.3485)\n",
      "7815 Traning Loss: tensor(3.3485)\n",
      "7816 Traning Loss: tensor(3.3485)\n",
      "7817 Traning Loss: tensor(3.3485)\n",
      "7818 Traning Loss: tensor(3.3485)\n",
      "7819 Traning Loss: tensor(3.3485)\n",
      "7820 Traning Loss: tensor(3.3485)\n",
      "7821 Traning Loss: tensor(3.3484)\n",
      "7822 Traning Loss: tensor(3.3484)\n",
      "7823 Traning Loss: tensor(3.3484)\n",
      "7824 Traning Loss: tensor(3.3484)\n",
      "7825 Traning Loss: tensor(3.3484)\n",
      "7826 Traning Loss: tensor(3.3484)\n",
      "7827 Traning Loss: tensor(3.3484)\n",
      "7828 Traning Loss: tensor(3.3484)\n",
      "7829 Traning Loss: tensor(3.3484)\n",
      "7830 Traning Loss: tensor(3.3484)\n",
      "7831 Traning Loss: tensor(3.3484)\n",
      "7832 Traning Loss: tensor(3.3484)\n",
      "7833 Traning Loss: tensor(3.3484)\n",
      "7834 Traning Loss: tensor(3.3484)\n",
      "7835 Traning Loss: tensor(3.3484)\n",
      "7836 Traning Loss: tensor(3.3484)\n",
      "7837 Traning Loss: tensor(3.3484)\n",
      "7838 Traning Loss: tensor(3.3484)\n",
      "7839 Traning Loss: tensor(3.3484)\n",
      "7840 Traning Loss: tensor(3.3484)\n",
      "7841 Traning Loss: tensor(3.3484)\n",
      "7842 Traning Loss: tensor(3.3484)\n",
      "7843 Traning Loss: tensor(3.3484)\n",
      "7844 Traning Loss: tensor(3.3484)\n",
      "7845 Traning Loss: tensor(3.3484)\n",
      "7846 Traning Loss: tensor(3.3484)\n",
      "7847 Traning Loss: tensor(3.3484)\n",
      "7848 Traning Loss: tensor(3.3484)\n",
      "7849 Traning Loss: tensor(3.3484)\n",
      "7850 Traning Loss: tensor(3.3484)\n",
      "7851 Traning Loss: tensor(3.3484)\n",
      "7852 Traning Loss: tensor(3.3484)\n",
      "7853 Traning Loss: tensor(3.3483)\n",
      "7854 Traning Loss: tensor(3.3483)\n",
      "7855 Traning Loss: tensor(3.3483)\n",
      "7856 Traning Loss: tensor(3.3483)\n",
      "7857 Traning Loss: tensor(3.3483)\n",
      "7858 Traning Loss: tensor(3.3483)\n",
      "7859 Traning Loss: tensor(3.3483)\n",
      "7860 Traning Loss: tensor(3.3483)\n",
      "7861 Traning Loss: tensor(3.3483)\n",
      "7862 Traning Loss: tensor(3.3483)\n",
      "7863 Traning Loss: tensor(3.3483)\n",
      "7864 Traning Loss: tensor(3.3483)\n",
      "7865 Traning Loss: tensor(3.3483)\n",
      "7866 Traning Loss: tensor(3.3483)\n",
      "7867 Traning Loss: tensor(3.3483)\n",
      "7868 Traning Loss: tensor(3.3483)\n",
      "7869 Traning Loss: tensor(3.3483)\n",
      "7870 Traning Loss: tensor(3.3483)\n",
      "7871 Traning Loss: tensor(3.3483)\n",
      "7872 Traning Loss: tensor(3.3483)\n",
      "7873 Traning Loss: tensor(3.3483)\n",
      "7874 Traning Loss: tensor(3.3483)\n",
      "7875 Traning Loss: tensor(3.3483)\n",
      "7876 Traning Loss: tensor(3.3483)\n",
      "7877 Traning Loss: tensor(3.3483)\n",
      "7878 Traning Loss: tensor(3.3482)\n",
      "7879 Traning Loss: tensor(3.3482)\n",
      "7880 Traning Loss: tensor(3.3482)\n",
      "7881 Traning Loss: tensor(3.3482)\n",
      "7882 Traning Loss: tensor(3.3482)\n",
      "7883 Traning Loss: tensor(3.3482)\n",
      "7884 Traning Loss: tensor(3.3482)\n",
      "7885 Traning Loss: tensor(3.3482)\n",
      "7886 Traning Loss: tensor(3.3482)\n",
      "7887 Traning Loss: tensor(3.3482)\n",
      "7888 Traning Loss: tensor(3.3482)\n",
      "7889 Traning Loss: tensor(3.3482)\n",
      "7890 Traning Loss: tensor(3.3482)\n",
      "7891 Traning Loss: tensor(3.3482)\n",
      "7892 Traning Loss: tensor(3.3482)\n",
      "7893 Traning Loss: tensor(3.3482)\n",
      "7894 Traning Loss: tensor(3.3482)\n",
      "7895 Traning Loss: tensor(3.3482)\n",
      "7896 Traning Loss: tensor(3.3482)\n",
      "7897 Traning Loss: tensor(3.3482)\n",
      "7898 Traning Loss: tensor(3.3481)\n",
      "7899 Traning Loss: tensor(3.3481)\n",
      "7900 Traning Loss: tensor(3.3481)\n",
      "7901 Traning Loss: tensor(3.3481)\n",
      "7902 Traning Loss: tensor(3.3481)\n",
      "7903 Traning Loss: tensor(3.3481)\n",
      "7904 Traning Loss: tensor(3.3481)\n",
      "7905 Traning Loss: tensor(3.3481)\n",
      "7906 Traning Loss: tensor(3.3481)\n",
      "7907 Traning Loss: tensor(3.3481)\n",
      "7908 Traning Loss: tensor(3.3481)\n",
      "7909 Traning Loss: tensor(3.3481)\n",
      "7910 Traning Loss: tensor(3.3481)\n",
      "7911 Traning Loss: tensor(3.3481)\n",
      "7912 Traning Loss: tensor(3.3481)\n",
      "7913 Traning Loss: tensor(3.3481)\n",
      "7914 Traning Loss: tensor(3.3480)\n",
      "7915 Traning Loss: tensor(3.3480)\n",
      "7916 Traning Loss: tensor(3.3480)\n",
      "7917 Traning Loss: tensor(3.3480)\n",
      "7918 Traning Loss: tensor(3.3480)\n",
      "7919 Traning Loss: tensor(3.3480)\n",
      "7920 Traning Loss: tensor(3.3480)\n",
      "7921 Traning Loss: tensor(3.3480)\n",
      "7922 Traning Loss: tensor(3.3480)\n",
      "7923 Traning Loss: tensor(3.3480)\n",
      "7924 Traning Loss: tensor(3.3480)\n",
      "7925 Traning Loss: tensor(3.3480)\n",
      "7926 Traning Loss: tensor(3.3480)\n",
      "7927 Traning Loss: tensor(3.3480)\n",
      "7928 Traning Loss: tensor(3.3480)\n",
      "7929 Traning Loss: tensor(3.3479)\n",
      "7930 Traning Loss: tensor(3.3479)\n",
      "7931 Traning Loss: tensor(3.3479)\n",
      "7932 Traning Loss: tensor(3.3479)\n",
      "7933 Traning Loss: tensor(3.3479)\n",
      "7934 Traning Loss: tensor(3.3479)\n",
      "7935 Traning Loss: tensor(3.3479)\n",
      "7936 Traning Loss: tensor(3.3479)\n",
      "7937 Traning Loss: tensor(3.3479)\n",
      "7938 Traning Loss: tensor(3.3479)\n",
      "7939 Traning Loss: tensor(3.3479)\n",
      "7940 Traning Loss: tensor(3.3479)\n",
      "7941 Traning Loss: tensor(3.3479)\n",
      "7942 Traning Loss: tensor(3.3478)\n",
      "7943 Traning Loss: tensor(3.3478)\n",
      "7944 Traning Loss: tensor(3.3478)\n",
      "7945 Traning Loss: tensor(3.3478)\n",
      "7946 Traning Loss: tensor(3.3478)\n",
      "7947 Traning Loss: tensor(3.3478)\n",
      "7948 Traning Loss: tensor(3.3478)\n",
      "7949 Traning Loss: tensor(3.3478)\n",
      "7950 Traning Loss: tensor(3.3478)\n",
      "7951 Traning Loss: tensor(3.3478)\n",
      "7952 Traning Loss: tensor(3.3478)\n",
      "7953 Traning Loss: tensor(3.3477)\n",
      "7954 Traning Loss: tensor(3.3477)\n",
      "7955 Traning Loss: tensor(3.3477)\n",
      "7956 Traning Loss: tensor(3.3477)\n",
      "7957 Traning Loss: tensor(3.3477)\n",
      "7958 Traning Loss: tensor(3.3477)\n",
      "7959 Traning Loss: tensor(3.3477)\n",
      "7960 Traning Loss: tensor(3.3477)\n",
      "7961 Traning Loss: tensor(3.3477)\n",
      "7962 Traning Loss: tensor(3.3477)\n",
      "7963 Traning Loss: tensor(3.3476)\n",
      "7964 Traning Loss: tensor(3.3476)\n",
      "7965 Traning Loss: tensor(3.3476)\n",
      "7966 Traning Loss: tensor(3.3476)\n",
      "7967 Traning Loss: tensor(3.3476)\n",
      "7968 Traning Loss: tensor(3.3476)\n",
      "7969 Traning Loss: tensor(3.3476)\n",
      "7970 Traning Loss: tensor(3.3476)\n",
      "7971 Traning Loss: tensor(3.3476)\n",
      "7972 Traning Loss: tensor(3.3476)\n",
      "7973 Traning Loss: tensor(3.3475)\n",
      "7974 Traning Loss: tensor(3.3475)\n",
      "7975 Traning Loss: tensor(3.3475)\n",
      "7976 Traning Loss: tensor(3.3475)\n",
      "7977 Traning Loss: tensor(3.3475)\n",
      "7978 Traning Loss: tensor(3.3475)\n",
      "7979 Traning Loss: tensor(3.3475)\n",
      "7980 Traning Loss: tensor(3.3475)\n",
      "7981 Traning Loss: tensor(3.3475)\n",
      "7982 Traning Loss: tensor(3.3474)\n",
      "7983 Traning Loss: tensor(3.3474)\n",
      "7984 Traning Loss: tensor(3.3474)\n",
      "7985 Traning Loss: tensor(3.3474)\n",
      "7986 Traning Loss: tensor(3.3474)\n",
      "7987 Traning Loss: tensor(3.3474)\n",
      "7988 Traning Loss: tensor(3.3474)\n",
      "7989 Traning Loss: tensor(3.3473)\n",
      "7990 Traning Loss: tensor(3.3473)\n",
      "7991 Traning Loss: tensor(3.3473)\n",
      "7992 Traning Loss: tensor(3.3473)\n",
      "7993 Traning Loss: tensor(3.3473)\n",
      "7994 Traning Loss: tensor(3.3473)\n",
      "7995 Traning Loss: tensor(3.3473)\n",
      "7996 Traning Loss: tensor(3.3473)\n",
      "7997 Traning Loss: tensor(3.3472)\n",
      "7998 Traning Loss: tensor(3.3472)\n",
      "7999 Traning Loss: tensor(3.3472)\n",
      "8000 Traning Loss: tensor(3.3472)\n",
      "8001 Traning Loss: tensor(3.3472)\n",
      "8002 Traning Loss: tensor(3.3472)\n",
      "8003 Traning Loss: tensor(3.3471)\n",
      "8004 Traning Loss: tensor(3.3471)\n",
      "8005 Traning Loss: tensor(3.3471)\n",
      "8006 Traning Loss: tensor(3.3471)\n",
      "8007 Traning Loss: tensor(3.3471)\n",
      "8008 Traning Loss: tensor(3.3471)\n",
      "8009 Traning Loss: tensor(3.3471)\n",
      "8010 Traning Loss: tensor(3.3470)\n",
      "8011 Traning Loss: tensor(3.3470)\n",
      "8012 Traning Loss: tensor(3.3470)\n",
      "8013 Traning Loss: tensor(3.3470)\n",
      "8014 Traning Loss: tensor(3.3470)\n",
      "8015 Traning Loss: tensor(3.3470)\n",
      "8016 Traning Loss: tensor(3.3470)\n",
      "8017 Traning Loss: tensor(3.3469)\n",
      "8018 Traning Loss: tensor(3.3469)\n",
      "8019 Traning Loss: tensor(3.3469)\n",
      "8020 Traning Loss: tensor(3.3469)\n",
      "8021 Traning Loss: tensor(3.3469)\n",
      "8022 Traning Loss: tensor(3.3469)\n",
      "8023 Traning Loss: tensor(3.3468)\n",
      "8024 Traning Loss: tensor(3.3468)\n",
      "8025 Traning Loss: tensor(3.3468)\n",
      "8026 Traning Loss: tensor(3.3468)\n",
      "8027 Traning Loss: tensor(3.3468)\n",
      "8028 Traning Loss: tensor(3.3467)\n",
      "8029 Traning Loss: tensor(3.3467)\n",
      "8030 Traning Loss: tensor(3.3467)\n",
      "8031 Traning Loss: tensor(3.3467)\n",
      "8032 Traning Loss: tensor(3.3467)\n",
      "8033 Traning Loss: tensor(3.3466)\n",
      "8034 Traning Loss: tensor(3.3466)\n",
      "8035 Traning Loss: tensor(3.3466)\n",
      "8036 Traning Loss: tensor(3.3466)\n",
      "8037 Traning Loss: tensor(3.3466)\n",
      "8038 Traning Loss: tensor(3.3465)\n",
      "8039 Traning Loss: tensor(3.3465)\n",
      "8040 Traning Loss: tensor(3.3465)\n",
      "8041 Traning Loss: tensor(3.3465)\n",
      "8042 Traning Loss: tensor(3.3465)\n",
      "8043 Traning Loss: tensor(3.3464)\n",
      "8044 Traning Loss: tensor(3.3464)\n",
      "8045 Traning Loss: tensor(3.3464)\n",
      "8046 Traning Loss: tensor(3.3464)\n",
      "8047 Traning Loss: tensor(3.3464)\n",
      "8048 Traning Loss: tensor(3.3464)\n",
      "8049 Traning Loss: tensor(3.3463)\n",
      "8050 Traning Loss: tensor(3.3463)\n",
      "8051 Traning Loss: tensor(3.3463)\n",
      "8052 Traning Loss: tensor(3.3463)\n",
      "8053 Traning Loss: tensor(3.3462)\n",
      "8054 Traning Loss: tensor(3.3462)\n",
      "8055 Traning Loss: tensor(3.3462)\n",
      "8056 Traning Loss: tensor(3.3462)\n",
      "8057 Traning Loss: tensor(3.3462)\n",
      "8058 Traning Loss: tensor(3.3461)\n",
      "8059 Traning Loss: tensor(3.3461)\n",
      "8060 Traning Loss: tensor(3.3461)\n",
      "8061 Traning Loss: tensor(3.3460)\n",
      "8062 Traning Loss: tensor(3.3460)\n",
      "8063 Traning Loss: tensor(3.3460)\n",
      "8064 Traning Loss: tensor(3.3460)\n",
      "8065 Traning Loss: tensor(3.3460)\n",
      "8066 Traning Loss: tensor(3.3459)\n",
      "8067 Traning Loss: tensor(3.3459)\n",
      "8068 Traning Loss: tensor(3.3459)\n",
      "8069 Traning Loss: tensor(3.3459)\n",
      "8070 Traning Loss: tensor(3.3458)\n",
      "8071 Traning Loss: tensor(3.3458)\n",
      "8072 Traning Loss: tensor(3.3458)\n",
      "8073 Traning Loss: tensor(3.3458)\n",
      "8074 Traning Loss: tensor(3.3457)\n",
      "8075 Traning Loss: tensor(3.3457)\n",
      "8076 Traning Loss: tensor(3.3457)\n",
      "8077 Traning Loss: tensor(3.3457)\n",
      "8078 Traning Loss: tensor(3.3457)\n",
      "8079 Traning Loss: tensor(3.3456)\n",
      "8080 Traning Loss: tensor(3.3456)\n",
      "8081 Traning Loss: tensor(3.3456)\n",
      "8082 Traning Loss: tensor(3.3455)\n",
      "8083 Traning Loss: tensor(3.3455)\n",
      "8084 Traning Loss: tensor(3.3455)\n",
      "8085 Traning Loss: tensor(3.3454)\n",
      "8086 Traning Loss: tensor(3.3455)\n",
      "8087 Traning Loss: tensor(3.3455)\n",
      "8088 Traning Loss: tensor(3.3454)\n",
      "8089 Traning Loss: tensor(3.3454)\n",
      "8090 Traning Loss: tensor(3.3453)\n",
      "8091 Traning Loss: tensor(3.3453)\n",
      "8092 Traning Loss: tensor(3.3452)\n",
      "8093 Traning Loss: tensor(3.3453)\n",
      "8094 Traning Loss: tensor(3.3452)\n",
      "8095 Traning Loss: tensor(3.3452)\n",
      "8096 Traning Loss: tensor(3.3452)\n",
      "8097 Traning Loss: tensor(3.3451)\n",
      "8098 Traning Loss: tensor(3.3451)\n",
      "8099 Traning Loss: tensor(3.3451)\n",
      "8100 Traning Loss: tensor(3.3450)\n",
      "8101 Traning Loss: tensor(3.3450)\n",
      "8102 Traning Loss: tensor(3.3450)\n",
      "8103 Traning Loss: tensor(3.3450)\n",
      "8104 Traning Loss: tensor(3.3450)\n",
      "8105 Traning Loss: tensor(3.3449)\n",
      "8106 Traning Loss: tensor(3.3449)\n",
      "8107 Traning Loss: tensor(3.3449)\n",
      "8108 Traning Loss: tensor(3.3448)\n",
      "8109 Traning Loss: tensor(3.3449)\n",
      "8110 Traning Loss: tensor(3.3447)\n",
      "8111 Traning Loss: tensor(3.3447)\n",
      "8112 Traning Loss: tensor(3.3448)\n",
      "8113 Traning Loss: tensor(3.3447)\n",
      "8114 Traning Loss: tensor(3.3447)\n",
      "8115 Traning Loss: tensor(3.3447)\n",
      "8116 Traning Loss: tensor(3.3445)\n",
      "8117 Traning Loss: tensor(3.3445)\n",
      "8118 Traning Loss: tensor(3.3446)\n",
      "8119 Traning Loss: tensor(3.3444)\n",
      "8120 Traning Loss: tensor(3.3444)\n",
      "8121 Traning Loss: tensor(3.3443)\n",
      "8122 Traning Loss: tensor(3.3444)\n",
      "8123 Traning Loss: tensor(3.3443)\n",
      "8124 Traning Loss: tensor(3.3442)\n",
      "8125 Traning Loss: tensor(3.3443)\n",
      "8126 Traning Loss: tensor(3.3444)\n",
      "8127 Traning Loss: tensor(3.3443)\n",
      "8128 Traning Loss: tensor(3.3442)\n",
      "8129 Traning Loss: tensor(3.3442)\n",
      "8130 Traning Loss: tensor(3.3442)\n",
      "8131 Traning Loss: tensor(3.3442)\n",
      "8132 Traning Loss: tensor(3.3440)\n",
      "8133 Traning Loss: tensor(3.3439)\n",
      "8134 Traning Loss: tensor(3.3440)\n",
      "8135 Traning Loss: tensor(3.3440)\n",
      "8136 Traning Loss: tensor(3.3439)\n",
      "8137 Traning Loss: tensor(3.3439)\n",
      "8138 Traning Loss: tensor(3.3438)\n",
      "8139 Traning Loss: tensor(3.3438)\n",
      "8140 Traning Loss: tensor(3.3439)\n",
      "8141 Traning Loss: tensor(3.3439)\n",
      "8142 Traning Loss: tensor(3.3438)\n",
      "8143 Traning Loss: tensor(3.3437)\n",
      "8144 Traning Loss: tensor(3.3436)\n",
      "8145 Traning Loss: tensor(3.3437)\n",
      "8146 Traning Loss: tensor(3.3436)\n",
      "8147 Traning Loss: tensor(3.3435)\n",
      "8148 Traning Loss: tensor(3.3435)\n",
      "8149 Traning Loss: tensor(3.3435)\n",
      "8150 Traning Loss: tensor(3.3436)\n",
      "8151 Traning Loss: tensor(3.3433)\n",
      "8152 Traning Loss: tensor(3.3434)\n",
      "8153 Traning Loss: tensor(3.3435)\n",
      "8154 Traning Loss: tensor(3.3433)\n",
      "8155 Traning Loss: tensor(3.3433)\n",
      "8156 Traning Loss: tensor(3.3433)\n",
      "8157 Traning Loss: tensor(3.3433)\n",
      "8158 Traning Loss: tensor(3.3431)\n",
      "8159 Traning Loss: tensor(3.3431)\n",
      "8160 Traning Loss: tensor(3.3431)\n",
      "8161 Traning Loss: tensor(3.3431)\n",
      "8162 Traning Loss: tensor(3.3430)\n",
      "8163 Traning Loss: tensor(3.3430)\n",
      "8164 Traning Loss: tensor(3.3429)\n",
      "8165 Traning Loss: tensor(3.3430)\n",
      "8166 Traning Loss: tensor(3.3430)\n",
      "8167 Traning Loss: tensor(3.3429)\n",
      "8168 Traning Loss: tensor(3.3429)\n",
      "8169 Traning Loss: tensor(3.3427)\n",
      "8170 Traning Loss: tensor(3.3426)\n",
      "8171 Traning Loss: tensor(3.3428)\n",
      "8172 Traning Loss: tensor(3.3427)\n",
      "8173 Traning Loss: tensor(3.3426)\n",
      "8174 Traning Loss: tensor(3.3427)\n",
      "8175 Traning Loss: tensor(3.3426)\n",
      "8176 Traning Loss: tensor(3.3424)\n",
      "8177 Traning Loss: tensor(3.3423)\n",
      "8178 Traning Loss: tensor(3.3424)\n",
      "8179 Traning Loss: tensor(3.3424)\n",
      "8180 Traning Loss: tensor(3.3426)\n",
      "8181 Traning Loss: tensor(3.3424)\n",
      "8182 Traning Loss: tensor(3.3426)\n",
      "8183 Traning Loss: tensor(3.3424)\n",
      "8184 Traning Loss: tensor(3.3424)\n",
      "8185 Traning Loss: tensor(3.3420)\n",
      "8186 Traning Loss: tensor(3.3421)\n",
      "8187 Traning Loss: tensor(3.3420)\n",
      "8188 Traning Loss: tensor(3.3421)\n",
      "8189 Traning Loss: tensor(3.3420)\n",
      "8190 Traning Loss: tensor(3.3419)\n",
      "8191 Traning Loss: tensor(3.3418)\n",
      "8192 Traning Loss: tensor(3.3419)\n",
      "8193 Traning Loss: tensor(3.3418)\n",
      "8194 Traning Loss: tensor(3.3420)\n",
      "8195 Traning Loss: tensor(3.3416)\n",
      "8196 Traning Loss: tensor(3.3416)\n",
      "8197 Traning Loss: tensor(3.3418)\n",
      "8198 Traning Loss: tensor(3.3415)\n",
      "8199 Traning Loss: tensor(3.3417)\n",
      "8200 Traning Loss: tensor(3.3415)\n",
      "8201 Traning Loss: tensor(3.3414)\n",
      "8202 Traning Loss: tensor(3.3414)\n",
      "8203 Traning Loss: tensor(3.3415)\n",
      "8204 Traning Loss: tensor(3.3414)\n",
      "8205 Traning Loss: tensor(3.3413)\n",
      "8206 Traning Loss: tensor(3.3412)\n",
      "8207 Traning Loss: tensor(3.3415)\n",
      "8208 Traning Loss: tensor(3.3412)\n",
      "8209 Traning Loss: tensor(3.3410)\n",
      "8210 Traning Loss: tensor(3.3411)\n",
      "8211 Traning Loss: tensor(3.3414)\n",
      "8212 Traning Loss: tensor(3.3410)\n",
      "8213 Traning Loss: tensor(3.3410)\n",
      "8214 Traning Loss: tensor(3.3410)\n",
      "8215 Traning Loss: tensor(3.3408)\n",
      "8216 Traning Loss: tensor(3.3408)\n",
      "8217 Traning Loss: tensor(3.3411)\n",
      "8218 Traning Loss: tensor(3.3405)\n",
      "8219 Traning Loss: tensor(3.3406)\n",
      "8220 Traning Loss: tensor(3.3404)\n",
      "8221 Traning Loss: tensor(3.3407)\n",
      "8222 Traning Loss: tensor(3.3409)\n",
      "8223 Traning Loss: tensor(3.3406)\n",
      "8224 Traning Loss: tensor(3.3406)\n",
      "8225 Traning Loss: tensor(3.3404)\n",
      "8226 Traning Loss: tensor(3.3403)\n",
      "8227 Traning Loss: tensor(3.3402)\n",
      "8228 Traning Loss: tensor(3.3403)\n",
      "8229 Traning Loss: tensor(3.3406)\n",
      "8230 Traning Loss: tensor(3.3402)\n",
      "8231 Traning Loss: tensor(3.3405)\n",
      "8232 Traning Loss: tensor(3.3403)\n",
      "8233 Traning Loss: tensor(3.3404)\n",
      "8234 Traning Loss: tensor(3.3399)\n",
      "8235 Traning Loss: tensor(3.3398)\n",
      "8236 Traning Loss: tensor(3.3401)\n",
      "8237 Traning Loss: tensor(3.3400)\n",
      "8238 Traning Loss: tensor(3.3404)\n",
      "8239 Traning Loss: tensor(3.3401)\n",
      "8240 Traning Loss: tensor(3.3399)\n",
      "8241 Traning Loss: tensor(3.3399)\n",
      "8242 Traning Loss: tensor(3.3398)\n",
      "8243 Traning Loss: tensor(3.3399)\n",
      "8244 Traning Loss: tensor(3.3396)\n",
      "8245 Traning Loss: tensor(3.3398)\n",
      "8246 Traning Loss: tensor(3.3394)\n",
      "8247 Traning Loss: tensor(3.3395)\n",
      "8248 Traning Loss: tensor(3.3397)\n",
      "8249 Traning Loss: tensor(3.3395)\n",
      "8250 Traning Loss: tensor(3.3391)\n",
      "8251 Traning Loss: tensor(3.3391)\n",
      "8252 Traning Loss: tensor(3.3392)\n",
      "8253 Traning Loss: tensor(3.3391)\n",
      "8254 Traning Loss: tensor(3.3393)\n",
      "8255 Traning Loss: tensor(3.3390)\n",
      "8256 Traning Loss: tensor(3.3393)\n",
      "8257 Traning Loss: tensor(3.3389)\n",
      "8258 Traning Loss: tensor(3.3392)\n",
      "8259 Traning Loss: tensor(3.3395)\n",
      "8260 Traning Loss: tensor(3.3389)\n",
      "8261 Traning Loss: tensor(3.3390)\n",
      "8262 Traning Loss: tensor(3.3391)\n",
      "8263 Traning Loss: tensor(3.3389)\n",
      "8264 Traning Loss: tensor(3.3386)\n",
      "8265 Traning Loss: tensor(3.3387)\n",
      "8266 Traning Loss: tensor(3.3386)\n",
      "8267 Traning Loss: tensor(3.3386)\n",
      "8268 Traning Loss: tensor(3.3385)\n",
      "8269 Traning Loss: tensor(3.3384)\n",
      "8270 Traning Loss: tensor(3.3381)\n",
      "8271 Traning Loss: tensor(3.3383)\n",
      "8272 Traning Loss: tensor(3.3385)\n",
      "8273 Traning Loss: tensor(3.3383)\n",
      "8274 Traning Loss: tensor(3.3384)\n",
      "8275 Traning Loss: tensor(3.3385)\n",
      "8276 Traning Loss: tensor(3.3380)\n",
      "8277 Traning Loss: tensor(3.3382)\n",
      "8278 Traning Loss: tensor(3.3378)\n",
      "8279 Traning Loss: tensor(3.3383)\n",
      "8280 Traning Loss: tensor(3.3376)\n",
      "8281 Traning Loss: tensor(3.3385)\n",
      "8282 Traning Loss: tensor(3.3379)\n",
      "8283 Traning Loss: tensor(3.3376)\n",
      "8284 Traning Loss: tensor(3.3376)\n",
      "8285 Traning Loss: tensor(3.3380)\n",
      "8286 Traning Loss: tensor(3.3372)\n",
      "8287 Traning Loss: tensor(3.3375)\n",
      "8288 Traning Loss: tensor(3.3372)\n",
      "8289 Traning Loss: tensor(3.3372)\n",
      "8290 Traning Loss: tensor(3.3377)\n",
      "8291 Traning Loss: tensor(3.3376)\n",
      "8292 Traning Loss: tensor(3.3369)\n",
      "8293 Traning Loss: tensor(3.3372)\n",
      "8294 Traning Loss: tensor(3.3373)\n",
      "8295 Traning Loss: tensor(3.3378)\n",
      "8296 Traning Loss: tensor(3.3372)\n",
      "8297 Traning Loss: tensor(3.3370)\n",
      "8298 Traning Loss: tensor(3.3373)\n",
      "8299 Traning Loss: tensor(3.3370)\n",
      "8300 Traning Loss: tensor(3.3375)\n",
      "8301 Traning Loss: tensor(3.3372)\n",
      "8302 Traning Loss: tensor(3.3370)\n",
      "8303 Traning Loss: tensor(3.3368)\n",
      "8304 Traning Loss: tensor(3.3372)\n",
      "8305 Traning Loss: tensor(3.3368)\n",
      "8306 Traning Loss: tensor(3.3365)\n",
      "8307 Traning Loss: tensor(3.3369)\n",
      "8308 Traning Loss: tensor(3.3369)\n",
      "8309 Traning Loss: tensor(3.3363)\n",
      "8310 Traning Loss: tensor(3.3366)\n",
      "8311 Traning Loss: tensor(3.3364)\n",
      "8312 Traning Loss: tensor(3.3369)\n",
      "8313 Traning Loss: tensor(3.3363)\n",
      "8314 Traning Loss: tensor(3.3366)\n",
      "8315 Traning Loss: tensor(3.3365)\n",
      "8316 Traning Loss: tensor(3.3366)\n",
      "8317 Traning Loss: tensor(3.3367)\n",
      "8318 Traning Loss: tensor(3.3365)\n",
      "8319 Traning Loss: tensor(3.3362)\n",
      "8320 Traning Loss: tensor(3.3363)\n",
      "8321 Traning Loss: tensor(3.3360)\n",
      "8322 Traning Loss: tensor(3.3369)\n",
      "8323 Traning Loss: tensor(3.3363)\n",
      "8324 Traning Loss: tensor(3.3359)\n",
      "8325 Traning Loss: tensor(3.3360)\n",
      "8326 Traning Loss: tensor(3.3360)\n",
      "8327 Traning Loss: tensor(3.3351)\n",
      "8328 Traning Loss: tensor(3.3364)\n",
      "8329 Traning Loss: tensor(3.3354)\n",
      "8330 Traning Loss: tensor(3.3359)\n",
      "8331 Traning Loss: tensor(3.3352)\n",
      "8332 Traning Loss: tensor(3.3359)\n",
      "8333 Traning Loss: tensor(3.3353)\n",
      "8334 Traning Loss: tensor(3.3354)\n",
      "8335 Traning Loss: tensor(3.3355)\n",
      "8336 Traning Loss: tensor(3.3358)\n",
      "8337 Traning Loss: tensor(3.3355)\n",
      "8338 Traning Loss: tensor(3.3358)\n",
      "8339 Traning Loss: tensor(3.3348)\n",
      "8340 Traning Loss: tensor(3.3355)\n",
      "8341 Traning Loss: tensor(3.3351)\n",
      "8342 Traning Loss: tensor(3.3352)\n",
      "8343 Traning Loss: tensor(3.3359)\n",
      "8344 Traning Loss: tensor(3.3355)\n",
      "8345 Traning Loss: tensor(3.3349)\n",
      "8346 Traning Loss: tensor(3.3355)\n",
      "8347 Traning Loss: tensor(3.3358)\n",
      "8348 Traning Loss: tensor(3.3353)\n",
      "8349 Traning Loss: tensor(3.3347)\n",
      "8350 Traning Loss: tensor(3.3345)\n",
      "8351 Traning Loss: tensor(3.3351)\n",
      "8352 Traning Loss: tensor(3.3351)\n",
      "8353 Traning Loss: tensor(3.3359)\n",
      "8354 Traning Loss: tensor(3.3353)\n",
      "8355 Traning Loss: tensor(3.3351)\n",
      "8356 Traning Loss: tensor(3.3352)\n",
      "8357 Traning Loss: tensor(3.3350)\n",
      "8358 Traning Loss: tensor(3.3344)\n",
      "8359 Traning Loss: tensor(3.3349)\n",
      "8360 Traning Loss: tensor(3.3346)\n",
      "8361 Traning Loss: tensor(3.3344)\n",
      "8362 Traning Loss: tensor(3.3341)\n",
      "8363 Traning Loss: tensor(3.3349)\n",
      "8364 Traning Loss: tensor(3.3350)\n",
      "8365 Traning Loss: tensor(3.3342)\n",
      "8366 Traning Loss: tensor(3.3349)\n",
      "8367 Traning Loss: tensor(3.3354)\n",
      "8368 Traning Loss: tensor(3.3338)\n",
      "8369 Traning Loss: tensor(3.3341)\n",
      "8370 Traning Loss: tensor(3.3343)\n",
      "8371 Traning Loss: tensor(3.3342)\n",
      "8372 Traning Loss: tensor(3.3349)\n",
      "8373 Traning Loss: tensor(3.3340)\n",
      "8374 Traning Loss: tensor(3.3348)\n",
      "8375 Traning Loss: tensor(3.3337)\n",
      "8376 Traning Loss: tensor(3.3333)\n",
      "8377 Traning Loss: tensor(3.3341)\n",
      "8378 Traning Loss: tensor(3.3342)\n",
      "8379 Traning Loss: tensor(3.3338)\n",
      "8380 Traning Loss: tensor(3.3335)\n",
      "8381 Traning Loss: tensor(3.3339)\n",
      "8382 Traning Loss: tensor(3.3336)\n",
      "8383 Traning Loss: tensor(3.3343)\n",
      "8384 Traning Loss: tensor(3.3329)\n",
      "8385 Traning Loss: tensor(3.3342)\n",
      "8386 Traning Loss: tensor(3.3333)\n",
      "8387 Traning Loss: tensor(3.3342)\n",
      "8388 Traning Loss: tensor(3.3328)\n",
      "8389 Traning Loss: tensor(3.3325)\n",
      "8390 Traning Loss: tensor(3.3338)\n",
      "8391 Traning Loss: tensor(3.3339)\n",
      "8392 Traning Loss: tensor(3.3328)\n",
      "8393 Traning Loss: tensor(3.3336)\n",
      "8394 Traning Loss: tensor(3.3339)\n",
      "8395 Traning Loss: tensor(3.3336)\n",
      "8396 Traning Loss: tensor(3.3323)\n",
      "8397 Traning Loss: tensor(3.3336)\n",
      "8398 Traning Loss: tensor(3.3326)\n",
      "8399 Traning Loss: tensor(3.3323)\n",
      "8400 Traning Loss: tensor(3.3330)\n",
      "8401 Traning Loss: tensor(3.3338)\n",
      "8402 Traning Loss: tensor(3.3328)\n",
      "8403 Traning Loss: tensor(3.3326)\n",
      "8404 Traning Loss: tensor(3.3329)\n",
      "8405 Traning Loss: tensor(3.3332)\n",
      "8406 Traning Loss: tensor(3.3333)\n",
      "8407 Traning Loss: tensor(3.3325)\n",
      "8408 Traning Loss: tensor(3.3336)\n",
      "8409 Traning Loss: tensor(3.3329)\n",
      "8410 Traning Loss: tensor(3.3324)\n",
      "8411 Traning Loss: tensor(3.3318)\n",
      "8412 Traning Loss: tensor(3.3319)\n",
      "8413 Traning Loss: tensor(3.3324)\n",
      "8414 Traning Loss: tensor(3.3325)\n",
      "8415 Traning Loss: tensor(3.3331)\n",
      "8416 Traning Loss: tensor(3.3313)\n",
      "8417 Traning Loss: tensor(3.3336)\n",
      "8418 Traning Loss: tensor(3.3324)\n",
      "8419 Traning Loss: tensor(3.3329)\n",
      "8420 Traning Loss: tensor(3.3335)\n",
      "8421 Traning Loss: tensor(3.3311)\n",
      "8422 Traning Loss: tensor(3.3318)\n",
      "8423 Traning Loss: tensor(3.3320)\n",
      "8424 Traning Loss: tensor(3.3325)\n",
      "8425 Traning Loss: tensor(3.3321)\n",
      "8426 Traning Loss: tensor(3.3316)\n",
      "8427 Traning Loss: tensor(3.3311)\n",
      "8428 Traning Loss: tensor(3.3329)\n",
      "8429 Traning Loss: tensor(3.3317)\n",
      "8430 Traning Loss: tensor(3.3316)\n",
      "8431 Traning Loss: tensor(3.3327)\n",
      "8432 Traning Loss: tensor(3.3307)\n",
      "8433 Traning Loss: tensor(3.3312)\n",
      "8434 Traning Loss: tensor(3.3317)\n",
      "8435 Traning Loss: tensor(3.3310)\n",
      "8436 Traning Loss: tensor(3.3306)\n",
      "8437 Traning Loss: tensor(3.3323)\n",
      "8438 Traning Loss: tensor(3.3325)\n",
      "8439 Traning Loss: tensor(3.3313)\n",
      "8440 Traning Loss: tensor(3.3311)\n",
      "8441 Traning Loss: tensor(3.3317)\n",
      "8442 Traning Loss: tensor(3.3306)\n",
      "8443 Traning Loss: tensor(3.3303)\n",
      "8444 Traning Loss: tensor(3.3306)\n",
      "8445 Traning Loss: tensor(3.3315)\n",
      "8446 Traning Loss: tensor(3.3300)\n",
      "8447 Traning Loss: tensor(3.3307)\n",
      "8448 Traning Loss: tensor(3.3306)\n",
      "8449 Traning Loss: tensor(3.3312)\n",
      "8450 Traning Loss: tensor(3.3317)\n",
      "8451 Traning Loss: tensor(3.3295)\n",
      "8452 Traning Loss: tensor(3.3309)\n",
      "8453 Traning Loss: tensor(3.3305)\n",
      "8454 Traning Loss: tensor(3.3319)\n",
      "8455 Traning Loss: tensor(3.3297)\n",
      "8456 Traning Loss: tensor(3.3321)\n",
      "8457 Traning Loss: tensor(3.3303)\n",
      "8458 Traning Loss: tensor(3.3293)\n",
      "8459 Traning Loss: tensor(3.3307)\n",
      "8460 Traning Loss: tensor(3.3294)\n",
      "8461 Traning Loss: tensor(3.3305)\n",
      "8462 Traning Loss: tensor(3.3299)\n",
      "8463 Traning Loss: tensor(3.3305)\n",
      "8464 Traning Loss: tensor(3.3301)\n",
      "8465 Traning Loss: tensor(3.3292)\n",
      "8466 Traning Loss: tensor(3.3306)\n",
      "8467 Traning Loss: tensor(3.3290)\n",
      "8468 Traning Loss: tensor(3.3299)\n",
      "8469 Traning Loss: tensor(3.3298)\n",
      "8470 Traning Loss: tensor(3.3300)\n",
      "8471 Traning Loss: tensor(3.3301)\n",
      "8472 Traning Loss: tensor(3.3298)\n",
      "8473 Traning Loss: tensor(3.3291)\n",
      "8474 Traning Loss: tensor(3.3289)\n",
      "8475 Traning Loss: tensor(3.3301)\n",
      "8476 Traning Loss: tensor(3.3300)\n",
      "8477 Traning Loss: tensor(3.3286)\n",
      "8478 Traning Loss: tensor(3.3297)\n",
      "8479 Traning Loss: tensor(3.3285)\n",
      "8480 Traning Loss: tensor(3.3286)\n",
      "8481 Traning Loss: tensor(3.3302)\n",
      "8482 Traning Loss: tensor(3.3299)\n",
      "8483 Traning Loss: tensor(3.3296)\n",
      "8484 Traning Loss: tensor(3.3279)\n",
      "8485 Traning Loss: tensor(3.3276)\n",
      "8486 Traning Loss: tensor(3.3284)\n",
      "8487 Traning Loss: tensor(3.3273)\n",
      "8488 Traning Loss: tensor(3.3301)\n",
      "8489 Traning Loss: tensor(3.3278)\n",
      "8490 Traning Loss: tensor(3.3295)\n",
      "8491 Traning Loss: tensor(3.3282)\n",
      "8492 Traning Loss: tensor(3.3282)\n",
      "8493 Traning Loss: tensor(3.3295)\n",
      "8494 Traning Loss: tensor(3.3279)\n",
      "8495 Traning Loss: tensor(3.3295)\n",
      "8496 Traning Loss: tensor(3.3282)\n",
      "8497 Traning Loss: tensor(3.3271)\n",
      "8498 Traning Loss: tensor(3.3267)\n",
      "8499 Traning Loss: tensor(3.3274)\n",
      "8500 Traning Loss: tensor(3.3291)\n",
      "8501 Traning Loss: tensor(3.3288)\n",
      "8502 Traning Loss: tensor(3.3266)\n",
      "8503 Traning Loss: tensor(3.3272)\n",
      "8504 Traning Loss: tensor(3.3273)\n",
      "8505 Traning Loss: tensor(3.3264)\n",
      "8506 Traning Loss: tensor(3.3264)\n",
      "8507 Traning Loss: tensor(3.3272)\n",
      "8508 Traning Loss: tensor(3.3277)\n",
      "8509 Traning Loss: tensor(3.3271)\n",
      "8510 Traning Loss: tensor(3.3267)\n",
      "8511 Traning Loss: tensor(3.3264)\n",
      "8512 Traning Loss: tensor(3.3294)\n",
      "8513 Traning Loss: tensor(3.3274)\n",
      "8514 Traning Loss: tensor(3.3266)\n",
      "8515 Traning Loss: tensor(3.3257)\n",
      "8516 Traning Loss: tensor(3.3268)\n",
      "8517 Traning Loss: tensor(3.3261)\n",
      "8518 Traning Loss: tensor(3.3267)\n",
      "8519 Traning Loss: tensor(3.3272)\n",
      "8520 Traning Loss: tensor(3.3264)\n",
      "8521 Traning Loss: tensor(3.3266)\n",
      "8522 Traning Loss: tensor(3.3266)\n",
      "8523 Traning Loss: tensor(3.3257)\n",
      "8524 Traning Loss: tensor(3.3267)\n",
      "8525 Traning Loss: tensor(3.3271)\n",
      "8526 Traning Loss: tensor(3.3258)\n",
      "8527 Traning Loss: tensor(3.3275)\n",
      "8528 Traning Loss: tensor(3.3266)\n",
      "8529 Traning Loss: tensor(3.3268)\n",
      "8530 Traning Loss: tensor(3.3257)\n",
      "8531 Traning Loss: tensor(3.3258)\n",
      "8532 Traning Loss: tensor(3.3254)\n",
      "8533 Traning Loss: tensor(3.3247)\n",
      "8534 Traning Loss: tensor(3.3258)\n",
      "8535 Traning Loss: tensor(3.3270)\n",
      "8536 Traning Loss: tensor(3.3244)\n",
      "8537 Traning Loss: tensor(3.3250)\n",
      "8538 Traning Loss: tensor(3.3234)\n",
      "8539 Traning Loss: tensor(3.3251)\n",
      "8540 Traning Loss: tensor(3.3245)\n",
      "8541 Traning Loss: tensor(3.3249)\n",
      "8542 Traning Loss: tensor(3.3229)\n",
      "8543 Traning Loss: tensor(3.3249)\n",
      "8544 Traning Loss: tensor(3.3259)\n",
      "8545 Traning Loss: tensor(3.3251)\n",
      "8546 Traning Loss: tensor(3.3240)\n",
      "8547 Traning Loss: tensor(3.3230)\n",
      "8548 Traning Loss: tensor(3.3235)\n",
      "8549 Traning Loss: tensor(3.3237)\n",
      "8550 Traning Loss: tensor(3.3244)\n",
      "8551 Traning Loss: tensor(3.3241)\n",
      "8552 Traning Loss: tensor(3.3233)\n",
      "8553 Traning Loss: tensor(3.3217)\n",
      "8554 Traning Loss: tensor(3.3240)\n",
      "8555 Traning Loss: tensor(3.3217)\n",
      "8556 Traning Loss: tensor(3.3225)\n",
      "8557 Traning Loss: tensor(3.3239)\n",
      "8558 Traning Loss: tensor(3.3228)\n",
      "8559 Traning Loss: tensor(3.3224)\n",
      "8560 Traning Loss: tensor(3.3245)\n",
      "8561 Traning Loss: tensor(3.3230)\n",
      "8562 Traning Loss: tensor(3.3228)\n",
      "8563 Traning Loss: tensor(3.3233)\n",
      "8564 Traning Loss: tensor(3.3224)\n",
      "8565 Traning Loss: tensor(3.3206)\n",
      "8566 Traning Loss: tensor(3.3214)\n",
      "8567 Traning Loss: tensor(3.3213)\n",
      "8568 Traning Loss: tensor(3.3213)\n",
      "8569 Traning Loss: tensor(3.3229)\n",
      "8570 Traning Loss: tensor(3.3200)\n",
      "8571 Traning Loss: tensor(3.3226)\n",
      "8572 Traning Loss: tensor(3.3214)\n",
      "8573 Traning Loss: tensor(3.3215)\n",
      "8574 Traning Loss: tensor(3.3209)\n",
      "8575 Traning Loss: tensor(3.3217)\n",
      "8576 Traning Loss: tensor(3.3215)\n",
      "8577 Traning Loss: tensor(3.3231)\n",
      "8578 Traning Loss: tensor(3.3203)\n",
      "8579 Traning Loss: tensor(3.3212)\n",
      "8580 Traning Loss: tensor(3.3211)\n",
      "8581 Traning Loss: tensor(3.3203)\n",
      "8582 Traning Loss: tensor(3.3201)\n",
      "8583 Traning Loss: tensor(3.3207)\n",
      "8584 Traning Loss: tensor(3.3187)\n",
      "8585 Traning Loss: tensor(3.3184)\n",
      "8586 Traning Loss: tensor(3.3207)\n",
      "8587 Traning Loss: tensor(3.3207)\n",
      "8588 Traning Loss: tensor(3.3210)\n",
      "8589 Traning Loss: tensor(3.3223)\n",
      "8590 Traning Loss: tensor(3.3213)\n",
      "8591 Traning Loss: tensor(3.3187)\n",
      "8592 Traning Loss: tensor(3.3215)\n",
      "8593 Traning Loss: tensor(3.3195)\n",
      "8594 Traning Loss: tensor(3.3220)\n",
      "8595 Traning Loss: tensor(3.3188)\n",
      "8596 Traning Loss: tensor(3.3183)\n",
      "8597 Traning Loss: tensor(3.3182)\n",
      "8598 Traning Loss: tensor(3.3169)\n",
      "8599 Traning Loss: tensor(3.3194)\n",
      "8600 Traning Loss: tensor(3.3188)\n",
      "8601 Traning Loss: tensor(3.3185)\n",
      "8602 Traning Loss: tensor(3.3207)\n",
      "8603 Traning Loss: tensor(3.3185)\n",
      "8604 Traning Loss: tensor(3.3174)\n",
      "8605 Traning Loss: tensor(3.3202)\n",
      "8606 Traning Loss: tensor(3.3178)\n",
      "8607 Traning Loss: tensor(3.3195)\n",
      "8608 Traning Loss: tensor(3.3170)\n",
      "8609 Traning Loss: tensor(3.3177)\n",
      "8610 Traning Loss: tensor(3.3166)\n",
      "8611 Traning Loss: tensor(3.3181)\n",
      "8612 Traning Loss: tensor(3.3170)\n",
      "8613 Traning Loss: tensor(3.3161)\n",
      "8614 Traning Loss: tensor(3.3173)\n",
      "8615 Traning Loss: tensor(3.3171)\n",
      "8616 Traning Loss: tensor(3.3169)\n",
      "8617 Traning Loss: tensor(3.3151)\n",
      "8618 Traning Loss: tensor(3.3147)\n",
      "8619 Traning Loss: tensor(3.3161)\n",
      "8620 Traning Loss: tensor(3.3160)\n",
      "8621 Traning Loss: tensor(3.3155)\n",
      "8622 Traning Loss: tensor(3.3163)\n",
      "8623 Traning Loss: tensor(3.3160)\n",
      "8624 Traning Loss: tensor(3.3157)\n",
      "8625 Traning Loss: tensor(3.3169)\n",
      "8626 Traning Loss: tensor(3.3144)\n",
      "8627 Traning Loss: tensor(3.3146)\n",
      "8628 Traning Loss: tensor(3.3155)\n",
      "8629 Traning Loss: tensor(3.3157)\n",
      "8630 Traning Loss: tensor(3.3157)\n",
      "8631 Traning Loss: tensor(3.3157)\n",
      "8632 Traning Loss: tensor(3.3149)\n",
      "8633 Traning Loss: tensor(3.3129)\n",
      "8634 Traning Loss: tensor(3.3151)\n",
      "8635 Traning Loss: tensor(3.3140)\n",
      "8636 Traning Loss: tensor(3.3159)\n",
      "8637 Traning Loss: tensor(3.3128)\n",
      "8638 Traning Loss: tensor(3.3130)\n",
      "8639 Traning Loss: tensor(3.3126)\n",
      "8640 Traning Loss: tensor(3.3143)\n",
      "8641 Traning Loss: tensor(3.3144)\n",
      "8642 Traning Loss: tensor(3.3139)\n",
      "8643 Traning Loss: tensor(3.3143)\n",
      "8644 Traning Loss: tensor(3.3133)\n",
      "8645 Traning Loss: tensor(3.3126)\n",
      "8646 Traning Loss: tensor(3.3125)\n",
      "8647 Traning Loss: tensor(3.3139)\n",
      "8648 Traning Loss: tensor(3.3115)\n",
      "8649 Traning Loss: tensor(3.3119)\n",
      "8650 Traning Loss: tensor(3.3121)\n",
      "8651 Traning Loss: tensor(3.3146)\n",
      "8652 Traning Loss: tensor(3.3093)\n",
      "8653 Traning Loss: tensor(3.3144)\n",
      "8654 Traning Loss: tensor(3.3094)\n",
      "8655 Traning Loss: tensor(3.3121)\n",
      "8656 Traning Loss: tensor(3.3115)\n",
      "8657 Traning Loss: tensor(3.3100)\n",
      "8658 Traning Loss: tensor(3.3125)\n",
      "8659 Traning Loss: tensor(3.3094)\n",
      "8660 Traning Loss: tensor(3.3133)\n",
      "8661 Traning Loss: tensor(3.3107)\n",
      "8662 Traning Loss: tensor(3.3107)\n",
      "8663 Traning Loss: tensor(3.3108)\n",
      "8664 Traning Loss: tensor(3.3114)\n",
      "8665 Traning Loss: tensor(3.3101)\n",
      "8666 Traning Loss: tensor(3.3121)\n",
      "8667 Traning Loss: tensor(3.3084)\n",
      "8668 Traning Loss: tensor(3.3107)\n",
      "8669 Traning Loss: tensor(3.3090)\n",
      "8670 Traning Loss: tensor(3.3089)\n",
      "8671 Traning Loss: tensor(3.3098)\n",
      "8672 Traning Loss: tensor(3.3086)\n",
      "8673 Traning Loss: tensor(3.3090)\n",
      "8674 Traning Loss: tensor(3.3093)\n",
      "8675 Traning Loss: tensor(3.3097)\n",
      "8676 Traning Loss: tensor(3.3113)\n",
      "8677 Traning Loss: tensor(3.3065)\n",
      "8678 Traning Loss: tensor(3.3089)\n",
      "8679 Traning Loss: tensor(3.3059)\n",
      "8680 Traning Loss: tensor(3.3061)\n",
      "8681 Traning Loss: tensor(3.3092)\n",
      "8682 Traning Loss: tensor(3.3103)\n",
      "8683 Traning Loss: tensor(3.3073)\n",
      "8684 Traning Loss: tensor(3.3059)\n",
      "8685 Traning Loss: tensor(3.3065)\n",
      "8686 Traning Loss: tensor(3.3055)\n",
      "8687 Traning Loss: tensor(3.3059)\n",
      "8688 Traning Loss: tensor(3.3067)\n",
      "8689 Traning Loss: tensor(3.3054)\n",
      "8690 Traning Loss: tensor(3.3052)\n",
      "8691 Traning Loss: tensor(3.3075)\n",
      "8692 Traning Loss: tensor(3.3046)\n",
      "8693 Traning Loss: tensor(3.3011)\n",
      "8694 Traning Loss: tensor(3.3057)\n",
      "8695 Traning Loss: tensor(3.3069)\n",
      "8696 Traning Loss: tensor(3.3079)\n",
      "8697 Traning Loss: tensor(3.3085)\n",
      "8698 Traning Loss: tensor(3.3062)\n",
      "8699 Traning Loss: tensor(3.3057)\n",
      "8700 Traning Loss: tensor(3.3054)\n",
      "8701 Traning Loss: tensor(3.3048)\n",
      "8702 Traning Loss: tensor(3.3052)\n",
      "8703 Traning Loss: tensor(3.3030)\n",
      "8704 Traning Loss: tensor(3.3023)\n",
      "8705 Traning Loss: tensor(3.3024)\n",
      "8706 Traning Loss: tensor(3.2995)\n",
      "8707 Traning Loss: tensor(3.3025)\n",
      "8708 Traning Loss: tensor(3.3053)\n",
      "8709 Traning Loss: tensor(3.3032)\n",
      "8710 Traning Loss: tensor(3.3014)\n",
      "8711 Traning Loss: tensor(3.3008)\n",
      "8712 Traning Loss: tensor(3.3009)\n",
      "8713 Traning Loss: tensor(3.2993)\n",
      "8714 Traning Loss: tensor(3.2998)\n",
      "8715 Traning Loss: tensor(3.3042)\n",
      "8716 Traning Loss: tensor(3.3016)\n",
      "8717 Traning Loss: tensor(3.2995)\n",
      "8718 Traning Loss: tensor(3.3003)\n",
      "8719 Traning Loss: tensor(3.3010)\n",
      "8720 Traning Loss: tensor(3.3054)\n",
      "8721 Traning Loss: tensor(3.2977)\n",
      "8722 Traning Loss: tensor(3.3011)\n",
      "8723 Traning Loss: tensor(3.3022)\n",
      "8724 Traning Loss: tensor(3.3008)\n",
      "8725 Traning Loss: tensor(3.2995)\n",
      "8726 Traning Loss: tensor(3.3005)\n",
      "8727 Traning Loss: tensor(3.2993)\n",
      "8728 Traning Loss: tensor(3.3000)\n",
      "8729 Traning Loss: tensor(3.2990)\n",
      "8730 Traning Loss: tensor(3.2952)\n",
      "8731 Traning Loss: tensor(3.2967)\n",
      "8732 Traning Loss: tensor(3.2949)\n",
      "8733 Traning Loss: tensor(3.2972)\n",
      "8734 Traning Loss: tensor(3.2941)\n",
      "8735 Traning Loss: tensor(3.2977)\n",
      "8736 Traning Loss: tensor(3.2994)\n",
      "8737 Traning Loss: tensor(3.2969)\n",
      "8738 Traning Loss: tensor(3.2982)\n",
      "8739 Traning Loss: tensor(3.2940)\n",
      "8740 Traning Loss: tensor(3.2970)\n",
      "8741 Traning Loss: tensor(3.2960)\n",
      "8742 Traning Loss: tensor(3.2956)\n",
      "8743 Traning Loss: tensor(3.2963)\n",
      "8744 Traning Loss: tensor(3.2968)\n",
      "8745 Traning Loss: tensor(3.2974)\n",
      "8746 Traning Loss: tensor(3.2978)\n",
      "8747 Traning Loss: tensor(3.2944)\n",
      "8748 Traning Loss: tensor(3.2928)\n",
      "8749 Traning Loss: tensor(3.2960)\n",
      "8750 Traning Loss: tensor(3.2959)\n",
      "8751 Traning Loss: tensor(3.2966)\n",
      "8752 Traning Loss: tensor(3.2931)\n",
      "8753 Traning Loss: tensor(3.2913)\n",
      "8754 Traning Loss: tensor(3.2953)\n",
      "8755 Traning Loss: tensor(3.2935)\n",
      "8756 Traning Loss: tensor(3.2977)\n",
      "8757 Traning Loss: tensor(3.2960)\n",
      "8758 Traning Loss: tensor(3.2925)\n",
      "8759 Traning Loss: tensor(3.2958)\n",
      "8760 Traning Loss: tensor(3.2960)\n",
      "8761 Traning Loss: tensor(3.2961)\n",
      "8762 Traning Loss: tensor(3.2953)\n",
      "8763 Traning Loss: tensor(3.2939)\n",
      "8764 Traning Loss: tensor(3.2964)\n",
      "8765 Traning Loss: tensor(3.2949)\n",
      "8766 Traning Loss: tensor(3.2919)\n",
      "8767 Traning Loss: tensor(3.2903)\n",
      "8768 Traning Loss: tensor(3.2908)\n",
      "8769 Traning Loss: tensor(3.2901)\n",
      "8770 Traning Loss: tensor(3.2937)\n",
      "8771 Traning Loss: tensor(3.2903)\n",
      "8772 Traning Loss: tensor(3.2912)\n",
      "8773 Traning Loss: tensor(3.2905)\n",
      "8774 Traning Loss: tensor(3.2904)\n",
      "8775 Traning Loss: tensor(3.2911)\n",
      "8776 Traning Loss: tensor(3.2921)\n",
      "8777 Traning Loss: tensor(3.2892)\n",
      "8778 Traning Loss: tensor(3.2928)\n",
      "8779 Traning Loss: tensor(3.2917)\n",
      "8780 Traning Loss: tensor(3.2872)\n",
      "8781 Traning Loss: tensor(3.2890)\n",
      "8782 Traning Loss: tensor(3.2907)\n",
      "8783 Traning Loss: tensor(3.2930)\n",
      "8784 Traning Loss: tensor(3.2911)\n",
      "8785 Traning Loss: tensor(3.2882)\n",
      "8786 Traning Loss: tensor(3.2916)\n",
      "8787 Traning Loss: tensor(3.2879)\n",
      "8788 Traning Loss: tensor(3.2848)\n",
      "8789 Traning Loss: tensor(3.2901)\n",
      "8790 Traning Loss: tensor(3.2877)\n",
      "8791 Traning Loss: tensor(3.2910)\n",
      "8792 Traning Loss: tensor(3.2896)\n",
      "8793 Traning Loss: tensor(3.2885)\n",
      "8794 Traning Loss: tensor(3.2882)\n",
      "8795 Traning Loss: tensor(3.2884)\n",
      "8796 Traning Loss: tensor(3.2864)\n",
      "8797 Traning Loss: tensor(3.2872)\n",
      "8798 Traning Loss: tensor(3.2887)\n",
      "8799 Traning Loss: tensor(3.2864)\n",
      "8800 Traning Loss: tensor(3.2867)\n",
      "8801 Traning Loss: tensor(3.2838)\n",
      "8802 Traning Loss: tensor(3.2858)\n",
      "8803 Traning Loss: tensor(3.2905)\n",
      "8804 Traning Loss: tensor(3.2850)\n",
      "8805 Traning Loss: tensor(3.2835)\n",
      "8806 Traning Loss: tensor(3.2895)\n",
      "8807 Traning Loss: tensor(3.2854)\n",
      "8808 Traning Loss: tensor(3.2918)\n",
      "8809 Traning Loss: tensor(3.2814)\n",
      "8810 Traning Loss: tensor(3.2931)\n",
      "8811 Traning Loss: tensor(3.2869)\n",
      "8812 Traning Loss: tensor(3.2844)\n",
      "8813 Traning Loss: tensor(3.2851)\n",
      "8814 Traning Loss: tensor(3.2861)\n",
      "8815 Traning Loss: tensor(3.2802)\n",
      "8816 Traning Loss: tensor(3.2824)\n",
      "8817 Traning Loss: tensor(3.2840)\n",
      "8818 Traning Loss: tensor(3.2872)\n",
      "8819 Traning Loss: tensor(3.2831)\n",
      "8820 Traning Loss: tensor(3.2835)\n",
      "8821 Traning Loss: tensor(3.2803)\n",
      "8822 Traning Loss: tensor(3.2864)\n",
      "8823 Traning Loss: tensor(3.2828)\n",
      "8824 Traning Loss: tensor(3.2811)\n",
      "8825 Traning Loss: tensor(3.2816)\n",
      "8826 Traning Loss: tensor(3.2837)\n",
      "8827 Traning Loss: tensor(3.2869)\n",
      "8828 Traning Loss: tensor(3.2833)\n",
      "8829 Traning Loss: tensor(3.2811)\n",
      "8830 Traning Loss: tensor(3.2783)\n",
      "8831 Traning Loss: tensor(3.2796)\n",
      "8832 Traning Loss: tensor(3.2819)\n",
      "8833 Traning Loss: tensor(3.2840)\n",
      "8834 Traning Loss: tensor(3.2785)\n",
      "8835 Traning Loss: tensor(3.2838)\n",
      "8836 Traning Loss: tensor(3.2807)\n",
      "8837 Traning Loss: tensor(3.2832)\n",
      "8838 Traning Loss: tensor(3.2795)\n",
      "8839 Traning Loss: tensor(3.2759)\n",
      "8840 Traning Loss: tensor(3.2786)\n",
      "8841 Traning Loss: tensor(3.2786)\n",
      "8842 Traning Loss: tensor(3.2778)\n",
      "8843 Traning Loss: tensor(3.2796)\n",
      "8844 Traning Loss: tensor(3.2774)\n",
      "8845 Traning Loss: tensor(3.2795)\n",
      "8846 Traning Loss: tensor(3.2751)\n",
      "8847 Traning Loss: tensor(3.2795)\n",
      "8848 Traning Loss: tensor(3.2817)\n",
      "8849 Traning Loss: tensor(3.2781)\n",
      "8850 Traning Loss: tensor(3.2754)\n",
      "8851 Traning Loss: tensor(3.2756)\n",
      "8852 Traning Loss: tensor(3.2790)\n",
      "8853 Traning Loss: tensor(3.2784)\n",
      "8854 Traning Loss: tensor(3.2800)\n",
      "8855 Traning Loss: tensor(3.2741)\n",
      "8856 Traning Loss: tensor(3.2813)\n",
      "8857 Traning Loss: tensor(3.2743)\n",
      "8858 Traning Loss: tensor(3.2749)\n",
      "8859 Traning Loss: tensor(3.2737)\n",
      "8860 Traning Loss: tensor(3.2763)\n",
      "8861 Traning Loss: tensor(3.2823)\n",
      "8862 Traning Loss: tensor(3.2748)\n",
      "8863 Traning Loss: tensor(3.2747)\n",
      "8864 Traning Loss: tensor(3.2780)\n",
      "8865 Traning Loss: tensor(3.2750)\n",
      "8866 Traning Loss: tensor(3.2738)\n",
      "8867 Traning Loss: tensor(3.2697)\n",
      "8868 Traning Loss: tensor(3.2757)\n",
      "8869 Traning Loss: tensor(3.2730)\n",
      "8870 Traning Loss: tensor(3.2775)\n",
      "8871 Traning Loss: tensor(3.2744)\n",
      "8872 Traning Loss: tensor(3.2730)\n",
      "8873 Traning Loss: tensor(3.2690)\n",
      "8874 Traning Loss: tensor(3.2785)\n",
      "8875 Traning Loss: tensor(3.2746)\n",
      "8876 Traning Loss: tensor(3.2748)\n",
      "8877 Traning Loss: tensor(3.2721)\n",
      "8878 Traning Loss: tensor(3.2758)\n",
      "8879 Traning Loss: tensor(3.2739)\n",
      "8880 Traning Loss: tensor(3.2694)\n",
      "8881 Traning Loss: tensor(3.2707)\n",
      "8882 Traning Loss: tensor(3.2737)\n",
      "8883 Traning Loss: tensor(3.2754)\n",
      "8884 Traning Loss: tensor(3.2732)\n",
      "8885 Traning Loss: tensor(3.2700)\n",
      "8886 Traning Loss: tensor(3.2737)\n",
      "8887 Traning Loss: tensor(3.2770)\n",
      "8888 Traning Loss: tensor(3.2656)\n",
      "8889 Traning Loss: tensor(3.2719)\n",
      "8890 Traning Loss: tensor(3.2699)\n",
      "8891 Traning Loss: tensor(3.2712)\n",
      "8892 Traning Loss: tensor(3.2704)\n",
      "8893 Traning Loss: tensor(3.2732)\n",
      "8894 Traning Loss: tensor(3.2737)\n",
      "8895 Traning Loss: tensor(3.2712)\n",
      "8896 Traning Loss: tensor(3.2658)\n",
      "8897 Traning Loss: tensor(3.2674)\n",
      "8898 Traning Loss: tensor(3.2667)\n",
      "8899 Traning Loss: tensor(3.2716)\n",
      "8900 Traning Loss: tensor(3.2638)\n",
      "8901 Traning Loss: tensor(3.2688)\n",
      "8902 Traning Loss: tensor(3.2703)\n",
      "8903 Traning Loss: tensor(3.2695)\n",
      "8904 Traning Loss: tensor(3.2696)\n",
      "8905 Traning Loss: tensor(3.2684)\n",
      "8906 Traning Loss: tensor(3.2655)\n",
      "8907 Traning Loss: tensor(3.2690)\n",
      "8908 Traning Loss: tensor(3.2712)\n",
      "8909 Traning Loss: tensor(3.2662)\n",
      "8910 Traning Loss: tensor(3.2614)\n",
      "8911 Traning Loss: tensor(3.2663)\n",
      "8912 Traning Loss: tensor(3.2726)\n",
      "8913 Traning Loss: tensor(3.2710)\n",
      "8914 Traning Loss: tensor(3.2662)\n",
      "8915 Traning Loss: tensor(3.2654)\n",
      "8916 Traning Loss: tensor(3.2701)\n",
      "8917 Traning Loss: tensor(3.2666)\n",
      "8918 Traning Loss: tensor(3.2649)\n",
      "8919 Traning Loss: tensor(3.2699)\n",
      "8920 Traning Loss: tensor(3.2670)\n",
      "8921 Traning Loss: tensor(3.2734)\n",
      "8922 Traning Loss: tensor(3.2623)\n",
      "8923 Traning Loss: tensor(3.2633)\n",
      "8924 Traning Loss: tensor(3.2736)\n",
      "8925 Traning Loss: tensor(3.2607)\n",
      "8926 Traning Loss: tensor(3.2648)\n",
      "8927 Traning Loss: tensor(3.2617)\n",
      "8928 Traning Loss: tensor(3.2643)\n",
      "8929 Traning Loss: tensor(3.2619)\n",
      "8930 Traning Loss: tensor(3.2636)\n",
      "8931 Traning Loss: tensor(3.2622)\n",
      "8932 Traning Loss: tensor(3.2688)\n",
      "8933 Traning Loss: tensor(3.2632)\n",
      "8934 Traning Loss: tensor(3.2585)\n",
      "8935 Traning Loss: tensor(3.2644)\n",
      "8936 Traning Loss: tensor(3.2689)\n",
      "8937 Traning Loss: tensor(3.2621)\n",
      "8938 Traning Loss: tensor(3.2663)\n",
      "8939 Traning Loss: tensor(3.2622)\n",
      "8940 Traning Loss: tensor(3.2622)\n",
      "8941 Traning Loss: tensor(3.2659)\n",
      "8942 Traning Loss: tensor(3.2627)\n",
      "8943 Traning Loss: tensor(3.2604)\n",
      "8944 Traning Loss: tensor(3.2588)\n",
      "8945 Traning Loss: tensor(3.2688)\n",
      "8946 Traning Loss: tensor(3.2701)\n",
      "8947 Traning Loss: tensor(3.2603)\n",
      "8948 Traning Loss: tensor(3.2646)\n",
      "8949 Traning Loss: tensor(3.2613)\n",
      "8950 Traning Loss: tensor(3.2620)\n",
      "8951 Traning Loss: tensor(3.2564)\n",
      "8952 Traning Loss: tensor(3.2615)\n",
      "8953 Traning Loss: tensor(3.2623)\n",
      "8954 Traning Loss: tensor(3.2625)\n",
      "8955 Traning Loss: tensor(3.2533)\n",
      "8956 Traning Loss: tensor(3.2637)\n",
      "8957 Traning Loss: tensor(3.2604)\n",
      "8958 Traning Loss: tensor(3.2607)\n",
      "8959 Traning Loss: tensor(3.2602)\n",
      "8960 Traning Loss: tensor(3.2591)\n",
      "8961 Traning Loss: tensor(3.2629)\n",
      "8962 Traning Loss: tensor(3.2625)\n",
      "8963 Traning Loss: tensor(3.2652)\n",
      "8964 Traning Loss: tensor(3.2590)\n",
      "8965 Traning Loss: tensor(3.2602)\n",
      "8966 Traning Loss: tensor(3.2596)\n",
      "8967 Traning Loss: tensor(3.2556)\n",
      "8968 Traning Loss: tensor(3.2557)\n",
      "8969 Traning Loss: tensor(3.2585)\n",
      "8970 Traning Loss: tensor(3.2585)\n",
      "8971 Traning Loss: tensor(3.2647)\n",
      "8972 Traning Loss: tensor(3.2488)\n",
      "8973 Traning Loss: tensor(3.2558)\n",
      "8974 Traning Loss: tensor(3.2602)\n",
      "8975 Traning Loss: tensor(3.2607)\n",
      "8976 Traning Loss: tensor(3.2646)\n",
      "8977 Traning Loss: tensor(3.2589)\n",
      "8978 Traning Loss: tensor(3.2530)\n",
      "8979 Traning Loss: tensor(3.2569)\n",
      "8980 Traning Loss: tensor(3.2524)\n",
      "8981 Traning Loss: tensor(3.2584)\n",
      "8982 Traning Loss: tensor(3.2566)\n",
      "8983 Traning Loss: tensor(3.2534)\n",
      "8984 Traning Loss: tensor(3.2515)\n",
      "8985 Traning Loss: tensor(3.2544)\n",
      "8986 Traning Loss: tensor(3.2617)\n",
      "8987 Traning Loss: tensor(3.2576)\n",
      "8988 Traning Loss: tensor(3.2586)\n",
      "8989 Traning Loss: tensor(3.2574)\n",
      "8990 Traning Loss: tensor(3.2556)\n",
      "8991 Traning Loss: tensor(3.2544)\n",
      "8992 Traning Loss: tensor(3.2574)\n",
      "8993 Traning Loss: tensor(3.2526)\n",
      "8994 Traning Loss: tensor(3.2559)\n",
      "8995 Traning Loss: tensor(3.2510)\n",
      "8996 Traning Loss: tensor(3.2512)\n",
      "8997 Traning Loss: tensor(3.2605)\n",
      "8998 Traning Loss: tensor(3.2560)\n",
      "8999 Traning Loss: tensor(3.2574)\n",
      "9000 Traning Loss: tensor(3.2549)\n",
      "9001 Traning Loss: tensor(3.2521)\n",
      "9002 Traning Loss: tensor(3.2517)\n",
      "9003 Traning Loss: tensor(3.2574)\n",
      "9004 Traning Loss: tensor(3.2455)\n",
      "9005 Traning Loss: tensor(3.2500)\n",
      "9006 Traning Loss: tensor(3.2492)\n",
      "9007 Traning Loss: tensor(3.2547)\n",
      "9008 Traning Loss: tensor(3.2516)\n",
      "9009 Traning Loss: tensor(3.2498)\n",
      "9010 Traning Loss: tensor(3.2466)\n",
      "9011 Traning Loss: tensor(3.2504)\n",
      "9012 Traning Loss: tensor(3.2513)\n",
      "9013 Traning Loss: tensor(3.2423)\n",
      "9014 Traning Loss: tensor(3.2504)\n",
      "9015 Traning Loss: tensor(3.2543)\n",
      "9016 Traning Loss: tensor(3.2525)\n",
      "9017 Traning Loss: tensor(3.2591)\n",
      "9018 Traning Loss: tensor(3.2523)\n",
      "9019 Traning Loss: tensor(3.2549)\n",
      "9020 Traning Loss: tensor(3.2512)\n",
      "9021 Traning Loss: tensor(3.2499)\n",
      "9022 Traning Loss: tensor(3.2478)\n",
      "9023 Traning Loss: tensor(3.2477)\n",
      "9024 Traning Loss: tensor(3.2447)\n",
      "9025 Traning Loss: tensor(3.2567)\n",
      "9026 Traning Loss: tensor(3.2536)\n",
      "9027 Traning Loss: tensor(3.2503)\n",
      "9028 Traning Loss: tensor(3.2538)\n",
      "9029 Traning Loss: tensor(3.2480)\n",
      "9030 Traning Loss: tensor(3.2476)\n",
      "9031 Traning Loss: tensor(3.2480)\n",
      "9032 Traning Loss: tensor(3.2468)\n",
      "9033 Traning Loss: tensor(3.2492)\n",
      "9034 Traning Loss: tensor(3.2497)\n",
      "9035 Traning Loss: tensor(3.2461)\n",
      "9036 Traning Loss: tensor(3.2402)\n",
      "9037 Traning Loss: tensor(3.2493)\n",
      "9038 Traning Loss: tensor(3.2451)\n",
      "9039 Traning Loss: tensor(3.2506)\n",
      "9040 Traning Loss: tensor(3.2475)\n",
      "9041 Traning Loss: tensor(3.2447)\n",
      "9042 Traning Loss: tensor(3.2405)\n",
      "9043 Traning Loss: tensor(3.2455)\n",
      "9044 Traning Loss: tensor(3.2443)\n",
      "9045 Traning Loss: tensor(3.2515)\n",
      "9046 Traning Loss: tensor(3.2452)\n",
      "9047 Traning Loss: tensor(3.2475)\n",
      "9048 Traning Loss: tensor(3.2454)\n",
      "9049 Traning Loss: tensor(3.2504)\n",
      "9050 Traning Loss: tensor(3.2602)\n",
      "9051 Traning Loss: tensor(3.2405)\n",
      "9052 Traning Loss: tensor(3.2462)\n",
      "9053 Traning Loss: tensor(3.2450)\n",
      "9054 Traning Loss: tensor(3.2437)\n",
      "9055 Traning Loss: tensor(3.2430)\n",
      "9056 Traning Loss: tensor(3.2517)\n",
      "9057 Traning Loss: tensor(3.2432)\n",
      "9058 Traning Loss: tensor(3.2393)\n",
      "9059 Traning Loss: tensor(3.2464)\n",
      "9060 Traning Loss: tensor(3.2482)\n",
      "9061 Traning Loss: tensor(3.2521)\n",
      "9062 Traning Loss: tensor(3.2414)\n",
      "9063 Traning Loss: tensor(3.2414)\n",
      "9064 Traning Loss: tensor(3.2463)\n",
      "9065 Traning Loss: tensor(3.2414)\n",
      "9066 Traning Loss: tensor(3.2417)\n",
      "9067 Traning Loss: tensor(3.2422)\n",
      "9068 Traning Loss: tensor(3.2414)\n",
      "9069 Traning Loss: tensor(3.2423)\n",
      "9070 Traning Loss: tensor(3.2461)\n",
      "9071 Traning Loss: tensor(3.2409)\n",
      "9072 Traning Loss: tensor(3.2392)\n",
      "9073 Traning Loss: tensor(3.2432)\n",
      "9074 Traning Loss: tensor(3.2431)\n",
      "9075 Traning Loss: tensor(3.2395)\n",
      "9076 Traning Loss: tensor(3.2427)\n",
      "9077 Traning Loss: tensor(3.2449)\n",
      "9078 Traning Loss: tensor(3.2423)\n",
      "9079 Traning Loss: tensor(3.2433)\n",
      "9080 Traning Loss: tensor(3.2428)\n",
      "9081 Traning Loss: tensor(3.2473)\n",
      "9082 Traning Loss: tensor(3.2424)\n",
      "9083 Traning Loss: tensor(3.2481)\n",
      "9084 Traning Loss: tensor(3.2400)\n",
      "9085 Traning Loss: tensor(3.2459)\n",
      "9086 Traning Loss: tensor(3.2330)\n",
      "9087 Traning Loss: tensor(3.2399)\n",
      "9088 Traning Loss: tensor(3.2425)\n",
      "9089 Traning Loss: tensor(3.2475)\n",
      "9090 Traning Loss: tensor(3.2486)\n",
      "9091 Traning Loss: tensor(3.2337)\n",
      "9092 Traning Loss: tensor(3.2429)\n",
      "9093 Traning Loss: tensor(3.2337)\n",
      "9094 Traning Loss: tensor(3.2377)\n",
      "9095 Traning Loss: tensor(3.2386)\n",
      "9096 Traning Loss: tensor(3.2325)\n",
      "9097 Traning Loss: tensor(3.2369)\n",
      "9098 Traning Loss: tensor(3.2345)\n",
      "9099 Traning Loss: tensor(3.2335)\n",
      "9100 Traning Loss: tensor(3.2425)\n",
      "9101 Traning Loss: tensor(3.2420)\n",
      "9102 Traning Loss: tensor(3.2351)\n",
      "9103 Traning Loss: tensor(3.2394)\n",
      "9104 Traning Loss: tensor(3.2382)\n",
      "9105 Traning Loss: tensor(3.2416)\n",
      "9106 Traning Loss: tensor(3.2352)\n",
      "9107 Traning Loss: tensor(3.2290)\n",
      "9108 Traning Loss: tensor(3.2383)\n",
      "9109 Traning Loss: tensor(3.2329)\n",
      "9110 Traning Loss: tensor(3.2465)\n",
      "9111 Traning Loss: tensor(3.2397)\n",
      "9112 Traning Loss: tensor(3.2447)\n",
      "9113 Traning Loss: tensor(3.2372)\n",
      "9114 Traning Loss: tensor(3.2341)\n",
      "9115 Traning Loss: tensor(3.2385)\n",
      "9116 Traning Loss: tensor(3.2253)\n",
      "9117 Traning Loss: tensor(3.2400)\n",
      "9118 Traning Loss: tensor(3.2315)\n",
      "9119 Traning Loss: tensor(3.2411)\n",
      "9120 Traning Loss: tensor(3.2352)\n",
      "9121 Traning Loss: tensor(3.2284)\n",
      "9122 Traning Loss: tensor(3.2445)\n",
      "9123 Traning Loss: tensor(3.2399)\n",
      "9124 Traning Loss: tensor(3.2364)\n",
      "9125 Traning Loss: tensor(3.2456)\n",
      "9126 Traning Loss: tensor(3.2331)\n",
      "9127 Traning Loss: tensor(3.2297)\n",
      "9128 Traning Loss: tensor(3.2368)\n",
      "9129 Traning Loss: tensor(3.2368)\n",
      "9130 Traning Loss: tensor(3.2373)\n",
      "9131 Traning Loss: tensor(3.2309)\n",
      "9132 Traning Loss: tensor(3.2289)\n",
      "9133 Traning Loss: tensor(3.2369)\n",
      "9134 Traning Loss: tensor(3.2358)\n",
      "9135 Traning Loss: tensor(3.2272)\n",
      "9136 Traning Loss: tensor(3.2259)\n",
      "9137 Traning Loss: tensor(3.2328)\n",
      "9138 Traning Loss: tensor(3.2306)\n",
      "9139 Traning Loss: tensor(3.2277)\n",
      "9140 Traning Loss: tensor(3.2363)\n",
      "9141 Traning Loss: tensor(3.2348)\n",
      "9142 Traning Loss: tensor(3.2342)\n",
      "9143 Traning Loss: tensor(3.2340)\n",
      "9144 Traning Loss: tensor(3.2324)\n",
      "9145 Traning Loss: tensor(3.2267)\n",
      "9146 Traning Loss: tensor(3.2203)\n",
      "9147 Traning Loss: tensor(3.2327)\n",
      "9148 Traning Loss: tensor(3.2284)\n",
      "9149 Traning Loss: tensor(3.2350)\n",
      "9150 Traning Loss: tensor(3.2231)\n",
      "9151 Traning Loss: tensor(3.2353)\n",
      "9152 Traning Loss: tensor(3.2249)\n",
      "9153 Traning Loss: tensor(3.2288)\n",
      "9154 Traning Loss: tensor(3.2261)\n",
      "9155 Traning Loss: tensor(3.2194)\n",
      "9156 Traning Loss: tensor(3.2314)\n",
      "9157 Traning Loss: tensor(3.2263)\n",
      "9158 Traning Loss: tensor(3.2285)\n",
      "9159 Traning Loss: tensor(3.2273)\n",
      "9160 Traning Loss: tensor(3.2326)\n",
      "9161 Traning Loss: tensor(3.2215)\n",
      "9162 Traning Loss: tensor(3.2289)\n",
      "9163 Traning Loss: tensor(3.2255)\n",
      "9164 Traning Loss: tensor(3.2265)\n",
      "9165 Traning Loss: tensor(3.2301)\n",
      "9166 Traning Loss: tensor(3.2320)\n",
      "9167 Traning Loss: tensor(3.2297)\n",
      "9168 Traning Loss: tensor(3.2328)\n",
      "9169 Traning Loss: tensor(3.2172)\n",
      "9170 Traning Loss: tensor(3.2293)\n",
      "9171 Traning Loss: tensor(3.2243)\n",
      "9172 Traning Loss: tensor(3.2310)\n",
      "9173 Traning Loss: tensor(3.2234)\n",
      "9174 Traning Loss: tensor(3.2271)\n",
      "9175 Traning Loss: tensor(3.2217)\n",
      "9176 Traning Loss: tensor(3.2282)\n",
      "9177 Traning Loss: tensor(3.2174)\n",
      "9178 Traning Loss: tensor(3.2248)\n",
      "9179 Traning Loss: tensor(3.2319)\n",
      "9180 Traning Loss: tensor(3.2249)\n",
      "9181 Traning Loss: tensor(3.2193)\n",
      "9182 Traning Loss: tensor(3.2175)\n",
      "9183 Traning Loss: tensor(3.2179)\n",
      "9184 Traning Loss: tensor(3.2255)\n",
      "9185 Traning Loss: tensor(3.2284)\n",
      "9186 Traning Loss: tensor(3.2282)\n",
      "9187 Traning Loss: tensor(3.2334)\n",
      "9188 Traning Loss: tensor(3.2280)\n",
      "9189 Traning Loss: tensor(3.2294)\n",
      "9190 Traning Loss: tensor(3.2321)\n",
      "9191 Traning Loss: tensor(3.2340)\n",
      "9192 Traning Loss: tensor(3.2180)\n",
      "9193 Traning Loss: tensor(3.2225)\n",
      "9194 Traning Loss: tensor(3.2207)\n",
      "9195 Traning Loss: tensor(3.2202)\n",
      "9196 Traning Loss: tensor(3.2331)\n",
      "9197 Traning Loss: tensor(3.2296)\n",
      "9198 Traning Loss: tensor(3.2282)\n",
      "9199 Traning Loss: tensor(3.2268)\n",
      "9200 Traning Loss: tensor(3.2179)\n",
      "9201 Traning Loss: tensor(3.2220)\n",
      "9202 Traning Loss: tensor(3.2192)\n",
      "9203 Traning Loss: tensor(3.2234)\n",
      "9204 Traning Loss: tensor(3.2144)\n",
      "9205 Traning Loss: tensor(3.2227)\n",
      "9206 Traning Loss: tensor(3.2184)\n",
      "9207 Traning Loss: tensor(3.2189)\n",
      "9208 Traning Loss: tensor(3.2242)\n",
      "9209 Traning Loss: tensor(3.2190)\n",
      "9210 Traning Loss: tensor(3.2258)\n",
      "9211 Traning Loss: tensor(3.2190)\n",
      "9212 Traning Loss: tensor(3.2176)\n",
      "9213 Traning Loss: tensor(3.2208)\n",
      "9214 Traning Loss: tensor(3.2265)\n",
      "9215 Traning Loss: tensor(3.2243)\n",
      "9216 Traning Loss: tensor(3.2172)\n",
      "9217 Traning Loss: tensor(3.2190)\n",
      "9218 Traning Loss: tensor(3.2206)\n",
      "9219 Traning Loss: tensor(3.2072)\n",
      "9220 Traning Loss: tensor(3.2210)\n",
      "9221 Traning Loss: tensor(3.2198)\n",
      "9222 Traning Loss: tensor(3.2180)\n",
      "9223 Traning Loss: tensor(3.2321)\n",
      "9224 Traning Loss: tensor(3.2254)\n",
      "9225 Traning Loss: tensor(3.2204)\n",
      "9226 Traning Loss: tensor(3.2292)\n",
      "9227 Traning Loss: tensor(3.2227)\n",
      "9228 Traning Loss: tensor(3.2156)\n",
      "9229 Traning Loss: tensor(3.2158)\n",
      "9230 Traning Loss: tensor(3.2164)\n",
      "9231 Traning Loss: tensor(3.2207)\n",
      "9232 Traning Loss: tensor(3.2216)\n",
      "9233 Traning Loss: tensor(3.2104)\n",
      "9234 Traning Loss: tensor(3.2246)\n",
      "9235 Traning Loss: tensor(3.2172)\n",
      "9236 Traning Loss: tensor(3.2173)\n",
      "9237 Traning Loss: tensor(3.2151)\n",
      "9238 Traning Loss: tensor(3.2124)\n",
      "9239 Traning Loss: tensor(3.2268)\n",
      "9240 Traning Loss: tensor(3.2177)\n",
      "9241 Traning Loss: tensor(3.2170)\n",
      "9242 Traning Loss: tensor(3.2167)\n",
      "9243 Traning Loss: tensor(3.2146)\n",
      "9244 Traning Loss: tensor(3.2209)\n",
      "9245 Traning Loss: tensor(3.2236)\n",
      "9246 Traning Loss: tensor(3.2136)\n",
      "9247 Traning Loss: tensor(3.2102)\n",
      "9248 Traning Loss: tensor(3.2157)\n",
      "9249 Traning Loss: tensor(3.2180)\n",
      "9250 Traning Loss: tensor(3.2129)\n",
      "9251 Traning Loss: tensor(3.2137)\n",
      "9252 Traning Loss: tensor(3.2179)\n",
      "9253 Traning Loss: tensor(3.2167)\n",
      "9254 Traning Loss: tensor(3.2257)\n",
      "9255 Traning Loss: tensor(3.2154)\n",
      "9256 Traning Loss: tensor(3.2133)\n",
      "9257 Traning Loss: tensor(3.2163)\n",
      "9258 Traning Loss: tensor(3.2158)\n",
      "9259 Traning Loss: tensor(3.2138)\n",
      "9260 Traning Loss: tensor(3.2128)\n",
      "9261 Traning Loss: tensor(3.2121)\n",
      "9262 Traning Loss: tensor(3.2152)\n",
      "9263 Traning Loss: tensor(3.2263)\n",
      "9264 Traning Loss: tensor(3.2195)\n",
      "9265 Traning Loss: tensor(3.2155)\n",
      "9266 Traning Loss: tensor(3.2104)\n",
      "9267 Traning Loss: tensor(3.2075)\n",
      "9268 Traning Loss: tensor(3.2125)\n",
      "9269 Traning Loss: tensor(3.2302)\n",
      "9270 Traning Loss: tensor(3.2212)\n",
      "9271 Traning Loss: tensor(3.2193)\n",
      "9272 Traning Loss: tensor(3.2091)\n",
      "9273 Traning Loss: tensor(3.2105)\n",
      "9274 Traning Loss: tensor(3.2078)\n",
      "9275 Traning Loss: tensor(3.2053)\n",
      "9276 Traning Loss: tensor(3.2096)\n",
      "9277 Traning Loss: tensor(3.2065)\n",
      "9278 Traning Loss: tensor(3.2048)\n",
      "9279 Traning Loss: tensor(3.2182)\n",
      "9280 Traning Loss: tensor(3.2090)\n",
      "9281 Traning Loss: tensor(3.2108)\n",
      "9282 Traning Loss: tensor(3.2055)\n",
      "9283 Traning Loss: tensor(3.2110)\n",
      "9284 Traning Loss: tensor(3.2073)\n",
      "9285 Traning Loss: tensor(3.2228)\n",
      "9286 Traning Loss: tensor(3.2080)\n",
      "9287 Traning Loss: tensor(3.2052)\n",
      "9288 Traning Loss: tensor(3.2199)\n",
      "9289 Traning Loss: tensor(3.2137)\n",
      "9290 Traning Loss: tensor(3.2058)\n",
      "9291 Traning Loss: tensor(3.2075)\n",
      "9292 Traning Loss: tensor(3.2051)\n",
      "9293 Traning Loss: tensor(3.2147)\n",
      "9294 Traning Loss: tensor(3.2011)\n",
      "9295 Traning Loss: tensor(3.2099)\n",
      "9296 Traning Loss: tensor(3.2081)\n",
      "9297 Traning Loss: tensor(3.2079)\n",
      "9298 Traning Loss: tensor(3.2125)\n",
      "9299 Traning Loss: tensor(3.2028)\n",
      "9300 Traning Loss: tensor(3.2022)\n",
      "9301 Traning Loss: tensor(3.2144)\n",
      "9302 Traning Loss: tensor(3.2126)\n",
      "9303 Traning Loss: tensor(3.2139)\n",
      "9304 Traning Loss: tensor(3.2028)\n",
      "9305 Traning Loss: tensor(3.2119)\n",
      "9306 Traning Loss: tensor(3.2070)\n",
      "9307 Traning Loss: tensor(3.2079)\n",
      "9308 Traning Loss: tensor(3.2156)\n",
      "9309 Traning Loss: tensor(3.2083)\n",
      "9310 Traning Loss: tensor(3.2070)\n",
      "9311 Traning Loss: tensor(3.2104)\n",
      "9312 Traning Loss: tensor(3.2109)\n",
      "9313 Traning Loss: tensor(3.2042)\n",
      "9314 Traning Loss: tensor(3.2045)\n",
      "9315 Traning Loss: tensor(3.2104)\n",
      "9316 Traning Loss: tensor(3.2064)\n",
      "9317 Traning Loss: tensor(3.2064)\n",
      "9318 Traning Loss: tensor(3.2018)\n",
      "9319 Traning Loss: tensor(3.2007)\n",
      "9320 Traning Loss: tensor(3.2118)\n",
      "9321 Traning Loss: tensor(3.2061)\n",
      "9322 Traning Loss: tensor(3.1993)\n",
      "9323 Traning Loss: tensor(3.2053)\n",
      "9324 Traning Loss: tensor(3.2072)\n",
      "9325 Traning Loss: tensor(3.2185)\n",
      "9326 Traning Loss: tensor(3.2030)\n",
      "9327 Traning Loss: tensor(3.2219)\n",
      "9328 Traning Loss: tensor(3.2075)\n",
      "9329 Traning Loss: tensor(3.1930)\n",
      "9330 Traning Loss: tensor(3.2131)\n",
      "9331 Traning Loss: tensor(3.2225)\n",
      "9332 Traning Loss: tensor(3.2076)\n",
      "9333 Traning Loss: tensor(3.2041)\n",
      "9334 Traning Loss: tensor(3.2025)\n",
      "9335 Traning Loss: tensor(3.1989)\n",
      "9336 Traning Loss: tensor(3.2046)\n",
      "9337 Traning Loss: tensor(3.2065)\n",
      "9338 Traning Loss: tensor(3.2090)\n",
      "9339 Traning Loss: tensor(3.2039)\n",
      "9340 Traning Loss: tensor(3.2166)\n",
      "9341 Traning Loss: tensor(3.2078)\n",
      "9342 Traning Loss: tensor(3.2073)\n",
      "9343 Traning Loss: tensor(3.2035)\n",
      "9344 Traning Loss: tensor(3.2078)\n",
      "9345 Traning Loss: tensor(3.2020)\n",
      "9346 Traning Loss: tensor(3.2036)\n",
      "9347 Traning Loss: tensor(3.2048)\n",
      "9348 Traning Loss: tensor(3.2109)\n",
      "9349 Traning Loss: tensor(3.1983)\n",
      "9350 Traning Loss: tensor(3.2058)\n",
      "9351 Traning Loss: tensor(3.2099)\n",
      "9352 Traning Loss: tensor(3.2088)\n",
      "9353 Traning Loss: tensor(3.2028)\n",
      "9354 Traning Loss: tensor(3.2085)\n",
      "9355 Traning Loss: tensor(3.2044)\n",
      "9356 Traning Loss: tensor(3.1960)\n",
      "9357 Traning Loss: tensor(3.2095)\n",
      "9358 Traning Loss: tensor(3.1982)\n",
      "9359 Traning Loss: tensor(3.2009)\n",
      "9360 Traning Loss: tensor(3.2021)\n",
      "9361 Traning Loss: tensor(3.2019)\n",
      "9362 Traning Loss: tensor(3.2010)\n",
      "9363 Traning Loss: tensor(3.2065)\n",
      "9364 Traning Loss: tensor(3.1967)\n",
      "9365 Traning Loss: tensor(3.1976)\n",
      "9366 Traning Loss: tensor(3.1997)\n",
      "9367 Traning Loss: tensor(3.1984)\n",
      "9368 Traning Loss: tensor(3.1955)\n",
      "9369 Traning Loss: tensor(3.2020)\n",
      "9370 Traning Loss: tensor(3.2037)\n",
      "9371 Traning Loss: tensor(3.2072)\n",
      "9372 Traning Loss: tensor(3.2166)\n",
      "9373 Traning Loss: tensor(3.1946)\n",
      "9374 Traning Loss: tensor(3.2006)\n",
      "9375 Traning Loss: tensor(3.1989)\n",
      "9376 Traning Loss: tensor(3.1995)\n",
      "9377 Traning Loss: tensor(3.2025)\n",
      "9378 Traning Loss: tensor(3.1944)\n",
      "9379 Traning Loss: tensor(3.2054)\n",
      "9380 Traning Loss: tensor(3.2014)\n",
      "9381 Traning Loss: tensor(3.1987)\n",
      "9382 Traning Loss: tensor(3.2100)\n",
      "9383 Traning Loss: tensor(3.2036)\n",
      "9384 Traning Loss: tensor(3.2021)\n",
      "9385 Traning Loss: tensor(3.1861)\n",
      "9386 Traning Loss: tensor(3.2024)\n",
      "9387 Traning Loss: tensor(3.2021)\n",
      "9388 Traning Loss: tensor(3.1924)\n",
      "9389 Traning Loss: tensor(3.1915)\n",
      "9390 Traning Loss: tensor(3.1915)\n",
      "9391 Traning Loss: tensor(3.2092)\n",
      "9392 Traning Loss: tensor(3.1978)\n",
      "9393 Traning Loss: tensor(3.1942)\n",
      "9394 Traning Loss: tensor(3.2051)\n",
      "9395 Traning Loss: tensor(3.1993)\n",
      "9396 Traning Loss: tensor(3.1982)\n",
      "9397 Traning Loss: tensor(3.1987)\n",
      "9398 Traning Loss: tensor(3.1967)\n",
      "9399 Traning Loss: tensor(3.2031)\n",
      "9400 Traning Loss: tensor(3.2038)\n",
      "9401 Traning Loss: tensor(3.1873)\n",
      "9402 Traning Loss: tensor(3.2046)\n",
      "9403 Traning Loss: tensor(3.1894)\n",
      "9404 Traning Loss: tensor(3.1931)\n",
      "9405 Traning Loss: tensor(3.1940)\n",
      "9406 Traning Loss: tensor(3.2021)\n",
      "9407 Traning Loss: tensor(3.2011)\n",
      "9408 Traning Loss: tensor(3.2038)\n",
      "9409 Traning Loss: tensor(3.1976)\n",
      "9410 Traning Loss: tensor(3.2010)\n",
      "9411 Traning Loss: tensor(3.1989)\n",
      "9412 Traning Loss: tensor(3.2091)\n",
      "9413 Traning Loss: tensor(3.1953)\n",
      "9414 Traning Loss: tensor(3.1897)\n",
      "9415 Traning Loss: tensor(3.1938)\n",
      "9416 Traning Loss: tensor(3.2021)\n",
      "9417 Traning Loss: tensor(3.1840)\n",
      "9418 Traning Loss: tensor(3.2024)\n",
      "9419 Traning Loss: tensor(3.2008)\n",
      "9420 Traning Loss: tensor(3.1896)\n",
      "9421 Traning Loss: tensor(3.1921)\n",
      "9422 Traning Loss: tensor(3.1858)\n",
      "9423 Traning Loss: tensor(3.2010)\n",
      "9424 Traning Loss: tensor(3.1933)\n",
      "9425 Traning Loss: tensor(3.1979)\n",
      "9426 Traning Loss: tensor(3.1953)\n",
      "9427 Traning Loss: tensor(3.1964)\n",
      "9428 Traning Loss: tensor(3.1892)\n",
      "9429 Traning Loss: tensor(3.1989)\n",
      "9430 Traning Loss: tensor(3.1916)\n",
      "9431 Traning Loss: tensor(3.1930)\n",
      "9432 Traning Loss: tensor(3.1885)\n",
      "9433 Traning Loss: tensor(3.1958)\n",
      "9434 Traning Loss: tensor(3.1923)\n",
      "9435 Traning Loss: tensor(3.1911)\n",
      "9436 Traning Loss: tensor(3.1881)\n",
      "9437 Traning Loss: tensor(3.1887)\n",
      "9438 Traning Loss: tensor(3.1949)\n",
      "9439 Traning Loss: tensor(3.1919)\n",
      "9440 Traning Loss: tensor(3.1870)\n",
      "9441 Traning Loss: tensor(3.1915)\n",
      "9442 Traning Loss: tensor(3.2013)\n",
      "9443 Traning Loss: tensor(3.1875)\n",
      "9444 Traning Loss: tensor(3.2004)\n",
      "9445 Traning Loss: tensor(3.1884)\n",
      "9446 Traning Loss: tensor(3.1954)\n",
      "9447 Traning Loss: tensor(3.1970)\n",
      "9448 Traning Loss: tensor(3.1936)\n",
      "9449 Traning Loss: tensor(3.1854)\n",
      "9450 Traning Loss: tensor(3.1928)\n",
      "9451 Traning Loss: tensor(3.1962)\n",
      "9452 Traning Loss: tensor(3.1973)\n",
      "9453 Traning Loss: tensor(3.1894)\n",
      "9454 Traning Loss: tensor(3.1927)\n",
      "9455 Traning Loss: tensor(3.1856)\n",
      "9456 Traning Loss: tensor(3.1860)\n",
      "9457 Traning Loss: tensor(3.1913)\n",
      "9458 Traning Loss: tensor(3.1939)\n",
      "9459 Traning Loss: tensor(3.1896)\n",
      "9460 Traning Loss: tensor(3.1819)\n",
      "9461 Traning Loss: tensor(3.1961)\n",
      "9462 Traning Loss: tensor(3.1873)\n",
      "9463 Traning Loss: tensor(3.1817)\n",
      "9464 Traning Loss: tensor(3.1859)\n",
      "9465 Traning Loss: tensor(3.1926)\n",
      "9466 Traning Loss: tensor(3.1917)\n",
      "9467 Traning Loss: tensor(3.1971)\n",
      "9468 Traning Loss: tensor(3.1853)\n",
      "9469 Traning Loss: tensor(3.1840)\n",
      "9470 Traning Loss: tensor(3.1849)\n",
      "9471 Traning Loss: tensor(3.2090)\n",
      "9472 Traning Loss: tensor(3.1906)\n",
      "9473 Traning Loss: tensor(3.1883)\n",
      "9474 Traning Loss: tensor(3.1894)\n",
      "9475 Traning Loss: tensor(3.1886)\n",
      "9476 Traning Loss: tensor(3.1909)\n",
      "9477 Traning Loss: tensor(3.1866)\n",
      "9478 Traning Loss: tensor(3.1806)\n",
      "9479 Traning Loss: tensor(3.1893)\n",
      "9480 Traning Loss: tensor(3.1802)\n",
      "9481 Traning Loss: tensor(3.1841)\n",
      "9482 Traning Loss: tensor(3.1882)\n",
      "9483 Traning Loss: tensor(3.1905)\n",
      "9484 Traning Loss: tensor(3.1902)\n",
      "9485 Traning Loss: tensor(3.1913)\n",
      "9486 Traning Loss: tensor(3.1798)\n",
      "9487 Traning Loss: tensor(3.1897)\n",
      "9488 Traning Loss: tensor(3.1843)\n",
      "9489 Traning Loss: tensor(3.1858)\n",
      "9490 Traning Loss: tensor(3.1837)\n",
      "9491 Traning Loss: tensor(3.1840)\n",
      "9492 Traning Loss: tensor(3.1925)\n",
      "9493 Traning Loss: tensor(3.1832)\n",
      "9494 Traning Loss: tensor(3.1853)\n",
      "9495 Traning Loss: tensor(3.1901)\n",
      "9496 Traning Loss: tensor(3.1789)\n",
      "9497 Traning Loss: tensor(3.1807)\n",
      "9498 Traning Loss: tensor(3.1823)\n",
      "9499 Traning Loss: tensor(3.1779)\n",
      "9500 Traning Loss: tensor(3.1925)\n",
      "9501 Traning Loss: tensor(3.1855)\n",
      "9502 Traning Loss: tensor(3.1866)\n",
      "9503 Traning Loss: tensor(3.1815)\n",
      "9504 Traning Loss: tensor(3.1853)\n",
      "9505 Traning Loss: tensor(3.1857)\n",
      "9506 Traning Loss: tensor(3.1815)\n",
      "9507 Traning Loss: tensor(3.1850)\n",
      "9508 Traning Loss: tensor(3.1825)\n",
      "9509 Traning Loss: tensor(3.1830)\n",
      "9510 Traning Loss: tensor(3.1811)\n",
      "9511 Traning Loss: tensor(3.1852)\n",
      "9512 Traning Loss: tensor(3.1815)\n",
      "9513 Traning Loss: tensor(3.1930)\n",
      "9514 Traning Loss: tensor(3.1750)\n",
      "9515 Traning Loss: tensor(3.1941)\n",
      "9516 Traning Loss: tensor(3.1773)\n",
      "9517 Traning Loss: tensor(3.1826)\n",
      "9518 Traning Loss: tensor(3.1741)\n",
      "9519 Traning Loss: tensor(3.1897)\n",
      "9520 Traning Loss: tensor(3.1808)\n",
      "9521 Traning Loss: tensor(3.1794)\n",
      "9522 Traning Loss: tensor(3.1745)\n",
      "9523 Traning Loss: tensor(3.1849)\n",
      "9524 Traning Loss: tensor(3.1812)\n",
      "9525 Traning Loss: tensor(3.1732)\n",
      "9526 Traning Loss: tensor(3.1772)\n",
      "9527 Traning Loss: tensor(3.1740)\n",
      "9528 Traning Loss: tensor(3.1874)\n",
      "9529 Traning Loss: tensor(3.1907)\n",
      "9530 Traning Loss: tensor(3.1741)\n",
      "9531 Traning Loss: tensor(3.1821)\n",
      "9532 Traning Loss: tensor(3.1946)\n",
      "9533 Traning Loss: tensor(3.1780)\n",
      "9534 Traning Loss: tensor(3.1901)\n",
      "9535 Traning Loss: tensor(3.1763)\n",
      "9536 Traning Loss: tensor(3.1825)\n",
      "9537 Traning Loss: tensor(3.1771)\n",
      "9538 Traning Loss: tensor(3.1784)\n",
      "9539 Traning Loss: tensor(3.1860)\n",
      "9540 Traning Loss: tensor(3.1928)\n",
      "9541 Traning Loss: tensor(3.1822)\n",
      "9542 Traning Loss: tensor(3.1776)\n",
      "9543 Traning Loss: tensor(3.1799)\n",
      "9544 Traning Loss: tensor(3.1834)\n",
      "9545 Traning Loss: tensor(3.1839)\n",
      "9546 Traning Loss: tensor(3.1849)\n",
      "9547 Traning Loss: tensor(3.1773)\n",
      "9548 Traning Loss: tensor(3.1821)\n",
      "9549 Traning Loss: tensor(3.1845)\n",
      "9550 Traning Loss: tensor(3.1834)\n",
      "9551 Traning Loss: tensor(3.1844)\n",
      "9552 Traning Loss: tensor(3.1793)\n",
      "9553 Traning Loss: tensor(3.1787)\n",
      "9554 Traning Loss: tensor(3.1740)\n",
      "9555 Traning Loss: tensor(3.1742)\n",
      "9556 Traning Loss: tensor(3.1799)\n",
      "9557 Traning Loss: tensor(3.1751)\n",
      "9558 Traning Loss: tensor(3.1819)\n",
      "9559 Traning Loss: tensor(3.1820)\n",
      "9560 Traning Loss: tensor(3.1795)\n",
      "9561 Traning Loss: tensor(3.1811)\n",
      "9562 Traning Loss: tensor(3.1828)\n",
      "9563 Traning Loss: tensor(3.1826)\n",
      "9564 Traning Loss: tensor(3.1824)\n",
      "9565 Traning Loss: tensor(3.1745)\n",
      "9566 Traning Loss: tensor(3.1703)\n",
      "9567 Traning Loss: tensor(3.1812)\n",
      "9568 Traning Loss: tensor(3.1794)\n",
      "9569 Traning Loss: tensor(3.1776)\n",
      "9570 Traning Loss: tensor(3.1797)\n",
      "9571 Traning Loss: tensor(3.1868)\n",
      "9572 Traning Loss: tensor(3.1824)\n",
      "9573 Traning Loss: tensor(3.1804)\n",
      "9574 Traning Loss: tensor(3.1791)\n",
      "9575 Traning Loss: tensor(3.1773)\n",
      "9576 Traning Loss: tensor(3.1801)\n",
      "9577 Traning Loss: tensor(3.1709)\n",
      "9578 Traning Loss: tensor(3.1788)\n",
      "9579 Traning Loss: tensor(3.1777)\n",
      "9580 Traning Loss: tensor(3.1847)\n",
      "9581 Traning Loss: tensor(3.1701)\n",
      "9582 Traning Loss: tensor(3.1681)\n",
      "9583 Traning Loss: tensor(3.1751)\n",
      "9584 Traning Loss: tensor(3.1721)\n",
      "9585 Traning Loss: tensor(3.1590)\n",
      "9586 Traning Loss: tensor(3.1852)\n",
      "9587 Traning Loss: tensor(3.1702)\n",
      "9588 Traning Loss: tensor(3.1803)\n",
      "9589 Traning Loss: tensor(3.1723)\n",
      "9590 Traning Loss: tensor(3.1663)\n",
      "9591 Traning Loss: tensor(3.1815)\n",
      "9592 Traning Loss: tensor(3.1690)\n",
      "9593 Traning Loss: tensor(3.1695)\n",
      "9594 Traning Loss: tensor(3.1627)\n",
      "9595 Traning Loss: tensor(3.1875)\n",
      "9596 Traning Loss: tensor(3.1746)\n",
      "9597 Traning Loss: tensor(3.1788)\n",
      "9598 Traning Loss: tensor(3.1847)\n",
      "9599 Traning Loss: tensor(3.1710)\n",
      "9600 Traning Loss: tensor(3.1657)\n",
      "9601 Traning Loss: tensor(3.1732)\n",
      "9602 Traning Loss: tensor(3.1812)\n",
      "9603 Traning Loss: tensor(3.1652)\n",
      "9604 Traning Loss: tensor(3.1750)\n",
      "9605 Traning Loss: tensor(3.1791)\n",
      "9606 Traning Loss: tensor(3.1771)\n",
      "9607 Traning Loss: tensor(3.1786)\n",
      "9608 Traning Loss: tensor(3.1761)\n",
      "9609 Traning Loss: tensor(3.1737)\n",
      "9610 Traning Loss: tensor(3.1743)\n",
      "9611 Traning Loss: tensor(3.1765)\n",
      "9612 Traning Loss: tensor(3.1773)\n",
      "9613 Traning Loss: tensor(3.1758)\n",
      "9614 Traning Loss: tensor(3.1701)\n",
      "9615 Traning Loss: tensor(3.1664)\n",
      "9616 Traning Loss: tensor(3.1717)\n",
      "9617 Traning Loss: tensor(3.1650)\n",
      "9618 Traning Loss: tensor(3.1734)\n",
      "9619 Traning Loss: tensor(3.1707)\n",
      "9620 Traning Loss: tensor(3.1703)\n",
      "9621 Traning Loss: tensor(3.1726)\n",
      "9622 Traning Loss: tensor(3.1831)\n",
      "9623 Traning Loss: tensor(3.1613)\n",
      "9624 Traning Loss: tensor(3.1735)\n",
      "9625 Traning Loss: tensor(3.1712)\n",
      "9626 Traning Loss: tensor(3.1763)\n",
      "9627 Traning Loss: tensor(3.1861)\n",
      "9628 Traning Loss: tensor(3.1760)\n",
      "9629 Traning Loss: tensor(3.1722)\n",
      "9630 Traning Loss: tensor(3.1713)\n",
      "9631 Traning Loss: tensor(3.1711)\n",
      "9632 Traning Loss: tensor(3.1739)\n",
      "9633 Traning Loss: tensor(3.1741)\n",
      "9634 Traning Loss: tensor(3.1713)\n",
      "9635 Traning Loss: tensor(3.1620)\n",
      "9636 Traning Loss: tensor(3.1631)\n",
      "9637 Traning Loss: tensor(3.1793)\n",
      "9638 Traning Loss: tensor(3.1792)\n",
      "9639 Traning Loss: tensor(3.1710)\n",
      "9640 Traning Loss: tensor(3.1627)\n",
      "9641 Traning Loss: tensor(3.1655)\n",
      "9642 Traning Loss: tensor(3.1586)\n",
      "9643 Traning Loss: tensor(3.1688)\n",
      "9644 Traning Loss: tensor(3.1688)\n",
      "9645 Traning Loss: tensor(3.1763)\n",
      "9646 Traning Loss: tensor(3.1708)\n",
      "9647 Traning Loss: tensor(3.1681)\n",
      "9648 Traning Loss: tensor(3.1697)\n",
      "9649 Traning Loss: tensor(3.1632)\n",
      "9650 Traning Loss: tensor(3.1695)\n",
      "9651 Traning Loss: tensor(3.1689)\n",
      "9652 Traning Loss: tensor(3.1690)\n",
      "9653 Traning Loss: tensor(3.1635)\n",
      "9654 Traning Loss: tensor(3.1754)\n",
      "9655 Traning Loss: tensor(3.1670)\n",
      "9656 Traning Loss: tensor(3.1811)\n",
      "9657 Traning Loss: tensor(3.1772)\n",
      "9658 Traning Loss: tensor(3.1620)\n",
      "9659 Traning Loss: tensor(3.1712)\n",
      "9660 Traning Loss: tensor(3.1639)\n",
      "9661 Traning Loss: tensor(3.1730)\n",
      "9662 Traning Loss: tensor(3.1644)\n",
      "9663 Traning Loss: tensor(3.1667)\n",
      "9664 Traning Loss: tensor(3.1663)\n",
      "9665 Traning Loss: tensor(3.1701)\n",
      "9666 Traning Loss: tensor(3.1738)\n",
      "9667 Traning Loss: tensor(3.1594)\n",
      "9668 Traning Loss: tensor(3.1722)\n",
      "9669 Traning Loss: tensor(3.1684)\n",
      "9670 Traning Loss: tensor(3.1638)\n",
      "9671 Traning Loss: tensor(3.1620)\n",
      "9672 Traning Loss: tensor(3.1663)\n",
      "9673 Traning Loss: tensor(3.1639)\n",
      "9674 Traning Loss: tensor(3.1754)\n",
      "9675 Traning Loss: tensor(3.1719)\n",
      "9676 Traning Loss: tensor(3.1647)\n",
      "9677 Traning Loss: tensor(3.1677)\n",
      "9678 Traning Loss: tensor(3.1616)\n",
      "9679 Traning Loss: tensor(3.1860)\n",
      "9680 Traning Loss: tensor(3.1785)\n",
      "9681 Traning Loss: tensor(3.1743)\n",
      "9682 Traning Loss: tensor(3.1638)\n",
      "9683 Traning Loss: tensor(3.1650)\n",
      "9684 Traning Loss: tensor(3.1535)\n",
      "9685 Traning Loss: tensor(3.1700)\n",
      "9686 Traning Loss: tensor(3.1681)\n",
      "9687 Traning Loss: tensor(3.1592)\n",
      "9688 Traning Loss: tensor(3.1630)\n",
      "9689 Traning Loss: tensor(3.1569)\n",
      "9690 Traning Loss: tensor(3.1627)\n",
      "9691 Traning Loss: tensor(3.1686)\n",
      "9692 Traning Loss: tensor(3.1571)\n",
      "9693 Traning Loss: tensor(3.1653)\n",
      "9694 Traning Loss: tensor(3.1839)\n",
      "9695 Traning Loss: tensor(3.1617)\n",
      "9696 Traning Loss: tensor(3.1647)\n",
      "9697 Traning Loss: tensor(3.1594)\n",
      "9698 Traning Loss: tensor(3.1657)\n",
      "9699 Traning Loss: tensor(3.1715)\n",
      "9700 Traning Loss: tensor(3.1661)\n",
      "9701 Traning Loss: tensor(3.1669)\n",
      "9702 Traning Loss: tensor(3.1707)\n",
      "9703 Traning Loss: tensor(3.1718)\n",
      "9704 Traning Loss: tensor(3.1577)\n",
      "9705 Traning Loss: tensor(3.1537)\n",
      "9706 Traning Loss: tensor(3.1643)\n",
      "9707 Traning Loss: tensor(3.1580)\n",
      "9708 Traning Loss: tensor(3.1692)\n",
      "9709 Traning Loss: tensor(3.1692)\n",
      "9710 Traning Loss: tensor(3.1599)\n",
      "9711 Traning Loss: tensor(3.1671)\n",
      "9712 Traning Loss: tensor(3.1556)\n",
      "9713 Traning Loss: tensor(3.1682)\n",
      "9714 Traning Loss: tensor(3.1593)\n",
      "9715 Traning Loss: tensor(3.1611)\n",
      "9716 Traning Loss: tensor(3.1553)\n",
      "9717 Traning Loss: tensor(3.1537)\n",
      "9718 Traning Loss: tensor(3.1635)\n",
      "9719 Traning Loss: tensor(3.1644)\n",
      "9720 Traning Loss: tensor(3.1560)\n",
      "9721 Traning Loss: tensor(3.1606)\n",
      "9722 Traning Loss: tensor(3.1536)\n",
      "9723 Traning Loss: tensor(3.1497)\n",
      "9724 Traning Loss: tensor(3.1544)\n",
      "9725 Traning Loss: tensor(3.1568)\n",
      "9726 Traning Loss: tensor(3.1679)\n",
      "9727 Traning Loss: tensor(3.1644)\n",
      "9728 Traning Loss: tensor(3.1567)\n",
      "9729 Traning Loss: tensor(3.1701)\n",
      "9730 Traning Loss: tensor(3.1613)\n",
      "9731 Traning Loss: tensor(3.1602)\n",
      "9732 Traning Loss: tensor(3.1593)\n",
      "9733 Traning Loss: tensor(3.1607)\n",
      "9734 Traning Loss: tensor(3.1626)\n",
      "9735 Traning Loss: tensor(3.1747)\n",
      "9736 Traning Loss: tensor(3.1597)\n",
      "9737 Traning Loss: tensor(3.1668)\n",
      "9738 Traning Loss: tensor(3.1640)\n",
      "9739 Traning Loss: tensor(3.1520)\n",
      "9740 Traning Loss: tensor(3.1562)\n",
      "9741 Traning Loss: tensor(3.1706)\n",
      "9742 Traning Loss: tensor(3.1573)\n",
      "9743 Traning Loss: tensor(3.1574)\n",
      "9744 Traning Loss: tensor(3.1615)\n",
      "9745 Traning Loss: tensor(3.1670)\n",
      "9746 Traning Loss: tensor(3.1539)\n",
      "9747 Traning Loss: tensor(3.1621)\n",
      "9748 Traning Loss: tensor(3.1677)\n",
      "9749 Traning Loss: tensor(3.1568)\n",
      "9750 Traning Loss: tensor(3.1505)\n",
      "9751 Traning Loss: tensor(3.1669)\n",
      "9752 Traning Loss: tensor(3.1712)\n",
      "9753 Traning Loss: tensor(3.1498)\n",
      "9754 Traning Loss: tensor(3.1604)\n",
      "9755 Traning Loss: tensor(3.1585)\n",
      "9756 Traning Loss: tensor(3.1470)\n",
      "9757 Traning Loss: tensor(3.1681)\n",
      "9758 Traning Loss: tensor(3.1632)\n",
      "9759 Traning Loss: tensor(3.1485)\n",
      "9760 Traning Loss: tensor(3.1609)\n",
      "9761 Traning Loss: tensor(3.1522)\n",
      "9762 Traning Loss: tensor(3.1586)\n",
      "9763 Traning Loss: tensor(3.1581)\n",
      "9764 Traning Loss: tensor(3.1641)\n",
      "9765 Traning Loss: tensor(3.1697)\n",
      "9766 Traning Loss: tensor(3.1535)\n",
      "9767 Traning Loss: tensor(3.1603)\n",
      "9768 Traning Loss: tensor(3.1608)\n",
      "9769 Traning Loss: tensor(3.1652)\n",
      "9770 Traning Loss: tensor(3.1621)\n",
      "9771 Traning Loss: tensor(3.1463)\n",
      "9772 Traning Loss: tensor(3.1595)\n",
      "9773 Traning Loss: tensor(3.1478)\n",
      "9774 Traning Loss: tensor(3.1630)\n",
      "9775 Traning Loss: tensor(3.1628)\n",
      "9776 Traning Loss: tensor(3.1520)\n",
      "9777 Traning Loss: tensor(3.1545)\n",
      "9778 Traning Loss: tensor(3.1651)\n",
      "9779 Traning Loss: tensor(3.1618)\n",
      "9780 Traning Loss: tensor(3.1577)\n",
      "9781 Traning Loss: tensor(3.1689)\n",
      "9782 Traning Loss: tensor(3.1673)\n",
      "9783 Traning Loss: tensor(3.1522)\n",
      "9784 Traning Loss: tensor(3.1499)\n",
      "9785 Traning Loss: tensor(3.1536)\n",
      "9786 Traning Loss: tensor(3.1495)\n",
      "9787 Traning Loss: tensor(3.1610)\n",
      "9788 Traning Loss: tensor(3.1554)\n",
      "9789 Traning Loss: tensor(3.1460)\n",
      "9790 Traning Loss: tensor(3.1504)\n",
      "9791 Traning Loss: tensor(3.1603)\n",
      "9792 Traning Loss: tensor(3.1531)\n",
      "9793 Traning Loss: tensor(3.1549)\n",
      "9794 Traning Loss: tensor(3.1496)\n",
      "9795 Traning Loss: tensor(3.1512)\n",
      "9796 Traning Loss: tensor(3.1543)\n",
      "9797 Traning Loss: tensor(3.1436)\n",
      "9798 Traning Loss: tensor(3.1476)\n",
      "9799 Traning Loss: tensor(3.1400)\n",
      "9800 Traning Loss: tensor(3.1593)\n",
      "9801 Traning Loss: tensor(3.1568)\n",
      "9802 Traning Loss: tensor(3.1511)\n",
      "9803 Traning Loss: tensor(3.1449)\n",
      "9804 Traning Loss: tensor(3.1474)\n",
      "9805 Traning Loss: tensor(3.1470)\n",
      "9806 Traning Loss: tensor(3.1508)\n",
      "9807 Traning Loss: tensor(3.1475)\n",
      "9808 Traning Loss: tensor(3.1495)\n",
      "9809 Traning Loss: tensor(3.1489)\n",
      "9810 Traning Loss: tensor(3.1517)\n",
      "9811 Traning Loss: tensor(3.1491)\n",
      "9812 Traning Loss: tensor(3.1549)\n",
      "9813 Traning Loss: tensor(3.1498)\n",
      "9814 Traning Loss: tensor(3.1500)\n",
      "9815 Traning Loss: tensor(3.1595)\n",
      "9816 Traning Loss: tensor(3.1499)\n",
      "9817 Traning Loss: tensor(3.1405)\n",
      "9818 Traning Loss: tensor(3.1557)\n",
      "9819 Traning Loss: tensor(3.1517)\n",
      "9820 Traning Loss: tensor(3.1601)\n",
      "9821 Traning Loss: tensor(3.1461)\n",
      "9822 Traning Loss: tensor(3.1449)\n",
      "9823 Traning Loss: tensor(3.1505)\n",
      "9824 Traning Loss: tensor(3.1480)\n",
      "9825 Traning Loss: tensor(3.1493)\n",
      "9826 Traning Loss: tensor(3.1495)\n",
      "9827 Traning Loss: tensor(3.1554)\n",
      "9828 Traning Loss: tensor(3.1473)\n",
      "9829 Traning Loss: tensor(3.1467)\n",
      "9830 Traning Loss: tensor(3.1448)\n",
      "9831 Traning Loss: tensor(3.1458)\n",
      "9832 Traning Loss: tensor(3.1468)\n",
      "9833 Traning Loss: tensor(3.1427)\n",
      "9834 Traning Loss: tensor(3.1391)\n",
      "9835 Traning Loss: tensor(3.1473)\n",
      "9836 Traning Loss: tensor(3.1528)\n",
      "9837 Traning Loss: tensor(3.1560)\n",
      "9838 Traning Loss: tensor(3.1471)\n",
      "9839 Traning Loss: tensor(3.1455)\n",
      "9840 Traning Loss: tensor(3.1580)\n",
      "9841 Traning Loss: tensor(3.1447)\n",
      "9842 Traning Loss: tensor(3.1481)\n",
      "9843 Traning Loss: tensor(3.1445)\n",
      "9844 Traning Loss: tensor(3.1541)\n",
      "9845 Traning Loss: tensor(3.1563)\n",
      "9846 Traning Loss: tensor(3.1501)\n",
      "9847 Traning Loss: tensor(3.1474)\n",
      "9848 Traning Loss: tensor(3.1450)\n",
      "9849 Traning Loss: tensor(3.1529)\n",
      "9850 Traning Loss: tensor(3.1547)\n",
      "9851 Traning Loss: tensor(3.1461)\n",
      "9852 Traning Loss: tensor(3.1533)\n",
      "9853 Traning Loss: tensor(3.1441)\n",
      "9854 Traning Loss: tensor(3.1460)\n",
      "9855 Traning Loss: tensor(3.1307)\n",
      "9856 Traning Loss: tensor(3.1539)\n",
      "9857 Traning Loss: tensor(3.1526)\n",
      "9858 Traning Loss: tensor(3.1534)\n",
      "9859 Traning Loss: tensor(3.1440)\n",
      "9860 Traning Loss: tensor(3.1436)\n",
      "9861 Traning Loss: tensor(3.1420)\n",
      "9862 Traning Loss: tensor(3.1539)\n",
      "9863 Traning Loss: tensor(3.1503)\n",
      "9864 Traning Loss: tensor(3.1474)\n",
      "9865 Traning Loss: tensor(3.1428)\n",
      "9866 Traning Loss: tensor(3.1404)\n",
      "9867 Traning Loss: tensor(3.1499)\n",
      "9868 Traning Loss: tensor(3.1536)\n",
      "9869 Traning Loss: tensor(3.1410)\n",
      "9870 Traning Loss: tensor(3.1415)\n",
      "9871 Traning Loss: tensor(3.1455)\n",
      "9872 Traning Loss: tensor(3.1416)\n",
      "9873 Traning Loss: tensor(3.1606)\n",
      "9874 Traning Loss: tensor(3.1469)\n",
      "9875 Traning Loss: tensor(3.1478)\n",
      "9876 Traning Loss: tensor(3.1414)\n",
      "9877 Traning Loss: tensor(3.1416)\n",
      "9878 Traning Loss: tensor(3.1405)\n",
      "9879 Traning Loss: tensor(3.1454)\n",
      "9880 Traning Loss: tensor(3.1445)\n",
      "9881 Traning Loss: tensor(3.1452)\n",
      "9882 Traning Loss: tensor(3.1558)\n",
      "9883 Traning Loss: tensor(3.1410)\n",
      "9884 Traning Loss: tensor(3.1384)\n",
      "9885 Traning Loss: tensor(3.1390)\n",
      "9886 Traning Loss: tensor(3.1429)\n",
      "9887 Traning Loss: tensor(3.1439)\n",
      "9888 Traning Loss: tensor(3.1589)\n",
      "9889 Traning Loss: tensor(3.1420)\n",
      "9890 Traning Loss: tensor(3.1410)\n",
      "9891 Traning Loss: tensor(3.1419)\n",
      "9892 Traning Loss: tensor(3.1440)\n",
      "9893 Traning Loss: tensor(3.1502)\n",
      "9894 Traning Loss: tensor(3.1393)\n",
      "9895 Traning Loss: tensor(3.1413)\n",
      "9896 Traning Loss: tensor(3.1561)\n",
      "9897 Traning Loss: tensor(3.1413)\n",
      "9898 Traning Loss: tensor(3.1424)\n",
      "9899 Traning Loss: tensor(3.1434)\n",
      "9900 Traning Loss: tensor(3.1475)\n",
      "9901 Traning Loss: tensor(3.1415)\n",
      "9902 Traning Loss: tensor(3.1406)\n",
      "9903 Traning Loss: tensor(3.1451)\n",
      "9904 Traning Loss: tensor(3.1426)\n",
      "9905 Traning Loss: tensor(3.1562)\n",
      "9906 Traning Loss: tensor(3.1445)\n",
      "9907 Traning Loss: tensor(3.1444)\n",
      "9908 Traning Loss: tensor(3.1384)\n",
      "9909 Traning Loss: tensor(3.1595)\n",
      "9910 Traning Loss: tensor(3.1352)\n",
      "9911 Traning Loss: tensor(3.1363)\n",
      "9912 Traning Loss: tensor(3.1446)\n",
      "9913 Traning Loss: tensor(3.1511)\n",
      "9914 Traning Loss: tensor(3.1352)\n",
      "9915 Traning Loss: tensor(3.1374)\n",
      "9916 Traning Loss: tensor(3.1417)\n",
      "9917 Traning Loss: tensor(3.1439)\n",
      "9918 Traning Loss: tensor(3.1419)\n",
      "9919 Traning Loss: tensor(3.1415)\n",
      "9920 Traning Loss: tensor(3.1455)\n",
      "9921 Traning Loss: tensor(3.1378)\n",
      "9922 Traning Loss: tensor(3.1400)\n",
      "9923 Traning Loss: tensor(3.1362)\n",
      "9924 Traning Loss: tensor(3.1392)\n",
      "9925 Traning Loss: tensor(3.1494)\n",
      "9926 Traning Loss: tensor(3.1404)\n",
      "9927 Traning Loss: tensor(3.1458)\n",
      "9928 Traning Loss: tensor(3.1380)\n",
      "9929 Traning Loss: tensor(3.1406)\n",
      "9930 Traning Loss: tensor(3.1316)\n",
      "9931 Traning Loss: tensor(3.1417)\n",
      "9932 Traning Loss: tensor(3.1369)\n",
      "9933 Traning Loss: tensor(3.1421)\n",
      "9934 Traning Loss: tensor(3.1348)\n",
      "9935 Traning Loss: tensor(3.1365)\n",
      "9936 Traning Loss: tensor(3.1400)\n",
      "9937 Traning Loss: tensor(3.1337)\n",
      "9938 Traning Loss: tensor(3.1575)\n",
      "9939 Traning Loss: tensor(3.1292)\n",
      "9940 Traning Loss: tensor(3.1424)\n",
      "9941 Traning Loss: tensor(3.1414)\n",
      "9942 Traning Loss: tensor(3.1388)\n",
      "9943 Traning Loss: tensor(3.1334)\n",
      "9944 Traning Loss: tensor(3.1342)\n",
      "9945 Traning Loss: tensor(3.1512)\n",
      "9946 Traning Loss: tensor(3.1423)\n",
      "9947 Traning Loss: tensor(3.1347)\n",
      "9948 Traning Loss: tensor(3.1357)\n",
      "9949 Traning Loss: tensor(3.1442)\n",
      "9950 Traning Loss: tensor(3.1348)\n",
      "9951 Traning Loss: tensor(3.1319)\n",
      "9952 Traning Loss: tensor(3.1402)\n",
      "9953 Traning Loss: tensor(3.1298)\n",
      "9954 Traning Loss: tensor(3.1333)\n",
      "9955 Traning Loss: tensor(3.1362)\n",
      "9956 Traning Loss: tensor(3.1476)\n",
      "9957 Traning Loss: tensor(3.1429)\n",
      "9958 Traning Loss: tensor(3.1328)\n",
      "9959 Traning Loss: tensor(3.1351)\n",
      "9960 Traning Loss: tensor(3.1328)\n",
      "9961 Traning Loss: tensor(3.1332)\n",
      "9962 Traning Loss: tensor(3.1338)\n",
      "9963 Traning Loss: tensor(3.1308)\n",
      "9964 Traning Loss: tensor(3.1288)\n",
      "9965 Traning Loss: tensor(3.1416)\n",
      "9966 Traning Loss: tensor(3.1457)\n",
      "9967 Traning Loss: tensor(3.1329)\n",
      "9968 Traning Loss: tensor(3.1400)\n",
      "9969 Traning Loss: tensor(3.1364)\n",
      "9970 Traning Loss: tensor(3.1348)\n",
      "9971 Traning Loss: tensor(3.1250)\n",
      "9972 Traning Loss: tensor(3.1456)\n",
      "9973 Traning Loss: tensor(3.1400)\n",
      "9974 Traning Loss: tensor(3.1424)\n",
      "9975 Traning Loss: tensor(3.1305)\n",
      "9976 Traning Loss: tensor(3.1402)\n",
      "9977 Traning Loss: tensor(3.1411)\n",
      "9978 Traning Loss: tensor(3.1383)\n",
      "9979 Traning Loss: tensor(3.1337)\n",
      "9980 Traning Loss: tensor(3.1325)\n",
      "9981 Traning Loss: tensor(3.1352)\n",
      "9982 Traning Loss: tensor(3.1392)\n",
      "9983 Traning Loss: tensor(3.1349)\n",
      "9984 Traning Loss: tensor(3.1405)\n",
      "9985 Traning Loss: tensor(3.1379)\n",
      "9986 Traning Loss: tensor(3.1385)\n",
      "9987 Traning Loss: tensor(3.1328)\n",
      "9988 Traning Loss: tensor(3.1448)\n",
      "9989 Traning Loss: tensor(3.1356)\n",
      "9990 Traning Loss: tensor(3.1324)\n",
      "9991 Traning Loss: tensor(3.1370)\n",
      "9992 Traning Loss: tensor(3.1302)\n",
      "9993 Traning Loss: tensor(3.1425)\n",
      "9994 Traning Loss: tensor(3.1310)\n",
      "9995 Traning Loss: tensor(3.1253)\n",
      "9996 Traning Loss: tensor(3.1322)\n",
      "9997 Traning Loss: tensor(3.1354)\n",
      "9998 Traning Loss: tensor(3.1370)\n",
      "9999 Traning Loss: tensor(3.1465)\n",
      "10000 Traning Loss: tensor(3.1284)\n",
      "10001 Traning Loss: tensor(3.1377)\n",
      "10002 Traning Loss: tensor(3.1347)\n",
      "10003 Traning Loss: tensor(3.1304)\n",
      "10004 Traning Loss: tensor(3.1387)\n",
      "10005 Traning Loss: tensor(3.1195)\n",
      "10006 Traning Loss: tensor(3.1287)\n",
      "10007 Traning Loss: tensor(3.1176)\n",
      "10008 Traning Loss: tensor(3.1355)\n",
      "10009 Traning Loss: tensor(3.1290)\n",
      "10010 Traning Loss: tensor(3.1474)\n",
      "10011 Traning Loss: tensor(3.1257)\n",
      "10012 Traning Loss: tensor(3.1182)\n",
      "10013 Traning Loss: tensor(3.1325)\n",
      "10014 Traning Loss: tensor(3.1254)\n",
      "10015 Traning Loss: tensor(3.1300)\n",
      "10016 Traning Loss: tensor(3.1318)\n",
      "10017 Traning Loss: tensor(3.1196)\n",
      "10018 Traning Loss: tensor(3.1237)\n",
      "10019 Traning Loss: tensor(3.1387)\n",
      "10020 Traning Loss: tensor(3.1283)\n",
      "10021 Traning Loss: tensor(3.1273)\n",
      "10022 Traning Loss: tensor(3.1212)\n",
      "10023 Traning Loss: tensor(3.1216)\n",
      "10024 Traning Loss: tensor(3.1284)\n",
      "10025 Traning Loss: tensor(3.1292)\n",
      "10026 Traning Loss: tensor(3.1321)\n",
      "10027 Traning Loss: tensor(3.1304)\n",
      "10028 Traning Loss: tensor(3.1344)\n",
      "10029 Traning Loss: tensor(3.1320)\n",
      "10030 Traning Loss: tensor(3.1258)\n",
      "10031 Traning Loss: tensor(3.1364)\n",
      "10032 Traning Loss: tensor(3.1300)\n",
      "10033 Traning Loss: tensor(3.1286)\n",
      "10034 Traning Loss: tensor(3.1392)\n",
      "10035 Traning Loss: tensor(3.1399)\n",
      "10036 Traning Loss: tensor(3.1288)\n",
      "10037 Traning Loss: tensor(3.1340)\n",
      "10038 Traning Loss: tensor(3.1231)\n",
      "10039 Traning Loss: tensor(3.1406)\n",
      "10040 Traning Loss: tensor(3.1385)\n",
      "10041 Traning Loss: tensor(3.1417)\n",
      "10042 Traning Loss: tensor(3.1274)\n",
      "10043 Traning Loss: tensor(3.1376)\n",
      "10044 Traning Loss: tensor(3.1284)\n",
      "10045 Traning Loss: tensor(3.1190)\n",
      "10046 Traning Loss: tensor(3.1230)\n",
      "10047 Traning Loss: tensor(3.1313)\n",
      "10048 Traning Loss: tensor(3.1409)\n",
      "10049 Traning Loss: tensor(3.1302)\n",
      "10050 Traning Loss: tensor(3.1216)\n",
      "10051 Traning Loss: tensor(3.1318)\n",
      "10052 Traning Loss: tensor(3.1258)\n",
      "10053 Traning Loss: tensor(3.1259)\n",
      "10054 Traning Loss: tensor(3.1236)\n",
      "10055 Traning Loss: tensor(3.1286)\n",
      "10056 Traning Loss: tensor(3.1262)\n",
      "10057 Traning Loss: tensor(3.1336)\n",
      "10058 Traning Loss: tensor(3.1199)\n",
      "10059 Traning Loss: tensor(3.1169)\n",
      "10060 Traning Loss: tensor(3.1204)\n",
      "10061 Traning Loss: tensor(3.1204)\n",
      "10062 Traning Loss: tensor(3.1310)\n",
      "10063 Traning Loss: tensor(3.1327)\n",
      "10064 Traning Loss: tensor(3.1127)\n",
      "10065 Traning Loss: tensor(3.1258)\n",
      "10066 Traning Loss: tensor(3.1297)\n",
      "10067 Traning Loss: tensor(3.1151)\n",
      "10068 Traning Loss: tensor(3.1254)\n",
      "10069 Traning Loss: tensor(3.1245)\n",
      "10070 Traning Loss: tensor(3.1376)\n",
      "10071 Traning Loss: tensor(3.1282)\n",
      "10072 Traning Loss: tensor(3.1366)\n",
      "10073 Traning Loss: tensor(3.1076)\n",
      "10074 Traning Loss: tensor(3.1381)\n",
      "10075 Traning Loss: tensor(3.1269)\n",
      "10076 Traning Loss: tensor(3.1162)\n",
      "10077 Traning Loss: tensor(3.1224)\n",
      "10078 Traning Loss: tensor(3.1361)\n",
      "10079 Traning Loss: tensor(3.1337)\n",
      "10080 Traning Loss: tensor(3.1179)\n",
      "10081 Traning Loss: tensor(3.1134)\n",
      "10082 Traning Loss: tensor(3.1181)\n",
      "10083 Traning Loss: tensor(3.1222)\n",
      "10084 Traning Loss: tensor(3.1241)\n",
      "10085 Traning Loss: tensor(3.1180)\n",
      "10086 Traning Loss: tensor(3.1092)\n",
      "10087 Traning Loss: tensor(3.1425)\n",
      "10088 Traning Loss: tensor(3.1228)\n",
      "10089 Traning Loss: tensor(3.1266)\n",
      "10090 Traning Loss: tensor(3.1243)\n",
      "10091 Traning Loss: tensor(3.1401)\n",
      "10092 Traning Loss: tensor(3.1091)\n",
      "10093 Traning Loss: tensor(3.1228)\n",
      "10094 Traning Loss: tensor(3.1154)\n",
      "10095 Traning Loss: tensor(3.1249)\n",
      "10096 Traning Loss: tensor(3.1386)\n",
      "10097 Traning Loss: tensor(3.1233)\n",
      "10098 Traning Loss: tensor(3.1181)\n",
      "10099 Traning Loss: tensor(3.1283)\n",
      "10100 Traning Loss: tensor(3.1216)\n",
      "10101 Traning Loss: tensor(3.1184)\n",
      "10102 Traning Loss: tensor(3.1323)\n",
      "10103 Traning Loss: tensor(3.1269)\n",
      "10104 Traning Loss: tensor(3.1289)\n",
      "10105 Traning Loss: tensor(3.1302)\n",
      "10106 Traning Loss: tensor(3.1270)\n",
      "10107 Traning Loss: tensor(3.1209)\n",
      "10108 Traning Loss: tensor(3.1105)\n",
      "10109 Traning Loss: tensor(3.1153)\n",
      "10110 Traning Loss: tensor(3.1193)\n",
      "10111 Traning Loss: tensor(3.1252)\n",
      "10112 Traning Loss: tensor(3.1157)\n",
      "10113 Traning Loss: tensor(3.1149)\n",
      "10114 Traning Loss: tensor(3.1226)\n",
      "10115 Traning Loss: tensor(3.1169)\n",
      "10116 Traning Loss: tensor(3.1224)\n",
      "10117 Traning Loss: tensor(3.1275)\n",
      "10118 Traning Loss: tensor(3.1224)\n",
      "10119 Traning Loss: tensor(3.1151)\n",
      "10120 Traning Loss: tensor(3.1120)\n",
      "10121 Traning Loss: tensor(3.1199)\n",
      "10122 Traning Loss: tensor(3.1218)\n",
      "10123 Traning Loss: tensor(3.1149)\n",
      "10124 Traning Loss: tensor(3.1301)\n",
      "10125 Traning Loss: tensor(3.1214)\n",
      "10126 Traning Loss: tensor(3.1257)\n",
      "10127 Traning Loss: tensor(3.1147)\n",
      "10128 Traning Loss: tensor(3.1248)\n",
      "10129 Traning Loss: tensor(3.1160)\n",
      "10130 Traning Loss: tensor(3.1359)\n",
      "10131 Traning Loss: tensor(3.1241)\n",
      "10132 Traning Loss: tensor(3.1121)\n",
      "10133 Traning Loss: tensor(3.1130)\n",
      "10134 Traning Loss: tensor(3.1162)\n",
      "10135 Traning Loss: tensor(3.1092)\n",
      "10136 Traning Loss: tensor(3.1245)\n",
      "10137 Traning Loss: tensor(3.1300)\n",
      "10138 Traning Loss: tensor(3.1200)\n",
      "10139 Traning Loss: tensor(3.1228)\n",
      "10140 Traning Loss: tensor(3.1260)\n",
      "10141 Traning Loss: tensor(3.1131)\n",
      "10142 Traning Loss: tensor(3.1090)\n",
      "10143 Traning Loss: tensor(3.1049)\n",
      "10144 Traning Loss: tensor(3.1123)\n",
      "10145 Traning Loss: tensor(3.1221)\n",
      "10146 Traning Loss: tensor(3.1165)\n",
      "10147 Traning Loss: tensor(3.1127)\n",
      "10148 Traning Loss: tensor(3.1136)\n",
      "10149 Traning Loss: tensor(3.1218)\n",
      "10150 Traning Loss: tensor(3.1177)\n",
      "10151 Traning Loss: tensor(3.1184)\n",
      "10152 Traning Loss: tensor(3.1196)\n",
      "10153 Traning Loss: tensor(3.1151)\n",
      "10154 Traning Loss: tensor(3.1295)\n",
      "10155 Traning Loss: tensor(3.1221)\n",
      "10156 Traning Loss: tensor(3.1138)\n",
      "10157 Traning Loss: tensor(3.1117)\n",
      "10158 Traning Loss: tensor(3.1307)\n",
      "10159 Traning Loss: tensor(3.1200)\n",
      "10160 Traning Loss: tensor(3.1166)\n",
      "10161 Traning Loss: tensor(3.1161)\n",
      "10162 Traning Loss: tensor(3.1202)\n",
      "10163 Traning Loss: tensor(3.1086)\n",
      "10164 Traning Loss: tensor(3.1096)\n",
      "10165 Traning Loss: tensor(3.1292)\n",
      "10166 Traning Loss: tensor(3.1297)\n",
      "10167 Traning Loss: tensor(3.1128)\n",
      "10168 Traning Loss: tensor(3.1149)\n",
      "10169 Traning Loss: tensor(3.1130)\n",
      "10170 Traning Loss: tensor(3.1033)\n",
      "10171 Traning Loss: tensor(3.1144)\n",
      "10172 Traning Loss: tensor(3.1135)\n",
      "10173 Traning Loss: tensor(3.1206)\n",
      "10174 Traning Loss: tensor(3.1117)\n",
      "10175 Traning Loss: tensor(3.1076)\n",
      "10176 Traning Loss: tensor(3.1112)\n",
      "10177 Traning Loss: tensor(3.1082)\n",
      "10178 Traning Loss: tensor(3.1019)\n",
      "10179 Traning Loss: tensor(3.1177)\n",
      "10180 Traning Loss: tensor(3.1066)\n",
      "10181 Traning Loss: tensor(3.1158)\n",
      "10182 Traning Loss: tensor(3.0968)\n",
      "10183 Traning Loss: tensor(3.1120)\n",
      "10184 Traning Loss: tensor(3.1151)\n",
      "10185 Traning Loss: tensor(3.1223)\n",
      "10186 Traning Loss: tensor(3.1232)\n",
      "10187 Traning Loss: tensor(3.1210)\n",
      "10188 Traning Loss: tensor(3.1082)\n",
      "10189 Traning Loss: tensor(3.1017)\n",
      "10190 Traning Loss: tensor(3.1074)\n",
      "10191 Traning Loss: tensor(3.1113)\n",
      "10192 Traning Loss: tensor(3.1148)\n",
      "10193 Traning Loss: tensor(3.1214)\n",
      "10194 Traning Loss: tensor(3.1247)\n",
      "10195 Traning Loss: tensor(3.1212)\n",
      "10196 Traning Loss: tensor(3.1149)\n",
      "10197 Traning Loss: tensor(3.1247)\n",
      "10198 Traning Loss: tensor(3.1100)\n",
      "10199 Traning Loss: tensor(3.1086)\n",
      "10200 Traning Loss: tensor(3.1082)\n",
      "10201 Traning Loss: tensor(3.1075)\n",
      "10202 Traning Loss: tensor(3.1081)\n",
      "10203 Traning Loss: tensor(3.1034)\n",
      "10204 Traning Loss: tensor(3.1142)\n",
      "10205 Traning Loss: tensor(3.1132)\n",
      "10206 Traning Loss: tensor(3.1149)\n",
      "10207 Traning Loss: tensor(3.1249)\n",
      "10208 Traning Loss: tensor(3.1254)\n",
      "10209 Traning Loss: tensor(3.1032)\n",
      "10210 Traning Loss: tensor(3.1133)\n",
      "10211 Traning Loss: tensor(3.1110)\n",
      "10212 Traning Loss: tensor(3.1195)\n",
      "10213 Traning Loss: tensor(3.0989)\n",
      "10214 Traning Loss: tensor(3.1090)\n",
      "10215 Traning Loss: tensor(3.1045)\n",
      "10216 Traning Loss: tensor(3.1090)\n",
      "10217 Traning Loss: tensor(3.1194)\n",
      "10218 Traning Loss: tensor(3.1103)\n",
      "10219 Traning Loss: tensor(3.1039)\n",
      "10220 Traning Loss: tensor(3.1088)\n",
      "10221 Traning Loss: tensor(3.1015)\n",
      "10222 Traning Loss: tensor(3.1169)\n",
      "10223 Traning Loss: tensor(3.1033)\n",
      "10224 Traning Loss: tensor(3.1073)\n",
      "10225 Traning Loss: tensor(3.0988)\n",
      "10226 Traning Loss: tensor(3.1025)\n",
      "10227 Traning Loss: tensor(3.1083)\n",
      "10228 Traning Loss: tensor(3.1059)\n",
      "10229 Traning Loss: tensor(3.1321)\n",
      "10230 Traning Loss: tensor(3.1055)\n",
      "10231 Traning Loss: tensor(3.1069)\n",
      "10232 Traning Loss: tensor(3.1039)\n",
      "10233 Traning Loss: tensor(3.1061)\n",
      "10234 Traning Loss: tensor(3.1092)\n",
      "10235 Traning Loss: tensor(3.1172)\n",
      "10236 Traning Loss: tensor(3.1074)\n",
      "10237 Traning Loss: tensor(3.1128)\n",
      "10238 Traning Loss: tensor(3.1130)\n",
      "10239 Traning Loss: tensor(3.1092)\n",
      "10240 Traning Loss: tensor(3.1086)\n",
      "10241 Traning Loss: tensor(3.0940)\n",
      "10242 Traning Loss: tensor(3.1063)\n",
      "10243 Traning Loss: tensor(3.1088)\n",
      "10244 Traning Loss: tensor(3.1019)\n",
      "10245 Traning Loss: tensor(3.1002)\n",
      "10246 Traning Loss: tensor(3.1118)\n",
      "10247 Traning Loss: tensor(3.1081)\n",
      "10248 Traning Loss: tensor(3.1018)\n",
      "10249 Traning Loss: tensor(3.1097)\n",
      "10250 Traning Loss: tensor(3.1086)\n",
      "10251 Traning Loss: tensor(3.1040)\n",
      "10252 Traning Loss: tensor(3.1108)\n",
      "10253 Traning Loss: tensor(3.0990)\n",
      "10254 Traning Loss: tensor(3.1069)\n",
      "10255 Traning Loss: tensor(3.0969)\n",
      "10256 Traning Loss: tensor(3.1148)\n",
      "10257 Traning Loss: tensor(3.1065)\n",
      "10258 Traning Loss: tensor(3.1113)\n",
      "10259 Traning Loss: tensor(3.1048)\n",
      "10260 Traning Loss: tensor(3.1013)\n",
      "10261 Traning Loss: tensor(3.1143)\n",
      "10262 Traning Loss: tensor(3.1047)\n",
      "10263 Traning Loss: tensor(3.0935)\n",
      "10264 Traning Loss: tensor(3.1127)\n",
      "10265 Traning Loss: tensor(3.0924)\n",
      "10266 Traning Loss: tensor(3.1048)\n",
      "10267 Traning Loss: tensor(3.0984)\n",
      "10268 Traning Loss: tensor(3.1176)\n",
      "10269 Traning Loss: tensor(3.1143)\n",
      "10270 Traning Loss: tensor(3.1216)\n",
      "10271 Traning Loss: tensor(3.1073)\n",
      "10272 Traning Loss: tensor(3.0922)\n",
      "10273 Traning Loss: tensor(3.0972)\n",
      "10274 Traning Loss: tensor(3.1081)\n",
      "10275 Traning Loss: tensor(3.1021)\n",
      "10276 Traning Loss: tensor(3.1038)\n",
      "10277 Traning Loss: tensor(3.1034)\n",
      "10278 Traning Loss: tensor(3.0947)\n",
      "10279 Traning Loss: tensor(3.0962)\n",
      "10280 Traning Loss: tensor(3.0967)\n",
      "10281 Traning Loss: tensor(3.0991)\n",
      "10282 Traning Loss: tensor(3.0961)\n",
      "10283 Traning Loss: tensor(3.1002)\n",
      "10284 Traning Loss: tensor(3.1009)\n",
      "10285 Traning Loss: tensor(3.1162)\n",
      "10286 Traning Loss: tensor(3.0956)\n",
      "10287 Traning Loss: tensor(3.1005)\n",
      "10288 Traning Loss: tensor(3.1001)\n",
      "10289 Traning Loss: tensor(3.0936)\n",
      "10290 Traning Loss: tensor(3.1025)\n",
      "10291 Traning Loss: tensor(3.0940)\n",
      "10292 Traning Loss: tensor(3.0868)\n",
      "10293 Traning Loss: tensor(3.1060)\n",
      "10294 Traning Loss: tensor(3.1027)\n",
      "10295 Traning Loss: tensor(3.1084)\n",
      "10296 Traning Loss: tensor(3.1067)\n",
      "10297 Traning Loss: tensor(3.1028)\n",
      "10298 Traning Loss: tensor(3.1038)\n",
      "10299 Traning Loss: tensor(3.1035)\n",
      "10300 Traning Loss: tensor(3.0954)\n",
      "10301 Traning Loss: tensor(3.0975)\n",
      "10302 Traning Loss: tensor(3.1078)\n",
      "10303 Traning Loss: tensor(3.0984)\n",
      "10304 Traning Loss: tensor(3.0877)\n",
      "10305 Traning Loss: tensor(3.1205)\n",
      "10306 Traning Loss: tensor(3.1090)\n",
      "10307 Traning Loss: tensor(3.1008)\n",
      "10308 Traning Loss: tensor(3.1105)\n",
      "10309 Traning Loss: tensor(3.1020)\n",
      "10310 Traning Loss: tensor(3.1005)\n",
      "10311 Traning Loss: tensor(3.1171)\n",
      "10312 Traning Loss: tensor(3.0952)\n",
      "10313 Traning Loss: tensor(3.0986)\n",
      "10314 Traning Loss: tensor(3.1071)\n",
      "10315 Traning Loss: tensor(3.0814)\n",
      "10316 Traning Loss: tensor(3.1076)\n",
      "10317 Traning Loss: tensor(3.1035)\n",
      "10318 Traning Loss: tensor(3.1059)\n",
      "10319 Traning Loss: tensor(3.1049)\n",
      "10320 Traning Loss: tensor(3.0952)\n",
      "10321 Traning Loss: tensor(3.0935)\n",
      "10322 Traning Loss: tensor(3.0975)\n",
      "10323 Traning Loss: tensor(3.0939)\n",
      "10324 Traning Loss: tensor(3.1071)\n",
      "10325 Traning Loss: tensor(3.0932)\n",
      "10326 Traning Loss: tensor(3.0926)\n",
      "10327 Traning Loss: tensor(3.1114)\n",
      "10328 Traning Loss: tensor(3.1099)\n",
      "10329 Traning Loss: tensor(3.1036)\n",
      "10330 Traning Loss: tensor(3.1076)\n",
      "10331 Traning Loss: tensor(3.0862)\n",
      "10332 Traning Loss: tensor(3.1113)\n",
      "10333 Traning Loss: tensor(3.0908)\n",
      "10334 Traning Loss: tensor(3.1057)\n",
      "10335 Traning Loss: tensor(3.1019)\n",
      "10336 Traning Loss: tensor(3.0986)\n",
      "10337 Traning Loss: tensor(3.0939)\n",
      "10338 Traning Loss: tensor(3.0986)\n",
      "10339 Traning Loss: tensor(3.0915)\n",
      "10340 Traning Loss: tensor(3.0999)\n",
      "10341 Traning Loss: tensor(3.0896)\n",
      "10342 Traning Loss: tensor(3.1036)\n",
      "10343 Traning Loss: tensor(3.0991)\n",
      "10344 Traning Loss: tensor(3.0914)\n",
      "10345 Traning Loss: tensor(3.0958)\n",
      "10346 Traning Loss: tensor(3.1026)\n",
      "10347 Traning Loss: tensor(3.1023)\n",
      "10348 Traning Loss: tensor(3.0974)\n",
      "10349 Traning Loss: tensor(3.0845)\n",
      "10350 Traning Loss: tensor(3.1005)\n",
      "10351 Traning Loss: tensor(3.1068)\n",
      "10352 Traning Loss: tensor(3.0839)\n",
      "10353 Traning Loss: tensor(3.0943)\n",
      "10354 Traning Loss: tensor(3.0964)\n",
      "10355 Traning Loss: tensor(3.1073)\n",
      "10356 Traning Loss: tensor(3.0884)\n",
      "10357 Traning Loss: tensor(3.0982)\n",
      "10358 Traning Loss: tensor(3.0888)\n",
      "10359 Traning Loss: tensor(3.0854)\n",
      "10360 Traning Loss: tensor(3.0973)\n",
      "10361 Traning Loss: tensor(3.0924)\n",
      "10362 Traning Loss: tensor(3.1042)\n",
      "10363 Traning Loss: tensor(3.1103)\n",
      "10364 Traning Loss: tensor(3.0952)\n",
      "10365 Traning Loss: tensor(3.0953)\n",
      "10366 Traning Loss: tensor(3.0955)\n",
      "10367 Traning Loss: tensor(3.0874)\n",
      "10368 Traning Loss: tensor(3.0944)\n",
      "10369 Traning Loss: tensor(3.0975)\n",
      "10370 Traning Loss: tensor(3.0969)\n",
      "10371 Traning Loss: tensor(3.0929)\n",
      "10372 Traning Loss: tensor(3.0990)\n",
      "10373 Traning Loss: tensor(3.0956)\n",
      "10374 Traning Loss: tensor(3.0860)\n",
      "10375 Traning Loss: tensor(3.0917)\n",
      "10376 Traning Loss: tensor(3.1015)\n",
      "10377 Traning Loss: tensor(3.0841)\n",
      "10378 Traning Loss: tensor(3.1000)\n",
      "10379 Traning Loss: tensor(3.0920)\n",
      "10380 Traning Loss: tensor(3.0769)\n",
      "10381 Traning Loss: tensor(3.0934)\n",
      "10382 Traning Loss: tensor(3.0926)\n",
      "10383 Traning Loss: tensor(3.1025)\n",
      "10384 Traning Loss: tensor(3.0849)\n",
      "10385 Traning Loss: tensor(3.0999)\n",
      "10386 Traning Loss: tensor(3.1045)\n",
      "10387 Traning Loss: tensor(3.0865)\n",
      "10388 Traning Loss: tensor(3.0808)\n",
      "10389 Traning Loss: tensor(3.0870)\n",
      "10390 Traning Loss: tensor(3.0904)\n",
      "10391 Traning Loss: tensor(3.0900)\n",
      "10392 Traning Loss: tensor(3.0956)\n",
      "10393 Traning Loss: tensor(3.0984)\n",
      "10394 Traning Loss: tensor(3.0764)\n",
      "10395 Traning Loss: tensor(3.1000)\n",
      "10396 Traning Loss: tensor(3.0898)\n",
      "10397 Traning Loss: tensor(3.0922)\n",
      "10398 Traning Loss: tensor(3.0983)\n",
      "10399 Traning Loss: tensor(3.0810)\n",
      "10400 Traning Loss: tensor(3.0877)\n",
      "10401 Traning Loss: tensor(3.0891)\n",
      "10402 Traning Loss: tensor(3.0897)\n",
      "10403 Traning Loss: tensor(3.0848)\n",
      "10404 Traning Loss: tensor(3.0820)\n",
      "10405 Traning Loss: tensor(3.0940)\n",
      "10406 Traning Loss: tensor(3.0826)\n",
      "10407 Traning Loss: tensor(3.0923)\n",
      "10408 Traning Loss: tensor(3.0793)\n",
      "10409 Traning Loss: tensor(3.0863)\n",
      "10410 Traning Loss: tensor(3.0876)\n",
      "10411 Traning Loss: tensor(3.0998)\n",
      "10412 Traning Loss: tensor(3.0841)\n",
      "10413 Traning Loss: tensor(3.0977)\n",
      "10414 Traning Loss: tensor(3.0879)\n",
      "10415 Traning Loss: tensor(3.0948)\n",
      "10416 Traning Loss: tensor(3.1052)\n",
      "10417 Traning Loss: tensor(3.0918)\n",
      "10418 Traning Loss: tensor(3.1016)\n",
      "10419 Traning Loss: tensor(3.0983)\n",
      "10420 Traning Loss: tensor(3.0999)\n",
      "10421 Traning Loss: tensor(3.0880)\n",
      "10422 Traning Loss: tensor(3.0838)\n",
      "10423 Traning Loss: tensor(3.0899)\n",
      "10424 Traning Loss: tensor(3.0977)\n",
      "10425 Traning Loss: tensor(3.0815)\n",
      "10426 Traning Loss: tensor(3.0861)\n",
      "10427 Traning Loss: tensor(3.0856)\n",
      "10428 Traning Loss: tensor(3.0901)\n",
      "10429 Traning Loss: tensor(3.0819)\n",
      "10430 Traning Loss: tensor(3.0859)\n",
      "10431 Traning Loss: tensor(3.0966)\n",
      "10432 Traning Loss: tensor(3.0878)\n",
      "10433 Traning Loss: tensor(3.0873)\n",
      "10434 Traning Loss: tensor(3.0831)\n",
      "10435 Traning Loss: tensor(3.0807)\n",
      "10436 Traning Loss: tensor(3.0845)\n",
      "10437 Traning Loss: tensor(3.0974)\n",
      "10438 Traning Loss: tensor(3.0885)\n",
      "10439 Traning Loss: tensor(3.0868)\n",
      "10440 Traning Loss: tensor(3.0871)\n",
      "10441 Traning Loss: tensor(3.0866)\n",
      "10442 Traning Loss: tensor(3.0929)\n",
      "10443 Traning Loss: tensor(3.0988)\n",
      "10444 Traning Loss: tensor(3.0928)\n",
      "10445 Traning Loss: tensor(3.0764)\n",
      "10446 Traning Loss: tensor(3.0899)\n",
      "10447 Traning Loss: tensor(3.0899)\n",
      "10448 Traning Loss: tensor(3.0905)\n",
      "10449 Traning Loss: tensor(3.0858)\n",
      "10450 Traning Loss: tensor(3.0947)\n",
      "10451 Traning Loss: tensor(3.0918)\n",
      "10452 Traning Loss: tensor(3.0861)\n",
      "10453 Traning Loss: tensor(3.0966)\n",
      "10454 Traning Loss: tensor(3.0837)\n",
      "10455 Traning Loss: tensor(3.0690)\n",
      "10456 Traning Loss: tensor(3.0938)\n",
      "10457 Traning Loss: tensor(3.0812)\n",
      "10458 Traning Loss: tensor(3.0792)\n",
      "10459 Traning Loss: tensor(3.0731)\n",
      "10460 Traning Loss: tensor(3.0843)\n",
      "10461 Traning Loss: tensor(3.0833)\n",
      "10462 Traning Loss: tensor(3.0932)\n",
      "10463 Traning Loss: tensor(3.0865)\n",
      "10464 Traning Loss: tensor(3.0780)\n",
      "10465 Traning Loss: tensor(3.0936)\n",
      "10466 Traning Loss: tensor(3.0917)\n",
      "10467 Traning Loss: tensor(3.0818)\n",
      "10468 Traning Loss: tensor(3.0838)\n",
      "10469 Traning Loss: tensor(3.1005)\n",
      "10470 Traning Loss: tensor(3.0761)\n",
      "10471 Traning Loss: tensor(3.0844)\n",
      "10472 Traning Loss: tensor(3.0943)\n",
      "10473 Traning Loss: tensor(3.0884)\n",
      "10474 Traning Loss: tensor(3.0830)\n",
      "10475 Traning Loss: tensor(3.0819)\n",
      "10476 Traning Loss: tensor(3.0834)\n",
      "10477 Traning Loss: tensor(3.0805)\n",
      "10478 Traning Loss: tensor(3.0632)\n",
      "10479 Traning Loss: tensor(3.0774)\n",
      "10480 Traning Loss: tensor(3.0797)\n",
      "10481 Traning Loss: tensor(3.0805)\n",
      "10482 Traning Loss: tensor(3.0816)\n",
      "10483 Traning Loss: tensor(3.0902)\n",
      "10484 Traning Loss: tensor(3.0878)\n",
      "10485 Traning Loss: tensor(3.0807)\n",
      "10486 Traning Loss: tensor(3.0728)\n",
      "10487 Traning Loss: tensor(3.0810)\n",
      "10488 Traning Loss: tensor(3.1037)\n",
      "10489 Traning Loss: tensor(3.0803)\n",
      "10490 Traning Loss: tensor(3.0718)\n",
      "10491 Traning Loss: tensor(3.0779)\n",
      "10492 Traning Loss: tensor(3.0818)\n",
      "10493 Traning Loss: tensor(3.0862)\n",
      "10494 Traning Loss: tensor(3.0776)\n",
      "10495 Traning Loss: tensor(3.0746)\n",
      "10496 Traning Loss: tensor(3.0797)\n",
      "10497 Traning Loss: tensor(3.0719)\n",
      "10498 Traning Loss: tensor(3.0857)\n",
      "10499 Traning Loss: tensor(3.0758)\n",
      "10500 Traning Loss: tensor(3.0771)\n",
      "10501 Traning Loss: tensor(3.0780)\n",
      "10502 Traning Loss: tensor(3.0804)\n",
      "10503 Traning Loss: tensor(3.0758)\n",
      "10504 Traning Loss: tensor(3.0987)\n",
      "10505 Traning Loss: tensor(3.0853)\n",
      "10506 Traning Loss: tensor(3.0860)\n",
      "10507 Traning Loss: tensor(3.0792)\n",
      "10508 Traning Loss: tensor(3.0808)\n",
      "10509 Traning Loss: tensor(3.0788)\n",
      "10510 Traning Loss: tensor(3.0718)\n",
      "10511 Traning Loss: tensor(3.0785)\n",
      "10512 Traning Loss: tensor(3.0788)\n",
      "10513 Traning Loss: tensor(3.0958)\n",
      "10514 Traning Loss: tensor(3.0803)\n",
      "10515 Traning Loss: tensor(3.0720)\n",
      "10516 Traning Loss: tensor(3.0898)\n",
      "10517 Traning Loss: tensor(3.0736)\n",
      "10518 Traning Loss: tensor(3.0763)\n",
      "10519 Traning Loss: tensor(3.0832)\n",
      "10520 Traning Loss: tensor(3.0750)\n",
      "10521 Traning Loss: tensor(3.0771)\n",
      "10522 Traning Loss: tensor(3.0909)\n",
      "10523 Traning Loss: tensor(3.0839)\n",
      "10524 Traning Loss: tensor(3.0724)\n",
      "10525 Traning Loss: tensor(3.0718)\n",
      "10526 Traning Loss: tensor(3.0713)\n",
      "10527 Traning Loss: tensor(3.0748)\n",
      "10528 Traning Loss: tensor(3.0827)\n",
      "10529 Traning Loss: tensor(3.0700)\n",
      "10530 Traning Loss: tensor(3.0737)\n",
      "10531 Traning Loss: tensor(3.0816)\n",
      "10532 Traning Loss: tensor(3.0918)\n",
      "10533 Traning Loss: tensor(3.0670)\n",
      "10534 Traning Loss: tensor(3.0787)\n",
      "10535 Traning Loss: tensor(3.0751)\n",
      "10536 Traning Loss: tensor(3.0800)\n",
      "10537 Traning Loss: tensor(3.0766)\n",
      "10538 Traning Loss: tensor(3.0735)\n",
      "10539 Traning Loss: tensor(3.0624)\n",
      "10540 Traning Loss: tensor(3.0850)\n",
      "10541 Traning Loss: tensor(3.0780)\n",
      "10542 Traning Loss: tensor(3.0838)\n",
      "10543 Traning Loss: tensor(3.0686)\n",
      "10544 Traning Loss: tensor(3.0851)\n",
      "10545 Traning Loss: tensor(3.0821)\n",
      "10546 Traning Loss: tensor(3.0933)\n",
      "10547 Traning Loss: tensor(3.0983)\n",
      "10548 Traning Loss: tensor(3.0648)\n",
      "10549 Traning Loss: tensor(3.0666)\n",
      "10550 Traning Loss: tensor(3.0862)\n",
      "10551 Traning Loss: tensor(3.0676)\n",
      "10552 Traning Loss: tensor(3.0777)\n",
      "10553 Traning Loss: tensor(3.0723)\n",
      "10554 Traning Loss: tensor(3.0795)\n",
      "10555 Traning Loss: tensor(3.0810)\n",
      "10556 Traning Loss: tensor(3.0606)\n",
      "10557 Traning Loss: tensor(3.0666)\n",
      "10558 Traning Loss: tensor(3.0636)\n",
      "10559 Traning Loss: tensor(3.0872)\n",
      "10560 Traning Loss: tensor(3.0795)\n",
      "10561 Traning Loss: tensor(3.0767)\n",
      "10562 Traning Loss: tensor(3.0738)\n",
      "10563 Traning Loss: tensor(3.0745)\n",
      "10564 Traning Loss: tensor(3.0701)\n",
      "10565 Traning Loss: tensor(3.0759)\n",
      "10566 Traning Loss: tensor(3.0717)\n",
      "10567 Traning Loss: tensor(3.0640)\n",
      "10568 Traning Loss: tensor(3.0664)\n",
      "10569 Traning Loss: tensor(3.0855)\n",
      "10570 Traning Loss: tensor(3.0652)\n",
      "10571 Traning Loss: tensor(3.0797)\n",
      "10572 Traning Loss: tensor(3.0705)\n",
      "10573 Traning Loss: tensor(3.0780)\n",
      "10574 Traning Loss: tensor(3.0766)\n",
      "10575 Traning Loss: tensor(3.0752)\n",
      "10576 Traning Loss: tensor(3.0716)\n",
      "10577 Traning Loss: tensor(3.0723)\n",
      "10578 Traning Loss: tensor(3.0673)\n",
      "10579 Traning Loss: tensor(3.0783)\n",
      "10580 Traning Loss: tensor(3.0755)\n",
      "10581 Traning Loss: tensor(3.0640)\n",
      "10582 Traning Loss: tensor(3.0839)\n",
      "10583 Traning Loss: tensor(3.0685)\n",
      "10584 Traning Loss: tensor(3.0787)\n",
      "10585 Traning Loss: tensor(3.0797)\n",
      "10586 Traning Loss: tensor(3.0667)\n",
      "10587 Traning Loss: tensor(3.0820)\n",
      "10588 Traning Loss: tensor(3.0654)\n",
      "10589 Traning Loss: tensor(3.0814)\n",
      "10590 Traning Loss: tensor(3.0767)\n",
      "10591 Traning Loss: tensor(3.0768)\n",
      "10592 Traning Loss: tensor(3.0879)\n",
      "10593 Traning Loss: tensor(3.0784)\n",
      "10594 Traning Loss: tensor(3.0831)\n",
      "10595 Traning Loss: tensor(3.0677)\n",
      "10596 Traning Loss: tensor(3.0830)\n",
      "10597 Traning Loss: tensor(3.0633)\n",
      "10598 Traning Loss: tensor(3.0759)\n",
      "10599 Traning Loss: tensor(3.0749)\n",
      "10600 Traning Loss: tensor(3.0719)\n",
      "10601 Traning Loss: tensor(3.0801)\n",
      "10602 Traning Loss: tensor(3.0781)\n",
      "10603 Traning Loss: tensor(3.0738)\n",
      "10604 Traning Loss: tensor(3.0684)\n",
      "10605 Traning Loss: tensor(3.0750)\n",
      "10606 Traning Loss: tensor(3.0777)\n",
      "10607 Traning Loss: tensor(3.0734)\n",
      "10608 Traning Loss: tensor(3.0611)\n",
      "10609 Traning Loss: tensor(3.0898)\n",
      "10610 Traning Loss: tensor(3.0881)\n",
      "10611 Traning Loss: tensor(3.0670)\n",
      "10612 Traning Loss: tensor(3.0594)\n",
      "10613 Traning Loss: tensor(3.0660)\n",
      "10614 Traning Loss: tensor(3.0690)\n",
      "10615 Traning Loss: tensor(3.0619)\n",
      "10616 Traning Loss: tensor(3.0631)\n",
      "10617 Traning Loss: tensor(3.0757)\n",
      "10618 Traning Loss: tensor(3.0676)\n",
      "10619 Traning Loss: tensor(3.0651)\n",
      "10620 Traning Loss: tensor(3.0647)\n",
      "10621 Traning Loss: tensor(3.0585)\n",
      "10622 Traning Loss: tensor(3.0527)\n",
      "10623 Traning Loss: tensor(3.0691)\n",
      "10624 Traning Loss: tensor(3.0702)\n",
      "10625 Traning Loss: tensor(3.0768)\n",
      "10626 Traning Loss: tensor(3.0655)\n",
      "10627 Traning Loss: tensor(3.0648)\n",
      "10628 Traning Loss: tensor(3.0808)\n",
      "10629 Traning Loss: tensor(3.0655)\n",
      "10630 Traning Loss: tensor(3.0675)\n",
      "10631 Traning Loss: tensor(3.0630)\n",
      "10632 Traning Loss: tensor(3.0631)\n",
      "10633 Traning Loss: tensor(3.0707)\n",
      "10634 Traning Loss: tensor(3.0592)\n",
      "10635 Traning Loss: tensor(3.0720)\n",
      "10636 Traning Loss: tensor(3.0837)\n",
      "10637 Traning Loss: tensor(3.0604)\n",
      "10638 Traning Loss: tensor(3.0812)\n",
      "10639 Traning Loss: tensor(3.0670)\n",
      "10640 Traning Loss: tensor(3.0695)\n",
      "10641 Traning Loss: tensor(3.0563)\n",
      "10642 Traning Loss: tensor(3.0710)\n",
      "10643 Traning Loss: tensor(3.0534)\n",
      "10644 Traning Loss: tensor(3.0681)\n",
      "10645 Traning Loss: tensor(3.0777)\n",
      "10646 Traning Loss: tensor(3.0585)\n",
      "10647 Traning Loss: tensor(3.0648)\n",
      "10648 Traning Loss: tensor(3.0575)\n",
      "10649 Traning Loss: tensor(3.0778)\n",
      "10650 Traning Loss: tensor(3.0670)\n",
      "10651 Traning Loss: tensor(3.0727)\n",
      "10652 Traning Loss: tensor(3.0691)\n",
      "10653 Traning Loss: tensor(3.0658)\n",
      "10654 Traning Loss: tensor(3.0659)\n",
      "10655 Traning Loss: tensor(3.0596)\n",
      "10656 Traning Loss: tensor(3.0658)\n",
      "10657 Traning Loss: tensor(3.0614)\n",
      "10658 Traning Loss: tensor(3.0797)\n",
      "10659 Traning Loss: tensor(3.0606)\n",
      "10660 Traning Loss: tensor(3.0559)\n",
      "10661 Traning Loss: tensor(3.0574)\n",
      "10662 Traning Loss: tensor(3.0875)\n",
      "10663 Traning Loss: tensor(3.0608)\n",
      "10664 Traning Loss: tensor(3.0659)\n",
      "10665 Traning Loss: tensor(3.0800)\n",
      "10666 Traning Loss: tensor(3.0616)\n",
      "10667 Traning Loss: tensor(3.0619)\n",
      "10668 Traning Loss: tensor(3.0651)\n",
      "10669 Traning Loss: tensor(3.0605)\n",
      "10670 Traning Loss: tensor(3.0571)\n",
      "10671 Traning Loss: tensor(3.0555)\n",
      "10672 Traning Loss: tensor(3.0573)\n",
      "10673 Traning Loss: tensor(3.0650)\n",
      "10674 Traning Loss: tensor(3.0745)\n",
      "10675 Traning Loss: tensor(3.0615)\n",
      "10676 Traning Loss: tensor(3.0658)\n",
      "10677 Traning Loss: tensor(3.0753)\n",
      "10678 Traning Loss: tensor(3.0574)\n",
      "10679 Traning Loss: tensor(3.0652)\n",
      "10680 Traning Loss: tensor(3.0556)\n",
      "10681 Traning Loss: tensor(3.0529)\n",
      "10682 Traning Loss: tensor(3.0557)\n",
      "10683 Traning Loss: tensor(3.0773)\n",
      "10684 Traning Loss: tensor(3.0606)\n",
      "10685 Traning Loss: tensor(3.0630)\n",
      "10686 Traning Loss: tensor(3.0563)\n",
      "10687 Traning Loss: tensor(3.0763)\n",
      "10688 Traning Loss: tensor(3.0643)\n",
      "10689 Traning Loss: tensor(3.0581)\n",
      "10690 Traning Loss: tensor(3.0468)\n",
      "10691 Traning Loss: tensor(3.0728)\n",
      "10692 Traning Loss: tensor(3.0560)\n",
      "10693 Traning Loss: tensor(3.0636)\n",
      "10694 Traning Loss: tensor(3.0641)\n",
      "10695 Traning Loss: tensor(3.0543)\n",
      "10696 Traning Loss: tensor(3.0659)\n",
      "10697 Traning Loss: tensor(3.0687)\n",
      "10698 Traning Loss: tensor(3.0710)\n",
      "10699 Traning Loss: tensor(3.0567)\n",
      "10700 Traning Loss: tensor(3.0706)\n",
      "10701 Traning Loss: tensor(3.0765)\n",
      "10702 Traning Loss: tensor(3.0566)\n",
      "10703 Traning Loss: tensor(3.0544)\n",
      "10704 Traning Loss: tensor(3.0487)\n",
      "10705 Traning Loss: tensor(3.0735)\n",
      "10706 Traning Loss: tensor(3.0609)\n",
      "10707 Traning Loss: tensor(3.0435)\n",
      "10708 Traning Loss: tensor(3.0678)\n",
      "10709 Traning Loss: tensor(3.0738)\n",
      "10710 Traning Loss: tensor(3.0622)\n",
      "10711 Traning Loss: tensor(3.0613)\n",
      "10712 Traning Loss: tensor(3.0618)\n",
      "10713 Traning Loss: tensor(3.0526)\n",
      "10714 Traning Loss: tensor(3.0581)\n",
      "10715 Traning Loss: tensor(3.0683)\n",
      "10716 Traning Loss: tensor(3.0564)\n",
      "10717 Traning Loss: tensor(3.0640)\n",
      "10718 Traning Loss: tensor(3.0571)\n",
      "10719 Traning Loss: tensor(3.0586)\n",
      "10720 Traning Loss: tensor(3.0586)\n",
      "10721 Traning Loss: tensor(3.0429)\n",
      "10722 Traning Loss: tensor(3.0520)\n",
      "10723 Traning Loss: tensor(3.0655)\n",
      "10724 Traning Loss: tensor(3.0570)\n",
      "10725 Traning Loss: tensor(3.0639)\n",
      "10726 Traning Loss: tensor(3.0483)\n",
      "10727 Traning Loss: tensor(3.0555)\n",
      "10728 Traning Loss: tensor(3.0548)\n",
      "10729 Traning Loss: tensor(3.0664)\n",
      "10730 Traning Loss: tensor(3.0554)\n",
      "10731 Traning Loss: tensor(3.0648)\n",
      "10732 Traning Loss: tensor(3.0551)\n",
      "10733 Traning Loss: tensor(3.0433)\n",
      "10734 Traning Loss: tensor(3.0494)\n",
      "10735 Traning Loss: tensor(3.0441)\n",
      "10736 Traning Loss: tensor(3.0586)\n",
      "10737 Traning Loss: tensor(3.0592)\n",
      "10738 Traning Loss: tensor(3.0554)\n",
      "10739 Traning Loss: tensor(3.0550)\n",
      "10740 Traning Loss: tensor(3.0611)\n",
      "10741 Traning Loss: tensor(3.0505)\n",
      "10742 Traning Loss: tensor(3.0439)\n",
      "10743 Traning Loss: tensor(3.0616)\n",
      "10744 Traning Loss: tensor(3.0510)\n",
      "10745 Traning Loss: tensor(3.0499)\n",
      "10746 Traning Loss: tensor(3.0452)\n",
      "10747 Traning Loss: tensor(3.0537)\n",
      "10748 Traning Loss: tensor(3.0596)\n",
      "10749 Traning Loss: tensor(3.0621)\n",
      "10750 Traning Loss: tensor(3.0624)\n",
      "10751 Traning Loss: tensor(3.0480)\n",
      "10752 Traning Loss: tensor(3.0342)\n",
      "10753 Traning Loss: tensor(3.0672)\n",
      "10754 Traning Loss: tensor(3.0430)\n",
      "10755 Traning Loss: tensor(3.0485)\n",
      "10756 Traning Loss: tensor(3.0639)\n",
      "10757 Traning Loss: tensor(3.0656)\n",
      "10758 Traning Loss: tensor(3.0585)\n",
      "10759 Traning Loss: tensor(3.0406)\n",
      "10760 Traning Loss: tensor(3.0636)\n",
      "10761 Traning Loss: tensor(3.0437)\n",
      "10762 Traning Loss: tensor(3.0613)\n",
      "10763 Traning Loss: tensor(3.0520)\n",
      "10764 Traning Loss: tensor(3.0452)\n",
      "10765 Traning Loss: tensor(3.0548)\n",
      "10766 Traning Loss: tensor(3.0522)\n",
      "10767 Traning Loss: tensor(3.0514)\n",
      "10768 Traning Loss: tensor(3.0556)\n",
      "10769 Traning Loss: tensor(3.0410)\n",
      "10770 Traning Loss: tensor(3.0725)\n",
      "10771 Traning Loss: tensor(3.0557)\n",
      "10772 Traning Loss: tensor(3.0479)\n",
      "10773 Traning Loss: tensor(3.0514)\n",
      "10774 Traning Loss: tensor(3.0647)\n",
      "10775 Traning Loss: tensor(3.0522)\n",
      "10776 Traning Loss: tensor(3.0624)\n",
      "10777 Traning Loss: tensor(3.0547)\n",
      "10778 Traning Loss: tensor(3.0519)\n",
      "10779 Traning Loss: tensor(3.0606)\n",
      "10780 Traning Loss: tensor(3.0455)\n",
      "10781 Traning Loss: tensor(3.0341)\n",
      "10782 Traning Loss: tensor(3.0666)\n",
      "10783 Traning Loss: tensor(3.0526)\n",
      "10784 Traning Loss: tensor(3.0457)\n",
      "10785 Traning Loss: tensor(3.0792)\n",
      "10786 Traning Loss: tensor(3.0602)\n",
      "10787 Traning Loss: tensor(3.0707)\n",
      "10788 Traning Loss: tensor(3.0592)\n",
      "10789 Traning Loss: tensor(3.0505)\n",
      "10790 Traning Loss: tensor(3.0509)\n",
      "10791 Traning Loss: tensor(3.0512)\n",
      "10792 Traning Loss: tensor(3.0596)\n",
      "10793 Traning Loss: tensor(3.0512)\n",
      "10794 Traning Loss: tensor(3.0597)\n",
      "10795 Traning Loss: tensor(3.0487)\n",
      "10796 Traning Loss: tensor(3.0556)\n",
      "10797 Traning Loss: tensor(3.0510)\n",
      "10798 Traning Loss: tensor(3.0440)\n",
      "10799 Traning Loss: tensor(3.0601)\n",
      "10800 Traning Loss: tensor(3.0508)\n",
      "10801 Traning Loss: tensor(3.0605)\n",
      "10802 Traning Loss: tensor(3.0449)\n",
      "10803 Traning Loss: tensor(3.0617)\n",
      "10804 Traning Loss: tensor(3.0501)\n",
      "10805 Traning Loss: tensor(3.0446)\n",
      "10806 Traning Loss: tensor(3.0495)\n",
      "10807 Traning Loss: tensor(3.0553)\n",
      "10808 Traning Loss: tensor(3.0486)\n",
      "10809 Traning Loss: tensor(3.0412)\n",
      "10810 Traning Loss: tensor(3.0495)\n",
      "10811 Traning Loss: tensor(3.0548)\n",
      "10812 Traning Loss: tensor(3.0426)\n",
      "10813 Traning Loss: tensor(3.0531)\n",
      "10814 Traning Loss: tensor(3.0578)\n",
      "10815 Traning Loss: tensor(3.0412)\n",
      "10816 Traning Loss: tensor(3.0509)\n",
      "10817 Traning Loss: tensor(3.0590)\n",
      "10818 Traning Loss: tensor(3.0468)\n",
      "10819 Traning Loss: tensor(3.0510)\n",
      "10820 Traning Loss: tensor(3.0601)\n",
      "10821 Traning Loss: tensor(3.0419)\n",
      "10822 Traning Loss: tensor(3.0414)\n",
      "10823 Traning Loss: tensor(3.0535)\n",
      "10824 Traning Loss: tensor(3.0440)\n",
      "10825 Traning Loss: tensor(3.0461)\n",
      "10826 Traning Loss: tensor(3.0550)\n",
      "10827 Traning Loss: tensor(3.0598)\n",
      "10828 Traning Loss: tensor(3.0404)\n",
      "10829 Traning Loss: tensor(3.0466)\n",
      "10830 Traning Loss: tensor(3.0382)\n",
      "10831 Traning Loss: tensor(3.0439)\n",
      "10832 Traning Loss: tensor(3.0483)\n",
      "10833 Traning Loss: tensor(3.0428)\n",
      "10834 Traning Loss: tensor(3.0440)\n",
      "10835 Traning Loss: tensor(3.0418)\n",
      "10836 Traning Loss: tensor(3.0450)\n",
      "10837 Traning Loss: tensor(3.0445)\n",
      "10838 Traning Loss: tensor(3.0556)\n",
      "10839 Traning Loss: tensor(3.0556)\n",
      "10840 Traning Loss: tensor(3.0626)\n",
      "10841 Traning Loss: tensor(3.0344)\n",
      "10842 Traning Loss: tensor(3.0472)\n",
      "10843 Traning Loss: tensor(3.0359)\n",
      "10844 Traning Loss: tensor(3.0558)\n",
      "10845 Traning Loss: tensor(3.0656)\n",
      "10846 Traning Loss: tensor(3.0453)\n",
      "10847 Traning Loss: tensor(3.0371)\n",
      "10848 Traning Loss: tensor(3.0392)\n",
      "10849 Traning Loss: tensor(3.0521)\n",
      "10850 Traning Loss: tensor(3.0464)\n",
      "10851 Traning Loss: tensor(3.0448)\n",
      "10852 Traning Loss: tensor(3.0492)\n",
      "10853 Traning Loss: tensor(3.0541)\n",
      "10854 Traning Loss: tensor(3.0453)\n",
      "10855 Traning Loss: tensor(3.0345)\n",
      "10856 Traning Loss: tensor(3.0482)\n",
      "10857 Traning Loss: tensor(3.0490)\n",
      "10858 Traning Loss: tensor(3.0349)\n",
      "10859 Traning Loss: tensor(3.0530)\n",
      "10860 Traning Loss: tensor(3.0593)\n",
      "10861 Traning Loss: tensor(3.0337)\n",
      "10862 Traning Loss: tensor(3.0420)\n",
      "10863 Traning Loss: tensor(3.0591)\n",
      "10864 Traning Loss: tensor(3.0475)\n",
      "10865 Traning Loss: tensor(3.0398)\n",
      "10866 Traning Loss: tensor(3.0469)\n",
      "10867 Traning Loss: tensor(3.0495)\n",
      "10868 Traning Loss: tensor(3.0359)\n",
      "10869 Traning Loss: tensor(3.0389)\n",
      "10870 Traning Loss: tensor(3.0503)\n",
      "10871 Traning Loss: tensor(3.0575)\n",
      "10872 Traning Loss: tensor(3.0425)\n",
      "10873 Traning Loss: tensor(3.0339)\n",
      "10874 Traning Loss: tensor(3.0265)\n",
      "10875 Traning Loss: tensor(3.0513)\n",
      "10876 Traning Loss: tensor(3.0384)\n",
      "10877 Traning Loss: tensor(3.0511)\n",
      "10878 Traning Loss: tensor(3.0380)\n",
      "10879 Traning Loss: tensor(3.0453)\n",
      "10880 Traning Loss: tensor(3.0401)\n",
      "10881 Traning Loss: tensor(3.0326)\n",
      "10882 Traning Loss: tensor(3.0430)\n",
      "10883 Traning Loss: tensor(3.0281)\n",
      "10884 Traning Loss: tensor(3.0458)\n",
      "10885 Traning Loss: tensor(3.0571)\n",
      "10886 Traning Loss: tensor(3.0332)\n",
      "10887 Traning Loss: tensor(3.0380)\n",
      "10888 Traning Loss: tensor(3.0430)\n",
      "10889 Traning Loss: tensor(3.0530)\n",
      "10890 Traning Loss: tensor(3.0348)\n",
      "10891 Traning Loss: tensor(3.0414)\n",
      "10892 Traning Loss: tensor(3.0476)\n",
      "10893 Traning Loss: tensor(3.0330)\n",
      "10894 Traning Loss: tensor(3.0410)\n",
      "10895 Traning Loss: tensor(3.0484)\n",
      "10896 Traning Loss: tensor(3.0385)\n",
      "10897 Traning Loss: tensor(3.0327)\n",
      "10898 Traning Loss: tensor(3.0344)\n",
      "10899 Traning Loss: tensor(3.0441)\n",
      "10900 Traning Loss: tensor(3.0296)\n",
      "10901 Traning Loss: tensor(3.0479)\n",
      "10902 Traning Loss: tensor(3.0296)\n",
      "10903 Traning Loss: tensor(3.0248)\n",
      "10904 Traning Loss: tensor(3.0392)\n",
      "10905 Traning Loss: tensor(3.0428)\n",
      "10906 Traning Loss: tensor(3.0399)\n",
      "10907 Traning Loss: tensor(3.0282)\n",
      "10908 Traning Loss: tensor(3.0489)\n",
      "10909 Traning Loss: tensor(3.0504)\n",
      "10910 Traning Loss: tensor(3.0371)\n",
      "10911 Traning Loss: tensor(3.0252)\n",
      "10912 Traning Loss: tensor(3.0408)\n",
      "10913 Traning Loss: tensor(3.0395)\n",
      "10914 Traning Loss: tensor(3.0366)\n",
      "10915 Traning Loss: tensor(3.0369)\n",
      "10916 Traning Loss: tensor(3.0444)\n",
      "10917 Traning Loss: tensor(3.0315)\n",
      "10918 Traning Loss: tensor(3.0424)\n",
      "10919 Traning Loss: tensor(3.0491)\n",
      "10920 Traning Loss: tensor(3.0426)\n",
      "10921 Traning Loss: tensor(3.0462)\n",
      "10922 Traning Loss: tensor(3.0385)\n",
      "10923 Traning Loss: tensor(3.0517)\n",
      "10924 Traning Loss: tensor(3.0412)\n",
      "10925 Traning Loss: tensor(3.0407)\n",
      "10926 Traning Loss: tensor(3.0248)\n",
      "10927 Traning Loss: tensor(3.0215)\n",
      "10928 Traning Loss: tensor(3.0431)\n",
      "10929 Traning Loss: tensor(3.0402)\n",
      "10930 Traning Loss: tensor(3.0439)\n",
      "10931 Traning Loss: tensor(3.0377)\n",
      "10932 Traning Loss: tensor(3.0410)\n",
      "10933 Traning Loss: tensor(3.0402)\n",
      "10934 Traning Loss: tensor(3.0264)\n",
      "10935 Traning Loss: tensor(3.0235)\n",
      "10936 Traning Loss: tensor(3.0423)\n",
      "10937 Traning Loss: tensor(3.0312)\n",
      "10938 Traning Loss: tensor(3.0382)\n",
      "10939 Traning Loss: tensor(3.0165)\n",
      "10940 Traning Loss: tensor(3.0429)\n",
      "10941 Traning Loss: tensor(3.0343)\n",
      "10942 Traning Loss: tensor(3.0439)\n",
      "10943 Traning Loss: tensor(3.0270)\n",
      "10944 Traning Loss: tensor(3.0286)\n",
      "10945 Traning Loss: tensor(3.0341)\n",
      "10946 Traning Loss: tensor(3.0241)\n",
      "10947 Traning Loss: tensor(3.0495)\n",
      "10948 Traning Loss: tensor(3.0241)\n",
      "10949 Traning Loss: tensor(3.0390)\n",
      "10950 Traning Loss: tensor(3.0316)\n",
      "10951 Traning Loss: tensor(3.0395)\n",
      "10952 Traning Loss: tensor(3.0320)\n",
      "10953 Traning Loss: tensor(3.0396)\n",
      "10954 Traning Loss: tensor(3.0344)\n",
      "10955 Traning Loss: tensor(3.0480)\n",
      "10956 Traning Loss: tensor(3.0265)\n",
      "10957 Traning Loss: tensor(3.0259)\n",
      "10958 Traning Loss: tensor(3.0312)\n",
      "10959 Traning Loss: tensor(3.0310)\n",
      "10960 Traning Loss: tensor(3.0369)\n",
      "10961 Traning Loss: tensor(3.0376)\n",
      "10962 Traning Loss: tensor(3.0240)\n",
      "10963 Traning Loss: tensor(3.0223)\n",
      "10964 Traning Loss: tensor(3.0393)\n",
      "10965 Traning Loss: tensor(3.0297)\n",
      "10966 Traning Loss: tensor(3.0206)\n",
      "10967 Traning Loss: tensor(3.0269)\n",
      "10968 Traning Loss: tensor(3.0267)\n",
      "10969 Traning Loss: tensor(3.0273)\n",
      "10970 Traning Loss: tensor(3.0312)\n",
      "10971 Traning Loss: tensor(3.0291)\n",
      "10972 Traning Loss: tensor(3.0300)\n",
      "10973 Traning Loss: tensor(3.0289)\n",
      "10974 Traning Loss: tensor(3.0428)\n",
      "10975 Traning Loss: tensor(3.0491)\n",
      "10976 Traning Loss: tensor(3.0377)\n",
      "10977 Traning Loss: tensor(3.0268)\n",
      "10978 Traning Loss: tensor(3.0407)\n",
      "10979 Traning Loss: tensor(3.0281)\n",
      "10980 Traning Loss: tensor(3.0248)\n",
      "10981 Traning Loss: tensor(3.0222)\n",
      "10982 Traning Loss: tensor(3.0352)\n",
      "10983 Traning Loss: tensor(3.0231)\n",
      "10984 Traning Loss: tensor(3.0248)\n",
      "10985 Traning Loss: tensor(3.0184)\n",
      "10986 Traning Loss: tensor(3.0271)\n",
      "10987 Traning Loss: tensor(3.0203)\n",
      "10988 Traning Loss: tensor(3.0258)\n",
      "10989 Traning Loss: tensor(3.0218)\n",
      "10990 Traning Loss: tensor(3.0262)\n",
      "10991 Traning Loss: tensor(3.0259)\n",
      "10992 Traning Loss: tensor(3.0257)\n",
      "10993 Traning Loss: tensor(3.0220)\n",
      "10994 Traning Loss: tensor(3.0251)\n",
      "10995 Traning Loss: tensor(3.0239)\n",
      "10996 Traning Loss: tensor(3.0316)\n",
      "10997 Traning Loss: tensor(3.0160)\n",
      "10998 Traning Loss: tensor(3.0292)\n",
      "10999 Traning Loss: tensor(3.0115)\n",
      "11000 Traning Loss: tensor(3.0320)\n",
      "11001 Traning Loss: tensor(3.0331)\n",
      "11002 Traning Loss: tensor(3.0239)\n",
      "11003 Traning Loss: tensor(3.0220)\n",
      "11004 Traning Loss: tensor(3.0172)\n",
      "11005 Traning Loss: tensor(3.0229)\n",
      "11006 Traning Loss: tensor(3.0287)\n",
      "11007 Traning Loss: tensor(3.0367)\n",
      "11008 Traning Loss: tensor(3.0187)\n",
      "11009 Traning Loss: tensor(3.0101)\n",
      "11010 Traning Loss: tensor(3.0224)\n",
      "11011 Traning Loss: tensor(3.0155)\n",
      "11012 Traning Loss: tensor(3.0163)\n",
      "11013 Traning Loss: tensor(3.0173)\n",
      "11014 Traning Loss: tensor(3.0250)\n",
      "11015 Traning Loss: tensor(3.0511)\n",
      "11016 Traning Loss: tensor(3.0150)\n",
      "11017 Traning Loss: tensor(3.0360)\n",
      "11018 Traning Loss: tensor(3.0305)\n",
      "11019 Traning Loss: tensor(3.0349)\n",
      "11020 Traning Loss: tensor(3.0237)\n",
      "11021 Traning Loss: tensor(3.0222)\n",
      "11022 Traning Loss: tensor(3.0279)\n",
      "11023 Traning Loss: tensor(3.0215)\n",
      "11024 Traning Loss: tensor(3.0253)\n",
      "11025 Traning Loss: tensor(3.0265)\n",
      "11026 Traning Loss: tensor(3.0218)\n",
      "11027 Traning Loss: tensor(3.0144)\n",
      "11028 Traning Loss: tensor(3.0179)\n",
      "11029 Traning Loss: tensor(3.0096)\n",
      "11030 Traning Loss: tensor(3.0242)\n",
      "11031 Traning Loss: tensor(3.0218)\n",
      "11032 Traning Loss: tensor(3.0144)\n",
      "11033 Traning Loss: tensor(3.0115)\n",
      "11034 Traning Loss: tensor(3.0085)\n",
      "11035 Traning Loss: tensor(3.0252)\n",
      "11036 Traning Loss: tensor(3.0225)\n",
      "11037 Traning Loss: tensor(3.0230)\n",
      "11038 Traning Loss: tensor(3.0285)\n",
      "11039 Traning Loss: tensor(3.0328)\n",
      "11040 Traning Loss: tensor(3.0159)\n",
      "11041 Traning Loss: tensor(3.0305)\n",
      "11042 Traning Loss: tensor(3.0322)\n",
      "11043 Traning Loss: tensor(3.0280)\n",
      "11044 Traning Loss: tensor(3.0169)\n",
      "11045 Traning Loss: tensor(3.0301)\n",
      "11046 Traning Loss: tensor(3.0100)\n",
      "11047 Traning Loss: tensor(3.0340)\n",
      "11048 Traning Loss: tensor(3.0234)\n",
      "11049 Traning Loss: tensor(3.0226)\n",
      "11050 Traning Loss: tensor(3.0264)\n",
      "11051 Traning Loss: tensor(3.0291)\n",
      "11052 Traning Loss: tensor(3.0138)\n",
      "11053 Traning Loss: tensor(3.0071)\n",
      "11054 Traning Loss: tensor(3.0211)\n",
      "11055 Traning Loss: tensor(3.0304)\n",
      "11056 Traning Loss: tensor(3.0069)\n",
      "11057 Traning Loss: tensor(3.0383)\n",
      "11058 Traning Loss: tensor(3.0173)\n",
      "11059 Traning Loss: tensor(3.0111)\n",
      "11060 Traning Loss: tensor(3.0172)\n",
      "11061 Traning Loss: tensor(3.0101)\n",
      "11062 Traning Loss: tensor(3.0234)\n",
      "11063 Traning Loss: tensor(3.0159)\n",
      "11064 Traning Loss: tensor(3.0112)\n",
      "11065 Traning Loss: tensor(3.0175)\n",
      "11066 Traning Loss: tensor(3.0101)\n",
      "11067 Traning Loss: tensor(3.0246)\n",
      "11068 Traning Loss: tensor(3.0096)\n",
      "11069 Traning Loss: tensor(3.0390)\n",
      "11070 Traning Loss: tensor(3.0176)\n",
      "11071 Traning Loss: tensor(3.0096)\n",
      "11072 Traning Loss: tensor(3.0193)\n",
      "11073 Traning Loss: tensor(3.0169)\n",
      "11074 Traning Loss: tensor(3.0110)\n",
      "11075 Traning Loss: tensor(3.0133)\n",
      "11076 Traning Loss: tensor(3.0019)\n",
      "11077 Traning Loss: tensor(3.0182)\n",
      "11078 Traning Loss: tensor(3.0171)\n",
      "11079 Traning Loss: tensor(3.0159)\n",
      "11080 Traning Loss: tensor(3.0299)\n",
      "11081 Traning Loss: tensor(3.0313)\n",
      "11082 Traning Loss: tensor(3.0194)\n",
      "11083 Traning Loss: tensor(3.0088)\n",
      "11084 Traning Loss: tensor(3.0113)\n",
      "11085 Traning Loss: tensor(3.0074)\n",
      "11086 Traning Loss: tensor(3.0183)\n",
      "11087 Traning Loss: tensor(3.0181)\n",
      "11088 Traning Loss: tensor(3.0030)\n",
      "11089 Traning Loss: tensor(3.0210)\n",
      "11090 Traning Loss: tensor(3.0160)\n",
      "11091 Traning Loss: tensor(3.0215)\n",
      "11092 Traning Loss: tensor(3.0150)\n",
      "11093 Traning Loss: tensor(3.0138)\n",
      "11094 Traning Loss: tensor(3.0138)\n",
      "11095 Traning Loss: tensor(3.0167)\n",
      "11096 Traning Loss: tensor(3.0106)\n",
      "11097 Traning Loss: tensor(3.0317)\n",
      "11098 Traning Loss: tensor(3.0047)\n",
      "11099 Traning Loss: tensor(3.0035)\n",
      "11100 Traning Loss: tensor(3.0089)\n",
      "11101 Traning Loss: tensor(3.0166)\n",
      "11102 Traning Loss: tensor(3.0074)\n",
      "11103 Traning Loss: tensor(3.0059)\n",
      "11104 Traning Loss: tensor(3.0072)\n",
      "11105 Traning Loss: tensor(3.0136)\n",
      "11106 Traning Loss: tensor(3.0132)\n",
      "11107 Traning Loss: tensor(3.0003)\n",
      "11108 Traning Loss: tensor(3.0132)\n",
      "11109 Traning Loss: tensor(2.9992)\n",
      "11110 Traning Loss: tensor(3.0272)\n",
      "11111 Traning Loss: tensor(3.0069)\n",
      "11112 Traning Loss: tensor(3.0160)\n",
      "11113 Traning Loss: tensor(3.0068)\n",
      "11114 Traning Loss: tensor(3.0250)\n",
      "11115 Traning Loss: tensor(3.0063)\n",
      "11116 Traning Loss: tensor(3.0060)\n",
      "11117 Traning Loss: tensor(3.0179)\n",
      "11118 Traning Loss: tensor(2.9997)\n",
      "11119 Traning Loss: tensor(3.0214)\n",
      "11120 Traning Loss: tensor(3.0241)\n",
      "11121 Traning Loss: tensor(3.0194)\n",
      "11122 Traning Loss: tensor(3.0250)\n",
      "11123 Traning Loss: tensor(3.0053)\n",
      "11124 Traning Loss: tensor(3.0088)\n",
      "11125 Traning Loss: tensor(3.0038)\n",
      "11126 Traning Loss: tensor(3.0131)\n",
      "11127 Traning Loss: tensor(3.0139)\n",
      "11128 Traning Loss: tensor(3.0030)\n",
      "11129 Traning Loss: tensor(3.0088)\n",
      "11130 Traning Loss: tensor(3.0053)\n",
      "11131 Traning Loss: tensor(3.0056)\n",
      "11132 Traning Loss: tensor(3.0127)\n",
      "11133 Traning Loss: tensor(3.0104)\n",
      "11134 Traning Loss: tensor(3.0095)\n",
      "11135 Traning Loss: tensor(3.0125)\n",
      "11136 Traning Loss: tensor(3.0032)\n",
      "11137 Traning Loss: tensor(2.9999)\n",
      "11138 Traning Loss: tensor(3.0126)\n",
      "11139 Traning Loss: tensor(3.0252)\n",
      "11140 Traning Loss: tensor(3.0026)\n",
      "11141 Traning Loss: tensor(3.0026)\n",
      "11142 Traning Loss: tensor(3.0094)\n",
      "11143 Traning Loss: tensor(3.0196)\n",
      "11144 Traning Loss: tensor(3.0249)\n",
      "11145 Traning Loss: tensor(3.0113)\n",
      "11146 Traning Loss: tensor(2.9937)\n",
      "11147 Traning Loss: tensor(3.0037)\n",
      "11148 Traning Loss: tensor(3.0047)\n",
      "11149 Traning Loss: tensor(3.0011)\n",
      "11150 Traning Loss: tensor(3.0079)\n",
      "11151 Traning Loss: tensor(3.0077)\n",
      "11152 Traning Loss: tensor(3.0111)\n",
      "11153 Traning Loss: tensor(3.0153)\n",
      "11154 Traning Loss: tensor(3.0013)\n",
      "11155 Traning Loss: tensor(3.0206)\n",
      "11156 Traning Loss: tensor(3.0079)\n",
      "11157 Traning Loss: tensor(3.0061)\n",
      "11158 Traning Loss: tensor(3.0045)\n",
      "11159 Traning Loss: tensor(2.9888)\n",
      "11160 Traning Loss: tensor(2.9927)\n",
      "11161 Traning Loss: tensor(3.0080)\n",
      "11162 Traning Loss: tensor(2.9973)\n",
      "11163 Traning Loss: tensor(3.0223)\n",
      "11164 Traning Loss: tensor(3.0102)\n",
      "11165 Traning Loss: tensor(3.0056)\n",
      "11166 Traning Loss: tensor(2.9877)\n",
      "11167 Traning Loss: tensor(3.0150)\n",
      "11168 Traning Loss: tensor(2.9980)\n",
      "11169 Traning Loss: tensor(3.0006)\n",
      "11170 Traning Loss: tensor(3.0091)\n",
      "11171 Traning Loss: tensor(3.0069)\n",
      "11172 Traning Loss: tensor(2.9969)\n",
      "11173 Traning Loss: tensor(2.9958)\n",
      "11174 Traning Loss: tensor(3.0022)\n",
      "11175 Traning Loss: tensor(3.0011)\n",
      "11176 Traning Loss: tensor(2.9913)\n",
      "11177 Traning Loss: tensor(2.9972)\n",
      "11178 Traning Loss: tensor(3.0145)\n",
      "11179 Traning Loss: tensor(3.0014)\n",
      "11180 Traning Loss: tensor(3.0025)\n",
      "11181 Traning Loss: tensor(2.9984)\n",
      "11182 Traning Loss: tensor(3.0111)\n",
      "11183 Traning Loss: tensor(2.9862)\n",
      "11184 Traning Loss: tensor(2.9964)\n",
      "11185 Traning Loss: tensor(2.9995)\n",
      "11186 Traning Loss: tensor(2.9942)\n",
      "11187 Traning Loss: tensor(2.9978)\n",
      "11188 Traning Loss: tensor(2.9868)\n",
      "11189 Traning Loss: tensor(2.9934)\n",
      "11190 Traning Loss: tensor(3.0182)\n",
      "11191 Traning Loss: tensor(2.9992)\n",
      "11192 Traning Loss: tensor(2.9885)\n",
      "11193 Traning Loss: tensor(2.9925)\n",
      "11194 Traning Loss: tensor(3.0100)\n",
      "11195 Traning Loss: tensor(2.9986)\n",
      "11196 Traning Loss: tensor(3.0049)\n",
      "11197 Traning Loss: tensor(3.0058)\n",
      "11198 Traning Loss: tensor(3.0051)\n",
      "11199 Traning Loss: tensor(3.0219)\n",
      "11200 Traning Loss: tensor(3.0065)\n",
      "11201 Traning Loss: tensor(2.9854)\n",
      "11202 Traning Loss: tensor(2.9864)\n",
      "11203 Traning Loss: tensor(3.0050)\n",
      "11204 Traning Loss: tensor(2.9989)\n",
      "11205 Traning Loss: tensor(2.9890)\n",
      "11206 Traning Loss: tensor(3.0266)\n",
      "11207 Traning Loss: tensor(3.0026)\n",
      "11208 Traning Loss: tensor(2.9911)\n",
      "11209 Traning Loss: tensor(3.0129)\n",
      "11210 Traning Loss: tensor(2.9930)\n",
      "11211 Traning Loss: tensor(2.9961)\n",
      "11212 Traning Loss: tensor(2.9812)\n",
      "11213 Traning Loss: tensor(2.9992)\n",
      "11214 Traning Loss: tensor(2.9968)\n",
      "11215 Traning Loss: tensor(3.0059)\n",
      "11216 Traning Loss: tensor(2.9933)\n",
      "11217 Traning Loss: tensor(3.0091)\n",
      "11218 Traning Loss: tensor(2.9811)\n",
      "11219 Traning Loss: tensor(2.9792)\n",
      "11220 Traning Loss: tensor(2.9928)\n",
      "11221 Traning Loss: tensor(3.0090)\n",
      "11222 Traning Loss: tensor(3.0093)\n",
      "11223 Traning Loss: tensor(3.0053)\n",
      "11224 Traning Loss: tensor(2.9900)\n",
      "11225 Traning Loss: tensor(2.9857)\n",
      "11226 Traning Loss: tensor(2.9946)\n",
      "11227 Traning Loss: tensor(2.9940)\n",
      "11228 Traning Loss: tensor(3.0018)\n",
      "11229 Traning Loss: tensor(2.9877)\n",
      "11230 Traning Loss: tensor(2.9855)\n",
      "11231 Traning Loss: tensor(2.9959)\n",
      "11232 Traning Loss: tensor(2.9825)\n",
      "11233 Traning Loss: tensor(3.0132)\n",
      "11234 Traning Loss: tensor(2.9854)\n",
      "11235 Traning Loss: tensor(3.0037)\n",
      "11236 Traning Loss: tensor(2.9928)\n",
      "11237 Traning Loss: tensor(2.9977)\n",
      "11238 Traning Loss: tensor(2.9971)\n",
      "11239 Traning Loss: tensor(2.9823)\n",
      "11240 Traning Loss: tensor(2.9941)\n",
      "11241 Traning Loss: tensor(3.0011)\n",
      "11242 Traning Loss: tensor(2.9889)\n",
      "11243 Traning Loss: tensor(3.0036)\n",
      "11244 Traning Loss: tensor(2.9922)\n",
      "11245 Traning Loss: tensor(2.9910)\n",
      "11246 Traning Loss: tensor(2.9916)\n",
      "11247 Traning Loss: tensor(2.9802)\n",
      "11248 Traning Loss: tensor(2.9980)\n",
      "11249 Traning Loss: tensor(2.9925)\n",
      "11250 Traning Loss: tensor(2.9828)\n",
      "11251 Traning Loss: tensor(3.0013)\n",
      "11252 Traning Loss: tensor(2.9963)\n",
      "11253 Traning Loss: tensor(3.0208)\n",
      "11254 Traning Loss: tensor(2.9978)\n",
      "11255 Traning Loss: tensor(2.9853)\n",
      "11256 Traning Loss: tensor(2.9934)\n",
      "11257 Traning Loss: tensor(2.9815)\n",
      "11258 Traning Loss: tensor(2.9957)\n",
      "11259 Traning Loss: tensor(2.9883)\n",
      "11260 Traning Loss: tensor(2.9943)\n",
      "11261 Traning Loss: tensor(2.9959)\n",
      "11262 Traning Loss: tensor(2.9861)\n",
      "11263 Traning Loss: tensor(2.9965)\n",
      "11264 Traning Loss: tensor(2.9879)\n",
      "11265 Traning Loss: tensor(2.9927)\n",
      "11266 Traning Loss: tensor(2.9951)\n",
      "11267 Traning Loss: tensor(2.9771)\n",
      "11268 Traning Loss: tensor(2.9800)\n",
      "11269 Traning Loss: tensor(2.9892)\n",
      "11270 Traning Loss: tensor(2.9878)\n",
      "11271 Traning Loss: tensor(2.9878)\n",
      "11272 Traning Loss: tensor(2.9799)\n",
      "11273 Traning Loss: tensor(2.9863)\n",
      "11274 Traning Loss: tensor(2.9734)\n",
      "11275 Traning Loss: tensor(2.9874)\n",
      "11276 Traning Loss: tensor(3.0087)\n",
      "11277 Traning Loss: tensor(3.0070)\n",
      "11278 Traning Loss: tensor(2.9830)\n",
      "11279 Traning Loss: tensor(2.9935)\n",
      "11280 Traning Loss: tensor(2.9847)\n",
      "11281 Traning Loss: tensor(2.9869)\n",
      "11282 Traning Loss: tensor(2.9803)\n",
      "11283 Traning Loss: tensor(2.9966)\n",
      "11284 Traning Loss: tensor(2.9872)\n",
      "11285 Traning Loss: tensor(2.9742)\n",
      "11286 Traning Loss: tensor(2.9863)\n",
      "11287 Traning Loss: tensor(2.9877)\n",
      "11288 Traning Loss: tensor(2.9863)\n",
      "11289 Traning Loss: tensor(2.9869)\n",
      "11290 Traning Loss: tensor(3.0175)\n",
      "11291 Traning Loss: tensor(2.9738)\n",
      "11292 Traning Loss: tensor(2.9864)\n",
      "11293 Traning Loss: tensor(2.9774)\n",
      "11294 Traning Loss: tensor(2.9718)\n",
      "11295 Traning Loss: tensor(2.9866)\n",
      "11296 Traning Loss: tensor(2.9868)\n",
      "11297 Traning Loss: tensor(2.9907)\n",
      "11298 Traning Loss: tensor(3.0043)\n",
      "11299 Traning Loss: tensor(2.9906)\n",
      "11300 Traning Loss: tensor(2.9865)\n",
      "11301 Traning Loss: tensor(2.9918)\n",
      "11302 Traning Loss: tensor(2.9832)\n",
      "11303 Traning Loss: tensor(2.9798)\n",
      "11304 Traning Loss: tensor(2.9744)\n",
      "11305 Traning Loss: tensor(2.9892)\n",
      "11306 Traning Loss: tensor(2.9795)\n",
      "11307 Traning Loss: tensor(2.9825)\n",
      "11308 Traning Loss: tensor(2.9874)\n",
      "11309 Traning Loss: tensor(2.9933)\n",
      "11310 Traning Loss: tensor(2.9756)\n",
      "11311 Traning Loss: tensor(2.9737)\n",
      "11312 Traning Loss: tensor(2.9960)\n",
      "11313 Traning Loss: tensor(2.9863)\n",
      "11314 Traning Loss: tensor(2.9731)\n",
      "11315 Traning Loss: tensor(2.9859)\n",
      "11316 Traning Loss: tensor(2.9925)\n",
      "11317 Traning Loss: tensor(2.9728)\n",
      "11318 Traning Loss: tensor(3.0006)\n",
      "11319 Traning Loss: tensor(2.9942)\n",
      "11320 Traning Loss: tensor(2.9707)\n",
      "11321 Traning Loss: tensor(2.9679)\n",
      "11322 Traning Loss: tensor(2.9732)\n",
      "11323 Traning Loss: tensor(2.9689)\n",
      "11324 Traning Loss: tensor(2.9760)\n",
      "11325 Traning Loss: tensor(2.9755)\n",
      "11326 Traning Loss: tensor(2.9731)\n",
      "11327 Traning Loss: tensor(2.9768)\n",
      "11328 Traning Loss: tensor(2.9727)\n",
      "11329 Traning Loss: tensor(2.9802)\n",
      "11330 Traning Loss: tensor(2.9756)\n",
      "11331 Traning Loss: tensor(2.9962)\n",
      "11332 Traning Loss: tensor(2.9845)\n",
      "11333 Traning Loss: tensor(2.9879)\n",
      "11334 Traning Loss: tensor(2.9904)\n",
      "11335 Traning Loss: tensor(2.9726)\n",
      "11336 Traning Loss: tensor(2.9780)\n",
      "11337 Traning Loss: tensor(2.9707)\n",
      "11338 Traning Loss: tensor(2.9764)\n",
      "11339 Traning Loss: tensor(2.9811)\n",
      "11340 Traning Loss: tensor(2.9725)\n",
      "11341 Traning Loss: tensor(2.9845)\n",
      "11342 Traning Loss: tensor(2.9747)\n",
      "11343 Traning Loss: tensor(2.9801)\n",
      "11344 Traning Loss: tensor(2.9962)\n",
      "11345 Traning Loss: tensor(2.9778)\n",
      "11346 Traning Loss: tensor(2.9896)\n",
      "11347 Traning Loss: tensor(2.9766)\n",
      "11348 Traning Loss: tensor(2.9793)\n",
      "11349 Traning Loss: tensor(2.9687)\n",
      "11350 Traning Loss: tensor(2.9989)\n",
      "11351 Traning Loss: tensor(2.9749)\n",
      "11352 Traning Loss: tensor(2.9709)\n",
      "11353 Traning Loss: tensor(2.9626)\n",
      "11354 Traning Loss: tensor(2.9726)\n",
      "11355 Traning Loss: tensor(2.9743)\n",
      "11356 Traning Loss: tensor(2.9789)\n",
      "11357 Traning Loss: tensor(2.9671)\n",
      "11358 Traning Loss: tensor(2.9690)\n",
      "11359 Traning Loss: tensor(2.9740)\n",
      "11360 Traning Loss: tensor(2.9697)\n",
      "11361 Traning Loss: tensor(2.9737)\n",
      "11362 Traning Loss: tensor(2.9647)\n",
      "11363 Traning Loss: tensor(2.9752)\n",
      "11364 Traning Loss: tensor(2.9905)\n",
      "11365 Traning Loss: tensor(2.9648)\n",
      "11366 Traning Loss: tensor(2.9734)\n",
      "11367 Traning Loss: tensor(2.9701)\n",
      "11368 Traning Loss: tensor(2.9803)\n",
      "11369 Traning Loss: tensor(3.0006)\n",
      "11370 Traning Loss: tensor(2.9719)\n",
      "11371 Traning Loss: tensor(2.9661)\n",
      "11372 Traning Loss: tensor(2.9705)\n",
      "11373 Traning Loss: tensor(2.9619)\n",
      "11374 Traning Loss: tensor(2.9603)\n",
      "11375 Traning Loss: tensor(2.9764)\n",
      "11376 Traning Loss: tensor(2.9711)\n",
      "11377 Traning Loss: tensor(2.9709)\n",
      "11378 Traning Loss: tensor(2.9649)\n",
      "11379 Traning Loss: tensor(2.9722)\n",
      "11380 Traning Loss: tensor(2.9623)\n",
      "11381 Traning Loss: tensor(2.9779)\n",
      "11382 Traning Loss: tensor(2.9840)\n",
      "11383 Traning Loss: tensor(2.9635)\n",
      "11384 Traning Loss: tensor(2.9681)\n",
      "11385 Traning Loss: tensor(2.9648)\n",
      "11386 Traning Loss: tensor(2.9679)\n",
      "11387 Traning Loss: tensor(2.9650)\n",
      "11388 Traning Loss: tensor(2.9766)\n",
      "11389 Traning Loss: tensor(2.9891)\n",
      "11390 Traning Loss: tensor(2.9589)\n",
      "11391 Traning Loss: tensor(2.9776)\n",
      "11392 Traning Loss: tensor(2.9758)\n",
      "11393 Traning Loss: tensor(2.9757)\n",
      "11394 Traning Loss: tensor(2.9732)\n",
      "11395 Traning Loss: tensor(2.9701)\n",
      "11396 Traning Loss: tensor(2.9726)\n",
      "11397 Traning Loss: tensor(2.9765)\n",
      "11398 Traning Loss: tensor(2.9697)\n",
      "11399 Traning Loss: tensor(2.9713)\n",
      "11400 Traning Loss: tensor(2.9580)\n",
      "11401 Traning Loss: tensor(2.9743)\n",
      "11402 Traning Loss: tensor(2.9704)\n",
      "11403 Traning Loss: tensor(2.9837)\n",
      "11404 Traning Loss: tensor(2.9683)\n",
      "11405 Traning Loss: tensor(2.9633)\n",
      "11406 Traning Loss: tensor(2.9723)\n",
      "11407 Traning Loss: tensor(2.9640)\n",
      "11408 Traning Loss: tensor(2.9626)\n",
      "11409 Traning Loss: tensor(2.9694)\n",
      "11410 Traning Loss: tensor(2.9671)\n",
      "11411 Traning Loss: tensor(2.9773)\n",
      "11412 Traning Loss: tensor(2.9705)\n",
      "11413 Traning Loss: tensor(2.9843)\n",
      "11414 Traning Loss: tensor(2.9666)\n",
      "11415 Traning Loss: tensor(2.9554)\n",
      "11416 Traning Loss: tensor(2.9591)\n",
      "11417 Traning Loss: tensor(2.9677)\n",
      "11418 Traning Loss: tensor(2.9580)\n",
      "11419 Traning Loss: tensor(2.9565)\n",
      "11420 Traning Loss: tensor(2.9710)\n",
      "11421 Traning Loss: tensor(2.9678)\n",
      "11422 Traning Loss: tensor(2.9710)\n",
      "11423 Traning Loss: tensor(2.9838)\n",
      "11424 Traning Loss: tensor(2.9761)\n",
      "11425 Traning Loss: tensor(2.9599)\n",
      "11426 Traning Loss: tensor(2.9839)\n",
      "11427 Traning Loss: tensor(2.9548)\n",
      "11428 Traning Loss: tensor(2.9602)\n",
      "11429 Traning Loss: tensor(2.9620)\n",
      "11430 Traning Loss: tensor(2.9711)\n",
      "11431 Traning Loss: tensor(2.9492)\n",
      "11432 Traning Loss: tensor(2.9588)\n",
      "11433 Traning Loss: tensor(2.9632)\n",
      "11434 Traning Loss: tensor(2.9698)\n",
      "11435 Traning Loss: tensor(2.9647)\n",
      "11436 Traning Loss: tensor(2.9586)\n",
      "11437 Traning Loss: tensor(2.9678)\n",
      "11438 Traning Loss: tensor(2.9610)\n",
      "11439 Traning Loss: tensor(2.9672)\n",
      "11440 Traning Loss: tensor(2.9505)\n",
      "11441 Traning Loss: tensor(2.9600)\n",
      "11442 Traning Loss: tensor(2.9565)\n",
      "11443 Traning Loss: tensor(2.9700)\n",
      "11444 Traning Loss: tensor(2.9564)\n",
      "11445 Traning Loss: tensor(2.9681)\n",
      "11446 Traning Loss: tensor(2.9578)\n",
      "11447 Traning Loss: tensor(2.9568)\n",
      "11448 Traning Loss: tensor(2.9747)\n",
      "11449 Traning Loss: tensor(2.9438)\n",
      "11450 Traning Loss: tensor(2.9538)\n",
      "11451 Traning Loss: tensor(2.9765)\n",
      "11452 Traning Loss: tensor(2.9557)\n",
      "11453 Traning Loss: tensor(2.9677)\n",
      "11454 Traning Loss: tensor(2.9479)\n",
      "11455 Traning Loss: tensor(2.9590)\n",
      "11456 Traning Loss: tensor(2.9649)\n",
      "11457 Traning Loss: tensor(2.9727)\n",
      "11458 Traning Loss: tensor(2.9621)\n",
      "11459 Traning Loss: tensor(2.9579)\n",
      "11460 Traning Loss: tensor(2.9681)\n",
      "11461 Traning Loss: tensor(2.9565)\n",
      "11462 Traning Loss: tensor(2.9622)\n",
      "11463 Traning Loss: tensor(2.9690)\n",
      "11464 Traning Loss: tensor(2.9612)\n",
      "11465 Traning Loss: tensor(2.9674)\n",
      "11466 Traning Loss: tensor(2.9523)\n",
      "11467 Traning Loss: tensor(2.9562)\n",
      "11468 Traning Loss: tensor(2.9654)\n",
      "11469 Traning Loss: tensor(2.9572)\n",
      "11470 Traning Loss: tensor(2.9461)\n",
      "11471 Traning Loss: tensor(2.9622)\n",
      "11472 Traning Loss: tensor(2.9616)\n",
      "11473 Traning Loss: tensor(2.9516)\n",
      "11474 Traning Loss: tensor(2.9529)\n",
      "11475 Traning Loss: tensor(2.9522)\n",
      "11476 Traning Loss: tensor(2.9696)\n",
      "11477 Traning Loss: tensor(2.9595)\n",
      "11478 Traning Loss: tensor(2.9522)\n",
      "11479 Traning Loss: tensor(2.9679)\n",
      "11480 Traning Loss: tensor(2.9575)\n",
      "11481 Traning Loss: tensor(2.9531)\n",
      "11482 Traning Loss: tensor(2.9318)\n",
      "11483 Traning Loss: tensor(2.9487)\n",
      "11484 Traning Loss: tensor(2.9610)\n",
      "11485 Traning Loss: tensor(2.9551)\n",
      "11486 Traning Loss: tensor(2.9570)\n",
      "11487 Traning Loss: tensor(2.9683)\n",
      "11488 Traning Loss: tensor(2.9534)\n",
      "11489 Traning Loss: tensor(2.9550)\n",
      "11490 Traning Loss: tensor(2.9625)\n",
      "11491 Traning Loss: tensor(2.9551)\n",
      "11492 Traning Loss: tensor(2.9528)\n",
      "11493 Traning Loss: tensor(2.9512)\n",
      "11494 Traning Loss: tensor(2.9601)\n",
      "11495 Traning Loss: tensor(2.9514)\n",
      "11496 Traning Loss: tensor(2.9602)\n",
      "11497 Traning Loss: tensor(2.9502)\n",
      "11498 Traning Loss: tensor(2.9556)\n",
      "11499 Traning Loss: tensor(2.9711)\n",
      "11500 Traning Loss: tensor(2.9526)\n",
      "11501 Traning Loss: tensor(2.9528)\n",
      "11502 Traning Loss: tensor(2.9556)\n",
      "11503 Traning Loss: tensor(2.9796)\n",
      "11504 Traning Loss: tensor(2.9517)\n",
      "11505 Traning Loss: tensor(2.9536)\n",
      "11506 Traning Loss: tensor(2.9564)\n",
      "11507 Traning Loss: tensor(2.9531)\n",
      "11508 Traning Loss: tensor(2.9439)\n",
      "11509 Traning Loss: tensor(2.9453)\n",
      "11510 Traning Loss: tensor(2.9437)\n",
      "11511 Traning Loss: tensor(2.9479)\n",
      "11512 Traning Loss: tensor(2.9504)\n",
      "11513 Traning Loss: tensor(2.9454)\n",
      "11514 Traning Loss: tensor(2.9386)\n",
      "11515 Traning Loss: tensor(2.9560)\n",
      "11516 Traning Loss: tensor(2.9538)\n",
      "11517 Traning Loss: tensor(2.9506)\n",
      "11518 Traning Loss: tensor(2.9488)\n",
      "11519 Traning Loss: tensor(2.9531)\n",
      "11520 Traning Loss: tensor(2.9431)\n",
      "11521 Traning Loss: tensor(2.9378)\n",
      "11522 Traning Loss: tensor(2.9517)\n",
      "11523 Traning Loss: tensor(2.9568)\n",
      "11524 Traning Loss: tensor(2.9477)\n",
      "11525 Traning Loss: tensor(2.9564)\n",
      "11526 Traning Loss: tensor(2.9495)\n",
      "11527 Traning Loss: tensor(2.9557)\n",
      "11528 Traning Loss: tensor(2.9469)\n",
      "11529 Traning Loss: tensor(2.9385)\n",
      "11530 Traning Loss: tensor(2.9626)\n",
      "11531 Traning Loss: tensor(2.9417)\n",
      "11532 Traning Loss: tensor(2.9549)\n",
      "11533 Traning Loss: tensor(2.9469)\n",
      "11534 Traning Loss: tensor(2.9364)\n",
      "11535 Traning Loss: tensor(2.9337)\n",
      "11536 Traning Loss: tensor(2.9408)\n",
      "11537 Traning Loss: tensor(2.9517)\n",
      "11538 Traning Loss: tensor(2.9517)\n",
      "11539 Traning Loss: tensor(2.9453)\n",
      "11540 Traning Loss: tensor(2.9334)\n",
      "11541 Traning Loss: tensor(2.9650)\n",
      "11542 Traning Loss: tensor(2.9653)\n",
      "11543 Traning Loss: tensor(2.9453)\n",
      "11544 Traning Loss: tensor(2.9455)\n",
      "11545 Traning Loss: tensor(2.9503)\n",
      "11546 Traning Loss: tensor(2.9722)\n",
      "11547 Traning Loss: tensor(2.9619)\n",
      "11548 Traning Loss: tensor(2.9477)\n",
      "11549 Traning Loss: tensor(2.9437)\n",
      "11550 Traning Loss: tensor(2.9323)\n",
      "11551 Traning Loss: tensor(2.9434)\n",
      "11552 Traning Loss: tensor(2.9559)\n",
      "11553 Traning Loss: tensor(2.9486)\n",
      "11554 Traning Loss: tensor(2.9555)\n",
      "11555 Traning Loss: tensor(2.9506)\n",
      "11556 Traning Loss: tensor(2.9507)\n",
      "11557 Traning Loss: tensor(2.9557)\n",
      "11558 Traning Loss: tensor(2.9292)\n",
      "11559 Traning Loss: tensor(2.9470)\n",
      "11560 Traning Loss: tensor(2.9347)\n",
      "11561 Traning Loss: tensor(2.9538)\n",
      "11562 Traning Loss: tensor(2.9481)\n",
      "11563 Traning Loss: tensor(2.9461)\n",
      "11564 Traning Loss: tensor(2.9545)\n",
      "11565 Traning Loss: tensor(2.9474)\n",
      "11566 Traning Loss: tensor(2.9529)\n",
      "11567 Traning Loss: tensor(2.9410)\n",
      "11568 Traning Loss: tensor(2.9520)\n",
      "11569 Traning Loss: tensor(2.9488)\n",
      "11570 Traning Loss: tensor(2.9455)\n",
      "11571 Traning Loss: tensor(2.9348)\n",
      "11572 Traning Loss: tensor(2.9656)\n",
      "11573 Traning Loss: tensor(2.9276)\n",
      "11574 Traning Loss: tensor(2.9554)\n",
      "11575 Traning Loss: tensor(2.9502)\n",
      "11576 Traning Loss: tensor(2.9380)\n",
      "11577 Traning Loss: tensor(2.9458)\n",
      "11578 Traning Loss: tensor(2.9370)\n",
      "11579 Traning Loss: tensor(2.9483)\n",
      "11580 Traning Loss: tensor(2.9327)\n",
      "11581 Traning Loss: tensor(2.9385)\n",
      "11582 Traning Loss: tensor(2.9323)\n",
      "11583 Traning Loss: tensor(2.9418)\n",
      "11584 Traning Loss: tensor(2.9390)\n",
      "11585 Traning Loss: tensor(2.9355)\n",
      "11586 Traning Loss: tensor(2.9333)\n",
      "11587 Traning Loss: tensor(2.9611)\n",
      "11588 Traning Loss: tensor(2.9476)\n",
      "11589 Traning Loss: tensor(2.9296)\n",
      "11590 Traning Loss: tensor(2.9315)\n",
      "11591 Traning Loss: tensor(2.9393)\n",
      "11592 Traning Loss: tensor(2.9316)\n",
      "11593 Traning Loss: tensor(2.9492)\n",
      "11594 Traning Loss: tensor(2.9353)\n",
      "11595 Traning Loss: tensor(2.9458)\n",
      "11596 Traning Loss: tensor(2.9417)\n",
      "11597 Traning Loss: tensor(2.9484)\n",
      "11598 Traning Loss: tensor(2.9416)\n",
      "11599 Traning Loss: tensor(2.9584)\n",
      "11600 Traning Loss: tensor(2.9636)\n",
      "11601 Traning Loss: tensor(2.9200)\n",
      "11602 Traning Loss: tensor(2.9487)\n",
      "11603 Traning Loss: tensor(2.9347)\n",
      "11604 Traning Loss: tensor(2.9464)\n",
      "11605 Traning Loss: tensor(2.9461)\n",
      "11606 Traning Loss: tensor(2.9323)\n",
      "11607 Traning Loss: tensor(2.9427)\n",
      "11608 Traning Loss: tensor(2.9312)\n",
      "11609 Traning Loss: tensor(2.9367)\n",
      "11610 Traning Loss: tensor(2.9456)\n",
      "11611 Traning Loss: tensor(2.9544)\n",
      "11612 Traning Loss: tensor(2.9328)\n",
      "11613 Traning Loss: tensor(2.9472)\n",
      "11614 Traning Loss: tensor(2.9486)\n",
      "11615 Traning Loss: tensor(2.9575)\n",
      "11616 Traning Loss: tensor(2.9433)\n",
      "11617 Traning Loss: tensor(2.9314)\n",
      "11618 Traning Loss: tensor(2.9260)\n",
      "11619 Traning Loss: tensor(2.9339)\n",
      "11620 Traning Loss: tensor(2.9506)\n",
      "11621 Traning Loss: tensor(2.9560)\n",
      "11622 Traning Loss: tensor(2.9290)\n",
      "11623 Traning Loss: tensor(2.9377)\n",
      "11624 Traning Loss: tensor(2.9431)\n",
      "11625 Traning Loss: tensor(2.9288)\n",
      "11626 Traning Loss: tensor(2.9290)\n",
      "11627 Traning Loss: tensor(2.9435)\n",
      "11628 Traning Loss: tensor(2.9430)\n",
      "11629 Traning Loss: tensor(2.9651)\n",
      "11630 Traning Loss: tensor(2.9272)\n",
      "11631 Traning Loss: tensor(2.9513)\n",
      "11632 Traning Loss: tensor(2.9243)\n",
      "11633 Traning Loss: tensor(2.9251)\n",
      "11634 Traning Loss: tensor(2.9324)\n",
      "11635 Traning Loss: tensor(2.9362)\n",
      "11636 Traning Loss: tensor(2.9315)\n",
      "11637 Traning Loss: tensor(2.9310)\n",
      "11638 Traning Loss: tensor(2.9420)\n",
      "11639 Traning Loss: tensor(2.9381)\n",
      "11640 Traning Loss: tensor(2.9425)\n",
      "11641 Traning Loss: tensor(2.9449)\n",
      "11642 Traning Loss: tensor(2.9331)\n",
      "11643 Traning Loss: tensor(2.9430)\n",
      "11644 Traning Loss: tensor(2.9459)\n",
      "11645 Traning Loss: tensor(2.9321)\n",
      "11646 Traning Loss: tensor(2.9421)\n",
      "11647 Traning Loss: tensor(2.9374)\n",
      "11648 Traning Loss: tensor(2.9417)\n",
      "11649 Traning Loss: tensor(2.9470)\n",
      "11650 Traning Loss: tensor(2.9361)\n",
      "11651 Traning Loss: tensor(2.9354)\n",
      "11652 Traning Loss: tensor(2.9221)\n",
      "11653 Traning Loss: tensor(2.9235)\n",
      "11654 Traning Loss: tensor(2.9282)\n",
      "11655 Traning Loss: tensor(2.9421)\n",
      "11656 Traning Loss: tensor(2.9553)\n",
      "11657 Traning Loss: tensor(2.9297)\n",
      "11658 Traning Loss: tensor(2.9273)\n",
      "11659 Traning Loss: tensor(2.9453)\n",
      "11660 Traning Loss: tensor(2.9256)\n",
      "11661 Traning Loss: tensor(2.9379)\n",
      "11662 Traning Loss: tensor(2.9340)\n",
      "11663 Traning Loss: tensor(2.9315)\n",
      "11664 Traning Loss: tensor(2.9423)\n",
      "11665 Traning Loss: tensor(2.9297)\n",
      "11666 Traning Loss: tensor(2.9205)\n",
      "11667 Traning Loss: tensor(2.9495)\n",
      "11668 Traning Loss: tensor(2.9331)\n",
      "11669 Traning Loss: tensor(2.9337)\n",
      "11670 Traning Loss: tensor(2.9389)\n",
      "11671 Traning Loss: tensor(2.9334)\n",
      "11672 Traning Loss: tensor(2.9278)\n",
      "11673 Traning Loss: tensor(2.9370)\n",
      "11674 Traning Loss: tensor(2.9253)\n",
      "11675 Traning Loss: tensor(2.9283)\n",
      "11676 Traning Loss: tensor(2.9347)\n",
      "11677 Traning Loss: tensor(2.9326)\n",
      "11678 Traning Loss: tensor(2.9455)\n",
      "11679 Traning Loss: tensor(2.9492)\n",
      "11680 Traning Loss: tensor(2.9352)\n",
      "11681 Traning Loss: tensor(2.9320)\n",
      "11682 Traning Loss: tensor(2.9273)\n",
      "11683 Traning Loss: tensor(2.9253)\n",
      "11684 Traning Loss: tensor(2.9114)\n",
      "11685 Traning Loss: tensor(2.9261)\n",
      "11686 Traning Loss: tensor(2.9215)\n",
      "11687 Traning Loss: tensor(2.9278)\n",
      "11688 Traning Loss: tensor(2.9327)\n",
      "11689 Traning Loss: tensor(2.9306)\n",
      "11690 Traning Loss: tensor(2.9262)\n",
      "11691 Traning Loss: tensor(2.9175)\n",
      "11692 Traning Loss: tensor(2.9154)\n",
      "11693 Traning Loss: tensor(2.9200)\n",
      "11694 Traning Loss: tensor(2.9425)\n",
      "11695 Traning Loss: tensor(2.9372)\n",
      "11696 Traning Loss: tensor(2.9330)\n",
      "11697 Traning Loss: tensor(2.9216)\n",
      "11698 Traning Loss: tensor(2.9236)\n",
      "11699 Traning Loss: tensor(2.9314)\n",
      "11700 Traning Loss: tensor(2.9312)\n",
      "11701 Traning Loss: tensor(2.9281)\n",
      "11702 Traning Loss: tensor(2.9308)\n",
      "11703 Traning Loss: tensor(2.9306)\n",
      "11704 Traning Loss: tensor(2.9141)\n",
      "11705 Traning Loss: tensor(2.9104)\n",
      "11706 Traning Loss: tensor(2.9269)\n",
      "11707 Traning Loss: tensor(2.9097)\n",
      "11708 Traning Loss: tensor(2.9238)\n",
      "11709 Traning Loss: tensor(2.9247)\n",
      "11710 Traning Loss: tensor(2.9132)\n",
      "11711 Traning Loss: tensor(2.9353)\n",
      "11712 Traning Loss: tensor(2.9507)\n",
      "11713 Traning Loss: tensor(2.9503)\n",
      "11714 Traning Loss: tensor(2.9129)\n",
      "11715 Traning Loss: tensor(2.9379)\n",
      "11716 Traning Loss: tensor(2.9478)\n",
      "11717 Traning Loss: tensor(2.9357)\n",
      "11718 Traning Loss: tensor(2.9343)\n",
      "11719 Traning Loss: tensor(2.9245)\n",
      "11720 Traning Loss: tensor(2.9327)\n",
      "11721 Traning Loss: tensor(2.9122)\n",
      "11722 Traning Loss: tensor(2.9200)\n",
      "11723 Traning Loss: tensor(2.9221)\n",
      "11724 Traning Loss: tensor(2.9422)\n",
      "11725 Traning Loss: tensor(2.9307)\n",
      "11726 Traning Loss: tensor(2.9341)\n",
      "11727 Traning Loss: tensor(2.9318)\n",
      "11728 Traning Loss: tensor(2.9392)\n",
      "11729 Traning Loss: tensor(2.9239)\n",
      "11730 Traning Loss: tensor(2.9259)\n",
      "11731 Traning Loss: tensor(2.9250)\n",
      "11732 Traning Loss: tensor(2.9208)\n",
      "11733 Traning Loss: tensor(2.9369)\n",
      "11734 Traning Loss: tensor(2.9202)\n",
      "11735 Traning Loss: tensor(2.9374)\n",
      "11736 Traning Loss: tensor(2.9248)\n",
      "11737 Traning Loss: tensor(2.9242)\n",
      "11738 Traning Loss: tensor(2.9252)\n",
      "11739 Traning Loss: tensor(2.9237)\n",
      "11740 Traning Loss: tensor(2.9254)\n",
      "11741 Traning Loss: tensor(2.9068)\n",
      "11742 Traning Loss: tensor(2.9544)\n",
      "11743 Traning Loss: tensor(2.9220)\n",
      "11744 Traning Loss: tensor(2.9389)\n",
      "11745 Traning Loss: tensor(2.9296)\n",
      "11746 Traning Loss: tensor(2.9142)\n",
      "11747 Traning Loss: tensor(2.9276)\n",
      "11748 Traning Loss: tensor(2.9132)\n",
      "11749 Traning Loss: tensor(2.9223)\n",
      "11750 Traning Loss: tensor(2.9315)\n",
      "11751 Traning Loss: tensor(2.9188)\n",
      "11752 Traning Loss: tensor(2.9289)\n",
      "11753 Traning Loss: tensor(2.9172)\n",
      "11754 Traning Loss: tensor(2.9259)\n",
      "11755 Traning Loss: tensor(2.9062)\n",
      "11756 Traning Loss: tensor(2.9160)\n",
      "11757 Traning Loss: tensor(2.9350)\n",
      "11758 Traning Loss: tensor(2.9327)\n",
      "11759 Traning Loss: tensor(2.9339)\n",
      "11760 Traning Loss: tensor(2.9352)\n",
      "11761 Traning Loss: tensor(2.9353)\n",
      "11762 Traning Loss: tensor(2.9400)\n",
      "11763 Traning Loss: tensor(2.9367)\n",
      "11764 Traning Loss: tensor(2.9073)\n",
      "11765 Traning Loss: tensor(2.9094)\n",
      "11766 Traning Loss: tensor(2.9067)\n",
      "11767 Traning Loss: tensor(2.9328)\n",
      "11768 Traning Loss: tensor(2.9102)\n",
      "11769 Traning Loss: tensor(2.9311)\n",
      "11770 Traning Loss: tensor(2.9208)\n",
      "11771 Traning Loss: tensor(2.9177)\n",
      "11772 Traning Loss: tensor(2.9181)\n",
      "11773 Traning Loss: tensor(2.9313)\n",
      "11774 Traning Loss: tensor(2.9126)\n",
      "11775 Traning Loss: tensor(2.9366)\n",
      "11776 Traning Loss: tensor(2.9082)\n",
      "11777 Traning Loss: tensor(2.9441)\n",
      "11778 Traning Loss: tensor(2.9100)\n",
      "11779 Traning Loss: tensor(2.9093)\n",
      "11780 Traning Loss: tensor(2.9333)\n",
      "11781 Traning Loss: tensor(2.9260)\n",
      "11782 Traning Loss: tensor(2.9398)\n",
      "11783 Traning Loss: tensor(2.9179)\n",
      "11784 Traning Loss: tensor(2.9242)\n",
      "11785 Traning Loss: tensor(2.9310)\n",
      "11786 Traning Loss: tensor(2.9114)\n",
      "11787 Traning Loss: tensor(2.9180)\n",
      "11788 Traning Loss: tensor(2.9106)\n",
      "11789 Traning Loss: tensor(2.9264)\n",
      "11790 Traning Loss: tensor(2.9196)\n",
      "11791 Traning Loss: tensor(2.9171)\n",
      "11792 Traning Loss: tensor(2.9251)\n",
      "11793 Traning Loss: tensor(2.9152)\n",
      "11794 Traning Loss: tensor(2.9362)\n",
      "11795 Traning Loss: tensor(2.9409)\n",
      "11796 Traning Loss: tensor(2.9202)\n",
      "11797 Traning Loss: tensor(2.9126)\n",
      "11798 Traning Loss: tensor(2.9056)\n",
      "11799 Traning Loss: tensor(2.9129)\n",
      "11800 Traning Loss: tensor(2.9159)\n",
      "11801 Traning Loss: tensor(2.9283)\n",
      "11802 Traning Loss: tensor(2.9174)\n",
      "11803 Traning Loss: tensor(2.9175)\n",
      "11804 Traning Loss: tensor(2.9212)\n",
      "11805 Traning Loss: tensor(2.9224)\n",
      "11806 Traning Loss: tensor(2.9249)\n",
      "11807 Traning Loss: tensor(2.9254)\n",
      "11808 Traning Loss: tensor(2.9251)\n",
      "11809 Traning Loss: tensor(2.9134)\n",
      "11810 Traning Loss: tensor(2.9168)\n",
      "11811 Traning Loss: tensor(2.9252)\n",
      "11812 Traning Loss: tensor(2.9184)\n",
      "11813 Traning Loss: tensor(2.9139)\n",
      "11814 Traning Loss: tensor(2.9117)\n",
      "11815 Traning Loss: tensor(2.9113)\n",
      "11816 Traning Loss: tensor(2.9185)\n",
      "11817 Traning Loss: tensor(2.9009)\n",
      "11818 Traning Loss: tensor(2.9159)\n",
      "11819 Traning Loss: tensor(2.9249)\n",
      "11820 Traning Loss: tensor(2.9119)\n",
      "11821 Traning Loss: tensor(2.9040)\n",
      "11822 Traning Loss: tensor(2.9300)\n",
      "11823 Traning Loss: tensor(2.9181)\n",
      "11824 Traning Loss: tensor(2.9150)\n",
      "11825 Traning Loss: tensor(2.9302)\n",
      "11826 Traning Loss: tensor(2.9103)\n",
      "11827 Traning Loss: tensor(2.9343)\n",
      "11828 Traning Loss: tensor(2.9228)\n",
      "11829 Traning Loss: tensor(2.9156)\n",
      "11830 Traning Loss: tensor(2.9209)\n",
      "11831 Traning Loss: tensor(2.9248)\n",
      "11832 Traning Loss: tensor(2.8953)\n",
      "11833 Traning Loss: tensor(2.9248)\n",
      "11834 Traning Loss: tensor(2.9127)\n",
      "11835 Traning Loss: tensor(2.9193)\n",
      "11836 Traning Loss: tensor(2.9171)\n",
      "11837 Traning Loss: tensor(2.8989)\n",
      "11838 Traning Loss: tensor(2.9031)\n",
      "11839 Traning Loss: tensor(2.9136)\n",
      "11840 Traning Loss: tensor(2.9135)\n",
      "11841 Traning Loss: tensor(2.9345)\n",
      "11842 Traning Loss: tensor(2.9181)\n",
      "11843 Traning Loss: tensor(2.9174)\n",
      "11844 Traning Loss: tensor(2.9042)\n",
      "11845 Traning Loss: tensor(2.9123)\n",
      "11846 Traning Loss: tensor(2.9118)\n",
      "11847 Traning Loss: tensor(2.9180)\n",
      "11848 Traning Loss: tensor(2.9266)\n",
      "11849 Traning Loss: tensor(2.9254)\n",
      "11850 Traning Loss: tensor(2.8987)\n",
      "11851 Traning Loss: tensor(2.9143)\n",
      "11852 Traning Loss: tensor(2.9213)\n",
      "11853 Traning Loss: tensor(2.9094)\n",
      "11854 Traning Loss: tensor(2.9131)\n",
      "11855 Traning Loss: tensor(2.9194)\n",
      "11856 Traning Loss: tensor(2.9139)\n",
      "11857 Traning Loss: tensor(2.9077)\n",
      "11858 Traning Loss: tensor(2.9101)\n",
      "11859 Traning Loss: tensor(2.9439)\n",
      "11860 Traning Loss: tensor(2.9060)\n",
      "11861 Traning Loss: tensor(2.9238)\n",
      "11862 Traning Loss: tensor(2.9125)\n",
      "11863 Traning Loss: tensor(2.9116)\n",
      "11864 Traning Loss: tensor(2.8947)\n",
      "11865 Traning Loss: tensor(2.9168)\n",
      "11866 Traning Loss: tensor(2.9193)\n",
      "11867 Traning Loss: tensor(2.9124)\n",
      "11868 Traning Loss: tensor(2.8978)\n",
      "11869 Traning Loss: tensor(2.9057)\n",
      "11870 Traning Loss: tensor(2.8966)\n",
      "11871 Traning Loss: tensor(2.9329)\n",
      "11872 Traning Loss: tensor(2.8980)\n",
      "11873 Traning Loss: tensor(2.9219)\n",
      "11874 Traning Loss: tensor(2.9123)\n",
      "11875 Traning Loss: tensor(2.9190)\n",
      "11876 Traning Loss: tensor(2.9038)\n",
      "11877 Traning Loss: tensor(2.9005)\n",
      "11878 Traning Loss: tensor(2.9110)\n",
      "11879 Traning Loss: tensor(2.9344)\n",
      "11880 Traning Loss: tensor(2.9085)\n",
      "11881 Traning Loss: tensor(2.9273)\n",
      "11882 Traning Loss: tensor(2.9341)\n",
      "11883 Traning Loss: tensor(2.9082)\n",
      "11884 Traning Loss: tensor(2.9104)\n",
      "11885 Traning Loss: tensor(2.9052)\n",
      "11886 Traning Loss: tensor(2.9270)\n",
      "11887 Traning Loss: tensor(2.9433)\n",
      "11888 Traning Loss: tensor(2.9173)\n",
      "11889 Traning Loss: tensor(2.9085)\n",
      "11890 Traning Loss: tensor(2.9133)\n",
      "11891 Traning Loss: tensor(2.9127)\n",
      "11892 Traning Loss: tensor(2.9044)\n",
      "11893 Traning Loss: tensor(2.8966)\n",
      "11894 Traning Loss: tensor(2.9095)\n",
      "11895 Traning Loss: tensor(2.9113)\n",
      "11896 Traning Loss: tensor(2.9174)\n",
      "11897 Traning Loss: tensor(2.9106)\n",
      "11898 Traning Loss: tensor(2.8929)\n",
      "11899 Traning Loss: tensor(2.9076)\n",
      "11900 Traning Loss: tensor(2.9109)\n",
      "11901 Traning Loss: tensor(2.9082)\n",
      "11902 Traning Loss: tensor(2.9153)\n",
      "11903 Traning Loss: tensor(2.9107)\n",
      "11904 Traning Loss: tensor(2.8988)\n",
      "11905 Traning Loss: tensor(2.8970)\n",
      "11906 Traning Loss: tensor(2.9149)\n",
      "11907 Traning Loss: tensor(2.9117)\n",
      "11908 Traning Loss: tensor(2.9111)\n",
      "11909 Traning Loss: tensor(2.9193)\n",
      "11910 Traning Loss: tensor(2.9144)\n",
      "11911 Traning Loss: tensor(2.9102)\n",
      "11912 Traning Loss: tensor(2.9145)\n",
      "11913 Traning Loss: tensor(2.9109)\n",
      "11914 Traning Loss: tensor(2.9180)\n",
      "11915 Traning Loss: tensor(2.9121)\n",
      "11916 Traning Loss: tensor(2.9080)\n",
      "11917 Traning Loss: tensor(2.9110)\n",
      "11918 Traning Loss: tensor(2.9008)\n",
      "11919 Traning Loss: tensor(2.9125)\n",
      "11920 Traning Loss: tensor(2.9075)\n",
      "11921 Traning Loss: tensor(2.9016)\n",
      "11922 Traning Loss: tensor(2.8924)\n",
      "11923 Traning Loss: tensor(2.9125)\n",
      "11924 Traning Loss: tensor(2.9110)\n",
      "11925 Traning Loss: tensor(2.9188)\n",
      "11926 Traning Loss: tensor(2.9124)\n",
      "11927 Traning Loss: tensor(2.9026)\n",
      "11928 Traning Loss: tensor(2.9126)\n",
      "11929 Traning Loss: tensor(2.9059)\n",
      "11930 Traning Loss: tensor(2.8990)\n",
      "11931 Traning Loss: tensor(2.8959)\n",
      "11932 Traning Loss: tensor(2.8929)\n",
      "11933 Traning Loss: tensor(2.9089)\n",
      "11934 Traning Loss: tensor(2.9218)\n",
      "11935 Traning Loss: tensor(2.8989)\n",
      "11936 Traning Loss: tensor(2.8998)\n",
      "11937 Traning Loss: tensor(2.8881)\n",
      "11938 Traning Loss: tensor(2.9270)\n",
      "11939 Traning Loss: tensor(2.9164)\n",
      "11940 Traning Loss: tensor(2.9111)\n",
      "11941 Traning Loss: tensor(2.9062)\n",
      "11942 Traning Loss: tensor(2.9029)\n",
      "11943 Traning Loss: tensor(2.9163)\n",
      "11944 Traning Loss: tensor(2.9092)\n",
      "11945 Traning Loss: tensor(2.9182)\n",
      "11946 Traning Loss: tensor(2.9174)\n",
      "11947 Traning Loss: tensor(2.8968)\n",
      "11948 Traning Loss: tensor(2.9042)\n",
      "11949 Traning Loss: tensor(2.8948)\n",
      "11950 Traning Loss: tensor(2.9075)\n",
      "11951 Traning Loss: tensor(2.9245)\n",
      "11952 Traning Loss: tensor(2.9195)\n",
      "11953 Traning Loss: tensor(2.8929)\n",
      "11954 Traning Loss: tensor(2.9136)\n",
      "11955 Traning Loss: tensor(2.9086)\n",
      "11956 Traning Loss: tensor(2.9084)\n",
      "11957 Traning Loss: tensor(2.9084)\n",
      "11958 Traning Loss: tensor(2.8999)\n",
      "11959 Traning Loss: tensor(2.9182)\n",
      "11960 Traning Loss: tensor(2.8980)\n",
      "11961 Traning Loss: tensor(2.8975)\n",
      "11962 Traning Loss: tensor(2.9105)\n",
      "11963 Traning Loss: tensor(2.9126)\n",
      "11964 Traning Loss: tensor(2.9108)\n",
      "11965 Traning Loss: tensor(2.9160)\n",
      "11966 Traning Loss: tensor(2.9118)\n",
      "11967 Traning Loss: tensor(2.9276)\n",
      "11968 Traning Loss: tensor(2.9020)\n",
      "11969 Traning Loss: tensor(2.9081)\n",
      "11970 Traning Loss: tensor(2.9063)\n",
      "11971 Traning Loss: tensor(2.8997)\n",
      "11972 Traning Loss: tensor(2.9178)\n",
      "11973 Traning Loss: tensor(2.9010)\n",
      "11974 Traning Loss: tensor(2.8895)\n",
      "11975 Traning Loss: tensor(2.9281)\n",
      "11976 Traning Loss: tensor(2.9054)\n",
      "11977 Traning Loss: tensor(2.9044)\n",
      "11978 Traning Loss: tensor(2.9183)\n",
      "11979 Traning Loss: tensor(2.8998)\n",
      "11980 Traning Loss: tensor(2.9084)\n",
      "11981 Traning Loss: tensor(2.8940)\n",
      "11982 Traning Loss: tensor(2.8951)\n",
      "11983 Traning Loss: tensor(2.8927)\n",
      "11984 Traning Loss: tensor(2.9079)\n",
      "11985 Traning Loss: tensor(2.9164)\n",
      "11986 Traning Loss: tensor(2.9134)\n",
      "11987 Traning Loss: tensor(2.9202)\n",
      "11988 Traning Loss: tensor(2.9112)\n",
      "11989 Traning Loss: tensor(2.8986)\n",
      "11990 Traning Loss: tensor(2.9119)\n",
      "11991 Traning Loss: tensor(2.9115)\n",
      "11992 Traning Loss: tensor(2.9200)\n",
      "11993 Traning Loss: tensor(2.8960)\n",
      "11994 Traning Loss: tensor(2.8936)\n",
      "11995 Traning Loss: tensor(2.9162)\n",
      "11996 Traning Loss: tensor(2.9096)\n",
      "11997 Traning Loss: tensor(2.9190)\n",
      "11998 Traning Loss: tensor(2.8930)\n",
      "11999 Traning Loss: tensor(2.9006)\n",
      "12000 Traning Loss: tensor(2.9013)\n",
      "12001 Traning Loss: tensor(2.8858)\n",
      "12002 Traning Loss: tensor(2.8924)\n",
      "12003 Traning Loss: tensor(2.8954)\n",
      "12004 Traning Loss: tensor(2.9048)\n",
      "12005 Traning Loss: tensor(2.8828)\n",
      "12006 Traning Loss: tensor(2.8952)\n",
      "12007 Traning Loss: tensor(2.9050)\n",
      "12008 Traning Loss: tensor(2.8875)\n",
      "12009 Traning Loss: tensor(2.8981)\n",
      "12010 Traning Loss: tensor(2.8946)\n",
      "12011 Traning Loss: tensor(2.9069)\n",
      "12012 Traning Loss: tensor(2.9089)\n",
      "12013 Traning Loss: tensor(2.8747)\n",
      "12014 Traning Loss: tensor(2.8948)\n",
      "12015 Traning Loss: tensor(2.9098)\n",
      "12016 Traning Loss: tensor(2.9033)\n",
      "12017 Traning Loss: tensor(2.9032)\n",
      "12018 Traning Loss: tensor(2.9045)\n",
      "12019 Traning Loss: tensor(2.8795)\n",
      "12020 Traning Loss: tensor(2.8920)\n",
      "12021 Traning Loss: tensor(2.9004)\n",
      "12022 Traning Loss: tensor(2.9142)\n",
      "12023 Traning Loss: tensor(2.9001)\n",
      "12024 Traning Loss: tensor(2.9021)\n",
      "12025 Traning Loss: tensor(2.9062)\n",
      "12026 Traning Loss: tensor(2.8919)\n",
      "12027 Traning Loss: tensor(2.9059)\n",
      "12028 Traning Loss: tensor(2.8970)\n",
      "12029 Traning Loss: tensor(2.8940)\n",
      "12030 Traning Loss: tensor(2.8907)\n",
      "12031 Traning Loss: tensor(2.9251)\n",
      "12032 Traning Loss: tensor(2.9085)\n",
      "12033 Traning Loss: tensor(2.9192)\n",
      "12034 Traning Loss: tensor(2.9084)\n",
      "12035 Traning Loss: tensor(2.8976)\n",
      "12036 Traning Loss: tensor(2.8987)\n",
      "12037 Traning Loss: tensor(2.8973)\n",
      "12038 Traning Loss: tensor(2.8925)\n",
      "12039 Traning Loss: tensor(2.9029)\n",
      "12040 Traning Loss: tensor(2.9107)\n",
      "12041 Traning Loss: tensor(2.8869)\n",
      "12042 Traning Loss: tensor(2.9063)\n",
      "12043 Traning Loss: tensor(2.8773)\n",
      "12044 Traning Loss: tensor(2.8920)\n",
      "12045 Traning Loss: tensor(2.9074)\n",
      "12046 Traning Loss: tensor(2.8921)\n",
      "12047 Traning Loss: tensor(2.9010)\n",
      "12048 Traning Loss: tensor(2.9170)\n",
      "12049 Traning Loss: tensor(2.8961)\n",
      "12050 Traning Loss: tensor(2.8966)\n",
      "12051 Traning Loss: tensor(2.8838)\n",
      "12052 Traning Loss: tensor(2.9035)\n",
      "12053 Traning Loss: tensor(2.9235)\n",
      "12054 Traning Loss: tensor(2.8917)\n",
      "12055 Traning Loss: tensor(2.8995)\n",
      "12056 Traning Loss: tensor(2.9003)\n",
      "12057 Traning Loss: tensor(2.8969)\n",
      "12058 Traning Loss: tensor(2.8899)\n",
      "12059 Traning Loss: tensor(2.9074)\n",
      "12060 Traning Loss: tensor(2.8947)\n",
      "12061 Traning Loss: tensor(2.9079)\n",
      "12062 Traning Loss: tensor(2.9214)\n",
      "12063 Traning Loss: tensor(2.8995)\n",
      "12064 Traning Loss: tensor(2.8981)\n",
      "12065 Traning Loss: tensor(2.8928)\n",
      "12066 Traning Loss: tensor(2.8985)\n",
      "12067 Traning Loss: tensor(2.9030)\n",
      "12068 Traning Loss: tensor(2.8906)\n",
      "12069 Traning Loss: tensor(2.8954)\n",
      "12070 Traning Loss: tensor(2.8909)\n",
      "12071 Traning Loss: tensor(2.8945)\n",
      "12072 Traning Loss: tensor(2.9016)\n",
      "12073 Traning Loss: tensor(2.8895)\n",
      "12074 Traning Loss: tensor(2.9065)\n",
      "12075 Traning Loss: tensor(2.9020)\n",
      "12076 Traning Loss: tensor(2.9041)\n",
      "12077 Traning Loss: tensor(2.8859)\n",
      "12078 Traning Loss: tensor(2.8829)\n",
      "12079 Traning Loss: tensor(2.8858)\n",
      "12080 Traning Loss: tensor(2.8813)\n",
      "12081 Traning Loss: tensor(2.9074)\n",
      "12082 Traning Loss: tensor(2.9005)\n",
      "12083 Traning Loss: tensor(2.8913)\n",
      "12084 Traning Loss: tensor(2.8928)\n",
      "12085 Traning Loss: tensor(2.8942)\n",
      "12086 Traning Loss: tensor(2.8888)\n",
      "12087 Traning Loss: tensor(2.9095)\n",
      "12088 Traning Loss: tensor(2.8966)\n",
      "12089 Traning Loss: tensor(2.9067)\n",
      "12090 Traning Loss: tensor(2.8772)\n",
      "12091 Traning Loss: tensor(2.9037)\n",
      "12092 Traning Loss: tensor(2.8872)\n",
      "12093 Traning Loss: tensor(2.8828)\n",
      "12094 Traning Loss: tensor(2.8883)\n",
      "12095 Traning Loss: tensor(2.8838)\n",
      "12096 Traning Loss: tensor(2.9061)\n",
      "12097 Traning Loss: tensor(2.8903)\n",
      "12098 Traning Loss: tensor(2.8783)\n",
      "12099 Traning Loss: tensor(2.8892)\n",
      "12100 Traning Loss: tensor(2.8924)\n",
      "12101 Traning Loss: tensor(2.8692)\n",
      "12102 Traning Loss: tensor(2.8908)\n",
      "12103 Traning Loss: tensor(2.8996)\n",
      "12104 Traning Loss: tensor(2.9066)\n",
      "12105 Traning Loss: tensor(2.9163)\n",
      "12106 Traning Loss: tensor(2.9014)\n",
      "12107 Traning Loss: tensor(2.8931)\n",
      "12108 Traning Loss: tensor(2.9039)\n",
      "12109 Traning Loss: tensor(2.8938)\n",
      "12110 Traning Loss: tensor(2.9040)\n",
      "12111 Traning Loss: tensor(2.8984)\n",
      "12112 Traning Loss: tensor(2.9110)\n",
      "12113 Traning Loss: tensor(2.8786)\n",
      "12114 Traning Loss: tensor(2.9101)\n",
      "12115 Traning Loss: tensor(2.8842)\n",
      "12116 Traning Loss: tensor(2.8988)\n",
      "12117 Traning Loss: tensor(2.9021)\n",
      "12118 Traning Loss: tensor(2.8801)\n",
      "12119 Traning Loss: tensor(2.8998)\n",
      "12120 Traning Loss: tensor(2.9049)\n",
      "12121 Traning Loss: tensor(2.8878)\n",
      "12122 Traning Loss: tensor(2.9064)\n",
      "12123 Traning Loss: tensor(2.8897)\n",
      "12124 Traning Loss: tensor(2.8831)\n",
      "12125 Traning Loss: tensor(2.9038)\n",
      "12126 Traning Loss: tensor(2.8766)\n",
      "12127 Traning Loss: tensor(2.8784)\n",
      "12128 Traning Loss: tensor(2.8858)\n",
      "12129 Traning Loss: tensor(2.8856)\n",
      "12130 Traning Loss: tensor(2.8905)\n",
      "12131 Traning Loss: tensor(2.8913)\n",
      "12132 Traning Loss: tensor(2.8904)\n",
      "12133 Traning Loss: tensor(2.8882)\n",
      "12134 Traning Loss: tensor(2.8930)\n",
      "12135 Traning Loss: tensor(2.8987)\n",
      "12136 Traning Loss: tensor(2.8806)\n",
      "12137 Traning Loss: tensor(2.8855)\n",
      "12138 Traning Loss: tensor(2.8807)\n",
      "12139 Traning Loss: tensor(2.8813)\n",
      "12140 Traning Loss: tensor(2.9047)\n",
      "12141 Traning Loss: tensor(2.8898)\n",
      "12142 Traning Loss: tensor(2.8957)\n",
      "12143 Traning Loss: tensor(2.8851)\n",
      "12144 Traning Loss: tensor(2.8954)\n",
      "12145 Traning Loss: tensor(2.8898)\n",
      "12146 Traning Loss: tensor(2.9087)\n",
      "12147 Traning Loss: tensor(2.8846)\n",
      "12148 Traning Loss: tensor(2.8852)\n",
      "12149 Traning Loss: tensor(2.8821)\n",
      "12150 Traning Loss: tensor(2.8782)\n",
      "12151 Traning Loss: tensor(2.8980)\n",
      "12152 Traning Loss: tensor(2.8867)\n",
      "12153 Traning Loss: tensor(2.8675)\n",
      "12154 Traning Loss: tensor(2.8971)\n",
      "12155 Traning Loss: tensor(2.9048)\n",
      "12156 Traning Loss: tensor(2.8676)\n",
      "12157 Traning Loss: tensor(2.8941)\n",
      "12158 Traning Loss: tensor(2.8872)\n",
      "12159 Traning Loss: tensor(2.8941)\n",
      "12160 Traning Loss: tensor(2.8742)\n",
      "12161 Traning Loss: tensor(2.8950)\n",
      "12162 Traning Loss: tensor(2.9039)\n",
      "12163 Traning Loss: tensor(2.8908)\n",
      "12164 Traning Loss: tensor(2.8940)\n",
      "12165 Traning Loss: tensor(2.8825)\n",
      "12166 Traning Loss: tensor(2.8890)\n",
      "12167 Traning Loss: tensor(2.8832)\n",
      "12168 Traning Loss: tensor(2.8707)\n",
      "12169 Traning Loss: tensor(2.8843)\n",
      "12170 Traning Loss: tensor(2.8959)\n",
      "12171 Traning Loss: tensor(2.8796)\n",
      "12172 Traning Loss: tensor(2.8999)\n",
      "12173 Traning Loss: tensor(2.8966)\n",
      "12174 Traning Loss: tensor(2.8673)\n",
      "12175 Traning Loss: tensor(2.8836)\n",
      "12176 Traning Loss: tensor(2.8968)\n",
      "12177 Traning Loss: tensor(2.9002)\n",
      "12178 Traning Loss: tensor(2.8944)\n",
      "12179 Traning Loss: tensor(2.8987)\n",
      "12180 Traning Loss: tensor(2.8958)\n",
      "12181 Traning Loss: tensor(2.8841)\n",
      "12182 Traning Loss: tensor(2.8753)\n",
      "12183 Traning Loss: tensor(2.8820)\n",
      "12184 Traning Loss: tensor(2.9158)\n",
      "12185 Traning Loss: tensor(2.8748)\n",
      "12186 Traning Loss: tensor(2.8804)\n",
      "12187 Traning Loss: tensor(2.8811)\n",
      "12188 Traning Loss: tensor(2.8967)\n",
      "12189 Traning Loss: tensor(2.9034)\n",
      "12190 Traning Loss: tensor(2.8956)\n",
      "12191 Traning Loss: tensor(2.8844)\n",
      "12192 Traning Loss: tensor(2.8897)\n",
      "12193 Traning Loss: tensor(2.8883)\n",
      "12194 Traning Loss: tensor(2.8742)\n",
      "12195 Traning Loss: tensor(2.8842)\n",
      "12196 Traning Loss: tensor(2.8998)\n",
      "12197 Traning Loss: tensor(2.9111)\n",
      "12198 Traning Loss: tensor(2.8923)\n",
      "12199 Traning Loss: tensor(2.8780)\n",
      "12200 Traning Loss: tensor(2.8985)\n",
      "12201 Traning Loss: tensor(2.8779)\n",
      "12202 Traning Loss: tensor(2.8683)\n",
      "12203 Traning Loss: tensor(2.8807)\n",
      "12204 Traning Loss: tensor(2.8878)\n",
      "12205 Traning Loss: tensor(2.8854)\n",
      "12206 Traning Loss: tensor(2.8945)\n",
      "12207 Traning Loss: tensor(2.8884)\n",
      "12208 Traning Loss: tensor(2.8785)\n",
      "12209 Traning Loss: tensor(2.8773)\n",
      "12210 Traning Loss: tensor(2.8847)\n",
      "12211 Traning Loss: tensor(2.8811)\n",
      "12212 Traning Loss: tensor(2.8945)\n",
      "12213 Traning Loss: tensor(2.8882)\n",
      "12214 Traning Loss: tensor(2.8602)\n",
      "12215 Traning Loss: tensor(2.8756)\n",
      "12216 Traning Loss: tensor(2.8765)\n",
      "12217 Traning Loss: tensor(2.8760)\n",
      "12218 Traning Loss: tensor(2.8819)\n",
      "12219 Traning Loss: tensor(2.8826)\n",
      "12220 Traning Loss: tensor(2.8808)\n",
      "12221 Traning Loss: tensor(2.8945)\n",
      "12222 Traning Loss: tensor(2.8933)\n",
      "12223 Traning Loss: tensor(2.8912)\n",
      "12224 Traning Loss: tensor(2.8836)\n",
      "12225 Traning Loss: tensor(2.8937)\n",
      "12226 Traning Loss: tensor(2.9052)\n",
      "12227 Traning Loss: tensor(2.8759)\n",
      "12228 Traning Loss: tensor(2.8860)\n",
      "12229 Traning Loss: tensor(2.8876)\n",
      "12230 Traning Loss: tensor(2.8712)\n",
      "12231 Traning Loss: tensor(2.8798)\n",
      "12232 Traning Loss: tensor(2.8920)\n",
      "12233 Traning Loss: tensor(2.8785)\n",
      "12234 Traning Loss: tensor(2.8741)\n",
      "12235 Traning Loss: tensor(2.8751)\n",
      "12236 Traning Loss: tensor(2.8863)\n",
      "12237 Traning Loss: tensor(2.8885)\n",
      "12238 Traning Loss: tensor(2.8899)\n",
      "12239 Traning Loss: tensor(2.8934)\n",
      "12240 Traning Loss: tensor(2.8902)\n",
      "12241 Traning Loss: tensor(2.8698)\n",
      "12242 Traning Loss: tensor(2.8819)\n",
      "12243 Traning Loss: tensor(2.8728)\n",
      "12244 Traning Loss: tensor(2.8920)\n",
      "12245 Traning Loss: tensor(2.8709)\n",
      "12246 Traning Loss: tensor(2.8667)\n",
      "12247 Traning Loss: tensor(2.8920)\n",
      "12248 Traning Loss: tensor(2.8847)\n",
      "12249 Traning Loss: tensor(2.8998)\n",
      "12250 Traning Loss: tensor(2.8695)\n",
      "12251 Traning Loss: tensor(2.8819)\n",
      "12252 Traning Loss: tensor(2.8768)\n",
      "12253 Traning Loss: tensor(2.8701)\n",
      "12254 Traning Loss: tensor(2.8957)\n",
      "12255 Traning Loss: tensor(2.9064)\n",
      "12256 Traning Loss: tensor(2.8771)\n",
      "12257 Traning Loss: tensor(2.8867)\n",
      "12258 Traning Loss: tensor(2.8872)\n",
      "12259 Traning Loss: tensor(2.8793)\n",
      "12260 Traning Loss: tensor(2.8913)\n",
      "12261 Traning Loss: tensor(2.8626)\n",
      "12262 Traning Loss: tensor(2.8717)\n",
      "12263 Traning Loss: tensor(2.8671)\n",
      "12264 Traning Loss: tensor(2.8829)\n",
      "12265 Traning Loss: tensor(2.8780)\n",
      "12266 Traning Loss: tensor(2.9064)\n",
      "12267 Traning Loss: tensor(2.8718)\n",
      "12268 Traning Loss: tensor(2.8851)\n",
      "12269 Traning Loss: tensor(2.8838)\n",
      "12270 Traning Loss: tensor(2.8737)\n",
      "12271 Traning Loss: tensor(2.9003)\n",
      "12272 Traning Loss: tensor(2.8607)\n",
      "12273 Traning Loss: tensor(2.8725)\n",
      "12274 Traning Loss: tensor(2.8848)\n",
      "12275 Traning Loss: tensor(2.8751)\n",
      "12276 Traning Loss: tensor(2.8815)\n",
      "12277 Traning Loss: tensor(2.8695)\n",
      "12278 Traning Loss: tensor(2.8771)\n",
      "12279 Traning Loss: tensor(2.8770)\n",
      "12280 Traning Loss: tensor(2.8980)\n",
      "12281 Traning Loss: tensor(2.8684)\n",
      "12282 Traning Loss: tensor(2.8748)\n",
      "12283 Traning Loss: tensor(2.8713)\n",
      "12284 Traning Loss: tensor(2.8838)\n",
      "12285 Traning Loss: tensor(2.9018)\n",
      "12286 Traning Loss: tensor(2.8959)\n",
      "12287 Traning Loss: tensor(2.8825)\n",
      "12288 Traning Loss: tensor(2.8678)\n",
      "12289 Traning Loss: tensor(2.8633)\n",
      "12290 Traning Loss: tensor(2.8820)\n",
      "12291 Traning Loss: tensor(2.8917)\n",
      "12292 Traning Loss: tensor(2.8849)\n",
      "12293 Traning Loss: tensor(2.8704)\n",
      "12294 Traning Loss: tensor(2.8659)\n",
      "12295 Traning Loss: tensor(2.8681)\n",
      "12296 Traning Loss: tensor(2.8882)\n",
      "12297 Traning Loss: tensor(2.8752)\n",
      "12298 Traning Loss: tensor(2.8626)\n",
      "12299 Traning Loss: tensor(2.8853)\n",
      "12300 Traning Loss: tensor(2.8638)\n",
      "12301 Traning Loss: tensor(2.9070)\n",
      "12302 Traning Loss: tensor(2.8767)\n",
      "12303 Traning Loss: tensor(2.8517)\n",
      "12304 Traning Loss: tensor(2.8715)\n",
      "12305 Traning Loss: tensor(2.8984)\n",
      "12306 Traning Loss: tensor(2.8780)\n",
      "12307 Traning Loss: tensor(2.8797)\n",
      "12308 Traning Loss: tensor(2.8938)\n",
      "12309 Traning Loss: tensor(2.8818)\n",
      "12310 Traning Loss: tensor(2.8800)\n",
      "12311 Traning Loss: tensor(2.8760)\n",
      "12312 Traning Loss: tensor(2.8849)\n",
      "12313 Traning Loss: tensor(2.8798)\n",
      "12314 Traning Loss: tensor(2.8762)\n",
      "12315 Traning Loss: tensor(2.8817)\n",
      "12316 Traning Loss: tensor(2.8888)\n",
      "12317 Traning Loss: tensor(2.8593)\n",
      "12318 Traning Loss: tensor(2.8754)\n",
      "12319 Traning Loss: tensor(2.8739)\n",
      "12320 Traning Loss: tensor(2.8872)\n",
      "12321 Traning Loss: tensor(2.8869)\n",
      "12322 Traning Loss: tensor(2.8709)\n",
      "12323 Traning Loss: tensor(2.8701)\n",
      "12324 Traning Loss: tensor(2.8614)\n",
      "12325 Traning Loss: tensor(2.8787)\n",
      "12326 Traning Loss: tensor(2.8718)\n",
      "12327 Traning Loss: tensor(2.8674)\n",
      "12328 Traning Loss: tensor(2.8798)\n",
      "12329 Traning Loss: tensor(2.8853)\n",
      "12330 Traning Loss: tensor(2.8993)\n",
      "12331 Traning Loss: tensor(2.8707)\n",
      "12332 Traning Loss: tensor(2.8513)\n",
      "12333 Traning Loss: tensor(2.8968)\n",
      "12334 Traning Loss: tensor(2.8671)\n",
      "12335 Traning Loss: tensor(2.8748)\n",
      "12336 Traning Loss: tensor(2.8894)\n",
      "12337 Traning Loss: tensor(2.8660)\n",
      "12338 Traning Loss: tensor(2.8673)\n",
      "12339 Traning Loss: tensor(2.8653)\n",
      "12340 Traning Loss: tensor(2.8871)\n",
      "12341 Traning Loss: tensor(2.8798)\n",
      "12342 Traning Loss: tensor(2.8645)\n",
      "12343 Traning Loss: tensor(2.8815)\n",
      "12344 Traning Loss: tensor(2.8781)\n",
      "12345 Traning Loss: tensor(2.8639)\n",
      "12346 Traning Loss: tensor(2.8727)\n",
      "12347 Traning Loss: tensor(2.8639)\n",
      "12348 Traning Loss: tensor(2.8757)\n",
      "12349 Traning Loss: tensor(2.8985)\n",
      "12350 Traning Loss: tensor(2.8796)\n",
      "12351 Traning Loss: tensor(2.8899)\n",
      "12352 Traning Loss: tensor(2.8771)\n",
      "12353 Traning Loss: tensor(2.8779)\n",
      "12354 Traning Loss: tensor(2.8726)\n",
      "12355 Traning Loss: tensor(2.8800)\n",
      "12356 Traning Loss: tensor(2.8495)\n",
      "12357 Traning Loss: tensor(2.8749)\n",
      "12358 Traning Loss: tensor(2.8553)\n",
      "12359 Traning Loss: tensor(2.8761)\n",
      "12360 Traning Loss: tensor(2.8668)\n",
      "12361 Traning Loss: tensor(2.8768)\n",
      "12362 Traning Loss: tensor(2.8866)\n",
      "12363 Traning Loss: tensor(2.8821)\n",
      "12364 Traning Loss: tensor(2.8695)\n",
      "12365 Traning Loss: tensor(2.8673)\n",
      "12366 Traning Loss: tensor(2.8666)\n",
      "12367 Traning Loss: tensor(2.8545)\n",
      "12368 Traning Loss: tensor(2.8666)\n",
      "12369 Traning Loss: tensor(2.8694)\n",
      "12370 Traning Loss: tensor(2.8756)\n",
      "12371 Traning Loss: tensor(2.8522)\n",
      "12372 Traning Loss: tensor(2.8834)\n",
      "12373 Traning Loss: tensor(2.8669)\n",
      "12374 Traning Loss: tensor(2.8871)\n",
      "12375 Traning Loss: tensor(2.8698)\n",
      "12376 Traning Loss: tensor(2.8904)\n",
      "12377 Traning Loss: tensor(2.8634)\n",
      "12378 Traning Loss: tensor(2.8996)\n",
      "12379 Traning Loss: tensor(2.8771)\n",
      "12380 Traning Loss: tensor(2.8643)\n",
      "12381 Traning Loss: tensor(2.8944)\n",
      "12382 Traning Loss: tensor(2.8624)\n",
      "12383 Traning Loss: tensor(2.8628)\n",
      "12384 Traning Loss: tensor(2.8718)\n",
      "12385 Traning Loss: tensor(2.8772)\n",
      "12386 Traning Loss: tensor(2.8788)\n",
      "12387 Traning Loss: tensor(2.8472)\n",
      "12388 Traning Loss: tensor(2.8803)\n",
      "12389 Traning Loss: tensor(2.8821)\n",
      "12390 Traning Loss: tensor(2.8733)\n",
      "12391 Traning Loss: tensor(2.8742)\n",
      "12392 Traning Loss: tensor(2.8587)\n",
      "12393 Traning Loss: tensor(2.8660)\n",
      "12394 Traning Loss: tensor(2.8768)\n",
      "12395 Traning Loss: tensor(2.8604)\n",
      "12396 Traning Loss: tensor(2.8792)\n",
      "12397 Traning Loss: tensor(2.8740)\n",
      "12398 Traning Loss: tensor(2.8659)\n",
      "12399 Traning Loss: tensor(2.8717)\n",
      "12400 Traning Loss: tensor(2.8630)\n",
      "12401 Traning Loss: tensor(2.8726)\n",
      "12402 Traning Loss: tensor(2.8599)\n",
      "12403 Traning Loss: tensor(2.8600)\n",
      "12404 Traning Loss: tensor(2.8926)\n",
      "12405 Traning Loss: tensor(2.8656)\n",
      "12406 Traning Loss: tensor(2.8672)\n",
      "12407 Traning Loss: tensor(2.8670)\n",
      "12408 Traning Loss: tensor(2.8695)\n",
      "12409 Traning Loss: tensor(2.8698)\n",
      "12410 Traning Loss: tensor(2.8594)\n",
      "12411 Traning Loss: tensor(2.8731)\n",
      "12412 Traning Loss: tensor(2.8549)\n",
      "12413 Traning Loss: tensor(2.8661)\n",
      "12414 Traning Loss: tensor(2.8583)\n",
      "12415 Traning Loss: tensor(2.8726)\n",
      "12416 Traning Loss: tensor(2.8915)\n",
      "12417 Traning Loss: tensor(2.8496)\n",
      "12418 Traning Loss: tensor(2.8734)\n",
      "12419 Traning Loss: tensor(2.8754)\n",
      "12420 Traning Loss: tensor(2.8914)\n",
      "12421 Traning Loss: tensor(2.8598)\n",
      "12422 Traning Loss: tensor(2.8605)\n",
      "12423 Traning Loss: tensor(2.8715)\n",
      "12424 Traning Loss: tensor(2.8985)\n",
      "12425 Traning Loss: tensor(2.8529)\n",
      "12426 Traning Loss: tensor(2.8549)\n",
      "12427 Traning Loss: tensor(2.8891)\n",
      "12428 Traning Loss: tensor(2.8915)\n",
      "12429 Traning Loss: tensor(2.8845)\n",
      "12430 Traning Loss: tensor(2.8831)\n",
      "12431 Traning Loss: tensor(2.8800)\n",
      "12432 Traning Loss: tensor(2.8735)\n",
      "12433 Traning Loss: tensor(2.8670)\n",
      "12434 Traning Loss: tensor(2.8622)\n",
      "12435 Traning Loss: tensor(2.8551)\n",
      "12436 Traning Loss: tensor(2.8605)\n",
      "12437 Traning Loss: tensor(2.8655)\n",
      "12438 Traning Loss: tensor(2.8859)\n",
      "12439 Traning Loss: tensor(2.8713)\n",
      "12440 Traning Loss: tensor(2.8590)\n",
      "12441 Traning Loss: tensor(2.8638)\n",
      "12442 Traning Loss: tensor(2.8547)\n",
      "12443 Traning Loss: tensor(2.8820)\n",
      "12444 Traning Loss: tensor(2.8605)\n",
      "12445 Traning Loss: tensor(2.8753)\n",
      "12446 Traning Loss: tensor(2.8674)\n",
      "12447 Traning Loss: tensor(2.8464)\n",
      "12448 Traning Loss: tensor(2.8940)\n",
      "12449 Traning Loss: tensor(2.8644)\n",
      "12450 Traning Loss: tensor(2.8605)\n",
      "12451 Traning Loss: tensor(2.8795)\n",
      "12452 Traning Loss: tensor(2.8885)\n",
      "12453 Traning Loss: tensor(2.8717)\n",
      "12454 Traning Loss: tensor(2.8605)\n",
      "12455 Traning Loss: tensor(2.8464)\n",
      "12456 Traning Loss: tensor(2.8482)\n",
      "12457 Traning Loss: tensor(2.8725)\n",
      "12458 Traning Loss: tensor(2.8618)\n",
      "12459 Traning Loss: tensor(2.8560)\n",
      "12460 Traning Loss: tensor(2.8670)\n",
      "12461 Traning Loss: tensor(2.8657)\n",
      "12462 Traning Loss: tensor(2.8588)\n",
      "12463 Traning Loss: tensor(2.8718)\n",
      "12464 Traning Loss: tensor(2.8569)\n",
      "12465 Traning Loss: tensor(2.8594)\n",
      "12466 Traning Loss: tensor(2.8653)\n",
      "12467 Traning Loss: tensor(2.8528)\n",
      "12468 Traning Loss: tensor(2.8816)\n",
      "12469 Traning Loss: tensor(2.8510)\n",
      "12470 Traning Loss: tensor(2.8797)\n",
      "12471 Traning Loss: tensor(2.8745)\n",
      "12472 Traning Loss: tensor(2.8700)\n",
      "12473 Traning Loss: tensor(2.8470)\n",
      "12474 Traning Loss: tensor(2.8845)\n",
      "12475 Traning Loss: tensor(2.8717)\n",
      "12476 Traning Loss: tensor(2.8621)\n",
      "12477 Traning Loss: tensor(2.8729)\n",
      "12478 Traning Loss: tensor(2.8475)\n",
      "12479 Traning Loss: tensor(2.8785)\n",
      "12480 Traning Loss: tensor(2.8654)\n",
      "12481 Traning Loss: tensor(2.8541)\n",
      "12482 Traning Loss: tensor(2.8715)\n",
      "12483 Traning Loss: tensor(2.8578)\n",
      "12484 Traning Loss: tensor(2.8716)\n",
      "12485 Traning Loss: tensor(2.8491)\n",
      "12486 Traning Loss: tensor(2.8952)\n",
      "12487 Traning Loss: tensor(2.8680)\n",
      "12488 Traning Loss: tensor(2.8737)\n",
      "12489 Traning Loss: tensor(2.8575)\n",
      "12490 Traning Loss: tensor(2.8440)\n",
      "12491 Traning Loss: tensor(2.8655)\n",
      "12492 Traning Loss: tensor(2.8586)\n",
      "12493 Traning Loss: tensor(2.8825)\n",
      "12494 Traning Loss: tensor(2.8724)\n",
      "12495 Traning Loss: tensor(2.8843)\n",
      "12496 Traning Loss: tensor(2.8659)\n",
      "12497 Traning Loss: tensor(2.8733)\n",
      "12498 Traning Loss: tensor(2.8506)\n",
      "12499 Traning Loss: tensor(2.8517)\n",
      "12500 Traning Loss: tensor(2.8502)\n",
      "12501 Traning Loss: tensor(2.8358)\n",
      "12502 Traning Loss: tensor(2.8574)\n",
      "12503 Traning Loss: tensor(2.8612)\n",
      "12504 Traning Loss: tensor(2.8787)\n",
      "12505 Traning Loss: tensor(2.8919)\n",
      "12506 Traning Loss: tensor(2.8479)\n",
      "12507 Traning Loss: tensor(2.8526)\n",
      "12508 Traning Loss: tensor(2.8615)\n",
      "12509 Traning Loss: tensor(2.8673)\n",
      "12510 Traning Loss: tensor(2.8502)\n",
      "12511 Traning Loss: tensor(2.8394)\n",
      "12512 Traning Loss: tensor(2.8886)\n",
      "12513 Traning Loss: tensor(2.8571)\n",
      "12514 Traning Loss: tensor(2.8677)\n",
      "12515 Traning Loss: tensor(2.8856)\n",
      "12516 Traning Loss: tensor(2.8642)\n",
      "12517 Traning Loss: tensor(2.8738)\n",
      "12518 Traning Loss: tensor(2.8588)\n",
      "12519 Traning Loss: tensor(2.8587)\n",
      "12520 Traning Loss: tensor(2.8502)\n",
      "12521 Traning Loss: tensor(2.8547)\n",
      "12522 Traning Loss: tensor(2.8698)\n",
      "12523 Traning Loss: tensor(2.8595)\n",
      "12524 Traning Loss: tensor(2.8774)\n",
      "12525 Traning Loss: tensor(2.8452)\n",
      "12526 Traning Loss: tensor(2.8762)\n",
      "12527 Traning Loss: tensor(2.8579)\n",
      "12528 Traning Loss: tensor(2.8557)\n",
      "12529 Traning Loss: tensor(2.8707)\n",
      "12530 Traning Loss: tensor(2.8606)\n",
      "12531 Traning Loss: tensor(2.8519)\n",
      "12532 Traning Loss: tensor(2.8718)\n",
      "12533 Traning Loss: tensor(2.8554)\n",
      "12534 Traning Loss: tensor(2.8446)\n",
      "12535 Traning Loss: tensor(2.8563)\n",
      "12536 Traning Loss: tensor(2.8601)\n",
      "12537 Traning Loss: tensor(2.8457)\n",
      "12538 Traning Loss: tensor(2.8458)\n",
      "12539 Traning Loss: tensor(2.8377)\n",
      "12540 Traning Loss: tensor(2.8638)\n",
      "12541 Traning Loss: tensor(2.8827)\n",
      "12542 Traning Loss: tensor(2.8484)\n",
      "12543 Traning Loss: tensor(2.8530)\n",
      "12544 Traning Loss: tensor(2.8469)\n",
      "12545 Traning Loss: tensor(2.8704)\n",
      "12546 Traning Loss: tensor(2.8474)\n",
      "12547 Traning Loss: tensor(2.8582)\n",
      "12548 Traning Loss: tensor(2.8782)\n",
      "12549 Traning Loss: tensor(2.8474)\n",
      "12550 Traning Loss: tensor(2.8551)\n",
      "12551 Traning Loss: tensor(2.8605)\n",
      "12552 Traning Loss: tensor(2.8588)\n",
      "12553 Traning Loss: tensor(2.8544)\n",
      "12554 Traning Loss: tensor(2.8509)\n",
      "12555 Traning Loss: tensor(2.8526)\n",
      "12556 Traning Loss: tensor(2.8606)\n",
      "12557 Traning Loss: tensor(2.8489)\n",
      "12558 Traning Loss: tensor(2.8791)\n",
      "12559 Traning Loss: tensor(2.8610)\n",
      "12560 Traning Loss: tensor(2.8474)\n",
      "12561 Traning Loss: tensor(2.8778)\n",
      "12562 Traning Loss: tensor(2.8550)\n",
      "12563 Traning Loss: tensor(2.8721)\n",
      "12564 Traning Loss: tensor(2.8461)\n",
      "12565 Traning Loss: tensor(2.8594)\n",
      "12566 Traning Loss: tensor(2.8557)\n",
      "12567 Traning Loss: tensor(2.8689)\n",
      "12568 Traning Loss: tensor(2.8488)\n",
      "12569 Traning Loss: tensor(2.8387)\n",
      "12570 Traning Loss: tensor(2.8522)\n",
      "12571 Traning Loss: tensor(2.8482)\n",
      "12572 Traning Loss: tensor(2.8434)\n",
      "12573 Traning Loss: tensor(2.8353)\n",
      "12574 Traning Loss: tensor(2.8402)\n",
      "12575 Traning Loss: tensor(2.8662)\n",
      "12576 Traning Loss: tensor(2.8531)\n",
      "12577 Traning Loss: tensor(2.8575)\n",
      "12578 Traning Loss: tensor(2.8529)\n",
      "12579 Traning Loss: tensor(2.8879)\n",
      "12580 Traning Loss: tensor(2.8391)\n",
      "12581 Traning Loss: tensor(2.8619)\n",
      "12582 Traning Loss: tensor(2.8657)\n",
      "12583 Traning Loss: tensor(2.8434)\n",
      "12584 Traning Loss: tensor(2.8485)\n",
      "12585 Traning Loss: tensor(2.8506)\n",
      "12586 Traning Loss: tensor(2.8569)\n",
      "12587 Traning Loss: tensor(2.8693)\n",
      "12588 Traning Loss: tensor(2.8313)\n",
      "12589 Traning Loss: tensor(2.8426)\n",
      "12590 Traning Loss: tensor(2.8436)\n",
      "12591 Traning Loss: tensor(2.8528)\n",
      "12592 Traning Loss: tensor(2.8555)\n",
      "12593 Traning Loss: tensor(2.8481)\n",
      "12594 Traning Loss: tensor(2.8590)\n",
      "12595 Traning Loss: tensor(2.8676)\n",
      "12596 Traning Loss: tensor(2.8390)\n",
      "12597 Traning Loss: tensor(2.8353)\n",
      "12598 Traning Loss: tensor(2.8466)\n",
      "12599 Traning Loss: tensor(2.8556)\n",
      "12600 Traning Loss: tensor(2.8633)\n",
      "12601 Traning Loss: tensor(2.8433)\n",
      "12602 Traning Loss: tensor(2.8458)\n",
      "12603 Traning Loss: tensor(2.8558)\n",
      "12604 Traning Loss: tensor(2.8330)\n",
      "12605 Traning Loss: tensor(2.8584)\n",
      "12606 Traning Loss: tensor(2.8627)\n",
      "12607 Traning Loss: tensor(2.8376)\n",
      "12608 Traning Loss: tensor(2.8246)\n",
      "12609 Traning Loss: tensor(2.8557)\n",
      "12610 Traning Loss: tensor(2.8545)\n",
      "12611 Traning Loss: tensor(2.8511)\n",
      "12612 Traning Loss: tensor(2.8712)\n",
      "12613 Traning Loss: tensor(2.8638)\n",
      "12614 Traning Loss: tensor(2.8425)\n",
      "12615 Traning Loss: tensor(2.8505)\n",
      "12616 Traning Loss: tensor(2.8661)\n",
      "12617 Traning Loss: tensor(2.8508)\n",
      "12618 Traning Loss: tensor(2.8582)\n",
      "12619 Traning Loss: tensor(2.8356)\n",
      "12620 Traning Loss: tensor(2.8384)\n",
      "12621 Traning Loss: tensor(2.8624)\n",
      "12622 Traning Loss: tensor(2.8550)\n",
      "12623 Traning Loss: tensor(2.8440)\n",
      "12624 Traning Loss: tensor(2.8455)\n",
      "12625 Traning Loss: tensor(2.8486)\n",
      "12626 Traning Loss: tensor(2.8414)\n",
      "12627 Traning Loss: tensor(2.8492)\n",
      "12628 Traning Loss: tensor(2.8430)\n",
      "12629 Traning Loss: tensor(2.8492)\n",
      "12630 Traning Loss: tensor(2.8486)\n",
      "12631 Traning Loss: tensor(2.8420)\n",
      "12632 Traning Loss: tensor(2.8518)\n",
      "12633 Traning Loss: tensor(2.8315)\n",
      "12634 Traning Loss: tensor(2.8472)\n",
      "12635 Traning Loss: tensor(2.8597)\n",
      "12636 Traning Loss: tensor(2.8522)\n",
      "12637 Traning Loss: tensor(2.8426)\n",
      "12638 Traning Loss: tensor(2.8375)\n",
      "12639 Traning Loss: tensor(2.8447)\n",
      "12640 Traning Loss: tensor(2.8274)\n",
      "12641 Traning Loss: tensor(2.8369)\n",
      "12642 Traning Loss: tensor(2.8517)\n",
      "12643 Traning Loss: tensor(2.8371)\n",
      "12644 Traning Loss: tensor(2.8536)\n",
      "12645 Traning Loss: tensor(2.8630)\n",
      "12646 Traning Loss: tensor(2.8460)\n",
      "12647 Traning Loss: tensor(2.8209)\n",
      "12648 Traning Loss: tensor(2.8657)\n",
      "12649 Traning Loss: tensor(2.8463)\n",
      "12650 Traning Loss: tensor(2.8488)\n",
      "12651 Traning Loss: tensor(2.8482)\n",
      "12652 Traning Loss: tensor(2.8314)\n",
      "12653 Traning Loss: tensor(2.8455)\n",
      "12654 Traning Loss: tensor(2.8333)\n",
      "12655 Traning Loss: tensor(2.8404)\n",
      "12656 Traning Loss: tensor(2.8300)\n",
      "12657 Traning Loss: tensor(2.8450)\n",
      "12658 Traning Loss: tensor(2.8704)\n",
      "12659 Traning Loss: tensor(2.8207)\n",
      "12660 Traning Loss: tensor(2.8488)\n",
      "12661 Traning Loss: tensor(2.8360)\n",
      "12662 Traning Loss: tensor(2.8387)\n",
      "12663 Traning Loss: tensor(2.8489)\n",
      "12664 Traning Loss: tensor(2.8401)\n",
      "12665 Traning Loss: tensor(2.8404)\n",
      "12666 Traning Loss: tensor(2.8350)\n",
      "12667 Traning Loss: tensor(2.8542)\n",
      "12668 Traning Loss: tensor(2.8491)\n",
      "12669 Traning Loss: tensor(2.8634)\n",
      "12670 Traning Loss: tensor(2.8307)\n",
      "12671 Traning Loss: tensor(2.8490)\n",
      "12672 Traning Loss: tensor(2.8399)\n",
      "12673 Traning Loss: tensor(2.8453)\n",
      "12674 Traning Loss: tensor(2.8269)\n",
      "12675 Traning Loss: tensor(2.8404)\n",
      "12676 Traning Loss: tensor(2.8446)\n",
      "12677 Traning Loss: tensor(2.8437)\n",
      "12678 Traning Loss: tensor(2.8365)\n",
      "12679 Traning Loss: tensor(2.8301)\n",
      "12680 Traning Loss: tensor(2.8571)\n",
      "12681 Traning Loss: tensor(2.8301)\n",
      "12682 Traning Loss: tensor(2.8327)\n",
      "12683 Traning Loss: tensor(2.8279)\n",
      "12684 Traning Loss: tensor(2.8401)\n",
      "12685 Traning Loss: tensor(2.8402)\n",
      "12686 Traning Loss: tensor(2.8320)\n",
      "12687 Traning Loss: tensor(2.8380)\n",
      "12688 Traning Loss: tensor(2.8424)\n",
      "12689 Traning Loss: tensor(2.8536)\n",
      "12690 Traning Loss: tensor(2.8523)\n",
      "12691 Traning Loss: tensor(2.8485)\n",
      "12692 Traning Loss: tensor(2.8258)\n",
      "12693 Traning Loss: tensor(2.8496)\n",
      "12694 Traning Loss: tensor(2.8466)\n",
      "12695 Traning Loss: tensor(2.8409)\n",
      "12696 Traning Loss: tensor(2.8324)\n",
      "12697 Traning Loss: tensor(2.8347)\n",
      "12698 Traning Loss: tensor(2.8500)\n",
      "12699 Traning Loss: tensor(2.8484)\n",
      "12700 Traning Loss: tensor(2.8526)\n",
      "12701 Traning Loss: tensor(2.8425)\n",
      "12702 Traning Loss: tensor(2.8504)\n",
      "12703 Traning Loss: tensor(2.8339)\n",
      "12704 Traning Loss: tensor(2.8291)\n",
      "12705 Traning Loss: tensor(2.8576)\n",
      "12706 Traning Loss: tensor(2.8327)\n",
      "12707 Traning Loss: tensor(2.8380)\n",
      "12708 Traning Loss: tensor(2.8306)\n",
      "12709 Traning Loss: tensor(2.8446)\n",
      "12710 Traning Loss: tensor(2.8329)\n",
      "12711 Traning Loss: tensor(2.8401)\n",
      "12712 Traning Loss: tensor(2.8304)\n",
      "12713 Traning Loss: tensor(2.8400)\n",
      "12714 Traning Loss: tensor(2.8239)\n",
      "12715 Traning Loss: tensor(2.8237)\n",
      "12716 Traning Loss: tensor(2.8405)\n",
      "12717 Traning Loss: tensor(2.8206)\n",
      "12718 Traning Loss: tensor(2.8344)\n",
      "12719 Traning Loss: tensor(2.8395)\n",
      "12720 Traning Loss: tensor(2.8384)\n",
      "12721 Traning Loss: tensor(2.8336)\n",
      "12722 Traning Loss: tensor(2.8306)\n",
      "12723 Traning Loss: tensor(2.8390)\n",
      "12724 Traning Loss: tensor(2.8336)\n",
      "12725 Traning Loss: tensor(2.8454)\n",
      "12726 Traning Loss: tensor(2.8160)\n",
      "12727 Traning Loss: tensor(2.8503)\n",
      "12728 Traning Loss: tensor(2.8145)\n",
      "12729 Traning Loss: tensor(2.8265)\n",
      "12730 Traning Loss: tensor(2.8385)\n",
      "12731 Traning Loss: tensor(2.8322)\n",
      "12732 Traning Loss: tensor(2.8367)\n",
      "12733 Traning Loss: tensor(2.8366)\n",
      "12734 Traning Loss: tensor(2.8512)\n",
      "12735 Traning Loss: tensor(2.8195)\n",
      "12736 Traning Loss: tensor(2.8156)\n",
      "12737 Traning Loss: tensor(2.8226)\n",
      "12738 Traning Loss: tensor(2.8252)\n",
      "12739 Traning Loss: tensor(2.8436)\n",
      "12740 Traning Loss: tensor(2.8366)\n",
      "12741 Traning Loss: tensor(2.8338)\n",
      "12742 Traning Loss: tensor(2.8380)\n",
      "12743 Traning Loss: tensor(2.8216)\n",
      "12744 Traning Loss: tensor(2.8262)\n",
      "12745 Traning Loss: tensor(2.8176)\n",
      "12746 Traning Loss: tensor(2.8271)\n",
      "12747 Traning Loss: tensor(2.8211)\n",
      "12748 Traning Loss: tensor(2.8253)\n",
      "12749 Traning Loss: tensor(2.8471)\n",
      "12750 Traning Loss: tensor(2.8274)\n",
      "12751 Traning Loss: tensor(2.8513)\n",
      "12752 Traning Loss: tensor(2.8444)\n",
      "12753 Traning Loss: tensor(2.8450)\n",
      "12754 Traning Loss: tensor(2.8383)\n",
      "12755 Traning Loss: tensor(2.8466)\n",
      "12756 Traning Loss: tensor(2.8197)\n",
      "12757 Traning Loss: tensor(2.8207)\n",
      "12758 Traning Loss: tensor(2.8360)\n",
      "12759 Traning Loss: tensor(2.8230)\n",
      "12760 Traning Loss: tensor(2.8358)\n",
      "12761 Traning Loss: tensor(2.8154)\n",
      "12762 Traning Loss: tensor(2.8503)\n",
      "12763 Traning Loss: tensor(2.8258)\n",
      "12764 Traning Loss: tensor(2.8229)\n",
      "12765 Traning Loss: tensor(2.8140)\n",
      "12766 Traning Loss: tensor(2.8325)\n",
      "12767 Traning Loss: tensor(2.8226)\n",
      "12768 Traning Loss: tensor(2.8363)\n",
      "12769 Traning Loss: tensor(2.8414)\n",
      "12770 Traning Loss: tensor(2.8368)\n",
      "12771 Traning Loss: tensor(2.8276)\n",
      "12772 Traning Loss: tensor(2.8222)\n",
      "12773 Traning Loss: tensor(2.8173)\n",
      "12774 Traning Loss: tensor(2.8135)\n",
      "12775 Traning Loss: tensor(2.8379)\n",
      "12776 Traning Loss: tensor(2.8180)\n",
      "12777 Traning Loss: tensor(2.8224)\n",
      "12778 Traning Loss: tensor(2.8271)\n",
      "12779 Traning Loss: tensor(2.8228)\n",
      "12780 Traning Loss: tensor(2.8144)\n",
      "12781 Traning Loss: tensor(2.8279)\n",
      "12782 Traning Loss: tensor(2.8414)\n",
      "12783 Traning Loss: tensor(2.8239)\n",
      "12784 Traning Loss: tensor(2.8342)\n",
      "12785 Traning Loss: tensor(2.8191)\n",
      "12786 Traning Loss: tensor(2.8351)\n",
      "12787 Traning Loss: tensor(2.8171)\n",
      "12788 Traning Loss: tensor(2.8255)\n",
      "12789 Traning Loss: tensor(2.8197)\n",
      "12790 Traning Loss: tensor(2.8293)\n",
      "12791 Traning Loss: tensor(2.8172)\n",
      "12792 Traning Loss: tensor(2.8256)\n",
      "12793 Traning Loss: tensor(2.8454)\n",
      "12794 Traning Loss: tensor(2.8340)\n",
      "12795 Traning Loss: tensor(2.8147)\n",
      "12796 Traning Loss: tensor(2.8198)\n",
      "12797 Traning Loss: tensor(2.8360)\n",
      "12798 Traning Loss: tensor(2.8328)\n",
      "12799 Traning Loss: tensor(2.8339)\n",
      "12800 Traning Loss: tensor(2.8273)\n",
      "12801 Traning Loss: tensor(2.8451)\n",
      "12802 Traning Loss: tensor(2.8342)\n",
      "12803 Traning Loss: tensor(2.8083)\n",
      "12804 Traning Loss: tensor(2.8410)\n",
      "12805 Traning Loss: tensor(2.8044)\n",
      "12806 Traning Loss: tensor(2.8102)\n",
      "12807 Traning Loss: tensor(2.8314)\n",
      "12808 Traning Loss: tensor(2.8538)\n",
      "12809 Traning Loss: tensor(2.8275)\n",
      "12810 Traning Loss: tensor(2.8279)\n",
      "12811 Traning Loss: tensor(2.8209)\n",
      "12812 Traning Loss: tensor(2.8246)\n",
      "12813 Traning Loss: tensor(2.8151)\n",
      "12814 Traning Loss: tensor(2.8109)\n",
      "12815 Traning Loss: tensor(2.8101)\n",
      "12816 Traning Loss: tensor(2.8027)\n",
      "12817 Traning Loss: tensor(2.8034)\n",
      "12818 Traning Loss: tensor(2.8668)\n",
      "12819 Traning Loss: tensor(2.8256)\n",
      "12820 Traning Loss: tensor(2.8073)\n",
      "12821 Traning Loss: tensor(2.8311)\n",
      "12822 Traning Loss: tensor(2.8099)\n",
      "12823 Traning Loss: tensor(2.8315)\n",
      "12824 Traning Loss: tensor(2.8177)\n",
      "12825 Traning Loss: tensor(2.8306)\n",
      "12826 Traning Loss: tensor(2.8072)\n",
      "12827 Traning Loss: tensor(2.7888)\n",
      "12828 Traning Loss: tensor(2.8626)\n",
      "12829 Traning Loss: tensor(2.8225)\n",
      "12830 Traning Loss: tensor(2.7914)\n",
      "12831 Traning Loss: tensor(2.8340)\n",
      "12832 Traning Loss: tensor(2.8055)\n",
      "12833 Traning Loss: tensor(2.8006)\n",
      "12834 Traning Loss: tensor(2.8316)\n",
      "12835 Traning Loss: tensor(2.8002)\n",
      "12836 Traning Loss: tensor(2.8229)\n",
      "12837 Traning Loss: tensor(2.8022)\n",
      "12838 Traning Loss: tensor(2.8047)\n",
      "12839 Traning Loss: tensor(2.7908)\n",
      "12840 Traning Loss: tensor(2.8178)\n",
      "12841 Traning Loss: tensor(2.8050)\n",
      "12842 Traning Loss: tensor(2.8366)\n",
      "12843 Traning Loss: tensor(2.8217)\n",
      "12844 Traning Loss: tensor(2.8080)\n",
      "12845 Traning Loss: tensor(2.8334)\n",
      "12846 Traning Loss: tensor(2.8100)\n",
      "12847 Traning Loss: tensor(2.8147)\n",
      "12848 Traning Loss: tensor(2.7938)\n",
      "12849 Traning Loss: tensor(2.8075)\n",
      "12850 Traning Loss: tensor(2.8096)\n",
      "12851 Traning Loss: tensor(2.8310)\n",
      "12852 Traning Loss: tensor(2.8173)\n",
      "12853 Traning Loss: tensor(2.8183)\n",
      "12854 Traning Loss: tensor(2.8331)\n",
      "12855 Traning Loss: tensor(2.8296)\n",
      "12856 Traning Loss: tensor(2.8212)\n",
      "12857 Traning Loss: tensor(2.8147)\n",
      "12858 Traning Loss: tensor(2.8242)\n",
      "12859 Traning Loss: tensor(2.8198)\n",
      "12860 Traning Loss: tensor(2.7991)\n",
      "12861 Traning Loss: tensor(2.8182)\n",
      "12862 Traning Loss: tensor(2.8116)\n",
      "12863 Traning Loss: tensor(2.8189)\n",
      "12864 Traning Loss: tensor(2.8212)\n",
      "12865 Traning Loss: tensor(2.8242)\n",
      "12866 Traning Loss: tensor(2.8281)\n",
      "12867 Traning Loss: tensor(2.8167)\n",
      "12868 Traning Loss: tensor(2.8081)\n",
      "12869 Traning Loss: tensor(2.8014)\n",
      "12870 Traning Loss: tensor(2.7870)\n",
      "12871 Traning Loss: tensor(2.8092)\n",
      "12872 Traning Loss: tensor(2.8047)\n",
      "12873 Traning Loss: tensor(2.7945)\n",
      "12874 Traning Loss: tensor(2.8016)\n",
      "12875 Traning Loss: tensor(2.8183)\n",
      "12876 Traning Loss: tensor(2.8033)\n",
      "12877 Traning Loss: tensor(2.8039)\n",
      "12878 Traning Loss: tensor(2.8154)\n",
      "12879 Traning Loss: tensor(2.8008)\n",
      "12880 Traning Loss: tensor(2.8121)\n",
      "12881 Traning Loss: tensor(2.8098)\n",
      "12882 Traning Loss: tensor(2.8060)\n",
      "12883 Traning Loss: tensor(2.8006)\n",
      "12884 Traning Loss: tensor(2.8114)\n",
      "12885 Traning Loss: tensor(2.7974)\n",
      "12886 Traning Loss: tensor(2.8036)\n",
      "12887 Traning Loss: tensor(2.8234)\n",
      "12888 Traning Loss: tensor(2.8298)\n",
      "12889 Traning Loss: tensor(2.8135)\n",
      "12890 Traning Loss: tensor(2.8205)\n",
      "12891 Traning Loss: tensor(2.7968)\n",
      "12892 Traning Loss: tensor(2.8009)\n",
      "12893 Traning Loss: tensor(2.8116)\n",
      "12894 Traning Loss: tensor(2.8020)\n",
      "12895 Traning Loss: tensor(2.7982)\n",
      "12896 Traning Loss: tensor(2.8181)\n",
      "12897 Traning Loss: tensor(2.8023)\n",
      "12898 Traning Loss: tensor(2.8179)\n",
      "12899 Traning Loss: tensor(2.7834)\n",
      "12900 Traning Loss: tensor(2.7905)\n",
      "12901 Traning Loss: tensor(2.8059)\n",
      "12902 Traning Loss: tensor(2.7891)\n",
      "12903 Traning Loss: tensor(2.8148)\n",
      "12904 Traning Loss: tensor(2.8068)\n",
      "12905 Traning Loss: tensor(2.8012)\n",
      "12906 Traning Loss: tensor(2.7933)\n",
      "12907 Traning Loss: tensor(2.7923)\n",
      "12908 Traning Loss: tensor(2.7965)\n",
      "12909 Traning Loss: tensor(2.7834)\n",
      "12910 Traning Loss: tensor(2.7880)\n",
      "12911 Traning Loss: tensor(2.8064)\n",
      "12912 Traning Loss: tensor(2.7996)\n",
      "12913 Traning Loss: tensor(2.8137)\n",
      "12914 Traning Loss: tensor(2.7905)\n",
      "12915 Traning Loss: tensor(2.7891)\n",
      "12916 Traning Loss: tensor(2.7948)\n",
      "12917 Traning Loss: tensor(2.7883)\n",
      "12918 Traning Loss: tensor(2.7922)\n",
      "12919 Traning Loss: tensor(2.7670)\n",
      "12920 Traning Loss: tensor(2.7964)\n",
      "12921 Traning Loss: tensor(2.7898)\n",
      "12922 Traning Loss: tensor(2.8090)\n",
      "12923 Traning Loss: tensor(2.7881)\n",
      "12924 Traning Loss: tensor(2.7776)\n",
      "12925 Traning Loss: tensor(2.8146)\n",
      "12926 Traning Loss: tensor(2.7905)\n",
      "12927 Traning Loss: tensor(2.8027)\n",
      "12928 Traning Loss: tensor(2.7889)\n",
      "12929 Traning Loss: tensor(2.7722)\n",
      "12930 Traning Loss: tensor(2.7880)\n",
      "12931 Traning Loss: tensor(2.7927)\n",
      "12932 Traning Loss: tensor(2.7795)\n",
      "12933 Traning Loss: tensor(2.7948)\n",
      "12934 Traning Loss: tensor(2.8050)\n",
      "12935 Traning Loss: tensor(2.7819)\n",
      "12936 Traning Loss: tensor(2.8016)\n",
      "12937 Traning Loss: tensor(2.7804)\n",
      "12938 Traning Loss: tensor(2.7912)\n",
      "12939 Traning Loss: tensor(2.7793)\n",
      "12940 Traning Loss: tensor(2.7706)\n",
      "12941 Traning Loss: tensor(2.7998)\n",
      "12942 Traning Loss: tensor(2.7955)\n",
      "12943 Traning Loss: tensor(2.7993)\n",
      "12944 Traning Loss: tensor(2.8036)\n",
      "12945 Traning Loss: tensor(2.8006)\n",
      "12946 Traning Loss: tensor(2.7772)\n",
      "12947 Traning Loss: tensor(2.8000)\n",
      "12948 Traning Loss: tensor(2.7978)\n",
      "12949 Traning Loss: tensor(2.7902)\n",
      "12950 Traning Loss: tensor(2.7833)\n",
      "12951 Traning Loss: tensor(2.7942)\n",
      "12952 Traning Loss: tensor(2.7837)\n",
      "12953 Traning Loss: tensor(2.7778)\n",
      "12954 Traning Loss: tensor(2.7764)\n",
      "12955 Traning Loss: tensor(2.7757)\n",
      "12956 Traning Loss: tensor(2.7805)\n",
      "12957 Traning Loss: tensor(2.8068)\n",
      "12958 Traning Loss: tensor(2.8013)\n",
      "12959 Traning Loss: tensor(2.7613)\n",
      "12960 Traning Loss: tensor(2.7690)\n",
      "12961 Traning Loss: tensor(2.7798)\n",
      "12962 Traning Loss: tensor(2.7862)\n",
      "12963 Traning Loss: tensor(2.7661)\n",
      "12964 Traning Loss: tensor(2.7907)\n",
      "12965 Traning Loss: tensor(2.7847)\n",
      "12966 Traning Loss: tensor(2.7737)\n",
      "12967 Traning Loss: tensor(2.8029)\n",
      "12968 Traning Loss: tensor(2.7707)\n",
      "12969 Traning Loss: tensor(2.7743)\n",
      "12970 Traning Loss: tensor(2.8001)\n",
      "12971 Traning Loss: tensor(2.7877)\n",
      "12972 Traning Loss: tensor(2.7592)\n",
      "12973 Traning Loss: tensor(2.7844)\n",
      "12974 Traning Loss: tensor(2.7978)\n",
      "12975 Traning Loss: tensor(2.7988)\n",
      "12976 Traning Loss: tensor(2.7900)\n",
      "12977 Traning Loss: tensor(2.7853)\n",
      "12978 Traning Loss: tensor(2.7932)\n",
      "12979 Traning Loss: tensor(2.7748)\n",
      "12980 Traning Loss: tensor(2.7805)\n",
      "12981 Traning Loss: tensor(2.7788)\n",
      "12982 Traning Loss: tensor(2.7805)\n",
      "12983 Traning Loss: tensor(2.7638)\n",
      "12984 Traning Loss: tensor(2.7813)\n",
      "12985 Traning Loss: tensor(2.7553)\n",
      "12986 Traning Loss: tensor(2.7721)\n",
      "12987 Traning Loss: tensor(2.7720)\n",
      "12988 Traning Loss: tensor(2.7596)\n",
      "12989 Traning Loss: tensor(2.7988)\n",
      "12990 Traning Loss: tensor(2.7988)\n",
      "12991 Traning Loss: tensor(2.7748)\n",
      "12992 Traning Loss: tensor(2.7631)\n",
      "12993 Traning Loss: tensor(2.7645)\n",
      "12994 Traning Loss: tensor(2.7744)\n",
      "12995 Traning Loss: tensor(2.7722)\n",
      "12996 Traning Loss: tensor(2.7797)\n",
      "12997 Traning Loss: tensor(2.8177)\n",
      "12998 Traning Loss: tensor(2.7828)\n",
      "12999 Traning Loss: tensor(2.7792)\n",
      "13000 Traning Loss: tensor(2.7442)\n",
      "13001 Traning Loss: tensor(2.7607)\n",
      "13002 Traning Loss: tensor(2.7804)\n",
      "13003 Traning Loss: tensor(2.7730)\n",
      "13004 Traning Loss: tensor(2.7709)\n",
      "13005 Traning Loss: tensor(2.7515)\n",
      "13006 Traning Loss: tensor(2.7626)\n",
      "13007 Traning Loss: tensor(2.7902)\n",
      "13008 Traning Loss: tensor(2.7570)\n",
      "13009 Traning Loss: tensor(2.7759)\n",
      "13010 Traning Loss: tensor(2.7510)\n",
      "13011 Traning Loss: tensor(2.7440)\n",
      "13012 Traning Loss: tensor(2.7597)\n",
      "13013 Traning Loss: tensor(2.7622)\n",
      "13014 Traning Loss: tensor(2.7462)\n",
      "13015 Traning Loss: tensor(2.7879)\n",
      "13016 Traning Loss: tensor(2.7714)\n",
      "13017 Traning Loss: tensor(2.7483)\n",
      "13018 Traning Loss: tensor(2.7645)\n",
      "13019 Traning Loss: tensor(2.7824)\n",
      "13020 Traning Loss: tensor(2.7459)\n",
      "13021 Traning Loss: tensor(2.7455)\n",
      "13022 Traning Loss: tensor(2.7352)\n",
      "13023 Traning Loss: tensor(2.7663)\n",
      "13024 Traning Loss: tensor(2.7641)\n",
      "13025 Traning Loss: tensor(2.7449)\n",
      "13026 Traning Loss: tensor(2.7646)\n",
      "13027 Traning Loss: tensor(2.7543)\n",
      "13028 Traning Loss: tensor(2.7620)\n",
      "13029 Traning Loss: tensor(2.7279)\n",
      "13030 Traning Loss: tensor(2.7996)\n",
      "13031 Traning Loss: tensor(2.7586)\n",
      "13032 Traning Loss: tensor(2.7513)\n",
      "13033 Traning Loss: tensor(2.7531)\n",
      "13034 Traning Loss: tensor(2.7301)\n",
      "13035 Traning Loss: tensor(2.7294)\n",
      "13036 Traning Loss: tensor(2.7801)\n",
      "13037 Traning Loss: tensor(2.7606)\n",
      "13038 Traning Loss: tensor(2.7646)\n",
      "13039 Traning Loss: tensor(2.7621)\n",
      "13040 Traning Loss: tensor(2.7604)\n",
      "13041 Traning Loss: tensor(2.7659)\n",
      "13042 Traning Loss: tensor(2.7746)\n",
      "13043 Traning Loss: tensor(2.7337)\n",
      "13044 Traning Loss: tensor(2.7476)\n",
      "13045 Traning Loss: tensor(2.7454)\n",
      "13046 Traning Loss: tensor(2.7949)\n",
      "13047 Traning Loss: tensor(2.7711)\n",
      "13048 Traning Loss: tensor(2.7331)\n",
      "13049 Traning Loss: tensor(2.7716)\n",
      "13050 Traning Loss: tensor(2.7545)\n",
      "13051 Traning Loss: tensor(2.7463)\n",
      "13052 Traning Loss: tensor(2.7357)\n",
      "13053 Traning Loss: tensor(2.7699)\n",
      "13054 Traning Loss: tensor(2.7427)\n",
      "13055 Traning Loss: tensor(2.7456)\n",
      "13056 Traning Loss: tensor(2.7497)\n",
      "13057 Traning Loss: tensor(2.7375)\n",
      "13058 Traning Loss: tensor(2.7411)\n",
      "13059 Traning Loss: tensor(2.7293)\n",
      "13060 Traning Loss: tensor(2.7277)\n",
      "13061 Traning Loss: tensor(2.7434)\n",
      "13062 Traning Loss: tensor(2.7542)\n",
      "13063 Traning Loss: tensor(2.7460)\n",
      "13064 Traning Loss: tensor(2.7457)\n",
      "13065 Traning Loss: tensor(2.7214)\n",
      "13066 Traning Loss: tensor(2.7136)\n",
      "13067 Traning Loss: tensor(2.7505)\n",
      "13068 Traning Loss: tensor(2.7183)\n",
      "13069 Traning Loss: tensor(2.7359)\n",
      "13070 Traning Loss: tensor(2.7167)\n",
      "13071 Traning Loss: tensor(2.7295)\n",
      "13072 Traning Loss: tensor(2.7157)\n",
      "13073 Traning Loss: tensor(2.7223)\n",
      "13074 Traning Loss: tensor(2.7341)\n",
      "13075 Traning Loss: tensor(2.7355)\n",
      "13076 Traning Loss: tensor(2.7360)\n",
      "13077 Traning Loss: tensor(2.7102)\n",
      "13078 Traning Loss: tensor(2.7332)\n",
      "13079 Traning Loss: tensor(2.7141)\n",
      "13080 Traning Loss: tensor(2.7303)\n",
      "13081 Traning Loss: tensor(2.7189)\n",
      "13082 Traning Loss: tensor(2.7236)\n",
      "13083 Traning Loss: tensor(2.7236)\n",
      "13084 Traning Loss: tensor(2.7499)\n",
      "13085 Traning Loss: tensor(2.7194)\n",
      "13086 Traning Loss: tensor(2.7202)\n",
      "13087 Traning Loss: tensor(2.7597)\n",
      "13088 Traning Loss: tensor(2.7183)\n",
      "13089 Traning Loss: tensor(2.7207)\n",
      "13090 Traning Loss: tensor(2.7478)\n",
      "13091 Traning Loss: tensor(2.7551)\n",
      "13092 Traning Loss: tensor(2.7137)\n",
      "13093 Traning Loss: tensor(2.7147)\n",
      "13094 Traning Loss: tensor(2.7220)\n",
      "13095 Traning Loss: tensor(2.7030)\n",
      "13096 Traning Loss: tensor(2.7169)\n",
      "13097 Traning Loss: tensor(2.7106)\n",
      "13098 Traning Loss: tensor(2.7269)\n",
      "13099 Traning Loss: tensor(2.7221)\n",
      "13100 Traning Loss: tensor(2.7343)\n",
      "13101 Traning Loss: tensor(2.7237)\n",
      "13102 Traning Loss: tensor(2.7099)\n",
      "13103 Traning Loss: tensor(2.7395)\n",
      "13104 Traning Loss: tensor(2.7193)\n",
      "13105 Traning Loss: tensor(2.6866)\n",
      "13106 Traning Loss: tensor(2.7016)\n",
      "13107 Traning Loss: tensor(2.7136)\n",
      "13108 Traning Loss: tensor(2.7324)\n",
      "13109 Traning Loss: tensor(2.6931)\n",
      "13110 Traning Loss: tensor(2.7155)\n",
      "13111 Traning Loss: tensor(2.7290)\n",
      "13112 Traning Loss: tensor(2.7082)\n",
      "13113 Traning Loss: tensor(2.6987)\n",
      "13114 Traning Loss: tensor(2.6848)\n",
      "13115 Traning Loss: tensor(2.6967)\n",
      "13116 Traning Loss: tensor(2.7213)\n",
      "13117 Traning Loss: tensor(2.6996)\n",
      "13118 Traning Loss: tensor(2.7251)\n",
      "13119 Traning Loss: tensor(2.7120)\n",
      "13120 Traning Loss: tensor(2.7276)\n",
      "13121 Traning Loss: tensor(2.6895)\n",
      "13122 Traning Loss: tensor(2.6799)\n",
      "13123 Traning Loss: tensor(2.7188)\n",
      "13124 Traning Loss: tensor(2.7110)\n",
      "13125 Traning Loss: tensor(2.7232)\n",
      "13126 Traning Loss: tensor(2.7013)\n",
      "13127 Traning Loss: tensor(2.6895)\n",
      "13128 Traning Loss: tensor(2.6965)\n",
      "13129 Traning Loss: tensor(2.7065)\n",
      "13130 Traning Loss: tensor(2.6732)\n",
      "13131 Traning Loss: tensor(2.7127)\n",
      "13132 Traning Loss: tensor(2.7069)\n",
      "13133 Traning Loss: tensor(2.7345)\n",
      "13134 Traning Loss: tensor(2.7060)\n",
      "13135 Traning Loss: tensor(2.6945)\n",
      "13136 Traning Loss: tensor(2.7045)\n",
      "13137 Traning Loss: tensor(2.7348)\n",
      "13138 Traning Loss: tensor(2.7131)\n",
      "13139 Traning Loss: tensor(2.6967)\n",
      "13140 Traning Loss: tensor(2.7012)\n",
      "13141 Traning Loss: tensor(2.6871)\n",
      "13142 Traning Loss: tensor(2.6849)\n",
      "13143 Traning Loss: tensor(2.6922)\n",
      "13144 Traning Loss: tensor(2.6986)\n",
      "13145 Traning Loss: tensor(2.6926)\n",
      "13146 Traning Loss: tensor(2.6718)\n",
      "13147 Traning Loss: tensor(2.6951)\n",
      "13148 Traning Loss: tensor(2.6780)\n",
      "13149 Traning Loss: tensor(2.6918)\n",
      "13150 Traning Loss: tensor(2.7029)\n",
      "13151 Traning Loss: tensor(2.6968)\n",
      "13152 Traning Loss: tensor(2.6790)\n",
      "13153 Traning Loss: tensor(2.6998)\n",
      "13154 Traning Loss: tensor(2.6744)\n",
      "13155 Traning Loss: tensor(2.6784)\n",
      "13156 Traning Loss: tensor(2.6780)\n",
      "13157 Traning Loss: tensor(2.6862)\n",
      "13158 Traning Loss: tensor(2.6622)\n",
      "13159 Traning Loss: tensor(2.7069)\n",
      "13160 Traning Loss: tensor(2.6852)\n",
      "13161 Traning Loss: tensor(2.6729)\n",
      "13162 Traning Loss: tensor(2.6773)\n",
      "13163 Traning Loss: tensor(2.7007)\n",
      "13164 Traning Loss: tensor(2.6972)\n",
      "13165 Traning Loss: tensor(2.6885)\n",
      "13166 Traning Loss: tensor(2.6557)\n",
      "13167 Traning Loss: tensor(2.7006)\n",
      "13168 Traning Loss: tensor(2.6965)\n",
      "13169 Traning Loss: tensor(2.6946)\n",
      "13170 Traning Loss: tensor(2.6708)\n",
      "13171 Traning Loss: tensor(2.6708)\n",
      "13172 Traning Loss: tensor(2.6465)\n",
      "13173 Traning Loss: tensor(2.6670)\n",
      "13174 Traning Loss: tensor(2.6536)\n",
      "13175 Traning Loss: tensor(2.6470)\n",
      "13176 Traning Loss: tensor(2.6812)\n",
      "13177 Traning Loss: tensor(2.6405)\n",
      "13178 Traning Loss: tensor(2.6642)\n",
      "13179 Traning Loss: tensor(2.6726)\n",
      "13180 Traning Loss: tensor(2.6624)\n",
      "13181 Traning Loss: tensor(2.6555)\n",
      "13182 Traning Loss: tensor(2.6727)\n",
      "13183 Traning Loss: tensor(2.6774)\n",
      "13184 Traning Loss: tensor(2.6459)\n",
      "13185 Traning Loss: tensor(2.6551)\n",
      "13186 Traning Loss: tensor(2.6599)\n",
      "13187 Traning Loss: tensor(2.6304)\n",
      "13188 Traning Loss: tensor(2.6506)\n",
      "13189 Traning Loss: tensor(2.6599)\n",
      "13190 Traning Loss: tensor(2.6426)\n",
      "13191 Traning Loss: tensor(2.6817)\n",
      "13192 Traning Loss: tensor(2.6201)\n",
      "13193 Traning Loss: tensor(2.6356)\n",
      "13194 Traning Loss: tensor(2.6619)\n",
      "13195 Traning Loss: tensor(2.6631)\n",
      "13196 Traning Loss: tensor(2.6426)\n",
      "13197 Traning Loss: tensor(2.6352)\n",
      "13198 Traning Loss: tensor(2.6473)\n",
      "13199 Traning Loss: tensor(2.6296)\n",
      "13200 Traning Loss: tensor(2.6312)\n",
      "13201 Traning Loss: tensor(2.6386)\n",
      "13202 Traning Loss: tensor(2.6475)\n",
      "13203 Traning Loss: tensor(2.6392)\n",
      "13204 Traning Loss: tensor(2.6425)\n",
      "13205 Traning Loss: tensor(2.6509)\n",
      "13206 Traning Loss: tensor(2.6263)\n",
      "13207 Traning Loss: tensor(2.6685)\n",
      "13208 Traning Loss: tensor(2.6242)\n",
      "13209 Traning Loss: tensor(2.6329)\n",
      "13210 Traning Loss: tensor(2.6357)\n",
      "13211 Traning Loss: tensor(2.6234)\n",
      "13212 Traning Loss: tensor(2.6278)\n",
      "13213 Traning Loss: tensor(2.6227)\n",
      "13214 Traning Loss: tensor(2.6304)\n",
      "13215 Traning Loss: tensor(2.6200)\n",
      "13216 Traning Loss: tensor(2.6486)\n",
      "13217 Traning Loss: tensor(2.6461)\n",
      "13218 Traning Loss: tensor(2.6369)\n",
      "13219 Traning Loss: tensor(2.6308)\n",
      "13220 Traning Loss: tensor(2.6041)\n",
      "13221 Traning Loss: tensor(2.6206)\n",
      "13222 Traning Loss: tensor(2.6096)\n",
      "13223 Traning Loss: tensor(2.6260)\n",
      "13224 Traning Loss: tensor(2.5843)\n",
      "13225 Traning Loss: tensor(2.6179)\n",
      "13226 Traning Loss: tensor(2.6064)\n",
      "13227 Traning Loss: tensor(2.6105)\n",
      "13228 Traning Loss: tensor(2.6120)\n",
      "13229 Traning Loss: tensor(2.5804)\n",
      "13230 Traning Loss: tensor(2.6160)\n",
      "13231 Traning Loss: tensor(2.5752)\n",
      "13232 Traning Loss: tensor(2.6090)\n",
      "13233 Traning Loss: tensor(2.5857)\n",
      "13234 Traning Loss: tensor(2.5847)\n",
      "13235 Traning Loss: tensor(2.6158)\n",
      "13236 Traning Loss: tensor(2.6078)\n",
      "13237 Traning Loss: tensor(2.5864)\n",
      "13238 Traning Loss: tensor(2.6049)\n",
      "13239 Traning Loss: tensor(2.6087)\n",
      "13240 Traning Loss: tensor(2.5942)\n",
      "13241 Traning Loss: tensor(2.5940)\n",
      "13242 Traning Loss: tensor(2.5900)\n",
      "13243 Traning Loss: tensor(2.6095)\n",
      "13244 Traning Loss: tensor(2.5497)\n",
      "13245 Traning Loss: tensor(2.5856)\n",
      "13246 Traning Loss: tensor(2.5675)\n",
      "13247 Traning Loss: tensor(2.5819)\n",
      "13248 Traning Loss: tensor(2.5712)\n",
      "13249 Traning Loss: tensor(2.6005)\n",
      "13250 Traning Loss: tensor(2.6057)\n",
      "13251 Traning Loss: tensor(2.5865)\n",
      "13252 Traning Loss: tensor(2.5764)\n",
      "13253 Traning Loss: tensor(2.5710)\n",
      "13254 Traning Loss: tensor(2.5780)\n",
      "13255 Traning Loss: tensor(2.5742)\n",
      "13256 Traning Loss: tensor(2.5549)\n",
      "13257 Traning Loss: tensor(2.5579)\n",
      "13258 Traning Loss: tensor(2.5827)\n",
      "13259 Traning Loss: tensor(2.5348)\n",
      "13260 Traning Loss: tensor(2.5756)\n",
      "13261 Traning Loss: tensor(2.5954)\n",
      "13262 Traning Loss: tensor(2.5650)\n",
      "13263 Traning Loss: tensor(2.5415)\n",
      "13264 Traning Loss: tensor(2.5876)\n",
      "13265 Traning Loss: tensor(2.5621)\n",
      "13266 Traning Loss: tensor(2.5975)\n",
      "13267 Traning Loss: tensor(2.5344)\n",
      "13268 Traning Loss: tensor(2.5643)\n",
      "13269 Traning Loss: tensor(2.5950)\n",
      "13270 Traning Loss: tensor(2.5555)\n",
      "13271 Traning Loss: tensor(2.5512)\n",
      "13272 Traning Loss: tensor(2.5818)\n",
      "13273 Traning Loss: tensor(2.5397)\n",
      "13274 Traning Loss: tensor(2.5563)\n",
      "13275 Traning Loss: tensor(2.5460)\n",
      "13276 Traning Loss: tensor(2.5438)\n",
      "13277 Traning Loss: tensor(2.5578)\n",
      "13278 Traning Loss: tensor(2.5385)\n",
      "13279 Traning Loss: tensor(2.5460)\n",
      "13280 Traning Loss: tensor(2.5244)\n",
      "13281 Traning Loss: tensor(2.5523)\n",
      "13282 Traning Loss: tensor(2.5345)\n",
      "13283 Traning Loss: tensor(2.5469)\n",
      "13284 Traning Loss: tensor(2.5354)\n",
      "13285 Traning Loss: tensor(2.5418)\n",
      "13286 Traning Loss: tensor(2.5152)\n",
      "13287 Traning Loss: tensor(2.5326)\n",
      "13288 Traning Loss: tensor(2.5330)\n",
      "13289 Traning Loss: tensor(2.5264)\n",
      "13290 Traning Loss: tensor(2.5400)\n",
      "13291 Traning Loss: tensor(2.5365)\n",
      "13292 Traning Loss: tensor(2.5210)\n",
      "13293 Traning Loss: tensor(2.5435)\n",
      "13294 Traning Loss: tensor(2.5241)\n",
      "13295 Traning Loss: tensor(2.5089)\n",
      "13296 Traning Loss: tensor(2.4915)\n",
      "13297 Traning Loss: tensor(2.5297)\n",
      "13298 Traning Loss: tensor(2.4983)\n",
      "13299 Traning Loss: tensor(2.4925)\n",
      "13300 Traning Loss: tensor(2.5369)\n",
      "13301 Traning Loss: tensor(2.4942)\n",
      "13302 Traning Loss: tensor(2.4889)\n",
      "13303 Traning Loss: tensor(2.5233)\n",
      "13304 Traning Loss: tensor(2.5028)\n",
      "13305 Traning Loss: tensor(2.4861)\n",
      "13306 Traning Loss: tensor(2.4984)\n",
      "13307 Traning Loss: tensor(2.4934)\n",
      "13308 Traning Loss: tensor(2.4773)\n",
      "13309 Traning Loss: tensor(2.4794)\n",
      "13310 Traning Loss: tensor(2.4749)\n",
      "13311 Traning Loss: tensor(2.4816)\n",
      "13312 Traning Loss: tensor(2.4816)\n",
      "13313 Traning Loss: tensor(2.4627)\n",
      "13314 Traning Loss: tensor(2.4637)\n",
      "13315 Traning Loss: tensor(2.4647)\n",
      "13316 Traning Loss: tensor(2.4662)\n",
      "13317 Traning Loss: tensor(2.4388)\n",
      "13318 Traning Loss: tensor(2.4972)\n",
      "13319 Traning Loss: tensor(2.5014)\n",
      "13320 Traning Loss: tensor(2.4804)\n",
      "13321 Traning Loss: tensor(2.4849)\n",
      "13322 Traning Loss: tensor(2.5131)\n",
      "13323 Traning Loss: tensor(2.4586)\n",
      "13324 Traning Loss: tensor(2.4780)\n",
      "13325 Traning Loss: tensor(2.4539)\n",
      "13326 Traning Loss: tensor(2.4759)\n",
      "13327 Traning Loss: tensor(2.4581)\n",
      "13328 Traning Loss: tensor(2.4461)\n",
      "13329 Traning Loss: tensor(2.4689)\n",
      "13330 Traning Loss: tensor(2.4852)\n",
      "13331 Traning Loss: tensor(2.4581)\n",
      "13332 Traning Loss: tensor(2.4426)\n",
      "13333 Traning Loss: tensor(2.4288)\n",
      "13334 Traning Loss: tensor(2.4538)\n",
      "13335 Traning Loss: tensor(2.4479)\n",
      "13336 Traning Loss: tensor(2.4605)\n",
      "13337 Traning Loss: tensor(2.4532)\n",
      "13338 Traning Loss: tensor(2.4559)\n",
      "13339 Traning Loss: tensor(2.4444)\n",
      "13340 Traning Loss: tensor(2.4257)\n",
      "13341 Traning Loss: tensor(2.4661)\n",
      "13342 Traning Loss: tensor(2.4303)\n",
      "13343 Traning Loss: tensor(2.4419)\n",
      "13344 Traning Loss: tensor(2.4176)\n",
      "13345 Traning Loss: tensor(2.4217)\n",
      "13346 Traning Loss: tensor(2.4851)\n",
      "13347 Traning Loss: tensor(2.4154)\n",
      "13348 Traning Loss: tensor(2.3963)\n",
      "13349 Traning Loss: tensor(2.4236)\n",
      "13350 Traning Loss: tensor(2.4397)\n",
      "13351 Traning Loss: tensor(2.4473)\n",
      "13352 Traning Loss: tensor(2.4224)\n",
      "13353 Traning Loss: tensor(2.4395)\n",
      "13354 Traning Loss: tensor(2.4269)\n",
      "13355 Traning Loss: tensor(2.4150)\n",
      "13356 Traning Loss: tensor(2.4181)\n",
      "13357 Traning Loss: tensor(2.4293)\n",
      "13358 Traning Loss: tensor(2.4159)\n",
      "13359 Traning Loss: tensor(2.4118)\n",
      "13360 Traning Loss: tensor(2.3882)\n",
      "13361 Traning Loss: tensor(2.4090)\n",
      "13362 Traning Loss: tensor(2.3829)\n",
      "13363 Traning Loss: tensor(2.4134)\n",
      "13364 Traning Loss: tensor(2.3978)\n",
      "13365 Traning Loss: tensor(2.3891)\n",
      "13366 Traning Loss: tensor(2.3968)\n",
      "13367 Traning Loss: tensor(2.3978)\n",
      "13368 Traning Loss: tensor(2.4051)\n",
      "13369 Traning Loss: tensor(2.3842)\n",
      "13370 Traning Loss: tensor(2.3754)\n",
      "13371 Traning Loss: tensor(2.3694)\n",
      "13372 Traning Loss: tensor(2.3601)\n",
      "13373 Traning Loss: tensor(2.3748)\n",
      "13374 Traning Loss: tensor(2.3631)\n",
      "13375 Traning Loss: tensor(2.3541)\n",
      "13376 Traning Loss: tensor(2.3977)\n",
      "13377 Traning Loss: tensor(2.3304)\n",
      "13378 Traning Loss: tensor(2.3710)\n",
      "13379 Traning Loss: tensor(2.3501)\n",
      "13380 Traning Loss: tensor(2.3319)\n",
      "13381 Traning Loss: tensor(2.3426)\n",
      "13382 Traning Loss: tensor(2.3229)\n",
      "13383 Traning Loss: tensor(2.3409)\n",
      "13384 Traning Loss: tensor(2.3553)\n",
      "13385 Traning Loss: tensor(2.3604)\n",
      "13386 Traning Loss: tensor(2.3438)\n",
      "13387 Traning Loss: tensor(2.3728)\n",
      "13388 Traning Loss: tensor(2.3346)\n",
      "13389 Traning Loss: tensor(2.3179)\n",
      "13390 Traning Loss: tensor(2.3558)\n",
      "13391 Traning Loss: tensor(2.3306)\n",
      "13392 Traning Loss: tensor(2.3286)\n",
      "13393 Traning Loss: tensor(2.3579)\n",
      "13394 Traning Loss: tensor(2.3349)\n",
      "13395 Traning Loss: tensor(2.3117)\n",
      "13396 Traning Loss: tensor(2.3363)\n",
      "13397 Traning Loss: tensor(2.3310)\n",
      "13398 Traning Loss: tensor(2.3198)\n",
      "13399 Traning Loss: tensor(2.3089)\n",
      "13400 Traning Loss: tensor(2.3400)\n",
      "13401 Traning Loss: tensor(2.3071)\n",
      "13402 Traning Loss: tensor(2.3300)\n",
      "13403 Traning Loss: tensor(2.3272)\n",
      "13404 Traning Loss: tensor(2.3258)\n",
      "13405 Traning Loss: tensor(2.3268)\n",
      "13406 Traning Loss: tensor(2.3028)\n",
      "13407 Traning Loss: tensor(2.2981)\n",
      "13408 Traning Loss: tensor(2.3133)\n",
      "13409 Traning Loss: tensor(2.3226)\n",
      "13410 Traning Loss: tensor(2.3047)\n",
      "13411 Traning Loss: tensor(2.3084)\n",
      "13412 Traning Loss: tensor(2.3077)\n",
      "13413 Traning Loss: tensor(2.2860)\n",
      "13414 Traning Loss: tensor(2.2695)\n",
      "13415 Traning Loss: tensor(2.3369)\n",
      "13416 Traning Loss: tensor(2.2925)\n",
      "13417 Traning Loss: tensor(2.2583)\n",
      "13418 Traning Loss: tensor(2.2876)\n",
      "13419 Traning Loss: tensor(2.3336)\n",
      "13420 Traning Loss: tensor(2.2934)\n",
      "13421 Traning Loss: tensor(2.2588)\n",
      "13422 Traning Loss: tensor(2.2836)\n",
      "13423 Traning Loss: tensor(2.2802)\n",
      "13424 Traning Loss: tensor(2.2854)\n",
      "13425 Traning Loss: tensor(2.2461)\n",
      "13426 Traning Loss: tensor(2.2569)\n",
      "13427 Traning Loss: tensor(2.2787)\n",
      "13428 Traning Loss: tensor(2.2470)\n",
      "13429 Traning Loss: tensor(2.2597)\n",
      "13430 Traning Loss: tensor(2.2596)\n",
      "13431 Traning Loss: tensor(2.2487)\n",
      "13432 Traning Loss: tensor(2.2869)\n",
      "13433 Traning Loss: tensor(2.2325)\n",
      "13434 Traning Loss: tensor(2.2533)\n",
      "13435 Traning Loss: tensor(2.2483)\n",
      "13436 Traning Loss: tensor(2.2559)\n",
      "13437 Traning Loss: tensor(2.2070)\n",
      "13438 Traning Loss: tensor(2.2441)\n",
      "13439 Traning Loss: tensor(2.2375)\n",
      "13440 Traning Loss: tensor(2.2168)\n",
      "13441 Traning Loss: tensor(2.2306)\n",
      "13442 Traning Loss: tensor(2.2689)\n",
      "13443 Traning Loss: tensor(2.2297)\n",
      "13444 Traning Loss: tensor(2.2454)\n",
      "13445 Traning Loss: tensor(2.2035)\n",
      "13446 Traning Loss: tensor(2.2265)\n",
      "13447 Traning Loss: tensor(2.2172)\n",
      "13448 Traning Loss: tensor(2.1789)\n",
      "13449 Traning Loss: tensor(2.1885)\n",
      "13450 Traning Loss: tensor(2.1737)\n",
      "13451 Traning Loss: tensor(2.1964)\n",
      "13452 Traning Loss: tensor(2.2205)\n",
      "13453 Traning Loss: tensor(2.1895)\n",
      "13454 Traning Loss: tensor(2.1692)\n",
      "13455 Traning Loss: tensor(2.1777)\n",
      "13456 Traning Loss: tensor(2.1854)\n",
      "13457 Traning Loss: tensor(2.1945)\n",
      "13458 Traning Loss: tensor(2.1641)\n",
      "13459 Traning Loss: tensor(2.2206)\n",
      "13460 Traning Loss: tensor(2.1814)\n",
      "13461 Traning Loss: tensor(2.1720)\n",
      "13462 Traning Loss: tensor(2.1492)\n",
      "13463 Traning Loss: tensor(2.2018)\n",
      "13464 Traning Loss: tensor(2.1467)\n",
      "13465 Traning Loss: tensor(2.1996)\n",
      "13466 Traning Loss: tensor(2.1833)\n",
      "13467 Traning Loss: tensor(2.1794)\n",
      "13468 Traning Loss: tensor(2.2328)\n",
      "13469 Traning Loss: tensor(2.1492)\n",
      "13470 Traning Loss: tensor(2.1475)\n",
      "13471 Traning Loss: tensor(2.1157)\n",
      "13472 Traning Loss: tensor(2.1828)\n",
      "13473 Traning Loss: tensor(2.1826)\n",
      "13474 Traning Loss: tensor(2.1602)\n",
      "13475 Traning Loss: tensor(2.1354)\n",
      "13476 Traning Loss: tensor(2.1211)\n",
      "13477 Traning Loss: tensor(2.1667)\n",
      "13478 Traning Loss: tensor(2.1645)\n",
      "13479 Traning Loss: tensor(2.1543)\n",
      "13480 Traning Loss: tensor(2.1265)\n",
      "13481 Traning Loss: tensor(2.1174)\n",
      "13482 Traning Loss: tensor(2.1424)\n",
      "13483 Traning Loss: tensor(2.1471)\n",
      "13484 Traning Loss: tensor(2.1663)\n",
      "13485 Traning Loss: tensor(2.1348)\n",
      "13486 Traning Loss: tensor(2.0948)\n",
      "13487 Traning Loss: tensor(2.1030)\n",
      "13488 Traning Loss: tensor(2.1706)\n",
      "13489 Traning Loss: tensor(2.0895)\n",
      "13490 Traning Loss: tensor(2.1073)\n",
      "13491 Traning Loss: tensor(2.1491)\n",
      "13492 Traning Loss: tensor(2.1114)\n",
      "13493 Traning Loss: tensor(2.0973)\n",
      "13494 Traning Loss: tensor(2.0676)\n",
      "13495 Traning Loss: tensor(2.0996)\n",
      "13496 Traning Loss: tensor(2.0944)\n",
      "13497 Traning Loss: tensor(2.0721)\n",
      "13498 Traning Loss: tensor(2.1062)\n",
      "13499 Traning Loss: tensor(2.1046)\n",
      "13500 Traning Loss: tensor(2.0642)\n",
      "13501 Traning Loss: tensor(2.1450)\n",
      "13502 Traning Loss: tensor(2.1181)\n",
      "13503 Traning Loss: tensor(2.1245)\n",
      "13504 Traning Loss: tensor(2.1130)\n",
      "13505 Traning Loss: tensor(2.0958)\n",
      "13506 Traning Loss: tensor(2.0672)\n",
      "13507 Traning Loss: tensor(2.0998)\n",
      "13508 Traning Loss: tensor(2.0999)\n",
      "13509 Traning Loss: tensor(2.0912)\n",
      "13510 Traning Loss: tensor(2.0903)\n",
      "13511 Traning Loss: tensor(2.0596)\n",
      "13512 Traning Loss: tensor(2.0329)\n",
      "13513 Traning Loss: tensor(2.0583)\n",
      "13514 Traning Loss: tensor(2.0742)\n",
      "13515 Traning Loss: tensor(2.0313)\n",
      "13516 Traning Loss: tensor(2.0576)\n",
      "13517 Traning Loss: tensor(2.0426)\n",
      "13518 Traning Loss: tensor(2.0563)\n",
      "13519 Traning Loss: tensor(2.0382)\n",
      "13520 Traning Loss: tensor(2.0663)\n",
      "13521 Traning Loss: tensor(2.0747)\n",
      "13522 Traning Loss: tensor(2.0190)\n",
      "13523 Traning Loss: tensor(2.0649)\n",
      "13524 Traning Loss: tensor(2.0347)\n",
      "13525 Traning Loss: tensor(2.0462)\n",
      "13526 Traning Loss: tensor(2.0226)\n",
      "13527 Traning Loss: tensor(2.0361)\n",
      "13528 Traning Loss: tensor(2.0204)\n",
      "13529 Traning Loss: tensor(2.0490)\n",
      "13530 Traning Loss: tensor(2.0105)\n",
      "13531 Traning Loss: tensor(2.0193)\n",
      "13532 Traning Loss: tensor(2.0544)\n",
      "13533 Traning Loss: tensor(2.0185)\n",
      "13534 Traning Loss: tensor(2.0232)\n",
      "13535 Traning Loss: tensor(2.0058)\n",
      "13536 Traning Loss: tensor(1.9874)\n",
      "13537 Traning Loss: tensor(2.0137)\n",
      "13538 Traning Loss: tensor(1.9899)\n",
      "13539 Traning Loss: tensor(2.0215)\n",
      "13540 Traning Loss: tensor(2.0487)\n",
      "13541 Traning Loss: tensor(2.0376)\n",
      "13542 Traning Loss: tensor(1.9834)\n",
      "13543 Traning Loss: tensor(1.9866)\n",
      "13544 Traning Loss: tensor(1.9912)\n",
      "13545 Traning Loss: tensor(1.9811)\n",
      "13546 Traning Loss: tensor(2.0228)\n",
      "13547 Traning Loss: tensor(2.0237)\n",
      "13548 Traning Loss: tensor(2.0268)\n",
      "13549 Traning Loss: tensor(1.9841)\n",
      "13550 Traning Loss: tensor(1.9695)\n",
      "13551 Traning Loss: tensor(1.9779)\n",
      "13552 Traning Loss: tensor(1.9992)\n",
      "13553 Traning Loss: tensor(2.0056)\n",
      "13554 Traning Loss: tensor(1.9934)\n",
      "13555 Traning Loss: tensor(2.0061)\n",
      "13556 Traning Loss: tensor(1.9599)\n",
      "13557 Traning Loss: tensor(1.9494)\n",
      "13558 Traning Loss: tensor(1.9610)\n",
      "13559 Traning Loss: tensor(1.9796)\n",
      "13560 Traning Loss: tensor(1.9580)\n",
      "13561 Traning Loss: tensor(1.9720)\n",
      "13562 Traning Loss: tensor(2.0084)\n",
      "13563 Traning Loss: tensor(1.9548)\n",
      "13564 Traning Loss: tensor(1.9517)\n",
      "13565 Traning Loss: tensor(1.9629)\n",
      "13566 Traning Loss: tensor(1.9556)\n",
      "13567 Traning Loss: tensor(1.9385)\n",
      "13568 Traning Loss: tensor(1.9734)\n",
      "13569 Traning Loss: tensor(1.9542)\n",
      "13570 Traning Loss: tensor(1.9508)\n",
      "13571 Traning Loss: tensor(1.9552)\n",
      "13572 Traning Loss: tensor(1.9227)\n",
      "13573 Traning Loss: tensor(1.9128)\n",
      "13574 Traning Loss: tensor(1.9187)\n",
      "13575 Traning Loss: tensor(1.9071)\n",
      "13576 Traning Loss: tensor(1.9025)\n",
      "13577 Traning Loss: tensor(1.9006)\n",
      "13578 Traning Loss: tensor(1.8960)\n",
      "13579 Traning Loss: tensor(1.9801)\n",
      "13580 Traning Loss: tensor(1.8733)\n",
      "13581 Traning Loss: tensor(1.9775)\n",
      "13582 Traning Loss: tensor(1.8896)\n",
      "13583 Traning Loss: tensor(1.9248)\n",
      "13584 Traning Loss: tensor(1.8932)\n",
      "13585 Traning Loss: tensor(1.9111)\n",
      "13586 Traning Loss: tensor(1.8683)\n",
      "13587 Traning Loss: tensor(1.8787)\n",
      "13588 Traning Loss: tensor(1.9202)\n",
      "13589 Traning Loss: tensor(1.8993)\n",
      "13590 Traning Loss: tensor(1.9131)\n",
      "13591 Traning Loss: tensor(1.8935)\n",
      "13592 Traning Loss: tensor(1.9368)\n",
      "13593 Traning Loss: tensor(1.8747)\n",
      "13594 Traning Loss: tensor(1.9186)\n",
      "13595 Traning Loss: tensor(1.9085)\n",
      "13596 Traning Loss: tensor(1.8749)\n",
      "13597 Traning Loss: tensor(1.8943)\n",
      "13598 Traning Loss: tensor(1.8805)\n",
      "13599 Traning Loss: tensor(1.8458)\n",
      "13600 Traning Loss: tensor(1.8457)\n",
      "13601 Traning Loss: tensor(1.8981)\n",
      "13602 Traning Loss: tensor(1.8903)\n",
      "13603 Traning Loss: tensor(1.8870)\n",
      "13604 Traning Loss: tensor(1.9240)\n",
      "13605 Traning Loss: tensor(1.9016)\n",
      "13606 Traning Loss: tensor(1.8562)\n",
      "13607 Traning Loss: tensor(1.8426)\n",
      "13608 Traning Loss: tensor(1.8531)\n",
      "13609 Traning Loss: tensor(1.8532)\n",
      "13610 Traning Loss: tensor(1.8360)\n",
      "13611 Traning Loss: tensor(1.8200)\n",
      "13612 Traning Loss: tensor(1.8210)\n",
      "13613 Traning Loss: tensor(1.8702)\n",
      "13614 Traning Loss: tensor(1.8220)\n",
      "13615 Traning Loss: tensor(1.8225)\n",
      "13616 Traning Loss: tensor(1.8887)\n",
      "13617 Traning Loss: tensor(1.7962)\n",
      "13618 Traning Loss: tensor(1.8136)\n",
      "13619 Traning Loss: tensor(1.8018)\n",
      "13620 Traning Loss: tensor(1.8171)\n",
      "13621 Traning Loss: tensor(1.8215)\n",
      "13622 Traning Loss: tensor(1.8146)\n",
      "13623 Traning Loss: tensor(1.8048)\n",
      "13624 Traning Loss: tensor(1.8378)\n",
      "13625 Traning Loss: tensor(1.8328)\n",
      "13626 Traning Loss: tensor(1.8550)\n",
      "13627 Traning Loss: tensor(1.7741)\n",
      "13628 Traning Loss: tensor(1.8315)\n",
      "13629 Traning Loss: tensor(1.8035)\n",
      "13630 Traning Loss: tensor(1.8445)\n",
      "13631 Traning Loss: tensor(1.8010)\n",
      "13632 Traning Loss: tensor(1.8078)\n",
      "13633 Traning Loss: tensor(1.7596)\n",
      "13634 Traning Loss: tensor(1.7913)\n",
      "13635 Traning Loss: tensor(1.8684)\n",
      "13636 Traning Loss: tensor(1.8063)\n",
      "13637 Traning Loss: tensor(1.7806)\n",
      "13638 Traning Loss: tensor(1.8348)\n",
      "13639 Traning Loss: tensor(1.7755)\n",
      "13640 Traning Loss: tensor(1.7631)\n",
      "13641 Traning Loss: tensor(1.8308)\n",
      "13642 Traning Loss: tensor(1.7648)\n",
      "13643 Traning Loss: tensor(1.7585)\n",
      "13644 Traning Loss: tensor(1.8055)\n",
      "13645 Traning Loss: tensor(1.8425)\n",
      "13646 Traning Loss: tensor(1.8332)\n",
      "13647 Traning Loss: tensor(1.8867)\n",
      "13648 Traning Loss: tensor(1.7745)\n",
      "13649 Traning Loss: tensor(1.7653)\n",
      "13650 Traning Loss: tensor(1.7921)\n",
      "13651 Traning Loss: tensor(1.7467)\n",
      "13652 Traning Loss: tensor(1.7647)\n",
      "13653 Traning Loss: tensor(1.7806)\n",
      "13654 Traning Loss: tensor(1.7284)\n",
      "13655 Traning Loss: tensor(1.7423)\n",
      "13656 Traning Loss: tensor(1.8469)\n",
      "13657 Traning Loss: tensor(1.8120)\n",
      "13658 Traning Loss: tensor(1.7681)\n",
      "13659 Traning Loss: tensor(1.7374)\n",
      "13660 Traning Loss: tensor(1.7515)\n",
      "13661 Traning Loss: tensor(1.7471)\n",
      "13662 Traning Loss: tensor(1.7532)\n",
      "13663 Traning Loss: tensor(1.8010)\n",
      "13664 Traning Loss: tensor(1.7477)\n",
      "13665 Traning Loss: tensor(1.7396)\n",
      "13666 Traning Loss: tensor(1.7316)\n",
      "13667 Traning Loss: tensor(1.7449)\n",
      "13668 Traning Loss: tensor(1.7149)\n",
      "13669 Traning Loss: tensor(1.7617)\n",
      "13670 Traning Loss: tensor(1.7576)\n",
      "13671 Traning Loss: tensor(1.7847)\n",
      "13672 Traning Loss: tensor(1.7349)\n",
      "13673 Traning Loss: tensor(1.7090)\n",
      "13674 Traning Loss: tensor(1.7382)\n",
      "13675 Traning Loss: tensor(1.7386)\n",
      "13676 Traning Loss: tensor(1.7305)\n",
      "13677 Traning Loss: tensor(1.7324)\n",
      "13678 Traning Loss: tensor(1.7102)\n",
      "13679 Traning Loss: tensor(1.7089)\n",
      "13680 Traning Loss: tensor(1.7078)\n",
      "13681 Traning Loss: tensor(1.7188)\n",
      "13682 Traning Loss: tensor(1.7271)\n",
      "13683 Traning Loss: tensor(1.7538)\n",
      "13684 Traning Loss: tensor(1.7338)\n",
      "13685 Traning Loss: tensor(1.6985)\n",
      "13686 Traning Loss: tensor(1.7193)\n",
      "13687 Traning Loss: tensor(1.7363)\n",
      "13688 Traning Loss: tensor(1.7398)\n",
      "13689 Traning Loss: tensor(1.7116)\n",
      "13690 Traning Loss: tensor(1.6941)\n",
      "13691 Traning Loss: tensor(1.7104)\n",
      "13692 Traning Loss: tensor(1.7175)\n",
      "13693 Traning Loss: tensor(1.6868)\n",
      "13694 Traning Loss: tensor(1.7091)\n",
      "13695 Traning Loss: tensor(1.7129)\n",
      "13696 Traning Loss: tensor(1.6640)\n",
      "13697 Traning Loss: tensor(1.6687)\n",
      "13698 Traning Loss: tensor(1.7118)\n",
      "13699 Traning Loss: tensor(1.6797)\n",
      "13700 Traning Loss: tensor(1.6938)\n",
      "13701 Traning Loss: tensor(1.6621)\n",
      "13702 Traning Loss: tensor(1.6909)\n",
      "13703 Traning Loss: tensor(1.6681)\n",
      "13704 Traning Loss: tensor(1.6491)\n",
      "13705 Traning Loss: tensor(1.6895)\n",
      "13706 Traning Loss: tensor(1.6797)\n",
      "13707 Traning Loss: tensor(1.6521)\n",
      "13708 Traning Loss: tensor(1.6490)\n",
      "13709 Traning Loss: tensor(1.6380)\n",
      "13710 Traning Loss: tensor(1.6746)\n",
      "13711 Traning Loss: tensor(1.6450)\n",
      "13712 Traning Loss: tensor(1.7032)\n",
      "13713 Traning Loss: tensor(1.6786)\n",
      "13714 Traning Loss: tensor(1.6951)\n",
      "13715 Traning Loss: tensor(1.6562)\n",
      "13716 Traning Loss: tensor(1.6359)\n",
      "13717 Traning Loss: tensor(1.6663)\n",
      "13718 Traning Loss: tensor(1.6480)\n",
      "13719 Traning Loss: tensor(1.6574)\n",
      "13720 Traning Loss: tensor(1.6209)\n",
      "13721 Traning Loss: tensor(1.6794)\n",
      "13722 Traning Loss: tensor(1.6180)\n",
      "13723 Traning Loss: tensor(1.6453)\n",
      "13724 Traning Loss: tensor(1.6254)\n",
      "13725 Traning Loss: tensor(1.6661)\n",
      "13726 Traning Loss: tensor(1.6366)\n",
      "13727 Traning Loss: tensor(1.6294)\n",
      "13728 Traning Loss: tensor(1.6371)\n",
      "13729 Traning Loss: tensor(1.6300)\n",
      "13730 Traning Loss: tensor(1.6403)\n",
      "13731 Traning Loss: tensor(1.7023)\n",
      "13732 Traning Loss: tensor(1.6408)\n",
      "13733 Traning Loss: tensor(1.6420)\n",
      "13734 Traning Loss: tensor(1.6482)\n",
      "13735 Traning Loss: tensor(1.6285)\n",
      "13736 Traning Loss: tensor(1.5940)\n",
      "13737 Traning Loss: tensor(1.6596)\n",
      "13738 Traning Loss: tensor(1.6651)\n",
      "13739 Traning Loss: tensor(1.5834)\n",
      "13740 Traning Loss: tensor(1.6069)\n",
      "13741 Traning Loss: tensor(1.6578)\n",
      "13742 Traning Loss: tensor(1.6573)\n",
      "13743 Traning Loss: tensor(1.5993)\n",
      "13744 Traning Loss: tensor(1.5951)\n",
      "13745 Traning Loss: tensor(1.5680)\n",
      "13746 Traning Loss: tensor(1.6555)\n",
      "13747 Traning Loss: tensor(1.5773)\n",
      "13748 Traning Loss: tensor(1.6421)\n",
      "13749 Traning Loss: tensor(1.6055)\n",
      "13750 Traning Loss: tensor(1.6465)\n",
      "13751 Traning Loss: tensor(1.5938)\n",
      "13752 Traning Loss: tensor(1.5550)\n",
      "13753 Traning Loss: tensor(1.5932)\n",
      "13754 Traning Loss: tensor(1.5838)\n",
      "13755 Traning Loss: tensor(1.5570)\n",
      "13756 Traning Loss: tensor(1.5747)\n",
      "13757 Traning Loss: tensor(1.6153)\n",
      "13758 Traning Loss: tensor(1.5646)\n",
      "13759 Traning Loss: tensor(1.6044)\n",
      "13760 Traning Loss: tensor(1.5486)\n",
      "13761 Traning Loss: tensor(1.6172)\n",
      "13762 Traning Loss: tensor(1.5852)\n",
      "13763 Traning Loss: tensor(1.5766)\n",
      "13764 Traning Loss: tensor(1.5734)\n",
      "13765 Traning Loss: tensor(1.5840)\n",
      "13766 Traning Loss: tensor(1.5875)\n",
      "13767 Traning Loss: tensor(1.5355)\n",
      "13768 Traning Loss: tensor(1.5725)\n",
      "13769 Traning Loss: tensor(1.5755)\n",
      "13770 Traning Loss: tensor(1.6167)\n",
      "13771 Traning Loss: tensor(1.5555)\n",
      "13772 Traning Loss: tensor(1.6218)\n",
      "13773 Traning Loss: tensor(1.5386)\n",
      "13774 Traning Loss: tensor(1.6089)\n",
      "13775 Traning Loss: tensor(1.5729)\n",
      "13776 Traning Loss: tensor(1.5281)\n",
      "13777 Traning Loss: tensor(1.5369)\n",
      "13778 Traning Loss: tensor(1.5470)\n",
      "13779 Traning Loss: tensor(1.6126)\n",
      "13780 Traning Loss: tensor(1.5402)\n",
      "13781 Traning Loss: tensor(1.4835)\n",
      "13782 Traning Loss: tensor(1.5585)\n",
      "13783 Traning Loss: tensor(1.5449)\n",
      "13784 Traning Loss: tensor(1.5663)\n",
      "13785 Traning Loss: tensor(1.5215)\n",
      "13786 Traning Loss: tensor(1.5888)\n",
      "13787 Traning Loss: tensor(1.5536)\n",
      "13788 Traning Loss: tensor(1.5328)\n",
      "13789 Traning Loss: tensor(1.5746)\n",
      "13790 Traning Loss: tensor(1.5576)\n",
      "13791 Traning Loss: tensor(1.5458)\n",
      "13792 Traning Loss: tensor(1.5785)\n",
      "13793 Traning Loss: tensor(1.5363)\n",
      "13794 Traning Loss: tensor(1.6129)\n",
      "13795 Traning Loss: tensor(1.5738)\n",
      "13796 Traning Loss: tensor(1.5399)\n",
      "13797 Traning Loss: tensor(1.5370)\n",
      "13798 Traning Loss: tensor(1.5362)\n",
      "13799 Traning Loss: tensor(1.5185)\n",
      "13800 Traning Loss: tensor(1.4958)\n",
      "13801 Traning Loss: tensor(1.5371)\n",
      "13802 Traning Loss: tensor(1.5354)\n",
      "13803 Traning Loss: tensor(1.5951)\n",
      "13804 Traning Loss: tensor(1.4348)\n",
      "13805 Traning Loss: tensor(1.6133)\n",
      "13806 Traning Loss: tensor(1.5198)\n",
      "13807 Traning Loss: tensor(1.5168)\n",
      "13808 Traning Loss: tensor(1.4916)\n",
      "13809 Traning Loss: tensor(1.4793)\n",
      "13810 Traning Loss: tensor(1.5319)\n",
      "13811 Traning Loss: tensor(1.4785)\n",
      "13812 Traning Loss: tensor(1.5424)\n",
      "13813 Traning Loss: tensor(1.5618)\n",
      "13814 Traning Loss: tensor(1.5443)\n",
      "13815 Traning Loss: tensor(1.4931)\n",
      "13816 Traning Loss: tensor(1.5049)\n",
      "13817 Traning Loss: tensor(1.5379)\n",
      "13818 Traning Loss: tensor(1.5399)\n",
      "13819 Traning Loss: tensor(1.4824)\n",
      "13820 Traning Loss: tensor(1.4944)\n",
      "13821 Traning Loss: tensor(1.5290)\n",
      "13822 Traning Loss: tensor(1.4922)\n",
      "13823 Traning Loss: tensor(1.4940)\n",
      "13824 Traning Loss: tensor(1.5039)\n",
      "13825 Traning Loss: tensor(1.4991)\n",
      "13826 Traning Loss: tensor(1.4676)\n",
      "13827 Traning Loss: tensor(1.4385)\n",
      "13828 Traning Loss: tensor(1.4753)\n",
      "13829 Traning Loss: tensor(1.4828)\n",
      "13830 Traning Loss: tensor(1.4959)\n",
      "13831 Traning Loss: tensor(1.5054)\n",
      "13832 Traning Loss: tensor(1.4972)\n",
      "13833 Traning Loss: tensor(1.5082)\n",
      "13834 Traning Loss: tensor(1.5226)\n",
      "13835 Traning Loss: tensor(1.4589)\n",
      "13836 Traning Loss: tensor(1.4899)\n",
      "13837 Traning Loss: tensor(1.4648)\n",
      "13838 Traning Loss: tensor(1.4948)\n",
      "13839 Traning Loss: tensor(1.4975)\n",
      "13840 Traning Loss: tensor(1.4611)\n",
      "13841 Traning Loss: tensor(1.4909)\n",
      "13842 Traning Loss: tensor(1.4556)\n",
      "13843 Traning Loss: tensor(1.4668)\n",
      "13844 Traning Loss: tensor(1.3851)\n",
      "13845 Traning Loss: tensor(1.4090)\n",
      "13846 Traning Loss: tensor(1.4857)\n",
      "13847 Traning Loss: tensor(1.4781)\n",
      "13848 Traning Loss: tensor(1.4981)\n",
      "13849 Traning Loss: tensor(1.5236)\n",
      "13850 Traning Loss: tensor(1.4482)\n",
      "13851 Traning Loss: tensor(1.4821)\n",
      "13852 Traning Loss: tensor(1.4188)\n",
      "13853 Traning Loss: tensor(1.4299)\n",
      "13854 Traning Loss: tensor(1.4168)\n",
      "13855 Traning Loss: tensor(1.4349)\n",
      "13856 Traning Loss: tensor(1.4250)\n",
      "13857 Traning Loss: tensor(1.4472)\n",
      "13858 Traning Loss: tensor(1.4937)\n",
      "13859 Traning Loss: tensor(1.4473)\n",
      "13860 Traning Loss: tensor(1.4898)\n",
      "13861 Traning Loss: tensor(1.4095)\n",
      "13862 Traning Loss: tensor(1.4351)\n",
      "13863 Traning Loss: tensor(1.4287)\n",
      "13864 Traning Loss: tensor(1.5315)\n",
      "13865 Traning Loss: tensor(1.4422)\n",
      "13866 Traning Loss: tensor(1.4097)\n",
      "13867 Traning Loss: tensor(1.3936)\n",
      "13868 Traning Loss: tensor(1.4995)\n",
      "13869 Traning Loss: tensor(1.4300)\n",
      "13870 Traning Loss: tensor(1.3574)\n",
      "13871 Traning Loss: tensor(1.4732)\n",
      "13872 Traning Loss: tensor(1.4209)\n",
      "13873 Traning Loss: tensor(1.4227)\n",
      "13874 Traning Loss: tensor(1.4288)\n",
      "13875 Traning Loss: tensor(1.4289)\n",
      "13876 Traning Loss: tensor(1.4628)\n",
      "13877 Traning Loss: tensor(1.4711)\n",
      "13878 Traning Loss: tensor(1.5011)\n",
      "13879 Traning Loss: tensor(1.3762)\n",
      "13880 Traning Loss: tensor(1.4022)\n",
      "13881 Traning Loss: tensor(1.3867)\n",
      "13882 Traning Loss: tensor(1.3717)\n",
      "13883 Traning Loss: tensor(1.4391)\n",
      "13884 Traning Loss: tensor(1.3919)\n",
      "13885 Traning Loss: tensor(1.4384)\n",
      "13886 Traning Loss: tensor(1.4811)\n",
      "13887 Traning Loss: tensor(1.3851)\n",
      "13888 Traning Loss: tensor(1.4053)\n",
      "13889 Traning Loss: tensor(1.4131)\n",
      "13890 Traning Loss: tensor(1.4024)\n",
      "13891 Traning Loss: tensor(1.3485)\n",
      "13892 Traning Loss: tensor(1.4327)\n",
      "13893 Traning Loss: tensor(1.3591)\n",
      "13894 Traning Loss: tensor(1.4398)\n",
      "13895 Traning Loss: tensor(1.3776)\n",
      "13896 Traning Loss: tensor(1.3629)\n",
      "13897 Traning Loss: tensor(1.4196)\n",
      "13898 Traning Loss: tensor(1.3859)\n",
      "13899 Traning Loss: tensor(1.3559)\n",
      "13900 Traning Loss: tensor(1.4020)\n",
      "13901 Traning Loss: tensor(1.3118)\n",
      "13902 Traning Loss: tensor(1.4156)\n",
      "13903 Traning Loss: tensor(1.3720)\n",
      "13904 Traning Loss: tensor(1.4049)\n",
      "13905 Traning Loss: tensor(1.3613)\n",
      "13906 Traning Loss: tensor(1.3441)\n",
      "13907 Traning Loss: tensor(1.3806)\n",
      "13908 Traning Loss: tensor(1.3719)\n",
      "13909 Traning Loss: tensor(1.3930)\n",
      "13910 Traning Loss: tensor(1.4156)\n",
      "13911 Traning Loss: tensor(1.3998)\n",
      "13912 Traning Loss: tensor(1.3229)\n",
      "13913 Traning Loss: tensor(1.3926)\n",
      "13914 Traning Loss: tensor(1.3632)\n",
      "13915 Traning Loss: tensor(1.3620)\n",
      "13916 Traning Loss: tensor(1.3722)\n",
      "13917 Traning Loss: tensor(1.3517)\n",
      "13918 Traning Loss: tensor(1.3496)\n",
      "13919 Traning Loss: tensor(1.3843)\n",
      "13920 Traning Loss: tensor(1.4478)\n",
      "13921 Traning Loss: tensor(1.4274)\n",
      "13922 Traning Loss: tensor(1.3919)\n",
      "13923 Traning Loss: tensor(1.3817)\n",
      "13924 Traning Loss: tensor(1.3295)\n",
      "13925 Traning Loss: tensor(1.3334)\n",
      "13926 Traning Loss: tensor(1.3339)\n",
      "13927 Traning Loss: tensor(1.3319)\n",
      "13928 Traning Loss: tensor(1.3438)\n",
      "13929 Traning Loss: tensor(1.3716)\n",
      "13930 Traning Loss: tensor(1.3142)\n",
      "13931 Traning Loss: tensor(1.2964)\n",
      "13932 Traning Loss: tensor(1.3127)\n",
      "13933 Traning Loss: tensor(1.3609)\n",
      "13934 Traning Loss: tensor(1.3157)\n",
      "13935 Traning Loss: tensor(1.3874)\n",
      "13936 Traning Loss: tensor(1.3672)\n",
      "13937 Traning Loss: tensor(1.3454)\n",
      "13938 Traning Loss: tensor(1.3441)\n",
      "13939 Traning Loss: tensor(1.3622)\n",
      "13940 Traning Loss: tensor(1.3354)\n",
      "13941 Traning Loss: tensor(1.3959)\n",
      "13942 Traning Loss: tensor(1.3857)\n",
      "13943 Traning Loss: tensor(1.4243)\n",
      "13944 Traning Loss: tensor(1.3673)\n",
      "13945 Traning Loss: tensor(1.3850)\n",
      "13946 Traning Loss: tensor(1.3449)\n",
      "13947 Traning Loss: tensor(1.3506)\n",
      "13948 Traning Loss: tensor(1.3060)\n",
      "13949 Traning Loss: tensor(1.3533)\n",
      "13950 Traning Loss: tensor(1.4313)\n",
      "13951 Traning Loss: tensor(1.3070)\n",
      "13952 Traning Loss: tensor(1.3091)\n",
      "13953 Traning Loss: tensor(1.3079)\n",
      "13954 Traning Loss: tensor(1.3464)\n",
      "13955 Traning Loss: tensor(1.3792)\n",
      "13956 Traning Loss: tensor(1.3302)\n",
      "13957 Traning Loss: tensor(1.3503)\n",
      "13958 Traning Loss: tensor(1.2684)\n",
      "13959 Traning Loss: tensor(1.3432)\n",
      "13960 Traning Loss: tensor(1.3280)\n",
      "13961 Traning Loss: tensor(1.3059)\n",
      "13962 Traning Loss: tensor(1.3477)\n",
      "13963 Traning Loss: tensor(1.3163)\n",
      "13964 Traning Loss: tensor(1.3475)\n",
      "13965 Traning Loss: tensor(1.2926)\n",
      "13966 Traning Loss: tensor(1.3122)\n",
      "13967 Traning Loss: tensor(1.3104)\n",
      "13968 Traning Loss: tensor(1.3277)\n",
      "13969 Traning Loss: tensor(1.3006)\n",
      "13970 Traning Loss: tensor(1.2835)\n",
      "13971 Traning Loss: tensor(1.3448)\n",
      "13972 Traning Loss: tensor(1.3414)\n",
      "13973 Traning Loss: tensor(1.2959)\n",
      "13974 Traning Loss: tensor(1.3459)\n",
      "13975 Traning Loss: tensor(1.3357)\n",
      "13976 Traning Loss: tensor(1.3464)\n",
      "13977 Traning Loss: tensor(1.3374)\n",
      "13978 Traning Loss: tensor(1.3147)\n",
      "13979 Traning Loss: tensor(1.2519)\n",
      "13980 Traning Loss: tensor(1.3007)\n",
      "13981 Traning Loss: tensor(1.2970)\n",
      "13982 Traning Loss: tensor(1.3302)\n",
      "13983 Traning Loss: tensor(1.2988)\n",
      "13984 Traning Loss: tensor(1.2707)\n",
      "13985 Traning Loss: tensor(1.2868)\n",
      "13986 Traning Loss: tensor(1.2719)\n",
      "13987 Traning Loss: tensor(1.2755)\n",
      "13988 Traning Loss: tensor(1.3119)\n",
      "13989 Traning Loss: tensor(1.2919)\n",
      "13990 Traning Loss: tensor(1.2193)\n",
      "13991 Traning Loss: tensor(1.3354)\n",
      "13992 Traning Loss: tensor(1.3561)\n",
      "13993 Traning Loss: tensor(1.2840)\n",
      "13994 Traning Loss: tensor(1.3538)\n",
      "13995 Traning Loss: tensor(1.3165)\n",
      "13996 Traning Loss: tensor(1.2683)\n",
      "13997 Traning Loss: tensor(1.2676)\n",
      "13998 Traning Loss: tensor(1.2552)\n",
      "13999 Traning Loss: tensor(1.3159)\n",
      "14000 Traning Loss: tensor(1.3028)\n",
      "14001 Traning Loss: tensor(1.2887)\n",
      "14002 Traning Loss: tensor(1.2796)\n",
      "14003 Traning Loss: tensor(1.2442)\n",
      "14004 Traning Loss: tensor(1.2837)\n",
      "14005 Traning Loss: tensor(1.2666)\n",
      "14006 Traning Loss: tensor(1.2671)\n",
      "14007 Traning Loss: tensor(1.3052)\n",
      "14008 Traning Loss: tensor(1.2897)\n",
      "14009 Traning Loss: tensor(1.2794)\n",
      "14010 Traning Loss: tensor(1.3270)\n",
      "14011 Traning Loss: tensor(1.3312)\n",
      "14012 Traning Loss: tensor(1.2919)\n",
      "14013 Traning Loss: tensor(1.3265)\n",
      "14014 Traning Loss: tensor(1.2993)\n",
      "14015 Traning Loss: tensor(1.3040)\n",
      "14016 Traning Loss: tensor(1.2067)\n",
      "14017 Traning Loss: tensor(1.2288)\n",
      "14018 Traning Loss: tensor(1.3357)\n",
      "14019 Traning Loss: tensor(1.3481)\n",
      "14020 Traning Loss: tensor(1.3654)\n",
      "14021 Traning Loss: tensor(1.2264)\n",
      "14022 Traning Loss: tensor(1.2491)\n",
      "14023 Traning Loss: tensor(1.2450)\n",
      "14024 Traning Loss: tensor(1.2281)\n",
      "14025 Traning Loss: tensor(1.2038)\n",
      "14026 Traning Loss: tensor(1.2636)\n",
      "14027 Traning Loss: tensor(1.2126)\n",
      "14028 Traning Loss: tensor(1.2758)\n",
      "14029 Traning Loss: tensor(1.2263)\n",
      "14030 Traning Loss: tensor(1.2889)\n",
      "14031 Traning Loss: tensor(1.2827)\n",
      "14032 Traning Loss: tensor(1.2470)\n",
      "14033 Traning Loss: tensor(1.2607)\n",
      "14034 Traning Loss: tensor(1.2811)\n",
      "14035 Traning Loss: tensor(1.2628)\n",
      "14036 Traning Loss: tensor(1.2376)\n",
      "14037 Traning Loss: tensor(1.2044)\n",
      "14038 Traning Loss: tensor(1.2643)\n",
      "14039 Traning Loss: tensor(1.2351)\n",
      "14040 Traning Loss: tensor(1.2213)\n",
      "14041 Traning Loss: tensor(1.2905)\n",
      "14042 Traning Loss: tensor(1.2832)\n",
      "14043 Traning Loss: tensor(1.2604)\n",
      "14044 Traning Loss: tensor(1.2853)\n",
      "14045 Traning Loss: tensor(1.2078)\n",
      "14046 Traning Loss: tensor(1.2030)\n",
      "14047 Traning Loss: tensor(1.2603)\n",
      "14048 Traning Loss: tensor(1.3188)\n",
      "14049 Traning Loss: tensor(1.2160)\n",
      "14050 Traning Loss: tensor(1.2474)\n",
      "14051 Traning Loss: tensor(1.2896)\n",
      "14052 Traning Loss: tensor(1.2135)\n",
      "14053 Traning Loss: tensor(1.3189)\n",
      "14054 Traning Loss: tensor(1.1883)\n",
      "14055 Traning Loss: tensor(1.2723)\n",
      "14056 Traning Loss: tensor(1.2523)\n",
      "14057 Traning Loss: tensor(1.2520)\n",
      "14058 Traning Loss: tensor(1.2276)\n",
      "14059 Traning Loss: tensor(1.1956)\n",
      "14060 Traning Loss: tensor(1.2461)\n",
      "14061 Traning Loss: tensor(1.2629)\n",
      "14062 Traning Loss: tensor(1.2419)\n",
      "14063 Traning Loss: tensor(1.1946)\n",
      "14064 Traning Loss: tensor(1.2669)\n",
      "14065 Traning Loss: tensor(1.2272)\n",
      "14066 Traning Loss: tensor(1.2441)\n",
      "14067 Traning Loss: tensor(1.1539)\n",
      "14068 Traning Loss: tensor(1.2757)\n",
      "14069 Traning Loss: tensor(1.1593)\n",
      "14070 Traning Loss: tensor(1.2246)\n",
      "14071 Traning Loss: tensor(1.1583)\n",
      "14072 Traning Loss: tensor(1.2614)\n",
      "14073 Traning Loss: tensor(1.2126)\n",
      "14074 Traning Loss: tensor(1.2339)\n",
      "14075 Traning Loss: tensor(1.1942)\n",
      "14076 Traning Loss: tensor(1.1783)\n",
      "14077 Traning Loss: tensor(1.1530)\n",
      "14078 Traning Loss: tensor(1.1732)\n",
      "14079 Traning Loss: tensor(1.2043)\n",
      "14080 Traning Loss: tensor(1.2234)\n",
      "14081 Traning Loss: tensor(1.2655)\n",
      "14082 Traning Loss: tensor(1.1599)\n",
      "14083 Traning Loss: tensor(1.2400)\n",
      "14084 Traning Loss: tensor(1.1842)\n",
      "14085 Traning Loss: tensor(1.1792)\n",
      "14086 Traning Loss: tensor(1.1255)\n",
      "14087 Traning Loss: tensor(1.1933)\n",
      "14088 Traning Loss: tensor(1.2011)\n",
      "14089 Traning Loss: tensor(1.1446)\n",
      "14090 Traning Loss: tensor(1.2194)\n",
      "14091 Traning Loss: tensor(1.2377)\n",
      "14092 Traning Loss: tensor(1.2363)\n",
      "14093 Traning Loss: tensor(1.1984)\n",
      "14094 Traning Loss: tensor(1.2823)\n",
      "14095 Traning Loss: tensor(1.2290)\n",
      "14096 Traning Loss: tensor(1.1533)\n",
      "14097 Traning Loss: tensor(1.2350)\n",
      "14098 Traning Loss: tensor(1.1932)\n",
      "14099 Traning Loss: tensor(1.2656)\n",
      "14100 Traning Loss: tensor(1.1886)\n",
      "14101 Traning Loss: tensor(1.2028)\n",
      "14102 Traning Loss: tensor(1.1600)\n",
      "14103 Traning Loss: tensor(1.2211)\n",
      "14104 Traning Loss: tensor(1.2350)\n",
      "14105 Traning Loss: tensor(1.2670)\n",
      "14106 Traning Loss: tensor(1.1794)\n",
      "14107 Traning Loss: tensor(1.2090)\n",
      "14108 Traning Loss: tensor(1.1486)\n",
      "14109 Traning Loss: tensor(1.1935)\n",
      "14110 Traning Loss: tensor(1.1502)\n",
      "14111 Traning Loss: tensor(1.1546)\n",
      "14112 Traning Loss: tensor(1.1418)\n",
      "14113 Traning Loss: tensor(1.2076)\n",
      "14114 Traning Loss: tensor(1.1781)\n",
      "14115 Traning Loss: tensor(1.2472)\n",
      "14116 Traning Loss: tensor(1.1839)\n",
      "14117 Traning Loss: tensor(1.2002)\n",
      "14118 Traning Loss: tensor(1.2464)\n",
      "14119 Traning Loss: tensor(1.1924)\n",
      "14120 Traning Loss: tensor(1.1391)\n",
      "14121 Traning Loss: tensor(1.1641)\n",
      "14122 Traning Loss: tensor(1.1657)\n",
      "14123 Traning Loss: tensor(1.1549)\n",
      "14124 Traning Loss: tensor(1.1477)\n",
      "14125 Traning Loss: tensor(1.1647)\n",
      "14126 Traning Loss: tensor(1.1442)\n",
      "14127 Traning Loss: tensor(1.1682)\n",
      "14128 Traning Loss: tensor(1.1450)\n",
      "14129 Traning Loss: tensor(1.1785)\n",
      "14130 Traning Loss: tensor(1.1913)\n",
      "14131 Traning Loss: tensor(1.1574)\n",
      "14132 Traning Loss: tensor(1.2250)\n",
      "14133 Traning Loss: tensor(1.1186)\n",
      "14134 Traning Loss: tensor(1.1511)\n",
      "14135 Traning Loss: tensor(1.1744)\n",
      "14136 Traning Loss: tensor(1.1642)\n",
      "14137 Traning Loss: tensor(1.1068)\n",
      "14138 Traning Loss: tensor(1.1077)\n",
      "14139 Traning Loss: tensor(1.1159)\n",
      "14140 Traning Loss: tensor(1.2008)\n",
      "14141 Traning Loss: tensor(1.1612)\n",
      "14142 Traning Loss: tensor(1.1192)\n",
      "14143 Traning Loss: tensor(1.1402)\n",
      "14144 Traning Loss: tensor(1.1944)\n",
      "14145 Traning Loss: tensor(1.1874)\n",
      "14146 Traning Loss: tensor(1.1790)\n",
      "14147 Traning Loss: tensor(1.1392)\n",
      "14148 Traning Loss: tensor(1.1492)\n",
      "14149 Traning Loss: tensor(1.1743)\n",
      "14150 Traning Loss: tensor(1.1277)\n",
      "14151 Traning Loss: tensor(1.1817)\n",
      "14152 Traning Loss: tensor(1.0762)\n",
      "14153 Traning Loss: tensor(1.1763)\n",
      "14154 Traning Loss: tensor(1.1650)\n",
      "14155 Traning Loss: tensor(1.2496)\n",
      "14156 Traning Loss: tensor(1.1760)\n",
      "14157 Traning Loss: tensor(1.2024)\n",
      "14158 Traning Loss: tensor(1.2013)\n",
      "14159 Traning Loss: tensor(1.0944)\n",
      "14160 Traning Loss: tensor(1.1516)\n",
      "14161 Traning Loss: tensor(1.1316)\n",
      "14162 Traning Loss: tensor(1.1202)\n",
      "14163 Traning Loss: tensor(1.1038)\n",
      "14164 Traning Loss: tensor(1.1318)\n",
      "14165 Traning Loss: tensor(1.0628)\n",
      "14166 Traning Loss: tensor(1.1885)\n",
      "14167 Traning Loss: tensor(1.1403)\n",
      "14168 Traning Loss: tensor(1.1742)\n",
      "14169 Traning Loss: tensor(1.1288)\n",
      "14170 Traning Loss: tensor(1.1794)\n",
      "14171 Traning Loss: tensor(1.1769)\n",
      "14172 Traning Loss: tensor(1.2104)\n",
      "14173 Traning Loss: tensor(1.1602)\n",
      "14174 Traning Loss: tensor(1.1086)\n",
      "14175 Traning Loss: tensor(1.0789)\n",
      "14176 Traning Loss: tensor(1.1543)\n",
      "14177 Traning Loss: tensor(1.1713)\n",
      "14178 Traning Loss: tensor(1.1241)\n",
      "14179 Traning Loss: tensor(1.1139)\n",
      "14180 Traning Loss: tensor(1.1620)\n",
      "14181 Traning Loss: tensor(1.1758)\n",
      "14182 Traning Loss: tensor(1.1344)\n",
      "14183 Traning Loss: tensor(1.0960)\n",
      "14184 Traning Loss: tensor(1.1577)\n",
      "14185 Traning Loss: tensor(1.0954)\n",
      "14186 Traning Loss: tensor(1.0997)\n",
      "14187 Traning Loss: tensor(1.0478)\n",
      "14188 Traning Loss: tensor(1.1219)\n",
      "14189 Traning Loss: tensor(1.2178)\n",
      "14190 Traning Loss: tensor(1.1755)\n",
      "14191 Traning Loss: tensor(1.1417)\n",
      "14192 Traning Loss: tensor(1.0902)\n",
      "14193 Traning Loss: tensor(1.1623)\n",
      "14194 Traning Loss: tensor(1.1028)\n",
      "14195 Traning Loss: tensor(1.1645)\n",
      "14196 Traning Loss: tensor(1.0981)\n",
      "14197 Traning Loss: tensor(1.0937)\n",
      "14198 Traning Loss: tensor(1.0750)\n",
      "14199 Traning Loss: tensor(1.1941)\n",
      "14200 Traning Loss: tensor(1.1529)\n",
      "14201 Traning Loss: tensor(1.0878)\n",
      "14202 Traning Loss: tensor(1.0526)\n",
      "14203 Traning Loss: tensor(1.1255)\n",
      "14204 Traning Loss: tensor(1.0828)\n",
      "14205 Traning Loss: tensor(1.1383)\n",
      "14206 Traning Loss: tensor(1.1377)\n",
      "14207 Traning Loss: tensor(1.1573)\n",
      "14208 Traning Loss: tensor(1.1689)\n",
      "14209 Traning Loss: tensor(1.0938)\n",
      "14210 Traning Loss: tensor(1.1465)\n",
      "14211 Traning Loss: tensor(1.1162)\n",
      "14212 Traning Loss: tensor(1.1400)\n",
      "14213 Traning Loss: tensor(1.1428)\n",
      "14214 Traning Loss: tensor(1.1364)\n",
      "14215 Traning Loss: tensor(1.1237)\n",
      "14216 Traning Loss: tensor(1.0233)\n",
      "14217 Traning Loss: tensor(1.1165)\n",
      "14218 Traning Loss: tensor(1.0739)\n",
      "14219 Traning Loss: tensor(1.1277)\n",
      "14220 Traning Loss: tensor(1.1301)\n",
      "14221 Traning Loss: tensor(1.0753)\n",
      "14222 Traning Loss: tensor(1.0725)\n",
      "14223 Traning Loss: tensor(1.1265)\n",
      "14224 Traning Loss: tensor(1.1189)\n",
      "14225 Traning Loss: tensor(1.1462)\n",
      "14226 Traning Loss: tensor(1.1148)\n",
      "14227 Traning Loss: tensor(1.0546)\n",
      "14228 Traning Loss: tensor(1.0650)\n",
      "14229 Traning Loss: tensor(1.1184)\n",
      "14230 Traning Loss: tensor(1.1032)\n",
      "14231 Traning Loss: tensor(1.0525)\n",
      "14232 Traning Loss: tensor(1.0855)\n",
      "14233 Traning Loss: tensor(1.0640)\n",
      "14234 Traning Loss: tensor(1.0986)\n",
      "14235 Traning Loss: tensor(1.0571)\n",
      "14236 Traning Loss: tensor(1.1072)\n",
      "14237 Traning Loss: tensor(1.0721)\n",
      "14238 Traning Loss: tensor(1.0667)\n",
      "14239 Traning Loss: tensor(1.0892)\n",
      "14240 Traning Loss: tensor(1.1662)\n",
      "14241 Traning Loss: tensor(1.1249)\n",
      "14242 Traning Loss: tensor(1.0504)\n",
      "14243 Traning Loss: tensor(1.0821)\n",
      "14244 Traning Loss: tensor(1.1176)\n",
      "14245 Traning Loss: tensor(0.9953)\n",
      "14246 Traning Loss: tensor(1.0727)\n",
      "14247 Traning Loss: tensor(1.0390)\n",
      "14248 Traning Loss: tensor(1.1242)\n",
      "14249 Traning Loss: tensor(1.0955)\n",
      "14250 Traning Loss: tensor(1.1054)\n",
      "14251 Traning Loss: tensor(1.0964)\n",
      "14252 Traning Loss: tensor(1.0795)\n",
      "14253 Traning Loss: tensor(1.0551)\n",
      "14254 Traning Loss: tensor(1.0589)\n",
      "14255 Traning Loss: tensor(1.0978)\n",
      "14256 Traning Loss: tensor(1.0954)\n",
      "14257 Traning Loss: tensor(1.0738)\n",
      "14258 Traning Loss: tensor(1.0013)\n",
      "14259 Traning Loss: tensor(1.0795)\n",
      "14260 Traning Loss: tensor(1.0210)\n",
      "14261 Traning Loss: tensor(1.0455)\n",
      "14262 Traning Loss: tensor(1.1116)\n",
      "14263 Traning Loss: tensor(1.1054)\n",
      "14264 Traning Loss: tensor(1.0571)\n",
      "14265 Traning Loss: tensor(1.0476)\n",
      "14266 Traning Loss: tensor(1.1735)\n",
      "14267 Traning Loss: tensor(1.0409)\n",
      "14268 Traning Loss: tensor(0.9944)\n",
      "14269 Traning Loss: tensor(1.1156)\n",
      "14270 Traning Loss: tensor(1.1168)\n",
      "14271 Traning Loss: tensor(1.1234)\n",
      "14272 Traning Loss: tensor(1.0707)\n",
      "14273 Traning Loss: tensor(1.1418)\n",
      "14274 Traning Loss: tensor(1.1183)\n",
      "14275 Traning Loss: tensor(1.0473)\n",
      "14276 Traning Loss: tensor(1.0609)\n",
      "14277 Traning Loss: tensor(1.0258)\n",
      "14278 Traning Loss: tensor(1.0621)\n",
      "14279 Traning Loss: tensor(1.0619)\n",
      "14280 Traning Loss: tensor(1.0192)\n",
      "14281 Traning Loss: tensor(1.0954)\n",
      "14282 Traning Loss: tensor(1.0728)\n",
      "14283 Traning Loss: tensor(1.0673)\n",
      "14284 Traning Loss: tensor(1.0613)\n",
      "14285 Traning Loss: tensor(1.0972)\n",
      "14286 Traning Loss: tensor(1.0328)\n",
      "14287 Traning Loss: tensor(1.0034)\n",
      "14288 Traning Loss: tensor(1.0342)\n",
      "14289 Traning Loss: tensor(1.0531)\n",
      "14290 Traning Loss: tensor(1.1145)\n",
      "14291 Traning Loss: tensor(1.0586)\n",
      "14292 Traning Loss: tensor(1.0566)\n",
      "14293 Traning Loss: tensor(1.0658)\n",
      "14294 Traning Loss: tensor(1.0293)\n",
      "14295 Traning Loss: tensor(1.0279)\n",
      "14296 Traning Loss: tensor(1.0904)\n",
      "14297 Traning Loss: tensor(1.0732)\n",
      "14298 Traning Loss: tensor(1.0508)\n",
      "14299 Traning Loss: tensor(0.9895)\n",
      "14300 Traning Loss: tensor(1.0117)\n",
      "14301 Traning Loss: tensor(1.1041)\n",
      "14302 Traning Loss: tensor(1.1212)\n",
      "14303 Traning Loss: tensor(1.0669)\n",
      "14304 Traning Loss: tensor(1.0014)\n",
      "14305 Traning Loss: tensor(1.0208)\n",
      "14306 Traning Loss: tensor(1.0826)\n",
      "14307 Traning Loss: tensor(1.0701)\n",
      "14308 Traning Loss: tensor(1.0505)\n",
      "14309 Traning Loss: tensor(1.0264)\n",
      "14310 Traning Loss: tensor(1.0294)\n",
      "14311 Traning Loss: tensor(1.0909)\n",
      "14312 Traning Loss: tensor(1.0748)\n",
      "14313 Traning Loss: tensor(0.9895)\n",
      "14314 Traning Loss: tensor(1.0012)\n",
      "14315 Traning Loss: tensor(1.0170)\n",
      "14316 Traning Loss: tensor(1.0320)\n",
      "14317 Traning Loss: tensor(1.1101)\n",
      "14318 Traning Loss: tensor(1.0582)\n",
      "14319 Traning Loss: tensor(1.0510)\n",
      "14320 Traning Loss: tensor(1.0731)\n",
      "14321 Traning Loss: tensor(0.9831)\n",
      "14322 Traning Loss: tensor(1.0934)\n",
      "14323 Traning Loss: tensor(0.9986)\n",
      "14324 Traning Loss: tensor(1.0039)\n",
      "14325 Traning Loss: tensor(1.0148)\n",
      "14326 Traning Loss: tensor(0.9708)\n",
      "14327 Traning Loss: tensor(1.0032)\n",
      "14328 Traning Loss: tensor(0.9823)\n",
      "14329 Traning Loss: tensor(1.0502)\n",
      "14330 Traning Loss: tensor(1.0189)\n",
      "14331 Traning Loss: tensor(1.0318)\n",
      "14332 Traning Loss: tensor(1.0077)\n",
      "14333 Traning Loss: tensor(1.0748)\n",
      "14334 Traning Loss: tensor(0.9874)\n",
      "14335 Traning Loss: tensor(1.0269)\n",
      "14336 Traning Loss: tensor(1.0302)\n",
      "14337 Traning Loss: tensor(1.0614)\n",
      "14338 Traning Loss: tensor(1.0162)\n",
      "14339 Traning Loss: tensor(1.0245)\n",
      "14340 Traning Loss: tensor(1.0447)\n",
      "14341 Traning Loss: tensor(0.9900)\n",
      "14342 Traning Loss: tensor(0.9890)\n",
      "14343 Traning Loss: tensor(0.9988)\n",
      "14344 Traning Loss: tensor(1.0456)\n",
      "14345 Traning Loss: tensor(1.0906)\n",
      "14346 Traning Loss: tensor(0.9860)\n",
      "14347 Traning Loss: tensor(1.0507)\n",
      "14348 Traning Loss: tensor(1.0157)\n",
      "14349 Traning Loss: tensor(1.0424)\n",
      "14350 Traning Loss: tensor(1.0371)\n",
      "14351 Traning Loss: tensor(1.0056)\n",
      "14352 Traning Loss: tensor(1.0252)\n",
      "14353 Traning Loss: tensor(0.9434)\n",
      "14354 Traning Loss: tensor(0.9992)\n",
      "14355 Traning Loss: tensor(0.9531)\n",
      "14356 Traning Loss: tensor(1.0445)\n",
      "14357 Traning Loss: tensor(0.9276)\n",
      "14358 Traning Loss: tensor(1.0507)\n",
      "14359 Traning Loss: tensor(0.9953)\n",
      "14360 Traning Loss: tensor(0.9625)\n",
      "14361 Traning Loss: tensor(1.0390)\n",
      "14362 Traning Loss: tensor(0.9204)\n",
      "14363 Traning Loss: tensor(0.9877)\n",
      "14364 Traning Loss: tensor(1.0611)\n",
      "14365 Traning Loss: tensor(1.0938)\n",
      "14366 Traning Loss: tensor(1.0303)\n",
      "14367 Traning Loss: tensor(0.9877)\n",
      "14368 Traning Loss: tensor(0.9866)\n",
      "14369 Traning Loss: tensor(0.9419)\n",
      "14370 Traning Loss: tensor(1.0438)\n",
      "14371 Traning Loss: tensor(0.9689)\n",
      "14372 Traning Loss: tensor(0.9705)\n",
      "14373 Traning Loss: tensor(0.9788)\n",
      "14374 Traning Loss: tensor(1.0365)\n",
      "14375 Traning Loss: tensor(1.0385)\n",
      "14376 Traning Loss: tensor(0.9895)\n",
      "14377 Traning Loss: tensor(0.9741)\n",
      "14378 Traning Loss: tensor(0.9435)\n",
      "14379 Traning Loss: tensor(1.0422)\n",
      "14380 Traning Loss: tensor(1.0060)\n",
      "14381 Traning Loss: tensor(1.0453)\n",
      "14382 Traning Loss: tensor(1.0378)\n",
      "14383 Traning Loss: tensor(0.9705)\n",
      "14384 Traning Loss: tensor(0.9867)\n",
      "14385 Traning Loss: tensor(0.9610)\n",
      "14386 Traning Loss: tensor(0.9680)\n",
      "14387 Traning Loss: tensor(0.9741)\n",
      "14388 Traning Loss: tensor(0.9915)\n",
      "14389 Traning Loss: tensor(0.8922)\n",
      "14390 Traning Loss: tensor(1.0119)\n",
      "14391 Traning Loss: tensor(0.9690)\n",
      "14392 Traning Loss: tensor(1.0159)\n",
      "14393 Traning Loss: tensor(0.9693)\n",
      "14394 Traning Loss: tensor(0.9486)\n",
      "14395 Traning Loss: tensor(0.9051)\n",
      "14396 Traning Loss: tensor(0.9581)\n",
      "14397 Traning Loss: tensor(0.9536)\n",
      "14398 Traning Loss: tensor(0.8912)\n",
      "14399 Traning Loss: tensor(0.8965)\n",
      "14400 Traning Loss: tensor(1.0179)\n",
      "14401 Traning Loss: tensor(0.9065)\n",
      "14402 Traning Loss: tensor(0.9353)\n",
      "14403 Traning Loss: tensor(0.9314)\n",
      "14404 Traning Loss: tensor(0.9335)\n",
      "14405 Traning Loss: tensor(0.9548)\n",
      "14406 Traning Loss: tensor(0.9641)\n",
      "14407 Traning Loss: tensor(0.9338)\n",
      "14408 Traning Loss: tensor(1.0235)\n",
      "14409 Traning Loss: tensor(0.9947)\n",
      "14410 Traning Loss: tensor(1.0347)\n",
      "14411 Traning Loss: tensor(0.9589)\n",
      "14412 Traning Loss: tensor(1.0920)\n",
      "14413 Traning Loss: tensor(1.0047)\n",
      "14414 Traning Loss: tensor(0.9919)\n",
      "14415 Traning Loss: tensor(0.9374)\n",
      "14416 Traning Loss: tensor(1.0105)\n",
      "14417 Traning Loss: tensor(0.9821)\n",
      "14418 Traning Loss: tensor(0.9691)\n",
      "14419 Traning Loss: tensor(1.0423)\n",
      "14420 Traning Loss: tensor(0.9324)\n",
      "14421 Traning Loss: tensor(1.0458)\n",
      "14422 Traning Loss: tensor(0.8985)\n",
      "14423 Traning Loss: tensor(1.0066)\n",
      "14424 Traning Loss: tensor(1.0161)\n",
      "14425 Traning Loss: tensor(1.0754)\n",
      "14426 Traning Loss: tensor(0.9124)\n",
      "14427 Traning Loss: tensor(0.9285)\n",
      "14428 Traning Loss: tensor(1.0280)\n",
      "14429 Traning Loss: tensor(0.9664)\n",
      "14430 Traning Loss: tensor(1.0136)\n",
      "14431 Traning Loss: tensor(0.9648)\n",
      "14432 Traning Loss: tensor(0.9609)\n",
      "14433 Traning Loss: tensor(1.0155)\n",
      "14434 Traning Loss: tensor(0.9738)\n",
      "14435 Traning Loss: tensor(1.0183)\n",
      "14436 Traning Loss: tensor(0.9731)\n",
      "14437 Traning Loss: tensor(0.9238)\n",
      "14438 Traning Loss: tensor(0.9935)\n",
      "14439 Traning Loss: tensor(0.9482)\n",
      "14440 Traning Loss: tensor(0.9559)\n",
      "14441 Traning Loss: tensor(0.9616)\n",
      "14442 Traning Loss: tensor(0.9793)\n",
      "14443 Traning Loss: tensor(0.9669)\n",
      "14444 Traning Loss: tensor(0.9472)\n",
      "14445 Traning Loss: tensor(0.9183)\n",
      "14446 Traning Loss: tensor(0.9678)\n",
      "14447 Traning Loss: tensor(0.9644)\n",
      "14448 Traning Loss: tensor(1.0102)\n",
      "14449 Traning Loss: tensor(0.9823)\n",
      "14450 Traning Loss: tensor(1.0210)\n",
      "14451 Traning Loss: tensor(0.9627)\n",
      "14452 Traning Loss: tensor(0.9745)\n",
      "14453 Traning Loss: tensor(0.9835)\n",
      "14454 Traning Loss: tensor(0.9609)\n",
      "14455 Traning Loss: tensor(0.9514)\n",
      "14456 Traning Loss: tensor(0.9086)\n",
      "14457 Traning Loss: tensor(0.8987)\n",
      "14458 Traning Loss: tensor(0.9414)\n",
      "14459 Traning Loss: tensor(0.9128)\n",
      "14460 Traning Loss: tensor(0.9826)\n",
      "14461 Traning Loss: tensor(0.9973)\n",
      "14462 Traning Loss: tensor(0.9161)\n",
      "14463 Traning Loss: tensor(1.0025)\n",
      "14464 Traning Loss: tensor(0.9222)\n",
      "14465 Traning Loss: tensor(0.9261)\n",
      "14466 Traning Loss: tensor(0.9094)\n",
      "14467 Traning Loss: tensor(0.9376)\n",
      "14468 Traning Loss: tensor(0.9112)\n",
      "14469 Traning Loss: tensor(0.9905)\n",
      "14470 Traning Loss: tensor(0.9579)\n",
      "14471 Traning Loss: tensor(0.9610)\n",
      "14472 Traning Loss: tensor(0.9019)\n",
      "14473 Traning Loss: tensor(0.9178)\n",
      "14474 Traning Loss: tensor(0.9438)\n",
      "14475 Traning Loss: tensor(1.0610)\n",
      "14476 Traning Loss: tensor(0.9031)\n",
      "14477 Traning Loss: tensor(0.9622)\n",
      "14478 Traning Loss: tensor(0.8984)\n",
      "14479 Traning Loss: tensor(0.8770)\n",
      "14480 Traning Loss: tensor(0.9386)\n",
      "14481 Traning Loss: tensor(0.9137)\n",
      "14482 Traning Loss: tensor(0.8826)\n",
      "14483 Traning Loss: tensor(0.9538)\n",
      "14484 Traning Loss: tensor(0.8892)\n",
      "14485 Traning Loss: tensor(1.0297)\n",
      "14486 Traning Loss: tensor(0.9088)\n",
      "14487 Traning Loss: tensor(0.8829)\n",
      "14488 Traning Loss: tensor(0.9958)\n",
      "14489 Traning Loss: tensor(0.9175)\n",
      "14490 Traning Loss: tensor(0.9620)\n",
      "14491 Traning Loss: tensor(0.9250)\n",
      "14492 Traning Loss: tensor(0.9617)\n",
      "14493 Traning Loss: tensor(0.8860)\n",
      "14494 Traning Loss: tensor(0.9455)\n",
      "14495 Traning Loss: tensor(0.9504)\n",
      "14496 Traning Loss: tensor(0.8626)\n",
      "14497 Traning Loss: tensor(0.9183)\n",
      "14498 Traning Loss: tensor(0.9380)\n",
      "14499 Traning Loss: tensor(0.8955)\n",
      "14500 Traning Loss: tensor(0.9316)\n",
      "14501 Traning Loss: tensor(0.9095)\n",
      "14502 Traning Loss: tensor(1.0644)\n",
      "14503 Traning Loss: tensor(0.9875)\n",
      "14504 Traning Loss: tensor(0.8994)\n",
      "14505 Traning Loss: tensor(0.9351)\n",
      "14506 Traning Loss: tensor(0.8471)\n",
      "14507 Traning Loss: tensor(0.8890)\n",
      "14508 Traning Loss: tensor(0.9563)\n",
      "14509 Traning Loss: tensor(0.9118)\n",
      "14510 Traning Loss: tensor(0.8696)\n",
      "14511 Traning Loss: tensor(0.9453)\n",
      "14512 Traning Loss: tensor(0.9089)\n",
      "14513 Traning Loss: tensor(0.8667)\n",
      "14514 Traning Loss: tensor(0.8527)\n",
      "14515 Traning Loss: tensor(0.9343)\n",
      "14516 Traning Loss: tensor(0.9299)\n",
      "14517 Traning Loss: tensor(0.9825)\n",
      "14518 Traning Loss: tensor(0.8757)\n",
      "14519 Traning Loss: tensor(0.8760)\n",
      "14520 Traning Loss: tensor(0.8956)\n",
      "14521 Traning Loss: tensor(0.8785)\n",
      "14522 Traning Loss: tensor(0.8536)\n",
      "14523 Traning Loss: tensor(0.8263)\n",
      "14524 Traning Loss: tensor(0.9050)\n",
      "14525 Traning Loss: tensor(0.9026)\n",
      "14526 Traning Loss: tensor(0.9223)\n",
      "14527 Traning Loss: tensor(0.9733)\n",
      "14528 Traning Loss: tensor(0.9673)\n",
      "14529 Traning Loss: tensor(0.9210)\n",
      "14530 Traning Loss: tensor(0.8984)\n",
      "14531 Traning Loss: tensor(0.9296)\n",
      "14532 Traning Loss: tensor(0.8607)\n",
      "14533 Traning Loss: tensor(0.9537)\n",
      "14534 Traning Loss: tensor(0.8462)\n",
      "14535 Traning Loss: tensor(0.8763)\n",
      "14536 Traning Loss: tensor(0.9728)\n",
      "14537 Traning Loss: tensor(0.8548)\n",
      "14538 Traning Loss: tensor(0.9436)\n",
      "14539 Traning Loss: tensor(0.8873)\n",
      "14540 Traning Loss: tensor(0.9228)\n",
      "14541 Traning Loss: tensor(0.8397)\n",
      "14542 Traning Loss: tensor(0.9032)\n",
      "14543 Traning Loss: tensor(0.8434)\n",
      "14544 Traning Loss: tensor(0.8550)\n",
      "14545 Traning Loss: tensor(0.8870)\n",
      "14546 Traning Loss: tensor(0.8850)\n",
      "14547 Traning Loss: tensor(1.0356)\n",
      "14548 Traning Loss: tensor(0.9278)\n",
      "14549 Traning Loss: tensor(0.9840)\n",
      "14550 Traning Loss: tensor(0.9371)\n",
      "14551 Traning Loss: tensor(0.9340)\n",
      "14552 Traning Loss: tensor(0.9452)\n",
      "14553 Traning Loss: tensor(0.8803)\n",
      "14554 Traning Loss: tensor(0.9264)\n",
      "14555 Traning Loss: tensor(0.9184)\n",
      "14556 Traning Loss: tensor(0.9002)\n",
      "14557 Traning Loss: tensor(0.9100)\n",
      "14558 Traning Loss: tensor(0.9118)\n",
      "14559 Traning Loss: tensor(0.8226)\n",
      "14560 Traning Loss: tensor(0.8703)\n",
      "14561 Traning Loss: tensor(0.8728)\n",
      "14562 Traning Loss: tensor(0.8801)\n",
      "14563 Traning Loss: tensor(0.8761)\n",
      "14564 Traning Loss: tensor(0.8691)\n",
      "14565 Traning Loss: tensor(0.8818)\n",
      "14566 Traning Loss: tensor(0.9641)\n",
      "14567 Traning Loss: tensor(0.9236)\n",
      "14568 Traning Loss: tensor(0.8546)\n",
      "14569 Traning Loss: tensor(0.8393)\n",
      "14570 Traning Loss: tensor(0.9037)\n",
      "14571 Traning Loss: tensor(0.9215)\n",
      "14572 Traning Loss: tensor(1.0110)\n",
      "14573 Traning Loss: tensor(0.8687)\n",
      "14574 Traning Loss: tensor(0.8510)\n",
      "14575 Traning Loss: tensor(0.8386)\n",
      "14576 Traning Loss: tensor(0.8837)\n",
      "14577 Traning Loss: tensor(0.8740)\n",
      "14578 Traning Loss: tensor(0.8992)\n",
      "14579 Traning Loss: tensor(0.8634)\n",
      "14580 Traning Loss: tensor(0.8915)\n",
      "14581 Traning Loss: tensor(0.7987)\n",
      "14582 Traning Loss: tensor(0.8969)\n",
      "14583 Traning Loss: tensor(0.8510)\n",
      "14584 Traning Loss: tensor(0.8458)\n",
      "14585 Traning Loss: tensor(0.9180)\n",
      "14586 Traning Loss: tensor(0.8895)\n",
      "14587 Traning Loss: tensor(0.9479)\n",
      "14588 Traning Loss: tensor(0.8774)\n",
      "14589 Traning Loss: tensor(0.9435)\n",
      "14590 Traning Loss: tensor(0.9141)\n",
      "14591 Traning Loss: tensor(0.9127)\n",
      "14592 Traning Loss: tensor(0.9101)\n",
      "14593 Traning Loss: tensor(0.9658)\n",
      "14594 Traning Loss: tensor(0.9046)\n",
      "14595 Traning Loss: tensor(0.9293)\n",
      "14596 Traning Loss: tensor(0.8484)\n",
      "14597 Traning Loss: tensor(0.9267)\n",
      "14598 Traning Loss: tensor(0.8865)\n",
      "14599 Traning Loss: tensor(0.8766)\n",
      "14600 Traning Loss: tensor(0.9297)\n",
      "14601 Traning Loss: tensor(0.8353)\n",
      "14602 Traning Loss: tensor(0.9192)\n",
      "14603 Traning Loss: tensor(0.9079)\n",
      "14604 Traning Loss: tensor(0.8781)\n",
      "14605 Traning Loss: tensor(0.9034)\n",
      "14606 Traning Loss: tensor(0.8245)\n",
      "14607 Traning Loss: tensor(0.8525)\n",
      "14608 Traning Loss: tensor(0.8649)\n",
      "14609 Traning Loss: tensor(0.9146)\n",
      "14610 Traning Loss: tensor(0.9154)\n",
      "14611 Traning Loss: tensor(0.8668)\n",
      "14612 Traning Loss: tensor(0.8635)\n",
      "14613 Traning Loss: tensor(0.8558)\n",
      "14614 Traning Loss: tensor(0.8911)\n",
      "14615 Traning Loss: tensor(0.8744)\n",
      "14616 Traning Loss: tensor(0.8860)\n",
      "14617 Traning Loss: tensor(0.9252)\n",
      "14618 Traning Loss: tensor(0.8909)\n",
      "14619 Traning Loss: tensor(0.8391)\n",
      "14620 Traning Loss: tensor(0.8656)\n",
      "14621 Traning Loss: tensor(0.8352)\n",
      "14622 Traning Loss: tensor(0.8411)\n",
      "14623 Traning Loss: tensor(0.8246)\n",
      "14624 Traning Loss: tensor(0.8206)\n",
      "14625 Traning Loss: tensor(0.8709)\n",
      "14626 Traning Loss: tensor(0.9014)\n",
      "14627 Traning Loss: tensor(0.8470)\n",
      "14628 Traning Loss: tensor(0.8402)\n",
      "14629 Traning Loss: tensor(0.8341)\n",
      "14630 Traning Loss: tensor(0.8344)\n",
      "14631 Traning Loss: tensor(0.8559)\n",
      "14632 Traning Loss: tensor(0.8361)\n",
      "14633 Traning Loss: tensor(0.8687)\n",
      "14634 Traning Loss: tensor(0.9194)\n",
      "14635 Traning Loss: tensor(0.8196)\n",
      "14636 Traning Loss: tensor(0.9277)\n",
      "14637 Traning Loss: tensor(0.8468)\n",
      "14638 Traning Loss: tensor(0.8129)\n",
      "14639 Traning Loss: tensor(0.9098)\n",
      "14640 Traning Loss: tensor(0.8854)\n",
      "14641 Traning Loss: tensor(0.8069)\n",
      "14642 Traning Loss: tensor(0.8361)\n",
      "14643 Traning Loss: tensor(0.8898)\n",
      "14644 Traning Loss: tensor(0.8625)\n",
      "14645 Traning Loss: tensor(0.8563)\n",
      "14646 Traning Loss: tensor(0.8060)\n",
      "14647 Traning Loss: tensor(0.8158)\n",
      "14648 Traning Loss: tensor(0.8313)\n",
      "14649 Traning Loss: tensor(0.8081)\n",
      "14650 Traning Loss: tensor(0.8282)\n",
      "14651 Traning Loss: tensor(0.8373)\n",
      "14652 Traning Loss: tensor(0.8816)\n",
      "14653 Traning Loss: tensor(0.8682)\n",
      "14654 Traning Loss: tensor(0.8849)\n",
      "14655 Traning Loss: tensor(0.9019)\n",
      "14656 Traning Loss: tensor(0.8592)\n",
      "14657 Traning Loss: tensor(0.8223)\n",
      "14658 Traning Loss: tensor(0.8614)\n",
      "14659 Traning Loss: tensor(0.8760)\n",
      "14660 Traning Loss: tensor(0.8200)\n",
      "14661 Traning Loss: tensor(0.8084)\n",
      "14662 Traning Loss: tensor(0.8194)\n",
      "14663 Traning Loss: tensor(0.8297)\n",
      "14664 Traning Loss: tensor(0.7946)\n",
      "14665 Traning Loss: tensor(0.8323)\n",
      "14666 Traning Loss: tensor(0.9598)\n",
      "14667 Traning Loss: tensor(0.7870)\n",
      "14668 Traning Loss: tensor(0.8435)\n",
      "14669 Traning Loss: tensor(0.7944)\n",
      "14670 Traning Loss: tensor(0.8905)\n",
      "14671 Traning Loss: tensor(0.8739)\n",
      "14672 Traning Loss: tensor(0.8566)\n",
      "14673 Traning Loss: tensor(0.8276)\n",
      "14674 Traning Loss: tensor(0.8464)\n",
      "14675 Traning Loss: tensor(0.8222)\n",
      "14676 Traning Loss: tensor(0.9250)\n",
      "14677 Traning Loss: tensor(0.8216)\n",
      "14678 Traning Loss: tensor(0.8439)\n",
      "14679 Traning Loss: tensor(0.8026)\n",
      "14680 Traning Loss: tensor(0.7763)\n",
      "14681 Traning Loss: tensor(0.8994)\n",
      "14682 Traning Loss: tensor(0.8327)\n",
      "14683 Traning Loss: tensor(0.8090)\n",
      "14684 Traning Loss: tensor(0.8419)\n",
      "14685 Traning Loss: tensor(0.8254)\n",
      "14686 Traning Loss: tensor(0.8566)\n",
      "14687 Traning Loss: tensor(0.7986)\n",
      "14688 Traning Loss: tensor(0.9067)\n",
      "14689 Traning Loss: tensor(0.8275)\n",
      "14690 Traning Loss: tensor(0.8708)\n",
      "14691 Traning Loss: tensor(0.8140)\n",
      "14692 Traning Loss: tensor(0.8593)\n",
      "14693 Traning Loss: tensor(0.8462)\n",
      "14694 Traning Loss: tensor(0.8386)\n",
      "14695 Traning Loss: tensor(0.8679)\n",
      "14696 Traning Loss: tensor(0.9020)\n",
      "14697 Traning Loss: tensor(0.8432)\n",
      "14698 Traning Loss: tensor(0.8614)\n",
      "14699 Traning Loss: tensor(0.8019)\n",
      "14700 Traning Loss: tensor(0.8724)\n",
      "14701 Traning Loss: tensor(0.7773)\n",
      "14702 Traning Loss: tensor(0.8360)\n",
      "14703 Traning Loss: tensor(0.8780)\n",
      "14704 Traning Loss: tensor(0.8511)\n",
      "14705 Traning Loss: tensor(0.8061)\n",
      "14706 Traning Loss: tensor(0.7917)\n",
      "14707 Traning Loss: tensor(0.7890)\n",
      "14708 Traning Loss: tensor(0.8128)\n",
      "14709 Traning Loss: tensor(0.8105)\n",
      "14710 Traning Loss: tensor(0.7992)\n",
      "14711 Traning Loss: tensor(0.8007)\n",
      "14712 Traning Loss: tensor(0.8714)\n",
      "14713 Traning Loss: tensor(0.8007)\n",
      "14714 Traning Loss: tensor(0.8608)\n",
      "14715 Traning Loss: tensor(0.8257)\n",
      "14716 Traning Loss: tensor(0.7769)\n",
      "14717 Traning Loss: tensor(0.8053)\n",
      "14718 Traning Loss: tensor(0.8438)\n",
      "14719 Traning Loss: tensor(0.8064)\n",
      "14720 Traning Loss: tensor(0.7994)\n",
      "14721 Traning Loss: tensor(0.8394)\n",
      "14722 Traning Loss: tensor(0.7732)\n",
      "14723 Traning Loss: tensor(0.8120)\n",
      "14724 Traning Loss: tensor(0.8052)\n",
      "14725 Traning Loss: tensor(0.8106)\n",
      "14726 Traning Loss: tensor(0.8329)\n",
      "14727 Traning Loss: tensor(0.8013)\n",
      "14728 Traning Loss: tensor(0.8377)\n",
      "14729 Traning Loss: tensor(0.8886)\n",
      "14730 Traning Loss: tensor(0.8399)\n",
      "14731 Traning Loss: tensor(0.7712)\n",
      "14732 Traning Loss: tensor(0.8509)\n",
      "14733 Traning Loss: tensor(0.7643)\n",
      "14734 Traning Loss: tensor(0.8296)\n",
      "14735 Traning Loss: tensor(0.8166)\n",
      "14736 Traning Loss: tensor(0.8263)\n",
      "14737 Traning Loss: tensor(0.7608)\n",
      "14738 Traning Loss: tensor(0.8300)\n",
      "14739 Traning Loss: tensor(0.7775)\n",
      "14740 Traning Loss: tensor(0.8332)\n",
      "14741 Traning Loss: tensor(0.8397)\n",
      "14742 Traning Loss: tensor(0.7843)\n",
      "14743 Traning Loss: tensor(0.7851)\n",
      "14744 Traning Loss: tensor(0.8994)\n",
      "14745 Traning Loss: tensor(0.7552)\n",
      "14746 Traning Loss: tensor(0.7976)\n",
      "14747 Traning Loss: tensor(0.7710)\n",
      "14748 Traning Loss: tensor(0.8568)\n",
      "14749 Traning Loss: tensor(0.7873)\n",
      "14750 Traning Loss: tensor(0.8147)\n",
      "14751 Traning Loss: tensor(0.7880)\n",
      "14752 Traning Loss: tensor(0.8303)\n",
      "14753 Traning Loss: tensor(0.8107)\n",
      "14754 Traning Loss: tensor(0.7671)\n",
      "14755 Traning Loss: tensor(0.9403)\n",
      "14756 Traning Loss: tensor(0.8966)\n",
      "14757 Traning Loss: tensor(0.7663)\n",
      "14758 Traning Loss: tensor(0.7348)\n",
      "14759 Traning Loss: tensor(0.8758)\n",
      "14760 Traning Loss: tensor(0.7745)\n",
      "14761 Traning Loss: tensor(0.8489)\n",
      "14762 Traning Loss: tensor(0.8113)\n",
      "14763 Traning Loss: tensor(0.8053)\n",
      "14764 Traning Loss: tensor(0.8661)\n",
      "14765 Traning Loss: tensor(0.8262)\n",
      "14766 Traning Loss: tensor(0.8239)\n",
      "14767 Traning Loss: tensor(0.8072)\n",
      "14768 Traning Loss: tensor(0.7640)\n",
      "14769 Traning Loss: tensor(0.7889)\n",
      "14770 Traning Loss: tensor(0.7872)\n",
      "14771 Traning Loss: tensor(0.7828)\n",
      "14772 Traning Loss: tensor(0.7737)\n",
      "14773 Traning Loss: tensor(0.7887)\n",
      "14774 Traning Loss: tensor(0.8311)\n",
      "14775 Traning Loss: tensor(0.7715)\n",
      "14776 Traning Loss: tensor(0.8302)\n",
      "14777 Traning Loss: tensor(0.7816)\n",
      "14778 Traning Loss: tensor(0.7884)\n",
      "14779 Traning Loss: tensor(0.7760)\n",
      "14780 Traning Loss: tensor(0.8039)\n",
      "14781 Traning Loss: tensor(0.7604)\n",
      "14782 Traning Loss: tensor(0.7744)\n",
      "14783 Traning Loss: tensor(0.8693)\n",
      "14784 Traning Loss: tensor(0.8748)\n",
      "14785 Traning Loss: tensor(0.8298)\n",
      "14786 Traning Loss: tensor(0.8166)\n",
      "14787 Traning Loss: tensor(0.7394)\n",
      "14788 Traning Loss: tensor(0.7523)\n",
      "14789 Traning Loss: tensor(0.8639)\n",
      "14790 Traning Loss: tensor(0.7790)\n",
      "14791 Traning Loss: tensor(0.8304)\n",
      "14792 Traning Loss: tensor(0.8410)\n",
      "14793 Traning Loss: tensor(0.7854)\n",
      "14794 Traning Loss: tensor(0.8086)\n",
      "14795 Traning Loss: tensor(0.7996)\n",
      "14796 Traning Loss: tensor(0.8019)\n",
      "14797 Traning Loss: tensor(0.7942)\n",
      "14798 Traning Loss: tensor(0.8906)\n",
      "14799 Traning Loss: tensor(0.8202)\n",
      "14800 Traning Loss: tensor(0.7601)\n",
      "14801 Traning Loss: tensor(0.7301)\n",
      "14802 Traning Loss: tensor(0.8318)\n",
      "14803 Traning Loss: tensor(0.7885)\n",
      "14804 Traning Loss: tensor(0.7979)\n",
      "14805 Traning Loss: tensor(0.7623)\n",
      "14806 Traning Loss: tensor(0.7708)\n",
      "14807 Traning Loss: tensor(0.7675)\n",
      "14808 Traning Loss: tensor(0.8388)\n",
      "14809 Traning Loss: tensor(0.8101)\n",
      "14810 Traning Loss: tensor(0.8632)\n",
      "14811 Traning Loss: tensor(0.7803)\n",
      "14812 Traning Loss: tensor(0.7945)\n",
      "14813 Traning Loss: tensor(0.7707)\n",
      "14814 Traning Loss: tensor(0.8347)\n",
      "14815 Traning Loss: tensor(0.8875)\n",
      "14816 Traning Loss: tensor(0.7740)\n",
      "14817 Traning Loss: tensor(0.7814)\n",
      "14818 Traning Loss: tensor(0.7615)\n",
      "14819 Traning Loss: tensor(0.7644)\n",
      "14820 Traning Loss: tensor(0.7919)\n",
      "14821 Traning Loss: tensor(0.8126)\n",
      "14822 Traning Loss: tensor(0.8078)\n",
      "14823 Traning Loss: tensor(0.7838)\n",
      "14824 Traning Loss: tensor(0.8054)\n",
      "14825 Traning Loss: tensor(0.8025)\n",
      "14826 Traning Loss: tensor(0.7701)\n",
      "14827 Traning Loss: tensor(0.8128)\n",
      "14828 Traning Loss: tensor(0.7589)\n",
      "14829 Traning Loss: tensor(0.7670)\n",
      "14830 Traning Loss: tensor(0.7993)\n",
      "14831 Traning Loss: tensor(0.7354)\n",
      "14832 Traning Loss: tensor(0.7607)\n",
      "14833 Traning Loss: tensor(0.7818)\n",
      "14834 Traning Loss: tensor(0.7358)\n",
      "14835 Traning Loss: tensor(0.7575)\n",
      "14836 Traning Loss: tensor(0.7616)\n",
      "14837 Traning Loss: tensor(0.8014)\n",
      "14838 Traning Loss: tensor(0.8280)\n",
      "14839 Traning Loss: tensor(0.7419)\n",
      "14840 Traning Loss: tensor(0.7344)\n",
      "14841 Traning Loss: tensor(0.7391)\n",
      "14842 Traning Loss: tensor(0.7599)\n",
      "14843 Traning Loss: tensor(0.7664)\n",
      "14844 Traning Loss: tensor(0.7851)\n",
      "14845 Traning Loss: tensor(0.8010)\n",
      "14846 Traning Loss: tensor(0.8169)\n",
      "14847 Traning Loss: tensor(0.8320)\n",
      "14848 Traning Loss: tensor(0.8278)\n",
      "14849 Traning Loss: tensor(0.7488)\n",
      "14850 Traning Loss: tensor(0.7458)\n",
      "14851 Traning Loss: tensor(0.7976)\n",
      "14852 Traning Loss: tensor(0.7992)\n",
      "14853 Traning Loss: tensor(0.7690)\n",
      "14854 Traning Loss: tensor(0.7227)\n",
      "14855 Traning Loss: tensor(0.7784)\n",
      "14856 Traning Loss: tensor(0.7581)\n",
      "14857 Traning Loss: tensor(0.7651)\n",
      "14858 Traning Loss: tensor(0.8164)\n",
      "14859 Traning Loss: tensor(0.7219)\n",
      "14860 Traning Loss: tensor(0.8197)\n",
      "14861 Traning Loss: tensor(0.7701)\n",
      "14862 Traning Loss: tensor(0.7556)\n",
      "14863 Traning Loss: tensor(0.7481)\n",
      "14864 Traning Loss: tensor(0.7924)\n",
      "14865 Traning Loss: tensor(0.7792)\n",
      "14866 Traning Loss: tensor(0.8209)\n",
      "14867 Traning Loss: tensor(0.7809)\n",
      "14868 Traning Loss: tensor(0.7270)\n",
      "14869 Traning Loss: tensor(0.6942)\n",
      "14870 Traning Loss: tensor(0.7471)\n",
      "14871 Traning Loss: tensor(0.8037)\n",
      "14872 Traning Loss: tensor(0.7653)\n",
      "14873 Traning Loss: tensor(0.7434)\n",
      "14874 Traning Loss: tensor(0.7627)\n",
      "14875 Traning Loss: tensor(0.7500)\n",
      "14876 Traning Loss: tensor(0.8309)\n",
      "14877 Traning Loss: tensor(0.7586)\n",
      "14878 Traning Loss: tensor(0.8001)\n",
      "14879 Traning Loss: tensor(0.7490)\n",
      "14880 Traning Loss: tensor(0.7727)\n",
      "14881 Traning Loss: tensor(0.6985)\n",
      "14882 Traning Loss: tensor(0.7730)\n",
      "14883 Traning Loss: tensor(0.7217)\n",
      "14884 Traning Loss: tensor(0.7184)\n",
      "14885 Traning Loss: tensor(0.7406)\n",
      "14886 Traning Loss: tensor(0.7796)\n",
      "14887 Traning Loss: tensor(0.7739)\n",
      "14888 Traning Loss: tensor(0.7590)\n",
      "14889 Traning Loss: tensor(0.7582)\n",
      "14890 Traning Loss: tensor(0.7362)\n",
      "14891 Traning Loss: tensor(0.7121)\n",
      "14892 Traning Loss: tensor(0.7645)\n",
      "14893 Traning Loss: tensor(0.6987)\n",
      "14894 Traning Loss: tensor(0.7504)\n",
      "14895 Traning Loss: tensor(0.8528)\n",
      "14896 Traning Loss: tensor(0.7677)\n",
      "14897 Traning Loss: tensor(0.7579)\n",
      "14898 Traning Loss: tensor(0.7346)\n",
      "14899 Traning Loss: tensor(0.7079)\n",
      "14900 Traning Loss: tensor(0.8049)\n",
      "14901 Traning Loss: tensor(0.7566)\n",
      "14902 Traning Loss: tensor(0.7526)\n",
      "14903 Traning Loss: tensor(0.7186)\n",
      "14904 Traning Loss: tensor(0.7669)\n",
      "14905 Traning Loss: tensor(0.7508)\n",
      "14906 Traning Loss: tensor(0.8166)\n",
      "14907 Traning Loss: tensor(0.7353)\n",
      "14908 Traning Loss: tensor(0.7055)\n",
      "14909 Traning Loss: tensor(0.7212)\n",
      "14910 Traning Loss: tensor(0.7445)\n",
      "14911 Traning Loss: tensor(0.7443)\n",
      "14912 Traning Loss: tensor(0.7669)\n",
      "14913 Traning Loss: tensor(0.6905)\n",
      "14914 Traning Loss: tensor(0.7506)\n",
      "14915 Traning Loss: tensor(0.7348)\n",
      "14916 Traning Loss: tensor(0.7519)\n",
      "14917 Traning Loss: tensor(0.6996)\n",
      "14918 Traning Loss: tensor(0.7674)\n",
      "14919 Traning Loss: tensor(0.7647)\n",
      "14920 Traning Loss: tensor(0.7414)\n",
      "14921 Traning Loss: tensor(0.7277)\n",
      "14922 Traning Loss: tensor(0.7175)\n",
      "14923 Traning Loss: tensor(0.7101)\n",
      "14924 Traning Loss: tensor(0.7726)\n",
      "14925 Traning Loss: tensor(0.7529)\n",
      "14926 Traning Loss: tensor(0.6956)\n",
      "14927 Traning Loss: tensor(0.7094)\n",
      "14928 Traning Loss: tensor(0.7284)\n",
      "14929 Traning Loss: tensor(0.6845)\n",
      "14930 Traning Loss: tensor(0.7256)\n",
      "14931 Traning Loss: tensor(0.7451)\n",
      "14932 Traning Loss: tensor(0.7590)\n",
      "14933 Traning Loss: tensor(0.7593)\n",
      "14934 Traning Loss: tensor(0.7359)\n",
      "14935 Traning Loss: tensor(0.7349)\n",
      "14936 Traning Loss: tensor(0.7143)\n",
      "14937 Traning Loss: tensor(0.7628)\n",
      "14938 Traning Loss: tensor(0.7740)\n",
      "14939 Traning Loss: tensor(0.7313)\n",
      "14940 Traning Loss: tensor(0.8132)\n",
      "14941 Traning Loss: tensor(0.7349)\n",
      "14942 Traning Loss: tensor(0.8152)\n",
      "14943 Traning Loss: tensor(0.7901)\n",
      "14944 Traning Loss: tensor(0.7308)\n",
      "14945 Traning Loss: tensor(0.7080)\n",
      "14946 Traning Loss: tensor(0.8185)\n",
      "14947 Traning Loss: tensor(0.8332)\n",
      "14948 Traning Loss: tensor(0.8035)\n",
      "14949 Traning Loss: tensor(0.7853)\n",
      "14950 Traning Loss: tensor(0.8597)\n",
      "14951 Traning Loss: tensor(0.7546)\n",
      "14952 Traning Loss: tensor(0.6947)\n",
      "14953 Traning Loss: tensor(0.6602)\n",
      "14954 Traning Loss: tensor(0.7883)\n",
      "14955 Traning Loss: tensor(0.7865)\n",
      "14956 Traning Loss: tensor(0.6948)\n",
      "14957 Traning Loss: tensor(0.7045)\n",
      "14958 Traning Loss: tensor(0.7595)\n",
      "14959 Traning Loss: tensor(0.6705)\n",
      "14960 Traning Loss: tensor(0.7441)\n",
      "14961 Traning Loss: tensor(0.7146)\n",
      "14962 Traning Loss: tensor(0.7871)\n",
      "14963 Traning Loss: tensor(0.7362)\n",
      "14964 Traning Loss: tensor(0.7665)\n",
      "14965 Traning Loss: tensor(0.7424)\n",
      "14966 Traning Loss: tensor(0.7457)\n",
      "14967 Traning Loss: tensor(0.6879)\n",
      "14968 Traning Loss: tensor(0.6597)\n",
      "14969 Traning Loss: tensor(0.7438)\n",
      "14970 Traning Loss: tensor(0.7433)\n",
      "14971 Traning Loss: tensor(0.7339)\n",
      "14972 Traning Loss: tensor(0.7755)\n",
      "14973 Traning Loss: tensor(0.7962)\n",
      "14974 Traning Loss: tensor(0.7632)\n",
      "14975 Traning Loss: tensor(0.6602)\n",
      "14976 Traning Loss: tensor(0.7908)\n",
      "14977 Traning Loss: tensor(0.7297)\n",
      "14978 Traning Loss: tensor(0.6881)\n",
      "14979 Traning Loss: tensor(0.7550)\n",
      "14980 Traning Loss: tensor(0.6931)\n",
      "14981 Traning Loss: tensor(0.6582)\n",
      "14982 Traning Loss: tensor(0.7771)\n",
      "14983 Traning Loss: tensor(0.6837)\n",
      "14984 Traning Loss: tensor(0.8525)\n",
      "14985 Traning Loss: tensor(0.7831)\n",
      "14986 Traning Loss: tensor(0.7801)\n",
      "14987 Traning Loss: tensor(0.7334)\n",
      "14988 Traning Loss: tensor(0.7157)\n",
      "14989 Traning Loss: tensor(0.7103)\n",
      "14990 Traning Loss: tensor(0.7166)\n",
      "14991 Traning Loss: tensor(0.7206)\n",
      "14992 Traning Loss: tensor(0.7427)\n",
      "14993 Traning Loss: tensor(0.7608)\n",
      "14994 Traning Loss: tensor(0.6737)\n",
      "14995 Traning Loss: tensor(0.7309)\n",
      "14996 Traning Loss: tensor(0.6932)\n",
      "14997 Traning Loss: tensor(0.7081)\n",
      "14998 Traning Loss: tensor(0.7769)\n",
      "14999 Traning Loss: tensor(0.7555)\n",
      "15000 Traning Loss: tensor(0.7060)\n",
      "15001 Traning Loss: tensor(0.7428)\n",
      "15002 Traning Loss: tensor(0.7287)\n",
      "15003 Traning Loss: tensor(0.6357)\n",
      "15004 Traning Loss: tensor(0.7081)\n",
      "15005 Traning Loss: tensor(0.8001)\n",
      "15006 Traning Loss: tensor(0.8469)\n",
      "15007 Traning Loss: tensor(0.6564)\n",
      "15008 Traning Loss: tensor(0.6754)\n",
      "15009 Traning Loss: tensor(0.7146)\n",
      "15010 Traning Loss: tensor(0.6509)\n",
      "15011 Traning Loss: tensor(0.6878)\n",
      "15012 Traning Loss: tensor(0.7170)\n",
      "15013 Traning Loss: tensor(0.6707)\n",
      "15014 Traning Loss: tensor(0.7347)\n",
      "15015 Traning Loss: tensor(0.7085)\n",
      "15016 Traning Loss: tensor(0.7011)\n",
      "15017 Traning Loss: tensor(0.7248)\n",
      "15018 Traning Loss: tensor(0.7007)\n",
      "15019 Traning Loss: tensor(0.6814)\n",
      "15020 Traning Loss: tensor(0.6878)\n",
      "15021 Traning Loss: tensor(0.7104)\n",
      "15022 Traning Loss: tensor(0.6993)\n",
      "15023 Traning Loss: tensor(0.6681)\n",
      "15024 Traning Loss: tensor(0.6699)\n",
      "15025 Traning Loss: tensor(0.6488)\n",
      "15026 Traning Loss: tensor(0.6919)\n",
      "15027 Traning Loss: tensor(0.7275)\n",
      "15028 Traning Loss: tensor(0.6846)\n",
      "15029 Traning Loss: tensor(0.7243)\n",
      "15030 Traning Loss: tensor(0.6614)\n",
      "15031 Traning Loss: tensor(0.7275)\n",
      "15032 Traning Loss: tensor(0.7174)\n",
      "15033 Traning Loss: tensor(0.6921)\n",
      "15034 Traning Loss: tensor(0.6605)\n",
      "15035 Traning Loss: tensor(0.6816)\n",
      "15036 Traning Loss: tensor(0.7036)\n",
      "15037 Traning Loss: tensor(0.8063)\n",
      "15038 Traning Loss: tensor(0.6297)\n",
      "15039 Traning Loss: tensor(0.7002)\n",
      "15040 Traning Loss: tensor(0.7020)\n",
      "15041 Traning Loss: tensor(0.7470)\n",
      "15042 Traning Loss: tensor(0.7177)\n",
      "15043 Traning Loss: tensor(0.6516)\n",
      "15044 Traning Loss: tensor(0.6700)\n",
      "15045 Traning Loss: tensor(0.7029)\n",
      "15046 Traning Loss: tensor(0.7371)\n",
      "15047 Traning Loss: tensor(0.6953)\n",
      "15048 Traning Loss: tensor(0.7434)\n",
      "15049 Traning Loss: tensor(0.7584)\n",
      "15050 Traning Loss: tensor(0.7721)\n",
      "15051 Traning Loss: tensor(0.6787)\n",
      "15052 Traning Loss: tensor(0.6913)\n",
      "15053 Traning Loss: tensor(0.7314)\n",
      "15054 Traning Loss: tensor(0.7203)\n",
      "15055 Traning Loss: tensor(0.7402)\n",
      "15056 Traning Loss: tensor(0.6797)\n",
      "15057 Traning Loss: tensor(0.6916)\n",
      "15058 Traning Loss: tensor(0.7816)\n",
      "15059 Traning Loss: tensor(0.7393)\n",
      "15060 Traning Loss: tensor(0.7180)\n",
      "15061 Traning Loss: tensor(0.6750)\n",
      "15062 Traning Loss: tensor(0.6990)\n",
      "15063 Traning Loss: tensor(0.6615)\n",
      "15064 Traning Loss: tensor(0.6839)\n",
      "15065 Traning Loss: tensor(0.7374)\n",
      "15066 Traning Loss: tensor(0.7088)\n",
      "15067 Traning Loss: tensor(0.6738)\n",
      "15068 Traning Loss: tensor(0.6303)\n",
      "15069 Traning Loss: tensor(0.6733)\n",
      "15070 Traning Loss: tensor(0.6936)\n",
      "15071 Traning Loss: tensor(0.7966)\n",
      "15072 Traning Loss: tensor(0.6674)\n",
      "15073 Traning Loss: tensor(0.6738)\n",
      "15074 Traning Loss: tensor(0.6836)\n",
      "15075 Traning Loss: tensor(0.6481)\n",
      "15076 Traning Loss: tensor(0.6657)\n",
      "15077 Traning Loss: tensor(0.7152)\n",
      "15078 Traning Loss: tensor(0.7263)\n",
      "15079 Traning Loss: tensor(0.6817)\n",
      "15080 Traning Loss: tensor(0.6816)\n",
      "15081 Traning Loss: tensor(0.6329)\n",
      "15082 Traning Loss: tensor(0.7107)\n",
      "15083 Traning Loss: tensor(0.6914)\n",
      "15084 Traning Loss: tensor(0.6910)\n",
      "15085 Traning Loss: tensor(0.6951)\n",
      "15086 Traning Loss: tensor(0.6508)\n",
      "15087 Traning Loss: tensor(0.6653)\n",
      "15088 Traning Loss: tensor(0.7446)\n",
      "15089 Traning Loss: tensor(0.6963)\n",
      "15090 Traning Loss: tensor(0.6919)\n",
      "15091 Traning Loss: tensor(0.6839)\n",
      "15092 Traning Loss: tensor(0.6795)\n",
      "15093 Traning Loss: tensor(0.6693)\n",
      "15094 Traning Loss: tensor(0.6993)\n",
      "15095 Traning Loss: tensor(0.6718)\n",
      "15096 Traning Loss: tensor(0.7398)\n",
      "15097 Traning Loss: tensor(0.7101)\n",
      "15098 Traning Loss: tensor(0.7222)\n",
      "15099 Traning Loss: tensor(0.6608)\n",
      "15100 Traning Loss: tensor(0.7100)\n",
      "15101 Traning Loss: tensor(0.6105)\n",
      "15102 Traning Loss: tensor(0.7378)\n",
      "15103 Traning Loss: tensor(0.6699)\n",
      "15104 Traning Loss: tensor(0.7491)\n",
      "15105 Traning Loss: tensor(0.6918)\n",
      "15106 Traning Loss: tensor(0.7270)\n",
      "15107 Traning Loss: tensor(0.6248)\n",
      "15108 Traning Loss: tensor(0.6917)\n",
      "15109 Traning Loss: tensor(0.6780)\n",
      "15110 Traning Loss: tensor(0.6831)\n",
      "15111 Traning Loss: tensor(0.6525)\n",
      "15112 Traning Loss: tensor(0.7179)\n",
      "15113 Traning Loss: tensor(0.6730)\n",
      "15114 Traning Loss: tensor(0.6626)\n",
      "15115 Traning Loss: tensor(0.6987)\n",
      "15116 Traning Loss: tensor(0.7045)\n",
      "15117 Traning Loss: tensor(0.6734)\n",
      "15118 Traning Loss: tensor(0.6364)\n",
      "15119 Traning Loss: tensor(0.6359)\n",
      "15120 Traning Loss: tensor(0.6471)\n",
      "15121 Traning Loss: tensor(0.6810)\n",
      "15122 Traning Loss: tensor(0.6632)\n",
      "15123 Traning Loss: tensor(0.6627)\n",
      "15124 Traning Loss: tensor(0.6300)\n",
      "15125 Traning Loss: tensor(0.6611)\n",
      "15126 Traning Loss: tensor(0.6576)\n",
      "15127 Traning Loss: tensor(0.6443)\n",
      "15128 Traning Loss: tensor(0.6518)\n",
      "15129 Traning Loss: tensor(0.6873)\n",
      "15130 Traning Loss: tensor(0.6788)\n",
      "15131 Traning Loss: tensor(0.6469)\n",
      "15132 Traning Loss: tensor(0.6937)\n",
      "15133 Traning Loss: tensor(0.6772)\n",
      "15134 Traning Loss: tensor(0.6826)\n",
      "15135 Traning Loss: tensor(0.6510)\n",
      "15136 Traning Loss: tensor(0.6731)\n",
      "15137 Traning Loss: tensor(0.6384)\n",
      "15138 Traning Loss: tensor(0.6314)\n",
      "15139 Traning Loss: tensor(0.7058)\n",
      "15140 Traning Loss: tensor(0.6152)\n",
      "15141 Traning Loss: tensor(0.7502)\n",
      "15142 Traning Loss: tensor(0.6404)\n",
      "15143 Traning Loss: tensor(0.6056)\n",
      "15144 Traning Loss: tensor(0.6820)\n",
      "15145 Traning Loss: tensor(0.6623)\n",
      "15146 Traning Loss: tensor(0.6660)\n",
      "15147 Traning Loss: tensor(0.6506)\n",
      "15148 Traning Loss: tensor(0.6213)\n",
      "15149 Traning Loss: tensor(0.6459)\n",
      "15150 Traning Loss: tensor(0.6976)\n",
      "15151 Traning Loss: tensor(0.6636)\n",
      "15152 Traning Loss: tensor(0.6334)\n",
      "15153 Traning Loss: tensor(0.6362)\n",
      "15154 Traning Loss: tensor(0.6539)\n",
      "15155 Traning Loss: tensor(0.6126)\n",
      "15156 Traning Loss: tensor(0.6986)\n",
      "15157 Traning Loss: tensor(0.7831)\n",
      "15158 Traning Loss: tensor(0.7446)\n",
      "15159 Traning Loss: tensor(0.6784)\n",
      "15160 Traning Loss: tensor(0.6672)\n",
      "15161 Traning Loss: tensor(0.6714)\n",
      "15162 Traning Loss: tensor(0.6432)\n",
      "15163 Traning Loss: tensor(0.6188)\n",
      "15164 Traning Loss: tensor(0.6408)\n",
      "15165 Traning Loss: tensor(0.6264)\n",
      "15166 Traning Loss: tensor(0.6338)\n",
      "15167 Traning Loss: tensor(0.7209)\n",
      "15168 Traning Loss: tensor(0.6201)\n",
      "15169 Traning Loss: tensor(0.6943)\n",
      "15170 Traning Loss: tensor(0.6146)\n",
      "15171 Traning Loss: tensor(0.7319)\n",
      "15172 Traning Loss: tensor(0.6049)\n",
      "15173 Traning Loss: tensor(0.6428)\n",
      "15174 Traning Loss: tensor(0.6519)\n",
      "15175 Traning Loss: tensor(0.6196)\n",
      "15176 Traning Loss: tensor(0.6448)\n",
      "15177 Traning Loss: tensor(0.6976)\n",
      "15178 Traning Loss: tensor(0.6074)\n",
      "15179 Traning Loss: tensor(0.6423)\n",
      "15180 Traning Loss: tensor(0.6735)\n",
      "15181 Traning Loss: tensor(0.6748)\n",
      "15182 Traning Loss: tensor(0.6456)\n",
      "15183 Traning Loss: tensor(0.6258)\n",
      "15184 Traning Loss: tensor(0.7192)\n",
      "15185 Traning Loss: tensor(0.6681)\n",
      "15186 Traning Loss: tensor(0.6293)\n",
      "15187 Traning Loss: tensor(0.6610)\n",
      "15188 Traning Loss: tensor(0.6678)\n",
      "15189 Traning Loss: tensor(0.6243)\n",
      "15190 Traning Loss: tensor(0.7270)\n",
      "15191 Traning Loss: tensor(0.6542)\n",
      "15192 Traning Loss: tensor(0.6667)\n",
      "15193 Traning Loss: tensor(0.6832)\n",
      "15194 Traning Loss: tensor(0.6086)\n",
      "15195 Traning Loss: tensor(0.5757)\n",
      "15196 Traning Loss: tensor(0.6855)\n",
      "15197 Traning Loss: tensor(0.6557)\n",
      "15198 Traning Loss: tensor(0.5717)\n",
      "15199 Traning Loss: tensor(0.6874)\n",
      "15200 Traning Loss: tensor(0.6445)\n",
      "15201 Traning Loss: tensor(0.6498)\n",
      "15202 Traning Loss: tensor(0.6940)\n",
      "15203 Traning Loss: tensor(0.6417)\n",
      "15204 Traning Loss: tensor(0.6243)\n",
      "15205 Traning Loss: tensor(0.6084)\n",
      "15206 Traning Loss: tensor(0.6597)\n",
      "15207 Traning Loss: tensor(0.6263)\n",
      "15208 Traning Loss: tensor(0.6512)\n",
      "15209 Traning Loss: tensor(0.6748)\n",
      "15210 Traning Loss: tensor(0.5972)\n",
      "15211 Traning Loss: tensor(0.6466)\n",
      "15212 Traning Loss: tensor(0.6051)\n",
      "15213 Traning Loss: tensor(0.6813)\n",
      "15214 Traning Loss: tensor(0.6299)\n",
      "15215 Traning Loss: tensor(0.6051)\n",
      "15216 Traning Loss: tensor(0.6633)\n",
      "15217 Traning Loss: tensor(0.6876)\n",
      "15218 Traning Loss: tensor(0.6265)\n",
      "15219 Traning Loss: tensor(0.5632)\n",
      "15220 Traning Loss: tensor(0.6530)\n",
      "15221 Traning Loss: tensor(0.7024)\n",
      "15222 Traning Loss: tensor(0.5986)\n",
      "15223 Traning Loss: tensor(0.6343)\n",
      "15224 Traning Loss: tensor(0.6867)\n",
      "15225 Traning Loss: tensor(0.6293)\n",
      "15226 Traning Loss: tensor(0.6466)\n",
      "15227 Traning Loss: tensor(0.6273)\n",
      "15228 Traning Loss: tensor(0.6210)\n",
      "15229 Traning Loss: tensor(0.5727)\n",
      "15230 Traning Loss: tensor(0.6908)\n",
      "15231 Traning Loss: tensor(0.5995)\n",
      "15232 Traning Loss: tensor(0.6174)\n",
      "15233 Traning Loss: tensor(0.6682)\n",
      "15234 Traning Loss: tensor(0.5926)\n",
      "15235 Traning Loss: tensor(0.6978)\n",
      "15236 Traning Loss: tensor(0.6198)\n",
      "15237 Traning Loss: tensor(0.6198)\n",
      "15238 Traning Loss: tensor(0.6032)\n",
      "15239 Traning Loss: tensor(0.5897)\n",
      "15240 Traning Loss: tensor(0.6298)\n",
      "15241 Traning Loss: tensor(0.6698)\n",
      "15242 Traning Loss: tensor(0.6354)\n",
      "15243 Traning Loss: tensor(0.6840)\n",
      "15244 Traning Loss: tensor(0.5930)\n",
      "15245 Traning Loss: tensor(0.6127)\n",
      "15246 Traning Loss: tensor(0.6601)\n",
      "15247 Traning Loss: tensor(0.5889)\n",
      "15248 Traning Loss: tensor(0.6606)\n",
      "15249 Traning Loss: tensor(0.6292)\n",
      "15250 Traning Loss: tensor(0.5844)\n",
      "15251 Traning Loss: tensor(0.5773)\n",
      "15252 Traning Loss: tensor(0.6446)\n",
      "15253 Traning Loss: tensor(0.6144)\n",
      "15254 Traning Loss: tensor(0.6654)\n",
      "15255 Traning Loss: tensor(0.6518)\n",
      "15256 Traning Loss: tensor(0.5679)\n",
      "15257 Traning Loss: tensor(0.6152)\n",
      "15258 Traning Loss: tensor(0.5908)\n",
      "15259 Traning Loss: tensor(0.5963)\n",
      "15260 Traning Loss: tensor(0.6214)\n",
      "15261 Traning Loss: tensor(0.5750)\n",
      "15262 Traning Loss: tensor(0.6296)\n",
      "15263 Traning Loss: tensor(0.6009)\n",
      "15264 Traning Loss: tensor(0.6759)\n",
      "15265 Traning Loss: tensor(0.7166)\n",
      "15266 Traning Loss: tensor(0.6409)\n",
      "15267 Traning Loss: tensor(0.5878)\n",
      "15268 Traning Loss: tensor(0.7397)\n",
      "15269 Traning Loss: tensor(0.6002)\n",
      "15270 Traning Loss: tensor(0.6006)\n",
      "15271 Traning Loss: tensor(0.5947)\n",
      "15272 Traning Loss: tensor(0.5928)\n",
      "15273 Traning Loss: tensor(0.6054)\n",
      "15274 Traning Loss: tensor(0.6809)\n",
      "15275 Traning Loss: tensor(0.6351)\n",
      "15276 Traning Loss: tensor(0.5932)\n",
      "15277 Traning Loss: tensor(0.6273)\n",
      "15278 Traning Loss: tensor(0.5876)\n",
      "15279 Traning Loss: tensor(0.6580)\n",
      "15280 Traning Loss: tensor(0.6408)\n",
      "15281 Traning Loss: tensor(0.5971)\n",
      "15282 Traning Loss: tensor(0.6517)\n",
      "15283 Traning Loss: tensor(0.6593)\n",
      "15284 Traning Loss: tensor(0.5973)\n",
      "15285 Traning Loss: tensor(0.6342)\n",
      "15286 Traning Loss: tensor(0.5769)\n",
      "15287 Traning Loss: tensor(0.5787)\n",
      "15288 Traning Loss: tensor(0.6270)\n",
      "15289 Traning Loss: tensor(0.6471)\n",
      "15290 Traning Loss: tensor(0.6343)\n",
      "15291 Traning Loss: tensor(0.6713)\n",
      "15292 Traning Loss: tensor(0.6199)\n",
      "15293 Traning Loss: tensor(0.6331)\n",
      "15294 Traning Loss: tensor(0.6135)\n",
      "15295 Traning Loss: tensor(0.6330)\n",
      "15296 Traning Loss: tensor(0.6179)\n",
      "15297 Traning Loss: tensor(0.6045)\n",
      "15298 Traning Loss: tensor(0.5951)\n",
      "15299 Traning Loss: tensor(0.6979)\n",
      "15300 Traning Loss: tensor(0.6667)\n",
      "15301 Traning Loss: tensor(0.6169)\n",
      "15302 Traning Loss: tensor(0.6075)\n",
      "15303 Traning Loss: tensor(0.5849)\n",
      "15304 Traning Loss: tensor(0.5933)\n",
      "15305 Traning Loss: tensor(0.6971)\n",
      "15306 Traning Loss: tensor(0.6076)\n",
      "15307 Traning Loss: tensor(0.6094)\n",
      "15308 Traning Loss: tensor(0.6259)\n",
      "15309 Traning Loss: tensor(0.6029)\n",
      "15310 Traning Loss: tensor(0.5706)\n",
      "15311 Traning Loss: tensor(0.6199)\n",
      "15312 Traning Loss: tensor(0.5973)\n",
      "15313 Traning Loss: tensor(0.5730)\n",
      "15314 Traning Loss: tensor(0.6314)\n",
      "15315 Traning Loss: tensor(0.6176)\n",
      "15316 Traning Loss: tensor(0.6684)\n",
      "15317 Traning Loss: tensor(0.5898)\n",
      "15318 Traning Loss: tensor(0.6427)\n",
      "15319 Traning Loss: tensor(0.6415)\n",
      "15320 Traning Loss: tensor(0.5728)\n",
      "15321 Traning Loss: tensor(0.6102)\n",
      "15322 Traning Loss: tensor(0.6747)\n",
      "15323 Traning Loss: tensor(0.6077)\n",
      "15324 Traning Loss: tensor(0.5939)\n",
      "15325 Traning Loss: tensor(0.6111)\n",
      "15326 Traning Loss: tensor(0.5831)\n",
      "15327 Traning Loss: tensor(0.6033)\n",
      "15328 Traning Loss: tensor(0.6135)\n",
      "15329 Traning Loss: tensor(0.5558)\n",
      "15330 Traning Loss: tensor(0.7171)\n",
      "15331 Traning Loss: tensor(0.5848)\n",
      "15332 Traning Loss: tensor(0.6055)\n",
      "15333 Traning Loss: tensor(0.6492)\n",
      "15334 Traning Loss: tensor(0.6305)\n",
      "15335 Traning Loss: tensor(0.6016)\n",
      "15336 Traning Loss: tensor(0.6464)\n",
      "15337 Traning Loss: tensor(0.6002)\n",
      "15338 Traning Loss: tensor(0.6052)\n",
      "15339 Traning Loss: tensor(0.6849)\n",
      "15340 Traning Loss: tensor(0.6740)\n",
      "15341 Traning Loss: tensor(0.6557)\n",
      "15342 Traning Loss: tensor(0.5892)\n",
      "15343 Traning Loss: tensor(0.6444)\n",
      "15344 Traning Loss: tensor(0.6068)\n",
      "15345 Traning Loss: tensor(0.6264)\n",
      "15346 Traning Loss: tensor(0.5597)\n",
      "15347 Traning Loss: tensor(0.6281)\n",
      "15348 Traning Loss: tensor(0.6833)\n",
      "15349 Traning Loss: tensor(0.5838)\n",
      "15350 Traning Loss: tensor(0.6060)\n",
      "15351 Traning Loss: tensor(0.5728)\n",
      "15352 Traning Loss: tensor(0.6075)\n",
      "15353 Traning Loss: tensor(0.6754)\n",
      "15354 Traning Loss: tensor(0.5979)\n",
      "15355 Traning Loss: tensor(0.6313)\n",
      "15356 Traning Loss: tensor(0.6120)\n",
      "15357 Traning Loss: tensor(0.6419)\n",
      "15358 Traning Loss: tensor(0.5511)\n",
      "15359 Traning Loss: tensor(0.6293)\n",
      "15360 Traning Loss: tensor(0.5963)\n",
      "15361 Traning Loss: tensor(0.5854)\n",
      "15362 Traning Loss: tensor(0.6122)\n",
      "15363 Traning Loss: tensor(0.6126)\n",
      "15364 Traning Loss: tensor(0.6164)\n",
      "15365 Traning Loss: tensor(0.5779)\n",
      "15366 Traning Loss: tensor(0.6045)\n",
      "15367 Traning Loss: tensor(0.6583)\n",
      "15368 Traning Loss: tensor(0.6219)\n",
      "15369 Traning Loss: tensor(0.5898)\n",
      "15370 Traning Loss: tensor(0.6612)\n",
      "15371 Traning Loss: tensor(0.5608)\n",
      "15372 Traning Loss: tensor(0.5514)\n",
      "15373 Traning Loss: tensor(0.6380)\n",
      "15374 Traning Loss: tensor(0.6508)\n",
      "15375 Traning Loss: tensor(0.6316)\n",
      "15376 Traning Loss: tensor(0.5365)\n",
      "15377 Traning Loss: tensor(0.6842)\n",
      "15378 Traning Loss: tensor(0.6021)\n",
      "15379 Traning Loss: tensor(0.5385)\n",
      "15380 Traning Loss: tensor(0.6272)\n",
      "15381 Traning Loss: tensor(0.6759)\n",
      "15382 Traning Loss: tensor(0.5662)\n",
      "15383 Traning Loss: tensor(0.6000)\n",
      "15384 Traning Loss: tensor(0.6301)\n",
      "15385 Traning Loss: tensor(0.5535)\n",
      "15386 Traning Loss: tensor(0.6719)\n",
      "15387 Traning Loss: tensor(0.5763)\n",
      "15388 Traning Loss: tensor(0.5971)\n",
      "15389 Traning Loss: tensor(0.6366)\n",
      "15390 Traning Loss: tensor(0.5620)\n",
      "15391 Traning Loss: tensor(0.5969)\n",
      "15392 Traning Loss: tensor(0.6256)\n",
      "15393 Traning Loss: tensor(0.6174)\n",
      "15394 Traning Loss: tensor(0.5618)\n",
      "15395 Traning Loss: tensor(0.6833)\n",
      "15396 Traning Loss: tensor(0.5693)\n",
      "15397 Traning Loss: tensor(0.6062)\n",
      "15398 Traning Loss: tensor(0.5597)\n",
      "15399 Traning Loss: tensor(0.6089)\n",
      "15400 Traning Loss: tensor(0.6077)\n",
      "15401 Traning Loss: tensor(0.6279)\n",
      "15402 Traning Loss: tensor(0.6314)\n",
      "15403 Traning Loss: tensor(0.5382)\n",
      "15404 Traning Loss: tensor(0.6879)\n",
      "15405 Traning Loss: tensor(0.5879)\n",
      "15406 Traning Loss: tensor(0.6231)\n",
      "15407 Traning Loss: tensor(0.5971)\n",
      "15408 Traning Loss: tensor(0.6227)\n",
      "15409 Traning Loss: tensor(0.6425)\n",
      "15410 Traning Loss: tensor(0.6113)\n",
      "15411 Traning Loss: tensor(0.5451)\n",
      "15412 Traning Loss: tensor(0.5905)\n",
      "15413 Traning Loss: tensor(0.6405)\n",
      "15414 Traning Loss: tensor(0.6110)\n",
      "15415 Traning Loss: tensor(0.5269)\n",
      "15416 Traning Loss: tensor(0.6433)\n",
      "15417 Traning Loss: tensor(0.6057)\n",
      "15418 Traning Loss: tensor(0.6476)\n",
      "15419 Traning Loss: tensor(0.5767)\n",
      "15420 Traning Loss: tensor(0.5724)\n",
      "15421 Traning Loss: tensor(0.5511)\n",
      "15422 Traning Loss: tensor(0.5558)\n",
      "15423 Traning Loss: tensor(0.5587)\n",
      "15424 Traning Loss: tensor(0.6584)\n",
      "15425 Traning Loss: tensor(0.5797)\n",
      "15426 Traning Loss: tensor(0.5729)\n",
      "15427 Traning Loss: tensor(0.5634)\n",
      "15428 Traning Loss: tensor(0.5343)\n",
      "15429 Traning Loss: tensor(0.5705)\n",
      "15430 Traning Loss: tensor(0.5604)\n",
      "15431 Traning Loss: tensor(0.5307)\n",
      "15432 Traning Loss: tensor(0.5725)\n",
      "15433 Traning Loss: tensor(0.5888)\n",
      "15434 Traning Loss: tensor(0.5470)\n",
      "15435 Traning Loss: tensor(0.5561)\n",
      "15436 Traning Loss: tensor(0.5503)\n",
      "15437 Traning Loss: tensor(0.6485)\n",
      "15438 Traning Loss: tensor(0.6314)\n",
      "15439 Traning Loss: tensor(0.6445)\n",
      "15440 Traning Loss: tensor(0.6185)\n",
      "15441 Traning Loss: tensor(0.5816)\n",
      "15442 Traning Loss: tensor(0.5834)\n",
      "15443 Traning Loss: tensor(0.6050)\n",
      "15444 Traning Loss: tensor(0.5838)\n",
      "15445 Traning Loss: tensor(0.6007)\n",
      "15446 Traning Loss: tensor(0.5766)\n",
      "15447 Traning Loss: tensor(0.5443)\n",
      "15448 Traning Loss: tensor(0.6075)\n",
      "15449 Traning Loss: tensor(0.6085)\n",
      "15450 Traning Loss: tensor(0.6490)\n",
      "15451 Traning Loss: tensor(0.5705)\n",
      "15452 Traning Loss: tensor(0.6064)\n",
      "15453 Traning Loss: tensor(0.5279)\n",
      "15454 Traning Loss: tensor(0.5630)\n",
      "15455 Traning Loss: tensor(0.5495)\n",
      "15456 Traning Loss: tensor(0.6109)\n",
      "15457 Traning Loss: tensor(0.6757)\n",
      "15458 Traning Loss: tensor(0.6310)\n",
      "15459 Traning Loss: tensor(0.5233)\n",
      "15460 Traning Loss: tensor(0.5521)\n",
      "15461 Traning Loss: tensor(0.6112)\n",
      "15462 Traning Loss: tensor(0.5291)\n",
      "15463 Traning Loss: tensor(0.5863)\n",
      "15464 Traning Loss: tensor(0.5627)\n",
      "15465 Traning Loss: tensor(0.5658)\n",
      "15466 Traning Loss: tensor(0.5962)\n",
      "15467 Traning Loss: tensor(0.5837)\n",
      "15468 Traning Loss: tensor(0.6099)\n",
      "15469 Traning Loss: tensor(0.6408)\n",
      "15470 Traning Loss: tensor(0.5406)\n",
      "15471 Traning Loss: tensor(0.5861)\n",
      "15472 Traning Loss: tensor(0.5650)\n",
      "15473 Traning Loss: tensor(0.5740)\n",
      "15474 Traning Loss: tensor(0.6077)\n",
      "15475 Traning Loss: tensor(0.5761)\n",
      "15476 Traning Loss: tensor(0.5848)\n",
      "15477 Traning Loss: tensor(0.5162)\n",
      "15478 Traning Loss: tensor(0.5883)\n",
      "15479 Traning Loss: tensor(0.5362)\n",
      "15480 Traning Loss: tensor(0.5547)\n",
      "15481 Traning Loss: tensor(0.6369)\n",
      "15482 Traning Loss: tensor(0.5561)\n",
      "15483 Traning Loss: tensor(0.5432)\n",
      "15484 Traning Loss: tensor(0.5744)\n",
      "15485 Traning Loss: tensor(0.5704)\n",
      "15486 Traning Loss: tensor(0.6029)\n",
      "15487 Traning Loss: tensor(0.5414)\n",
      "15488 Traning Loss: tensor(0.5823)\n",
      "15489 Traning Loss: tensor(0.5473)\n",
      "15490 Traning Loss: tensor(0.5746)\n",
      "15491 Traning Loss: tensor(0.5692)\n",
      "15492 Traning Loss: tensor(0.5847)\n",
      "15493 Traning Loss: tensor(0.5309)\n",
      "15494 Traning Loss: tensor(0.5830)\n",
      "15495 Traning Loss: tensor(0.5537)\n",
      "15496 Traning Loss: tensor(0.6489)\n",
      "15497 Traning Loss: tensor(0.6008)\n",
      "15498 Traning Loss: tensor(0.5740)\n",
      "15499 Traning Loss: tensor(0.5535)\n",
      "15500 Traning Loss: tensor(0.5492)\n",
      "15501 Traning Loss: tensor(0.5775)\n",
      "15502 Traning Loss: tensor(0.5691)\n",
      "15503 Traning Loss: tensor(0.5407)\n",
      "15504 Traning Loss: tensor(0.4974)\n",
      "15505 Traning Loss: tensor(0.6145)\n",
      "15506 Traning Loss: tensor(0.5682)\n",
      "15507 Traning Loss: tensor(0.5185)\n",
      "15508 Traning Loss: tensor(0.5799)\n",
      "15509 Traning Loss: tensor(0.5466)\n",
      "15510 Traning Loss: tensor(0.5803)\n",
      "15511 Traning Loss: tensor(0.5204)\n",
      "15512 Traning Loss: tensor(0.5574)\n",
      "15513 Traning Loss: tensor(0.5755)\n",
      "15514 Traning Loss: tensor(0.5768)\n",
      "15515 Traning Loss: tensor(0.5518)\n",
      "15516 Traning Loss: tensor(0.6062)\n",
      "15517 Traning Loss: tensor(0.5509)\n",
      "15518 Traning Loss: tensor(0.5374)\n",
      "15519 Traning Loss: tensor(0.6114)\n",
      "15520 Traning Loss: tensor(0.5336)\n",
      "15521 Traning Loss: tensor(0.5322)\n",
      "15522 Traning Loss: tensor(0.6218)\n",
      "15523 Traning Loss: tensor(0.5264)\n",
      "15524 Traning Loss: tensor(0.5556)\n",
      "15525 Traning Loss: tensor(0.5767)\n",
      "15526 Traning Loss: tensor(0.5390)\n",
      "15527 Traning Loss: tensor(0.5373)\n",
      "15528 Traning Loss: tensor(0.5228)\n",
      "15529 Traning Loss: tensor(0.6051)\n",
      "15530 Traning Loss: tensor(0.5431)\n",
      "15531 Traning Loss: tensor(0.5334)\n",
      "15532 Traning Loss: tensor(0.5541)\n",
      "15533 Traning Loss: tensor(0.6493)\n",
      "15534 Traning Loss: tensor(0.5107)\n",
      "15535 Traning Loss: tensor(0.5374)\n",
      "15536 Traning Loss: tensor(0.5407)\n",
      "15537 Traning Loss: tensor(0.5308)\n",
      "15538 Traning Loss: tensor(0.5989)\n",
      "15539 Traning Loss: tensor(0.4947)\n",
      "15540 Traning Loss: tensor(0.5735)\n",
      "15541 Traning Loss: tensor(0.5396)\n",
      "15542 Traning Loss: tensor(0.6132)\n",
      "15543 Traning Loss: tensor(0.6252)\n",
      "15544 Traning Loss: tensor(0.5330)\n",
      "15545 Traning Loss: tensor(0.5634)\n",
      "15546 Traning Loss: tensor(0.5720)\n",
      "15547 Traning Loss: tensor(0.5534)\n",
      "15548 Traning Loss: tensor(0.5368)\n",
      "15549 Traning Loss: tensor(0.5085)\n",
      "15550 Traning Loss: tensor(0.5290)\n",
      "15551 Traning Loss: tensor(0.5869)\n",
      "15552 Traning Loss: tensor(0.5399)\n",
      "15553 Traning Loss: tensor(0.5211)\n",
      "15554 Traning Loss: tensor(0.5420)\n",
      "15555 Traning Loss: tensor(0.5429)\n",
      "15556 Traning Loss: tensor(0.5555)\n",
      "15557 Traning Loss: tensor(0.5903)\n",
      "15558 Traning Loss: tensor(0.5664)\n",
      "15559 Traning Loss: tensor(0.5037)\n",
      "15560 Traning Loss: tensor(0.5547)\n",
      "15561 Traning Loss: tensor(0.5920)\n",
      "15562 Traning Loss: tensor(0.5478)\n",
      "15563 Traning Loss: tensor(0.5529)\n",
      "15564 Traning Loss: tensor(0.5173)\n",
      "15565 Traning Loss: tensor(0.5280)\n",
      "15566 Traning Loss: tensor(0.5057)\n",
      "15567 Traning Loss: tensor(0.5584)\n",
      "15568 Traning Loss: tensor(0.5208)\n",
      "15569 Traning Loss: tensor(0.6100)\n",
      "15570 Traning Loss: tensor(0.5323)\n",
      "15571 Traning Loss: tensor(0.5524)\n",
      "15572 Traning Loss: tensor(0.5296)\n",
      "15573 Traning Loss: tensor(0.5373)\n",
      "15574 Traning Loss: tensor(0.5108)\n",
      "15575 Traning Loss: tensor(0.5466)\n",
      "15576 Traning Loss: tensor(0.5372)\n",
      "15577 Traning Loss: tensor(0.5394)\n",
      "15578 Traning Loss: tensor(0.5715)\n",
      "15579 Traning Loss: tensor(0.5554)\n",
      "15580 Traning Loss: tensor(0.4996)\n",
      "15581 Traning Loss: tensor(0.5972)\n",
      "15582 Traning Loss: tensor(0.6036)\n",
      "15583 Traning Loss: tensor(0.5849)\n",
      "15584 Traning Loss: tensor(0.5187)\n",
      "15585 Traning Loss: tensor(0.5839)\n",
      "15586 Traning Loss: tensor(0.4728)\n",
      "15587 Traning Loss: tensor(0.5471)\n",
      "15588 Traning Loss: tensor(0.5473)\n",
      "15589 Traning Loss: tensor(0.5562)\n",
      "15590 Traning Loss: tensor(0.5515)\n",
      "15591 Traning Loss: tensor(0.5191)\n",
      "15592 Traning Loss: tensor(0.5780)\n",
      "15593 Traning Loss: tensor(0.5864)\n",
      "15594 Traning Loss: tensor(0.5672)\n",
      "15595 Traning Loss: tensor(0.5620)\n",
      "15596 Traning Loss: tensor(0.5219)\n",
      "15597 Traning Loss: tensor(0.5390)\n",
      "15598 Traning Loss: tensor(0.5649)\n",
      "15599 Traning Loss: tensor(0.5458)\n",
      "15600 Traning Loss: tensor(0.5093)\n",
      "15601 Traning Loss: tensor(0.5395)\n",
      "15602 Traning Loss: tensor(0.5781)\n",
      "15603 Traning Loss: tensor(0.5173)\n",
      "15604 Traning Loss: tensor(0.5141)\n",
      "15605 Traning Loss: tensor(0.5283)\n",
      "15606 Traning Loss: tensor(0.5593)\n",
      "15607 Traning Loss: tensor(0.5314)\n",
      "15608 Traning Loss: tensor(0.5338)\n",
      "15609 Traning Loss: tensor(0.5200)\n",
      "15610 Traning Loss: tensor(0.5635)\n",
      "15611 Traning Loss: tensor(0.5485)\n",
      "15612 Traning Loss: tensor(0.5064)\n",
      "15613 Traning Loss: tensor(0.5869)\n",
      "15614 Traning Loss: tensor(0.5337)\n",
      "15615 Traning Loss: tensor(0.5743)\n",
      "15616 Traning Loss: tensor(0.4943)\n",
      "15617 Traning Loss: tensor(0.5034)\n",
      "15618 Traning Loss: tensor(0.5024)\n",
      "15619 Traning Loss: tensor(0.5480)\n",
      "15620 Traning Loss: tensor(0.5913)\n",
      "15621 Traning Loss: tensor(0.6275)\n",
      "15622 Traning Loss: tensor(0.5471)\n",
      "15623 Traning Loss: tensor(0.5335)\n",
      "15624 Traning Loss: tensor(0.5986)\n",
      "15625 Traning Loss: tensor(0.5061)\n",
      "15626 Traning Loss: tensor(0.5271)\n",
      "15627 Traning Loss: tensor(0.4976)\n",
      "15628 Traning Loss: tensor(0.5628)\n",
      "15629 Traning Loss: tensor(0.5445)\n",
      "15630 Traning Loss: tensor(0.5299)\n",
      "15631 Traning Loss: tensor(0.5238)\n",
      "15632 Traning Loss: tensor(0.5738)\n",
      "15633 Traning Loss: tensor(0.5825)\n",
      "15634 Traning Loss: tensor(0.4997)\n",
      "15635 Traning Loss: tensor(0.5041)\n",
      "15636 Traning Loss: tensor(0.5501)\n",
      "15637 Traning Loss: tensor(0.5098)\n",
      "15638 Traning Loss: tensor(0.5292)\n",
      "15639 Traning Loss: tensor(0.5726)\n",
      "15640 Traning Loss: tensor(0.4925)\n",
      "15641 Traning Loss: tensor(0.5034)\n",
      "15642 Traning Loss: tensor(0.5059)\n",
      "15643 Traning Loss: tensor(0.5670)\n",
      "15644 Traning Loss: tensor(0.5307)\n",
      "15645 Traning Loss: tensor(0.5396)\n",
      "15646 Traning Loss: tensor(0.5473)\n",
      "15647 Traning Loss: tensor(0.5931)\n",
      "15648 Traning Loss: tensor(0.5305)\n",
      "15649 Traning Loss: tensor(0.5158)\n",
      "15650 Traning Loss: tensor(0.5324)\n",
      "15651 Traning Loss: tensor(0.5535)\n",
      "15652 Traning Loss: tensor(0.5170)\n",
      "15653 Traning Loss: tensor(0.5537)\n",
      "15654 Traning Loss: tensor(0.5836)\n",
      "15655 Traning Loss: tensor(0.5349)\n",
      "15656 Traning Loss: tensor(0.5641)\n",
      "15657 Traning Loss: tensor(0.5743)\n",
      "15658 Traning Loss: tensor(0.5056)\n",
      "15659 Traning Loss: tensor(0.5471)\n",
      "15660 Traning Loss: tensor(0.5096)\n",
      "15661 Traning Loss: tensor(0.5456)\n",
      "15662 Traning Loss: tensor(0.6384)\n",
      "15663 Traning Loss: tensor(0.5352)\n",
      "15664 Traning Loss: tensor(0.5232)\n",
      "15665 Traning Loss: tensor(0.5439)\n",
      "15666 Traning Loss: tensor(0.5019)\n",
      "15667 Traning Loss: tensor(0.5678)\n",
      "15668 Traning Loss: tensor(0.4515)\n",
      "15669 Traning Loss: tensor(0.5095)\n",
      "15670 Traning Loss: tensor(0.5323)\n",
      "15671 Traning Loss: tensor(0.5231)\n",
      "15672 Traning Loss: tensor(0.5478)\n",
      "15673 Traning Loss: tensor(0.5614)\n",
      "15674 Traning Loss: tensor(0.5145)\n",
      "15675 Traning Loss: tensor(0.5392)\n",
      "15676 Traning Loss: tensor(0.5428)\n",
      "15677 Traning Loss: tensor(0.4910)\n",
      "15678 Traning Loss: tensor(0.4623)\n",
      "15679 Traning Loss: tensor(0.5362)\n",
      "15680 Traning Loss: tensor(0.5383)\n",
      "15681 Traning Loss: tensor(0.5234)\n",
      "15682 Traning Loss: tensor(0.5279)\n",
      "15683 Traning Loss: tensor(0.5176)\n",
      "15684 Traning Loss: tensor(0.5479)\n",
      "15685 Traning Loss: tensor(0.6034)\n",
      "15686 Traning Loss: tensor(0.5222)\n",
      "15687 Traning Loss: tensor(0.4845)\n",
      "15688 Traning Loss: tensor(0.5074)\n",
      "15689 Traning Loss: tensor(0.5377)\n",
      "15690 Traning Loss: tensor(0.4873)\n",
      "15691 Traning Loss: tensor(0.5727)\n",
      "15692 Traning Loss: tensor(0.5586)\n",
      "15693 Traning Loss: tensor(0.4992)\n",
      "15694 Traning Loss: tensor(0.5219)\n",
      "15695 Traning Loss: tensor(0.5931)\n",
      "15696 Traning Loss: tensor(0.5179)\n",
      "15697 Traning Loss: tensor(0.5090)\n",
      "15698 Traning Loss: tensor(0.4738)\n",
      "15699 Traning Loss: tensor(0.5033)\n",
      "15700 Traning Loss: tensor(0.4689)\n",
      "15701 Traning Loss: tensor(0.5083)\n",
      "15702 Traning Loss: tensor(0.4959)\n",
      "15703 Traning Loss: tensor(0.4793)\n",
      "15704 Traning Loss: tensor(0.5082)\n",
      "15705 Traning Loss: tensor(0.5009)\n",
      "15706 Traning Loss: tensor(0.5323)\n",
      "15707 Traning Loss: tensor(0.4997)\n",
      "15708 Traning Loss: tensor(0.5887)\n",
      "15709 Traning Loss: tensor(0.4904)\n",
      "15710 Traning Loss: tensor(0.5124)\n",
      "15711 Traning Loss: tensor(0.5324)\n",
      "15712 Traning Loss: tensor(0.5375)\n",
      "15713 Traning Loss: tensor(0.5087)\n",
      "15714 Traning Loss: tensor(0.4563)\n",
      "15715 Traning Loss: tensor(0.5270)\n",
      "15716 Traning Loss: tensor(0.5710)\n",
      "15717 Traning Loss: tensor(0.5449)\n",
      "15718 Traning Loss: tensor(0.5288)\n",
      "15719 Traning Loss: tensor(0.5259)\n",
      "15720 Traning Loss: tensor(0.4926)\n",
      "15721 Traning Loss: tensor(0.5046)\n",
      "15722 Traning Loss: tensor(0.5068)\n",
      "15723 Traning Loss: tensor(0.4869)\n",
      "15724 Traning Loss: tensor(0.5612)\n",
      "15725 Traning Loss: tensor(0.5463)\n",
      "15726 Traning Loss: tensor(0.4872)\n",
      "15727 Traning Loss: tensor(0.5274)\n",
      "15728 Traning Loss: tensor(0.5138)\n",
      "15729 Traning Loss: tensor(0.4794)\n",
      "15730 Traning Loss: tensor(0.4757)\n",
      "15731 Traning Loss: tensor(0.5349)\n",
      "15732 Traning Loss: tensor(0.5536)\n",
      "15733 Traning Loss: tensor(0.5009)\n",
      "15734 Traning Loss: tensor(0.4911)\n",
      "15735 Traning Loss: tensor(0.5380)\n",
      "15736 Traning Loss: tensor(0.5145)\n",
      "15737 Traning Loss: tensor(0.5431)\n",
      "15738 Traning Loss: tensor(0.4782)\n",
      "15739 Traning Loss: tensor(0.5279)\n",
      "15740 Traning Loss: tensor(0.5164)\n",
      "15741 Traning Loss: tensor(0.5379)\n",
      "15742 Traning Loss: tensor(0.5357)\n",
      "15743 Traning Loss: tensor(0.5604)\n",
      "15744 Traning Loss: tensor(0.5582)\n",
      "15745 Traning Loss: tensor(0.5056)\n",
      "15746 Traning Loss: tensor(0.5772)\n",
      "15747 Traning Loss: tensor(0.5386)\n",
      "15748 Traning Loss: tensor(0.4973)\n",
      "15749 Traning Loss: tensor(0.5296)\n",
      "15750 Traning Loss: tensor(0.5275)\n",
      "15751 Traning Loss: tensor(0.4846)\n",
      "15752 Traning Loss: tensor(0.4709)\n",
      "15753 Traning Loss: tensor(0.5212)\n",
      "15754 Traning Loss: tensor(0.5270)\n",
      "15755 Traning Loss: tensor(0.4878)\n",
      "15756 Traning Loss: tensor(0.4840)\n",
      "15757 Traning Loss: tensor(0.5503)\n",
      "15758 Traning Loss: tensor(0.5254)\n",
      "15759 Traning Loss: tensor(0.5286)\n",
      "15760 Traning Loss: tensor(0.5282)\n",
      "15761 Traning Loss: tensor(0.4643)\n",
      "15762 Traning Loss: tensor(0.4837)\n",
      "15763 Traning Loss: tensor(0.4774)\n",
      "15764 Traning Loss: tensor(0.5239)\n",
      "15765 Traning Loss: tensor(0.4925)\n",
      "15766 Traning Loss: tensor(0.6277)\n",
      "15767 Traning Loss: tensor(0.5105)\n",
      "15768 Traning Loss: tensor(0.5962)\n",
      "15769 Traning Loss: tensor(0.5015)\n",
      "15770 Traning Loss: tensor(0.5510)\n",
      "15771 Traning Loss: tensor(0.4898)\n",
      "15772 Traning Loss: tensor(0.4796)\n",
      "15773 Traning Loss: tensor(0.5728)\n",
      "15774 Traning Loss: tensor(0.4814)\n",
      "15775 Traning Loss: tensor(0.4826)\n",
      "15776 Traning Loss: tensor(0.5280)\n",
      "15777 Traning Loss: tensor(0.5831)\n",
      "15778 Traning Loss: tensor(0.4825)\n",
      "15779 Traning Loss: tensor(0.4843)\n",
      "15780 Traning Loss: tensor(0.5145)\n",
      "15781 Traning Loss: tensor(0.5416)\n",
      "15782 Traning Loss: tensor(0.5121)\n",
      "15783 Traning Loss: tensor(0.5125)\n",
      "15784 Traning Loss: tensor(0.4297)\n",
      "15785 Traning Loss: tensor(0.5036)\n",
      "15786 Traning Loss: tensor(0.4951)\n",
      "15787 Traning Loss: tensor(0.5176)\n",
      "15788 Traning Loss: tensor(0.5554)\n",
      "15789 Traning Loss: tensor(0.5104)\n",
      "15790 Traning Loss: tensor(0.5003)\n",
      "15791 Traning Loss: tensor(0.5010)\n",
      "15792 Traning Loss: tensor(0.4919)\n",
      "15793 Traning Loss: tensor(0.4935)\n",
      "15794 Traning Loss: tensor(0.4923)\n",
      "15795 Traning Loss: tensor(0.5805)\n",
      "15796 Traning Loss: tensor(0.4861)\n",
      "15797 Traning Loss: tensor(0.4965)\n",
      "15798 Traning Loss: tensor(0.4828)\n",
      "15799 Traning Loss: tensor(0.5503)\n",
      "15800 Traning Loss: tensor(0.5024)\n",
      "15801 Traning Loss: tensor(0.4867)\n",
      "15802 Traning Loss: tensor(0.4708)\n",
      "15803 Traning Loss: tensor(0.5221)\n",
      "15804 Traning Loss: tensor(0.5170)\n",
      "15805 Traning Loss: tensor(0.4782)\n",
      "15806 Traning Loss: tensor(0.5763)\n",
      "15807 Traning Loss: tensor(0.4772)\n",
      "15808 Traning Loss: tensor(0.5337)\n",
      "15809 Traning Loss: tensor(0.4567)\n",
      "15810 Traning Loss: tensor(0.4911)\n",
      "15811 Traning Loss: tensor(0.4797)\n",
      "15812 Traning Loss: tensor(0.4970)\n",
      "15813 Traning Loss: tensor(0.4964)\n",
      "15814 Traning Loss: tensor(0.4802)\n",
      "15815 Traning Loss: tensor(0.5003)\n",
      "15816 Traning Loss: tensor(0.4909)\n",
      "15817 Traning Loss: tensor(0.5013)\n",
      "15818 Traning Loss: tensor(0.4941)\n",
      "15819 Traning Loss: tensor(0.4906)\n",
      "15820 Traning Loss: tensor(0.4894)\n",
      "15821 Traning Loss: tensor(0.4722)\n",
      "15822 Traning Loss: tensor(0.5249)\n",
      "15823 Traning Loss: tensor(0.5337)\n",
      "15824 Traning Loss: tensor(0.5032)\n",
      "15825 Traning Loss: tensor(0.5580)\n",
      "15826 Traning Loss: tensor(0.5349)\n",
      "15827 Traning Loss: tensor(0.5328)\n",
      "15828 Traning Loss: tensor(0.5032)\n",
      "15829 Traning Loss: tensor(0.5002)\n",
      "15830 Traning Loss: tensor(0.4805)\n",
      "15831 Traning Loss: tensor(0.4900)\n",
      "15832 Traning Loss: tensor(0.5034)\n",
      "15833 Traning Loss: tensor(0.4658)\n",
      "15834 Traning Loss: tensor(0.5604)\n",
      "15835 Traning Loss: tensor(0.4894)\n",
      "15836 Traning Loss: tensor(0.4751)\n",
      "15837 Traning Loss: tensor(0.5000)\n",
      "15838 Traning Loss: tensor(0.4991)\n",
      "15839 Traning Loss: tensor(0.4488)\n",
      "15840 Traning Loss: tensor(0.4606)\n",
      "15841 Traning Loss: tensor(0.5787)\n",
      "15842 Traning Loss: tensor(0.5207)\n",
      "15843 Traning Loss: tensor(0.5409)\n",
      "15844 Traning Loss: tensor(0.4977)\n",
      "15845 Traning Loss: tensor(0.4658)\n",
      "15846 Traning Loss: tensor(0.5282)\n",
      "15847 Traning Loss: tensor(0.5223)\n",
      "15848 Traning Loss: tensor(0.4915)\n",
      "15849 Traning Loss: tensor(0.4701)\n",
      "15850 Traning Loss: tensor(0.4974)\n",
      "15851 Traning Loss: tensor(0.5207)\n",
      "15852 Traning Loss: tensor(0.4779)\n",
      "15853 Traning Loss: tensor(0.4600)\n",
      "15854 Traning Loss: tensor(0.4776)\n",
      "15855 Traning Loss: tensor(0.4988)\n",
      "15856 Traning Loss: tensor(0.5226)\n",
      "15857 Traning Loss: tensor(0.4876)\n",
      "15858 Traning Loss: tensor(0.4948)\n",
      "15859 Traning Loss: tensor(0.4887)\n",
      "15860 Traning Loss: tensor(0.4561)\n",
      "15861 Traning Loss: tensor(0.5076)\n",
      "15862 Traning Loss: tensor(0.4791)\n",
      "15863 Traning Loss: tensor(0.4653)\n",
      "15864 Traning Loss: tensor(0.4773)\n",
      "15865 Traning Loss: tensor(0.4775)\n",
      "15866 Traning Loss: tensor(0.4627)\n",
      "15867 Traning Loss: tensor(0.4538)\n",
      "15868 Traning Loss: tensor(0.5384)\n",
      "15869 Traning Loss: tensor(0.4510)\n",
      "15870 Traning Loss: tensor(0.4759)\n",
      "15871 Traning Loss: tensor(0.4517)\n",
      "15872 Traning Loss: tensor(0.5135)\n",
      "15873 Traning Loss: tensor(0.4869)\n",
      "15874 Traning Loss: tensor(0.4835)\n",
      "15875 Traning Loss: tensor(0.5327)\n",
      "15876 Traning Loss: tensor(0.4322)\n",
      "15877 Traning Loss: tensor(0.5003)\n",
      "15878 Traning Loss: tensor(0.5306)\n",
      "15879 Traning Loss: tensor(0.5292)\n",
      "15880 Traning Loss: tensor(0.4995)\n",
      "15881 Traning Loss: tensor(0.5177)\n",
      "15882 Traning Loss: tensor(0.5087)\n",
      "15883 Traning Loss: tensor(0.5414)\n",
      "15884 Traning Loss: tensor(0.4638)\n",
      "15885 Traning Loss: tensor(0.4389)\n",
      "15886 Traning Loss: tensor(0.4805)\n",
      "15887 Traning Loss: tensor(0.4891)\n",
      "15888 Traning Loss: tensor(0.4645)\n",
      "15889 Traning Loss: tensor(0.4678)\n",
      "15890 Traning Loss: tensor(0.4599)\n",
      "15891 Traning Loss: tensor(0.5051)\n",
      "15892 Traning Loss: tensor(0.4620)\n",
      "15893 Traning Loss: tensor(0.5207)\n",
      "15894 Traning Loss: tensor(0.4275)\n",
      "15895 Traning Loss: tensor(0.4693)\n",
      "15896 Traning Loss: tensor(0.4829)\n",
      "15897 Traning Loss: tensor(0.4272)\n",
      "15898 Traning Loss: tensor(0.4885)\n",
      "15899 Traning Loss: tensor(0.4651)\n",
      "15900 Traning Loss: tensor(0.4592)\n",
      "15901 Traning Loss: tensor(0.4730)\n",
      "15902 Traning Loss: tensor(0.4443)\n",
      "15903 Traning Loss: tensor(0.5330)\n",
      "15904 Traning Loss: tensor(0.5821)\n",
      "15905 Traning Loss: tensor(0.4697)\n",
      "15906 Traning Loss: tensor(0.5081)\n",
      "15907 Traning Loss: tensor(0.4475)\n",
      "15908 Traning Loss: tensor(0.5016)\n",
      "15909 Traning Loss: tensor(0.4895)\n",
      "15910 Traning Loss: tensor(0.4485)\n",
      "15911 Traning Loss: tensor(0.4495)\n",
      "15912 Traning Loss: tensor(0.4355)\n",
      "15913 Traning Loss: tensor(0.4505)\n",
      "15914 Traning Loss: tensor(0.4593)\n",
      "15915 Traning Loss: tensor(0.4750)\n",
      "15916 Traning Loss: tensor(0.4665)\n",
      "15917 Traning Loss: tensor(0.4848)\n",
      "15918 Traning Loss: tensor(0.4531)\n",
      "15919 Traning Loss: tensor(0.4860)\n",
      "15920 Traning Loss: tensor(0.4559)\n",
      "15921 Traning Loss: tensor(0.4682)\n",
      "15922 Traning Loss: tensor(0.4470)\n",
      "15923 Traning Loss: tensor(0.4577)\n",
      "15924 Traning Loss: tensor(0.4783)\n",
      "15925 Traning Loss: tensor(0.5508)\n",
      "15926 Traning Loss: tensor(0.5235)\n",
      "15927 Traning Loss: tensor(0.4849)\n",
      "15928 Traning Loss: tensor(0.4450)\n",
      "15929 Traning Loss: tensor(0.4392)\n",
      "15930 Traning Loss: tensor(0.4818)\n",
      "15931 Traning Loss: tensor(0.5751)\n",
      "15932 Traning Loss: tensor(0.4102)\n",
      "15933 Traning Loss: tensor(0.5056)\n",
      "15934 Traning Loss: tensor(0.5424)\n",
      "15935 Traning Loss: tensor(0.4548)\n",
      "15936 Traning Loss: tensor(0.4340)\n",
      "15937 Traning Loss: tensor(0.4912)\n",
      "15938 Traning Loss: tensor(0.4618)\n",
      "15939 Traning Loss: tensor(0.5011)\n",
      "15940 Traning Loss: tensor(0.5364)\n",
      "15941 Traning Loss: tensor(0.5438)\n",
      "15942 Traning Loss: tensor(0.4963)\n",
      "15943 Traning Loss: tensor(0.4455)\n",
      "15944 Traning Loss: tensor(0.4522)\n",
      "15945 Traning Loss: tensor(0.4799)\n",
      "15946 Traning Loss: tensor(0.4090)\n",
      "15947 Traning Loss: tensor(0.4511)\n",
      "15948 Traning Loss: tensor(0.4401)\n",
      "15949 Traning Loss: tensor(0.4495)\n",
      "15950 Traning Loss: tensor(0.4636)\n",
      "15951 Traning Loss: tensor(0.4293)\n",
      "15952 Traning Loss: tensor(0.4482)\n",
      "15953 Traning Loss: tensor(0.4474)\n",
      "15954 Traning Loss: tensor(0.4567)\n",
      "15955 Traning Loss: tensor(0.4791)\n",
      "15956 Traning Loss: tensor(0.5049)\n",
      "15957 Traning Loss: tensor(0.5023)\n",
      "15958 Traning Loss: tensor(0.4915)\n",
      "15959 Traning Loss: tensor(0.4821)\n",
      "15960 Traning Loss: tensor(0.4895)\n",
      "15961 Traning Loss: tensor(0.4717)\n",
      "15962 Traning Loss: tensor(0.4828)\n",
      "15963 Traning Loss: tensor(0.4699)\n",
      "15964 Traning Loss: tensor(0.4546)\n",
      "15965 Traning Loss: tensor(0.4593)\n",
      "15966 Traning Loss: tensor(0.5549)\n",
      "15967 Traning Loss: tensor(0.4251)\n",
      "15968 Traning Loss: tensor(0.4851)\n",
      "15969 Traning Loss: tensor(0.4224)\n",
      "15970 Traning Loss: tensor(0.4789)\n",
      "15971 Traning Loss: tensor(0.5172)\n",
      "15972 Traning Loss: tensor(0.4794)\n",
      "15973 Traning Loss: tensor(0.4911)\n",
      "15974 Traning Loss: tensor(0.4749)\n",
      "15975 Traning Loss: tensor(0.4467)\n",
      "15976 Traning Loss: tensor(0.4180)\n",
      "15977 Traning Loss: tensor(0.4542)\n",
      "15978 Traning Loss: tensor(0.4665)\n",
      "15979 Traning Loss: tensor(0.4465)\n",
      "15980 Traning Loss: tensor(0.4875)\n",
      "15981 Traning Loss: tensor(0.4557)\n",
      "15982 Traning Loss: tensor(0.4582)\n",
      "15983 Traning Loss: tensor(0.4694)\n",
      "15984 Traning Loss: tensor(0.4455)\n",
      "15985 Traning Loss: tensor(0.5386)\n",
      "15986 Traning Loss: tensor(0.5097)\n",
      "15987 Traning Loss: tensor(0.4889)\n",
      "15988 Traning Loss: tensor(0.4639)\n",
      "15989 Traning Loss: tensor(0.5884)\n",
      "15990 Traning Loss: tensor(0.4966)\n",
      "15991 Traning Loss: tensor(0.4489)\n",
      "15992 Traning Loss: tensor(0.4570)\n",
      "15993 Traning Loss: tensor(0.4361)\n",
      "15994 Traning Loss: tensor(0.4803)\n",
      "15995 Traning Loss: tensor(0.4117)\n",
      "15996 Traning Loss: tensor(0.4797)\n",
      "15997 Traning Loss: tensor(0.4788)\n",
      "15998 Traning Loss: tensor(0.4941)\n",
      "15999 Traning Loss: tensor(0.4758)\n",
      "16000 Traning Loss: tensor(0.4991)\n",
      "16001 Traning Loss: tensor(0.5113)\n",
      "16002 Traning Loss: tensor(0.4973)\n",
      "16003 Traning Loss: tensor(0.4723)\n",
      "16004 Traning Loss: tensor(0.4342)\n",
      "16005 Traning Loss: tensor(0.4715)\n",
      "16006 Traning Loss: tensor(0.4659)\n",
      "16007 Traning Loss: tensor(0.4516)\n",
      "16008 Traning Loss: tensor(0.5136)\n",
      "16009 Traning Loss: tensor(0.5295)\n",
      "16010 Traning Loss: tensor(0.4443)\n",
      "16011 Traning Loss: tensor(0.4658)\n",
      "16012 Traning Loss: tensor(0.4874)\n",
      "16013 Traning Loss: tensor(0.4706)\n",
      "16014 Traning Loss: tensor(0.4290)\n",
      "16015 Traning Loss: tensor(0.4316)\n",
      "16016 Traning Loss: tensor(0.5027)\n",
      "16017 Traning Loss: tensor(0.4841)\n",
      "16018 Traning Loss: tensor(0.4361)\n",
      "16019 Traning Loss: tensor(0.4850)\n",
      "16020 Traning Loss: tensor(0.4703)\n",
      "16021 Traning Loss: tensor(0.4411)\n",
      "16022 Traning Loss: tensor(0.4261)\n",
      "16023 Traning Loss: tensor(0.4471)\n",
      "16024 Traning Loss: tensor(0.4480)\n",
      "16025 Traning Loss: tensor(0.4825)\n",
      "16026 Traning Loss: tensor(0.4958)\n",
      "16027 Traning Loss: tensor(0.5409)\n",
      "16028 Traning Loss: tensor(0.4504)\n",
      "16029 Traning Loss: tensor(0.4288)\n",
      "16030 Traning Loss: tensor(0.4730)\n",
      "16031 Traning Loss: tensor(0.4215)\n",
      "16032 Traning Loss: tensor(0.5018)\n",
      "16033 Traning Loss: tensor(0.5002)\n",
      "16034 Traning Loss: tensor(0.4952)\n",
      "16035 Traning Loss: tensor(0.4197)\n",
      "16036 Traning Loss: tensor(0.5022)\n",
      "16037 Traning Loss: tensor(0.5135)\n",
      "16038 Traning Loss: tensor(0.4382)\n",
      "16039 Traning Loss: tensor(0.4639)\n",
      "16040 Traning Loss: tensor(0.4693)\n",
      "16041 Traning Loss: tensor(0.4365)\n",
      "16042 Traning Loss: tensor(0.4760)\n",
      "16043 Traning Loss: tensor(0.5441)\n",
      "16044 Traning Loss: tensor(0.4827)\n",
      "16045 Traning Loss: tensor(0.4978)\n",
      "16046 Traning Loss: tensor(0.5304)\n",
      "16047 Traning Loss: tensor(0.4601)\n",
      "16048 Traning Loss: tensor(0.4171)\n",
      "16049 Traning Loss: tensor(0.4609)\n",
      "16050 Traning Loss: tensor(0.4091)\n",
      "16051 Traning Loss: tensor(0.4442)\n",
      "16052 Traning Loss: tensor(0.4852)\n",
      "16053 Traning Loss: tensor(0.4128)\n",
      "16054 Traning Loss: tensor(0.4579)\n",
      "16055 Traning Loss: tensor(0.4881)\n",
      "16056 Traning Loss: tensor(0.4633)\n",
      "16057 Traning Loss: tensor(0.4469)\n",
      "16058 Traning Loss: tensor(0.4530)\n",
      "16059 Traning Loss: tensor(0.4259)\n",
      "16060 Traning Loss: tensor(0.4381)\n",
      "16061 Traning Loss: tensor(0.4589)\n",
      "16062 Traning Loss: tensor(0.4557)\n",
      "16063 Traning Loss: tensor(0.4877)\n",
      "16064 Traning Loss: tensor(0.4114)\n",
      "16065 Traning Loss: tensor(0.4148)\n",
      "16066 Traning Loss: tensor(0.4650)\n",
      "16067 Traning Loss: tensor(0.4498)\n",
      "16068 Traning Loss: tensor(0.4774)\n",
      "16069 Traning Loss: tensor(0.5195)\n",
      "16070 Traning Loss: tensor(0.5005)\n",
      "16071 Traning Loss: tensor(0.4251)\n",
      "16072 Traning Loss: tensor(0.4348)\n",
      "16073 Traning Loss: tensor(0.4962)\n",
      "16074 Traning Loss: tensor(0.4637)\n",
      "16075 Traning Loss: tensor(0.4741)\n",
      "16076 Traning Loss: tensor(0.4277)\n",
      "16077 Traning Loss: tensor(0.4946)\n",
      "16078 Traning Loss: tensor(0.4805)\n",
      "16079 Traning Loss: tensor(0.4706)\n",
      "16080 Traning Loss: tensor(0.4792)\n",
      "16081 Traning Loss: tensor(0.5070)\n",
      "16082 Traning Loss: tensor(0.4610)\n",
      "16083 Traning Loss: tensor(0.4225)\n",
      "16084 Traning Loss: tensor(0.4753)\n",
      "16085 Traning Loss: tensor(0.4194)\n",
      "16086 Traning Loss: tensor(0.4321)\n",
      "16087 Traning Loss: tensor(0.4806)\n",
      "16088 Traning Loss: tensor(0.4239)\n",
      "16089 Traning Loss: tensor(0.4276)\n",
      "16090 Traning Loss: tensor(0.4736)\n",
      "16091 Traning Loss: tensor(0.4425)\n",
      "16092 Traning Loss: tensor(0.4677)\n",
      "16093 Traning Loss: tensor(0.4711)\n",
      "16094 Traning Loss: tensor(0.4223)\n",
      "16095 Traning Loss: tensor(0.4491)\n",
      "16096 Traning Loss: tensor(0.4501)\n",
      "16097 Traning Loss: tensor(0.4366)\n",
      "16098 Traning Loss: tensor(0.4062)\n",
      "16099 Traning Loss: tensor(0.4838)\n",
      "16100 Traning Loss: tensor(0.4805)\n",
      "16101 Traning Loss: tensor(0.4846)\n",
      "16102 Traning Loss: tensor(0.4155)\n",
      "16103 Traning Loss: tensor(0.4763)\n",
      "16104 Traning Loss: tensor(0.4449)\n",
      "16105 Traning Loss: tensor(0.4435)\n",
      "16106 Traning Loss: tensor(0.4886)\n",
      "16107 Traning Loss: tensor(0.4538)\n",
      "16108 Traning Loss: tensor(0.4059)\n",
      "16109 Traning Loss: tensor(0.4584)\n",
      "16110 Traning Loss: tensor(0.4671)\n",
      "16111 Traning Loss: tensor(0.4562)\n",
      "16112 Traning Loss: tensor(0.4184)\n",
      "16113 Traning Loss: tensor(0.3901)\n",
      "16114 Traning Loss: tensor(0.4071)\n",
      "16115 Traning Loss: tensor(0.3884)\n",
      "16116 Traning Loss: tensor(0.4486)\n",
      "16117 Traning Loss: tensor(0.4666)\n",
      "16118 Traning Loss: tensor(0.3881)\n",
      "16119 Traning Loss: tensor(0.4401)\n",
      "16120 Traning Loss: tensor(0.4323)\n",
      "16121 Traning Loss: tensor(0.5139)\n",
      "16122 Traning Loss: tensor(0.5202)\n",
      "16123 Traning Loss: tensor(0.4674)\n",
      "16124 Traning Loss: tensor(0.4547)\n",
      "16125 Traning Loss: tensor(0.4532)\n",
      "16126 Traning Loss: tensor(0.4526)\n",
      "16127 Traning Loss: tensor(0.4493)\n",
      "16128 Traning Loss: tensor(0.4284)\n",
      "16129 Traning Loss: tensor(0.4242)\n",
      "16130 Traning Loss: tensor(0.4298)\n",
      "16131 Traning Loss: tensor(0.4569)\n",
      "16132 Traning Loss: tensor(0.4253)\n",
      "16133 Traning Loss: tensor(0.4161)\n",
      "16134 Traning Loss: tensor(0.4384)\n",
      "16135 Traning Loss: tensor(0.4827)\n",
      "16136 Traning Loss: tensor(0.4286)\n",
      "16137 Traning Loss: tensor(0.3764)\n",
      "16138 Traning Loss: tensor(0.4177)\n",
      "16139 Traning Loss: tensor(0.4165)\n",
      "16140 Traning Loss: tensor(0.4448)\n",
      "16141 Traning Loss: tensor(0.4440)\n",
      "16142 Traning Loss: tensor(0.4295)\n",
      "16143 Traning Loss: tensor(0.4693)\n",
      "16144 Traning Loss: tensor(0.4462)\n",
      "16145 Traning Loss: tensor(0.5044)\n",
      "16146 Traning Loss: tensor(0.4876)\n",
      "16147 Traning Loss: tensor(0.4530)\n",
      "16148 Traning Loss: tensor(0.4405)\n",
      "16149 Traning Loss: tensor(0.3984)\n",
      "16150 Traning Loss: tensor(0.4475)\n",
      "16151 Traning Loss: tensor(0.4384)\n",
      "16152 Traning Loss: tensor(0.4109)\n",
      "16153 Traning Loss: tensor(0.4868)\n",
      "16154 Traning Loss: tensor(0.4476)\n",
      "16155 Traning Loss: tensor(0.4637)\n",
      "16156 Traning Loss: tensor(0.4909)\n",
      "16157 Traning Loss: tensor(0.4194)\n",
      "16158 Traning Loss: tensor(0.4613)\n",
      "16159 Traning Loss: tensor(0.4365)\n",
      "16160 Traning Loss: tensor(0.4250)\n",
      "16161 Traning Loss: tensor(0.4163)\n",
      "16162 Traning Loss: tensor(0.4061)\n",
      "16163 Traning Loss: tensor(0.4304)\n",
      "16164 Traning Loss: tensor(0.4645)\n",
      "16165 Traning Loss: tensor(0.4189)\n",
      "16166 Traning Loss: tensor(0.4117)\n",
      "16167 Traning Loss: tensor(0.4568)\n",
      "16168 Traning Loss: tensor(0.4817)\n",
      "16169 Traning Loss: tensor(0.4226)\n",
      "16170 Traning Loss: tensor(0.4371)\n",
      "16171 Traning Loss: tensor(0.4383)\n",
      "16172 Traning Loss: tensor(0.4292)\n",
      "16173 Traning Loss: tensor(0.4462)\n",
      "16174 Traning Loss: tensor(0.4591)\n",
      "16175 Traning Loss: tensor(0.4062)\n",
      "16176 Traning Loss: tensor(0.4921)\n",
      "16177 Traning Loss: tensor(0.3907)\n",
      "16178 Traning Loss: tensor(0.4713)\n",
      "16179 Traning Loss: tensor(0.4443)\n",
      "16180 Traning Loss: tensor(0.3981)\n",
      "16181 Traning Loss: tensor(0.4133)\n",
      "16182 Traning Loss: tensor(0.4367)\n",
      "16183 Traning Loss: tensor(0.4221)\n",
      "16184 Traning Loss: tensor(0.4506)\n",
      "16185 Traning Loss: tensor(0.4593)\n",
      "16186 Traning Loss: tensor(0.4475)\n",
      "16187 Traning Loss: tensor(0.4657)\n",
      "16188 Traning Loss: tensor(0.4429)\n",
      "16189 Traning Loss: tensor(0.4345)\n",
      "16190 Traning Loss: tensor(0.4080)\n",
      "16191 Traning Loss: tensor(0.4306)\n",
      "16192 Traning Loss: tensor(0.3835)\n",
      "16193 Traning Loss: tensor(0.4144)\n",
      "16194 Traning Loss: tensor(0.4504)\n",
      "16195 Traning Loss: tensor(0.4648)\n",
      "16196 Traning Loss: tensor(0.4285)\n",
      "16197 Traning Loss: tensor(0.4404)\n",
      "16198 Traning Loss: tensor(0.3969)\n",
      "16199 Traning Loss: tensor(0.4293)\n",
      "16200 Traning Loss: tensor(0.4104)\n",
      "16201 Traning Loss: tensor(0.4224)\n",
      "16202 Traning Loss: tensor(0.4052)\n",
      "16203 Traning Loss: tensor(0.5038)\n",
      "16204 Traning Loss: tensor(0.4249)\n",
      "16205 Traning Loss: tensor(0.4508)\n",
      "16206 Traning Loss: tensor(0.4411)\n",
      "16207 Traning Loss: tensor(0.4428)\n",
      "16208 Traning Loss: tensor(0.3879)\n",
      "16209 Traning Loss: tensor(0.4229)\n",
      "16210 Traning Loss: tensor(0.4414)\n",
      "16211 Traning Loss: tensor(0.4694)\n",
      "16212 Traning Loss: tensor(0.4567)\n",
      "16213 Traning Loss: tensor(0.4842)\n",
      "16214 Traning Loss: tensor(0.4646)\n",
      "16215 Traning Loss: tensor(0.4023)\n",
      "16216 Traning Loss: tensor(0.4058)\n",
      "16217 Traning Loss: tensor(0.5035)\n",
      "16218 Traning Loss: tensor(0.4188)\n",
      "16219 Traning Loss: tensor(0.4810)\n",
      "16220 Traning Loss: tensor(0.3824)\n",
      "16221 Traning Loss: tensor(0.4515)\n",
      "16222 Traning Loss: tensor(0.4081)\n",
      "16223 Traning Loss: tensor(0.4267)\n",
      "16224 Traning Loss: tensor(0.4084)\n",
      "16225 Traning Loss: tensor(0.3885)\n",
      "16226 Traning Loss: tensor(0.4049)\n",
      "16227 Traning Loss: tensor(0.4275)\n",
      "16228 Traning Loss: tensor(0.3996)\n",
      "16229 Traning Loss: tensor(0.4667)\n",
      "16230 Traning Loss: tensor(0.4315)\n",
      "16231 Traning Loss: tensor(0.3933)\n",
      "16232 Traning Loss: tensor(0.4559)\n",
      "16233 Traning Loss: tensor(0.4348)\n",
      "16234 Traning Loss: tensor(0.5219)\n",
      "16235 Traning Loss: tensor(0.4451)\n",
      "16236 Traning Loss: tensor(0.3807)\n",
      "16237 Traning Loss: tensor(0.4200)\n",
      "16238 Traning Loss: tensor(0.3707)\n",
      "16239 Traning Loss: tensor(0.4350)\n",
      "16240 Traning Loss: tensor(0.4828)\n",
      "16241 Traning Loss: tensor(0.4154)\n",
      "16242 Traning Loss: tensor(0.4035)\n",
      "16243 Traning Loss: tensor(0.5069)\n",
      "16244 Traning Loss: tensor(0.4081)\n",
      "16245 Traning Loss: tensor(0.4619)\n",
      "16246 Traning Loss: tensor(0.4625)\n",
      "16247 Traning Loss: tensor(0.4145)\n",
      "16248 Traning Loss: tensor(0.4248)\n",
      "16249 Traning Loss: tensor(0.4301)\n",
      "16250 Traning Loss: tensor(0.4395)\n",
      "16251 Traning Loss: tensor(0.3749)\n",
      "16252 Traning Loss: tensor(0.3775)\n",
      "16253 Traning Loss: tensor(0.4157)\n",
      "16254 Traning Loss: tensor(0.4284)\n",
      "16255 Traning Loss: tensor(0.3879)\n",
      "16256 Traning Loss: tensor(0.5100)\n",
      "16257 Traning Loss: tensor(0.3911)\n",
      "16258 Traning Loss: tensor(0.3994)\n",
      "16259 Traning Loss: tensor(0.4103)\n",
      "16260 Traning Loss: tensor(0.4252)\n",
      "16261 Traning Loss: tensor(0.3976)\n",
      "16262 Traning Loss: tensor(0.4238)\n",
      "16263 Traning Loss: tensor(0.3661)\n",
      "16264 Traning Loss: tensor(0.4188)\n",
      "16265 Traning Loss: tensor(0.3895)\n",
      "16266 Traning Loss: tensor(0.4572)\n",
      "16267 Traning Loss: tensor(0.4625)\n",
      "16268 Traning Loss: tensor(0.4802)\n",
      "16269 Traning Loss: tensor(0.3994)\n",
      "16270 Traning Loss: tensor(0.4698)\n",
      "16271 Traning Loss: tensor(0.4229)\n",
      "16272 Traning Loss: tensor(0.4246)\n",
      "16273 Traning Loss: tensor(0.4489)\n",
      "16274 Traning Loss: tensor(0.4498)\n",
      "16275 Traning Loss: tensor(0.4264)\n",
      "16276 Traning Loss: tensor(0.4544)\n",
      "16277 Traning Loss: tensor(0.3738)\n",
      "16278 Traning Loss: tensor(0.4076)\n",
      "16279 Traning Loss: tensor(0.3896)\n",
      "16280 Traning Loss: tensor(0.4048)\n",
      "16281 Traning Loss: tensor(0.4220)\n",
      "16282 Traning Loss: tensor(0.3893)\n",
      "16283 Traning Loss: tensor(0.4068)\n",
      "16284 Traning Loss: tensor(0.3834)\n",
      "16285 Traning Loss: tensor(0.4050)\n",
      "16286 Traning Loss: tensor(0.3963)\n",
      "16287 Traning Loss: tensor(0.4183)\n",
      "16288 Traning Loss: tensor(0.4094)\n",
      "16289 Traning Loss: tensor(0.4073)\n",
      "16290 Traning Loss: tensor(0.4080)\n",
      "16291 Traning Loss: tensor(0.4142)\n",
      "16292 Traning Loss: tensor(0.4143)\n",
      "16293 Traning Loss: tensor(0.4029)\n",
      "16294 Traning Loss: tensor(0.3776)\n",
      "16295 Traning Loss: tensor(0.4122)\n",
      "16296 Traning Loss: tensor(0.4450)\n",
      "16297 Traning Loss: tensor(0.3981)\n",
      "16298 Traning Loss: tensor(0.4208)\n",
      "16299 Traning Loss: tensor(0.4107)\n",
      "16300 Traning Loss: tensor(0.3775)\n",
      "16301 Traning Loss: tensor(0.3913)\n",
      "16302 Traning Loss: tensor(0.3851)\n",
      "16303 Traning Loss: tensor(0.3963)\n",
      "16304 Traning Loss: tensor(0.4161)\n",
      "16305 Traning Loss: tensor(0.4074)\n",
      "16306 Traning Loss: tensor(0.3934)\n",
      "16307 Traning Loss: tensor(0.4130)\n",
      "16308 Traning Loss: tensor(0.4303)\n",
      "16309 Traning Loss: tensor(0.3762)\n",
      "16310 Traning Loss: tensor(0.4677)\n",
      "16311 Traning Loss: tensor(0.3976)\n",
      "16312 Traning Loss: tensor(0.4483)\n",
      "16313 Traning Loss: tensor(0.4176)\n",
      "16314 Traning Loss: tensor(0.4283)\n",
      "16315 Traning Loss: tensor(0.3627)\n",
      "16316 Traning Loss: tensor(0.3912)\n",
      "16317 Traning Loss: tensor(0.4733)\n",
      "16318 Traning Loss: tensor(0.4043)\n",
      "16319 Traning Loss: tensor(0.3988)\n",
      "16320 Traning Loss: tensor(0.4458)\n",
      "16321 Traning Loss: tensor(0.4534)\n",
      "16322 Traning Loss: tensor(0.4295)\n",
      "16323 Traning Loss: tensor(0.4647)\n",
      "16324 Traning Loss: tensor(0.4216)\n",
      "16325 Traning Loss: tensor(0.4062)\n",
      "16326 Traning Loss: tensor(0.4158)\n",
      "16327 Traning Loss: tensor(0.3862)\n",
      "16328 Traning Loss: tensor(0.4192)\n",
      "16329 Traning Loss: tensor(0.3867)\n",
      "16330 Traning Loss: tensor(0.4434)\n",
      "16331 Traning Loss: tensor(0.4470)\n",
      "16332 Traning Loss: tensor(0.4040)\n",
      "16333 Traning Loss: tensor(0.4084)\n",
      "16334 Traning Loss: tensor(0.4193)\n",
      "16335 Traning Loss: tensor(0.4067)\n",
      "16336 Traning Loss: tensor(0.4126)\n",
      "16337 Traning Loss: tensor(0.4102)\n",
      "16338 Traning Loss: tensor(0.4263)\n",
      "16339 Traning Loss: tensor(0.4575)\n",
      "16340 Traning Loss: tensor(0.3684)\n",
      "16341 Traning Loss: tensor(0.4066)\n",
      "16342 Traning Loss: tensor(0.4561)\n",
      "16343 Traning Loss: tensor(0.3997)\n",
      "16344 Traning Loss: tensor(0.3741)\n",
      "16345 Traning Loss: tensor(0.3639)\n",
      "16346 Traning Loss: tensor(0.3811)\n",
      "16347 Traning Loss: tensor(0.3813)\n",
      "16348 Traning Loss: tensor(0.3786)\n",
      "16349 Traning Loss: tensor(0.4105)\n",
      "16350 Traning Loss: tensor(0.4002)\n",
      "16351 Traning Loss: tensor(0.3976)\n",
      "16352 Traning Loss: tensor(0.4062)\n",
      "16353 Traning Loss: tensor(0.3616)\n",
      "16354 Traning Loss: tensor(0.4084)\n",
      "16355 Traning Loss: tensor(0.3541)\n",
      "16356 Traning Loss: tensor(0.4030)\n",
      "16357 Traning Loss: tensor(0.3705)\n",
      "16358 Traning Loss: tensor(0.3995)\n",
      "16359 Traning Loss: tensor(0.4051)\n",
      "16360 Traning Loss: tensor(0.3963)\n",
      "16361 Traning Loss: tensor(0.4118)\n",
      "16362 Traning Loss: tensor(0.4248)\n",
      "16363 Traning Loss: tensor(0.4098)\n",
      "16364 Traning Loss: tensor(0.3878)\n",
      "16365 Traning Loss: tensor(0.3756)\n",
      "16366 Traning Loss: tensor(0.4589)\n",
      "16367 Traning Loss: tensor(0.4322)\n",
      "16368 Traning Loss: tensor(0.4110)\n",
      "16369 Traning Loss: tensor(0.4095)\n",
      "16370 Traning Loss: tensor(0.3466)\n",
      "16371 Traning Loss: tensor(0.3957)\n",
      "16372 Traning Loss: tensor(0.4162)\n",
      "16373 Traning Loss: tensor(0.4343)\n",
      "16374 Traning Loss: tensor(0.4049)\n",
      "16375 Traning Loss: tensor(0.4037)\n",
      "16376 Traning Loss: tensor(0.4121)\n",
      "16377 Traning Loss: tensor(0.3950)\n",
      "16378 Traning Loss: tensor(0.4096)\n",
      "16379 Traning Loss: tensor(0.4514)\n",
      "16380 Traning Loss: tensor(0.3869)\n",
      "16381 Traning Loss: tensor(0.3963)\n",
      "16382 Traning Loss: tensor(0.3768)\n",
      "16383 Traning Loss: tensor(0.4169)\n",
      "16384 Traning Loss: tensor(0.4862)\n",
      "16385 Traning Loss: tensor(0.3612)\n",
      "16386 Traning Loss: tensor(0.3926)\n",
      "16387 Traning Loss: tensor(0.4379)\n",
      "16388 Traning Loss: tensor(0.4364)\n",
      "16389 Traning Loss: tensor(0.3772)\n",
      "16390 Traning Loss: tensor(0.3916)\n",
      "16391 Traning Loss: tensor(0.3705)\n",
      "16392 Traning Loss: tensor(0.3904)\n",
      "16393 Traning Loss: tensor(0.4354)\n",
      "16394 Traning Loss: tensor(0.4511)\n",
      "16395 Traning Loss: tensor(0.4159)\n",
      "16396 Traning Loss: tensor(0.3623)\n",
      "16397 Traning Loss: tensor(0.3471)\n",
      "16398 Traning Loss: tensor(0.3873)\n",
      "16399 Traning Loss: tensor(0.4514)\n",
      "16400 Traning Loss: tensor(0.3892)\n",
      "16401 Traning Loss: tensor(0.3792)\n",
      "16402 Traning Loss: tensor(0.4126)\n",
      "16403 Traning Loss: tensor(0.4065)\n",
      "16404 Traning Loss: tensor(0.3870)\n",
      "16405 Traning Loss: tensor(0.3692)\n",
      "16406 Traning Loss: tensor(0.4107)\n",
      "16407 Traning Loss: tensor(0.3781)\n",
      "16408 Traning Loss: tensor(0.3873)\n",
      "16409 Traning Loss: tensor(0.3829)\n",
      "16410 Traning Loss: tensor(0.4101)\n",
      "16411 Traning Loss: tensor(0.3963)\n",
      "16412 Traning Loss: tensor(0.3754)\n",
      "16413 Traning Loss: tensor(0.3609)\n",
      "16414 Traning Loss: tensor(0.4439)\n",
      "16415 Traning Loss: tensor(0.3829)\n",
      "16416 Traning Loss: tensor(0.3792)\n",
      "16417 Traning Loss: tensor(0.3565)\n",
      "16418 Traning Loss: tensor(0.3533)\n",
      "16419 Traning Loss: tensor(0.4070)\n",
      "16420 Traning Loss: tensor(0.4477)\n",
      "16421 Traning Loss: tensor(0.4015)\n",
      "16422 Traning Loss: tensor(0.3740)\n",
      "16423 Traning Loss: tensor(0.3686)\n",
      "16424 Traning Loss: tensor(0.4037)\n",
      "16425 Traning Loss: tensor(0.3670)\n",
      "16426 Traning Loss: tensor(0.4081)\n",
      "16427 Traning Loss: tensor(0.3705)\n",
      "16428 Traning Loss: tensor(0.3851)\n",
      "16429 Traning Loss: tensor(0.3869)\n",
      "16430 Traning Loss: tensor(0.4138)\n",
      "16431 Traning Loss: tensor(0.3862)\n",
      "16432 Traning Loss: tensor(0.3586)\n",
      "16433 Traning Loss: tensor(0.3902)\n",
      "16434 Traning Loss: tensor(0.4231)\n",
      "16435 Traning Loss: tensor(0.4013)\n",
      "16436 Traning Loss: tensor(0.3911)\n",
      "16437 Traning Loss: tensor(0.4334)\n",
      "16438 Traning Loss: tensor(0.3598)\n",
      "16439 Traning Loss: tensor(0.4010)\n",
      "16440 Traning Loss: tensor(0.4199)\n",
      "16441 Traning Loss: tensor(0.4391)\n",
      "16442 Traning Loss: tensor(0.3707)\n",
      "16443 Traning Loss: tensor(0.4100)\n",
      "16444 Traning Loss: tensor(0.4105)\n",
      "16445 Traning Loss: tensor(0.3646)\n",
      "16446 Traning Loss: tensor(0.3812)\n",
      "16447 Traning Loss: tensor(0.3818)\n",
      "16448 Traning Loss: tensor(0.3522)\n",
      "16449 Traning Loss: tensor(0.4139)\n",
      "16450 Traning Loss: tensor(0.4259)\n",
      "16451 Traning Loss: tensor(0.4327)\n",
      "16452 Traning Loss: tensor(0.4043)\n",
      "16453 Traning Loss: tensor(0.4497)\n",
      "16454 Traning Loss: tensor(0.4124)\n",
      "16455 Traning Loss: tensor(0.4191)\n",
      "16456 Traning Loss: tensor(0.3636)\n",
      "16457 Traning Loss: tensor(0.3942)\n",
      "16458 Traning Loss: tensor(0.3976)\n",
      "16459 Traning Loss: tensor(0.4072)\n",
      "16460 Traning Loss: tensor(0.4313)\n",
      "16461 Traning Loss: tensor(0.3481)\n",
      "16462 Traning Loss: tensor(0.3649)\n",
      "16463 Traning Loss: tensor(0.4045)\n",
      "16464 Traning Loss: tensor(0.3617)\n",
      "16465 Traning Loss: tensor(0.4000)\n",
      "16466 Traning Loss: tensor(0.4073)\n",
      "16467 Traning Loss: tensor(0.4019)\n",
      "16468 Traning Loss: tensor(0.4151)\n",
      "16469 Traning Loss: tensor(0.4447)\n",
      "16470 Traning Loss: tensor(0.3972)\n",
      "16471 Traning Loss: tensor(0.4225)\n",
      "16472 Traning Loss: tensor(0.4270)\n",
      "16473 Traning Loss: tensor(0.4340)\n",
      "16474 Traning Loss: tensor(0.4145)\n",
      "16475 Traning Loss: tensor(0.3811)\n",
      "16476 Traning Loss: tensor(0.3366)\n",
      "16477 Traning Loss: tensor(0.4341)\n",
      "16478 Traning Loss: tensor(0.3631)\n",
      "16479 Traning Loss: tensor(0.4063)\n",
      "16480 Traning Loss: tensor(0.4364)\n",
      "16481 Traning Loss: tensor(0.3738)\n",
      "16482 Traning Loss: tensor(0.3973)\n",
      "16483 Traning Loss: tensor(0.3930)\n",
      "16484 Traning Loss: tensor(0.3960)\n",
      "16485 Traning Loss: tensor(0.3344)\n",
      "16486 Traning Loss: tensor(0.4254)\n",
      "16487 Traning Loss: tensor(0.4265)\n",
      "16488 Traning Loss: tensor(0.3706)\n",
      "16489 Traning Loss: tensor(0.3889)\n",
      "16490 Traning Loss: tensor(0.3485)\n",
      "16491 Traning Loss: tensor(0.3686)\n",
      "16492 Traning Loss: tensor(0.3848)\n",
      "16493 Traning Loss: tensor(0.3677)\n",
      "16494 Traning Loss: tensor(0.3670)\n",
      "16495 Traning Loss: tensor(0.4257)\n",
      "16496 Traning Loss: tensor(0.4065)\n",
      "16497 Traning Loss: tensor(0.3759)\n",
      "16498 Traning Loss: tensor(0.3608)\n",
      "16499 Traning Loss: tensor(0.3592)\n",
      "16500 Traning Loss: tensor(0.3972)\n",
      "16501 Traning Loss: tensor(0.3565)\n",
      "16502 Traning Loss: tensor(0.4337)\n",
      "16503 Traning Loss: tensor(0.3918)\n",
      "16504 Traning Loss: tensor(0.4020)\n",
      "16505 Traning Loss: tensor(0.4217)\n",
      "16506 Traning Loss: tensor(0.3805)\n",
      "16507 Traning Loss: tensor(0.3715)\n",
      "16508 Traning Loss: tensor(0.3616)\n",
      "16509 Traning Loss: tensor(0.3407)\n",
      "16510 Traning Loss: tensor(0.3790)\n",
      "16511 Traning Loss: tensor(0.3529)\n",
      "16512 Traning Loss: tensor(0.3676)\n",
      "16513 Traning Loss: tensor(0.4169)\n",
      "16514 Traning Loss: tensor(0.3597)\n",
      "16515 Traning Loss: tensor(0.3423)\n",
      "16516 Traning Loss: tensor(0.3758)\n",
      "16517 Traning Loss: tensor(0.3665)\n",
      "16518 Traning Loss: tensor(0.4004)\n",
      "16519 Traning Loss: tensor(0.3935)\n",
      "16520 Traning Loss: tensor(0.3285)\n",
      "16521 Traning Loss: tensor(0.3690)\n",
      "16522 Traning Loss: tensor(0.3952)\n",
      "16523 Traning Loss: tensor(0.3999)\n",
      "16524 Traning Loss: tensor(0.3838)\n",
      "16525 Traning Loss: tensor(0.3622)\n",
      "16526 Traning Loss: tensor(0.3987)\n",
      "16527 Traning Loss: tensor(0.3540)\n",
      "16528 Traning Loss: tensor(0.3439)\n",
      "16529 Traning Loss: tensor(0.3982)\n",
      "16530 Traning Loss: tensor(0.3600)\n",
      "16531 Traning Loss: tensor(0.3690)\n",
      "16532 Traning Loss: tensor(0.3890)\n",
      "16533 Traning Loss: tensor(0.3477)\n",
      "16534 Traning Loss: tensor(0.4144)\n",
      "16535 Traning Loss: tensor(0.3757)\n",
      "16536 Traning Loss: tensor(0.3720)\n",
      "16537 Traning Loss: tensor(0.3926)\n",
      "16538 Traning Loss: tensor(0.4034)\n",
      "16539 Traning Loss: tensor(0.3837)\n",
      "16540 Traning Loss: tensor(0.3955)\n",
      "16541 Traning Loss: tensor(0.3540)\n",
      "16542 Traning Loss: tensor(0.3934)\n",
      "16543 Traning Loss: tensor(0.3851)\n",
      "16544 Traning Loss: tensor(0.3957)\n",
      "16545 Traning Loss: tensor(0.3932)\n",
      "16546 Traning Loss: tensor(0.3808)\n",
      "16547 Traning Loss: tensor(0.3533)\n",
      "16548 Traning Loss: tensor(0.3639)\n",
      "16549 Traning Loss: tensor(0.3605)\n",
      "16550 Traning Loss: tensor(0.3891)\n",
      "16551 Traning Loss: tensor(0.4050)\n",
      "16552 Traning Loss: tensor(0.3847)\n",
      "16553 Traning Loss: tensor(0.3644)\n",
      "16554 Traning Loss: tensor(0.4211)\n",
      "16555 Traning Loss: tensor(0.3649)\n",
      "16556 Traning Loss: tensor(0.3815)\n",
      "16557 Traning Loss: tensor(0.3710)\n",
      "16558 Traning Loss: tensor(0.3766)\n",
      "16559 Traning Loss: tensor(0.3601)\n",
      "16560 Traning Loss: tensor(0.3609)\n",
      "16561 Traning Loss: tensor(0.3720)\n",
      "16562 Traning Loss: tensor(0.4198)\n",
      "16563 Traning Loss: tensor(0.3396)\n",
      "16564 Traning Loss: tensor(0.3343)\n",
      "16565 Traning Loss: tensor(0.4087)\n",
      "16566 Traning Loss: tensor(0.4407)\n",
      "16567 Traning Loss: tensor(0.3473)\n",
      "16568 Traning Loss: tensor(0.3626)\n",
      "16569 Traning Loss: tensor(0.3432)\n",
      "16570 Traning Loss: tensor(0.3968)\n",
      "16571 Traning Loss: tensor(0.3794)\n",
      "16572 Traning Loss: tensor(0.4184)\n",
      "16573 Traning Loss: tensor(0.4193)\n",
      "16574 Traning Loss: tensor(0.3791)\n",
      "16575 Traning Loss: tensor(0.3789)\n",
      "16576 Traning Loss: tensor(0.3774)\n",
      "16577 Traning Loss: tensor(0.4053)\n",
      "16578 Traning Loss: tensor(0.4064)\n",
      "16579 Traning Loss: tensor(0.4339)\n",
      "16580 Traning Loss: tensor(0.3754)\n",
      "16581 Traning Loss: tensor(0.3857)\n",
      "16582 Traning Loss: tensor(0.4284)\n",
      "16583 Traning Loss: tensor(0.3605)\n",
      "16584 Traning Loss: tensor(0.3820)\n",
      "16585 Traning Loss: tensor(0.3880)\n",
      "16586 Traning Loss: tensor(0.3802)\n",
      "16587 Traning Loss: tensor(0.4100)\n",
      "16588 Traning Loss: tensor(0.3505)\n",
      "16589 Traning Loss: tensor(0.3689)\n",
      "16590 Traning Loss: tensor(0.3877)\n",
      "16591 Traning Loss: tensor(0.3392)\n",
      "16592 Traning Loss: tensor(0.3606)\n",
      "16593 Traning Loss: tensor(0.4010)\n",
      "16594 Traning Loss: tensor(0.3542)\n",
      "16595 Traning Loss: tensor(0.4116)\n",
      "16596 Traning Loss: tensor(0.3221)\n",
      "16597 Traning Loss: tensor(0.3236)\n",
      "16598 Traning Loss: tensor(0.3993)\n",
      "16599 Traning Loss: tensor(0.3548)\n",
      "16600 Traning Loss: tensor(0.3603)\n",
      "16601 Traning Loss: tensor(0.3271)\n",
      "16602 Traning Loss: tensor(0.3671)\n",
      "16603 Traning Loss: tensor(0.4254)\n",
      "16604 Traning Loss: tensor(0.3935)\n",
      "16605 Traning Loss: tensor(0.3797)\n",
      "16606 Traning Loss: tensor(0.4565)\n",
      "16607 Traning Loss: tensor(0.3391)\n",
      "16608 Traning Loss: tensor(0.3857)\n",
      "16609 Traning Loss: tensor(0.3490)\n",
      "16610 Traning Loss: tensor(0.3550)\n",
      "16611 Traning Loss: tensor(0.3922)\n",
      "16612 Traning Loss: tensor(0.3876)\n",
      "16613 Traning Loss: tensor(0.4305)\n",
      "16614 Traning Loss: tensor(0.4205)\n",
      "16615 Traning Loss: tensor(0.3516)\n",
      "16616 Traning Loss: tensor(0.4048)\n",
      "16617 Traning Loss: tensor(0.4021)\n",
      "16618 Traning Loss: tensor(0.3814)\n",
      "16619 Traning Loss: tensor(0.4323)\n",
      "16620 Traning Loss: tensor(0.3877)\n",
      "16621 Traning Loss: tensor(0.3682)\n",
      "16622 Traning Loss: tensor(0.3469)\n",
      "16623 Traning Loss: tensor(0.3933)\n",
      "16624 Traning Loss: tensor(0.4275)\n",
      "16625 Traning Loss: tensor(0.3650)\n",
      "16626 Traning Loss: tensor(0.3726)\n",
      "16627 Traning Loss: tensor(0.3509)\n",
      "16628 Traning Loss: tensor(0.3619)\n",
      "16629 Traning Loss: tensor(0.4214)\n",
      "16630 Traning Loss: tensor(0.3357)\n",
      "16631 Traning Loss: tensor(0.3970)\n",
      "16632 Traning Loss: tensor(0.3767)\n",
      "16633 Traning Loss: tensor(0.3564)\n",
      "16634 Traning Loss: tensor(0.3547)\n",
      "16635 Traning Loss: tensor(0.3859)\n",
      "16636 Traning Loss: tensor(0.4341)\n",
      "16637 Traning Loss: tensor(0.3773)\n",
      "16638 Traning Loss: tensor(0.3590)\n",
      "16639 Traning Loss: tensor(0.3579)\n",
      "16640 Traning Loss: tensor(0.3289)\n",
      "16641 Traning Loss: tensor(0.4035)\n",
      "16642 Traning Loss: tensor(0.3312)\n",
      "16643 Traning Loss: tensor(0.3294)\n",
      "16644 Traning Loss: tensor(0.3840)\n",
      "16645 Traning Loss: tensor(0.3888)\n",
      "16646 Traning Loss: tensor(0.3846)\n",
      "16647 Traning Loss: tensor(0.4425)\n",
      "16648 Traning Loss: tensor(0.3874)\n",
      "16649 Traning Loss: tensor(0.3551)\n",
      "16650 Traning Loss: tensor(0.3559)\n",
      "16651 Traning Loss: tensor(0.3724)\n",
      "16652 Traning Loss: tensor(0.3450)\n",
      "16653 Traning Loss: tensor(0.3358)\n",
      "16654 Traning Loss: tensor(0.3503)\n",
      "16655 Traning Loss: tensor(0.3689)\n",
      "16656 Traning Loss: tensor(0.3577)\n",
      "16657 Traning Loss: tensor(0.3913)\n",
      "16658 Traning Loss: tensor(0.3622)\n",
      "16659 Traning Loss: tensor(0.3436)\n",
      "16660 Traning Loss: tensor(0.3523)\n",
      "16661 Traning Loss: tensor(0.4060)\n",
      "16662 Traning Loss: tensor(0.3724)\n",
      "16663 Traning Loss: tensor(0.3503)\n",
      "16664 Traning Loss: tensor(0.3482)\n",
      "16665 Traning Loss: tensor(0.3445)\n",
      "16666 Traning Loss: tensor(0.3973)\n",
      "16667 Traning Loss: tensor(0.3407)\n",
      "16668 Traning Loss: tensor(0.3275)\n",
      "16669 Traning Loss: tensor(0.3343)\n",
      "16670 Traning Loss: tensor(0.4099)\n",
      "16671 Traning Loss: tensor(0.3941)\n",
      "16672 Traning Loss: tensor(0.3430)\n",
      "16673 Traning Loss: tensor(0.3901)\n",
      "16674 Traning Loss: tensor(0.4077)\n",
      "16675 Traning Loss: tensor(0.3654)\n",
      "16676 Traning Loss: tensor(0.3669)\n",
      "16677 Traning Loss: tensor(0.3739)\n",
      "16678 Traning Loss: tensor(0.3152)\n",
      "16679 Traning Loss: tensor(0.3429)\n",
      "16680 Traning Loss: tensor(0.3338)\n",
      "16681 Traning Loss: tensor(0.3841)\n",
      "16682 Traning Loss: tensor(0.3517)\n",
      "16683 Traning Loss: tensor(0.3813)\n",
      "16684 Traning Loss: tensor(0.3856)\n",
      "16685 Traning Loss: tensor(0.3319)\n",
      "16686 Traning Loss: tensor(0.3386)\n",
      "16687 Traning Loss: tensor(0.3916)\n",
      "16688 Traning Loss: tensor(0.3271)\n",
      "16689 Traning Loss: tensor(0.3287)\n",
      "16690 Traning Loss: tensor(0.3436)\n",
      "16691 Traning Loss: tensor(0.3968)\n",
      "16692 Traning Loss: tensor(0.3545)\n",
      "16693 Traning Loss: tensor(0.4058)\n",
      "16694 Traning Loss: tensor(0.3326)\n",
      "16695 Traning Loss: tensor(0.3747)\n",
      "16696 Traning Loss: tensor(0.3568)\n",
      "16697 Traning Loss: tensor(0.3201)\n",
      "16698 Traning Loss: tensor(0.3501)\n",
      "16699 Traning Loss: tensor(0.3784)\n",
      "16700 Traning Loss: tensor(0.3499)\n",
      "16701 Traning Loss: tensor(0.3746)\n",
      "16702 Traning Loss: tensor(0.3725)\n",
      "16703 Traning Loss: tensor(0.3712)\n",
      "16704 Traning Loss: tensor(0.3566)\n",
      "16705 Traning Loss: tensor(0.3943)\n",
      "16706 Traning Loss: tensor(0.3507)\n",
      "16707 Traning Loss: tensor(0.3452)\n",
      "16708 Traning Loss: tensor(0.3572)\n",
      "16709 Traning Loss: tensor(0.3708)\n",
      "16710 Traning Loss: tensor(0.4410)\n",
      "16711 Traning Loss: tensor(0.3875)\n",
      "16712 Traning Loss: tensor(0.3702)\n",
      "16713 Traning Loss: tensor(0.3275)\n",
      "16714 Traning Loss: tensor(0.3679)\n",
      "16715 Traning Loss: tensor(0.4001)\n",
      "16716 Traning Loss: tensor(0.3246)\n",
      "16717 Traning Loss: tensor(0.3402)\n",
      "16718 Traning Loss: tensor(0.3582)\n",
      "16719 Traning Loss: tensor(0.3251)\n",
      "16720 Traning Loss: tensor(0.3657)\n",
      "16721 Traning Loss: tensor(0.3511)\n",
      "16722 Traning Loss: tensor(0.3065)\n",
      "16723 Traning Loss: tensor(0.3367)\n",
      "16724 Traning Loss: tensor(0.3114)\n",
      "16725 Traning Loss: tensor(0.3796)\n",
      "16726 Traning Loss: tensor(0.3868)\n",
      "16727 Traning Loss: tensor(0.3625)\n",
      "16728 Traning Loss: tensor(0.3522)\n",
      "16729 Traning Loss: tensor(0.3384)\n",
      "16730 Traning Loss: tensor(0.3566)\n",
      "16731 Traning Loss: tensor(0.3607)\n",
      "16732 Traning Loss: tensor(0.3787)\n",
      "16733 Traning Loss: tensor(0.3390)\n",
      "16734 Traning Loss: tensor(0.3522)\n",
      "16735 Traning Loss: tensor(0.3413)\n",
      "16736 Traning Loss: tensor(0.3430)\n",
      "16737 Traning Loss: tensor(0.3437)\n",
      "16738 Traning Loss: tensor(0.3360)\n",
      "16739 Traning Loss: tensor(0.3905)\n",
      "16740 Traning Loss: tensor(0.3779)\n",
      "16741 Traning Loss: tensor(0.3097)\n",
      "16742 Traning Loss: tensor(0.3315)\n",
      "16743 Traning Loss: tensor(0.3167)\n",
      "16744 Traning Loss: tensor(0.3734)\n",
      "16745 Traning Loss: tensor(0.3579)\n",
      "16746 Traning Loss: tensor(0.3441)\n",
      "16747 Traning Loss: tensor(0.3249)\n",
      "16748 Traning Loss: tensor(0.3433)\n",
      "16749 Traning Loss: tensor(0.3320)\n",
      "16750 Traning Loss: tensor(0.3298)\n",
      "16751 Traning Loss: tensor(0.3034)\n",
      "16752 Traning Loss: tensor(0.3276)\n",
      "16753 Traning Loss: tensor(0.3371)\n",
      "16754 Traning Loss: tensor(0.3108)\n",
      "16755 Traning Loss: tensor(0.3316)\n",
      "16756 Traning Loss: tensor(0.3657)\n",
      "16757 Traning Loss: tensor(0.3894)\n",
      "16758 Traning Loss: tensor(0.3023)\n",
      "16759 Traning Loss: tensor(0.3266)\n",
      "16760 Traning Loss: tensor(0.3676)\n",
      "16761 Traning Loss: tensor(0.3501)\n",
      "16762 Traning Loss: tensor(0.3742)\n",
      "16763 Traning Loss: tensor(0.3624)\n",
      "16764 Traning Loss: tensor(0.3817)\n",
      "16765 Traning Loss: tensor(0.3279)\n",
      "16766 Traning Loss: tensor(0.4131)\n",
      "16767 Traning Loss: tensor(0.3695)\n",
      "16768 Traning Loss: tensor(0.3335)\n",
      "16769 Traning Loss: tensor(0.3354)\n",
      "16770 Traning Loss: tensor(0.3245)\n",
      "16771 Traning Loss: tensor(0.3820)\n",
      "16772 Traning Loss: tensor(0.3160)\n",
      "16773 Traning Loss: tensor(0.3246)\n",
      "16774 Traning Loss: tensor(0.3443)\n",
      "16775 Traning Loss: tensor(0.3469)\n",
      "16776 Traning Loss: tensor(0.3263)\n",
      "16777 Traning Loss: tensor(0.3663)\n",
      "16778 Traning Loss: tensor(0.3392)\n",
      "16779 Traning Loss: tensor(0.3265)\n",
      "16780 Traning Loss: tensor(0.3117)\n",
      "16781 Traning Loss: tensor(0.3197)\n",
      "16782 Traning Loss: tensor(0.3214)\n",
      "16783 Traning Loss: tensor(0.3621)\n",
      "16784 Traning Loss: tensor(0.3694)\n",
      "16785 Traning Loss: tensor(0.3285)\n",
      "16786 Traning Loss: tensor(0.3768)\n",
      "16787 Traning Loss: tensor(0.3293)\n",
      "16788 Traning Loss: tensor(0.2909)\n",
      "16789 Traning Loss: tensor(0.3787)\n",
      "16790 Traning Loss: tensor(0.3639)\n",
      "16791 Traning Loss: tensor(0.3089)\n",
      "16792 Traning Loss: tensor(0.3850)\n",
      "16793 Traning Loss: tensor(0.3367)\n",
      "16794 Traning Loss: tensor(0.3109)\n",
      "16795 Traning Loss: tensor(0.3443)\n",
      "16796 Traning Loss: tensor(0.3477)\n",
      "16797 Traning Loss: tensor(0.3783)\n",
      "16798 Traning Loss: tensor(0.3664)\n",
      "16799 Traning Loss: tensor(0.3028)\n",
      "16800 Traning Loss: tensor(0.3274)\n",
      "16801 Traning Loss: tensor(0.3526)\n",
      "16802 Traning Loss: tensor(0.3460)\n",
      "16803 Traning Loss: tensor(0.3263)\n",
      "16804 Traning Loss: tensor(0.3074)\n",
      "16805 Traning Loss: tensor(0.3690)\n",
      "16806 Traning Loss: tensor(0.3064)\n",
      "16807 Traning Loss: tensor(0.3464)\n",
      "16808 Traning Loss: tensor(0.3375)\n",
      "16809 Traning Loss: tensor(0.3906)\n",
      "16810 Traning Loss: tensor(0.3647)\n",
      "16811 Traning Loss: tensor(0.3231)\n",
      "16812 Traning Loss: tensor(0.3277)\n",
      "16813 Traning Loss: tensor(0.3226)\n",
      "16814 Traning Loss: tensor(0.3005)\n",
      "16815 Traning Loss: tensor(0.3487)\n",
      "16816 Traning Loss: tensor(0.4173)\n",
      "16817 Traning Loss: tensor(0.3732)\n",
      "16818 Traning Loss: tensor(0.3198)\n",
      "16819 Traning Loss: tensor(0.3191)\n",
      "16820 Traning Loss: tensor(0.3257)\n",
      "16821 Traning Loss: tensor(0.3778)\n",
      "16822 Traning Loss: tensor(0.3125)\n",
      "16823 Traning Loss: tensor(0.3308)\n",
      "16824 Traning Loss: tensor(0.3211)\n",
      "16825 Traning Loss: tensor(0.3371)\n",
      "16826 Traning Loss: tensor(0.3121)\n",
      "16827 Traning Loss: tensor(0.3337)\n",
      "16828 Traning Loss: tensor(0.3462)\n",
      "16829 Traning Loss: tensor(0.3298)\n",
      "16830 Traning Loss: tensor(0.3122)\n",
      "16831 Traning Loss: tensor(0.3278)\n",
      "16832 Traning Loss: tensor(0.3297)\n",
      "16833 Traning Loss: tensor(0.3390)\n",
      "16834 Traning Loss: tensor(0.3214)\n",
      "16835 Traning Loss: tensor(0.3607)\n",
      "16836 Traning Loss: tensor(0.3087)\n",
      "16837 Traning Loss: tensor(0.3456)\n",
      "16838 Traning Loss: tensor(0.3607)\n",
      "16839 Traning Loss: tensor(0.3367)\n",
      "16840 Traning Loss: tensor(0.3461)\n",
      "16841 Traning Loss: tensor(0.3239)\n",
      "16842 Traning Loss: tensor(0.3249)\n",
      "16843 Traning Loss: tensor(0.3724)\n",
      "16844 Traning Loss: tensor(0.3549)\n",
      "16845 Traning Loss: tensor(0.2871)\n",
      "16846 Traning Loss: tensor(0.3183)\n",
      "16847 Traning Loss: tensor(0.3173)\n",
      "16848 Traning Loss: tensor(0.3489)\n",
      "16849 Traning Loss: tensor(0.3679)\n",
      "16850 Traning Loss: tensor(0.3219)\n",
      "16851 Traning Loss: tensor(0.2937)\n",
      "16852 Traning Loss: tensor(0.3481)\n",
      "16853 Traning Loss: tensor(0.3248)\n",
      "16854 Traning Loss: tensor(0.3209)\n",
      "16855 Traning Loss: tensor(0.3293)\n",
      "16856 Traning Loss: tensor(0.3109)\n",
      "16857 Traning Loss: tensor(0.3403)\n",
      "16858 Traning Loss: tensor(0.3145)\n",
      "16859 Traning Loss: tensor(0.3105)\n",
      "16860 Traning Loss: tensor(0.3222)\n",
      "16861 Traning Loss: tensor(0.3432)\n",
      "16862 Traning Loss: tensor(0.3525)\n",
      "16863 Traning Loss: tensor(0.3199)\n",
      "16864 Traning Loss: tensor(0.3628)\n",
      "16865 Traning Loss: tensor(0.3529)\n",
      "16866 Traning Loss: tensor(0.3190)\n",
      "16867 Traning Loss: tensor(0.3460)\n",
      "16868 Traning Loss: tensor(0.3662)\n",
      "16869 Traning Loss: tensor(0.3079)\n",
      "16870 Traning Loss: tensor(0.3429)\n",
      "16871 Traning Loss: tensor(0.3378)\n",
      "16872 Traning Loss: tensor(0.3465)\n",
      "16873 Traning Loss: tensor(0.3981)\n",
      "16874 Traning Loss: tensor(0.3312)\n",
      "16875 Traning Loss: tensor(0.3418)\n",
      "16876 Traning Loss: tensor(0.3488)\n",
      "16877 Traning Loss: tensor(0.3164)\n",
      "16878 Traning Loss: tensor(0.3295)\n",
      "16879 Traning Loss: tensor(0.3554)\n",
      "16880 Traning Loss: tensor(0.3294)\n",
      "16881 Traning Loss: tensor(0.3201)\n",
      "16882 Traning Loss: tensor(0.3586)\n",
      "16883 Traning Loss: tensor(0.4046)\n",
      "16884 Traning Loss: tensor(0.3142)\n",
      "16885 Traning Loss: tensor(0.3500)\n",
      "16886 Traning Loss: tensor(0.3069)\n",
      "16887 Traning Loss: tensor(0.4063)\n",
      "16888 Traning Loss: tensor(0.3466)\n",
      "16889 Traning Loss: tensor(0.3491)\n",
      "16890 Traning Loss: tensor(0.3831)\n",
      "16891 Traning Loss: tensor(0.3192)\n",
      "16892 Traning Loss: tensor(0.3294)\n",
      "16893 Traning Loss: tensor(0.3480)\n",
      "16894 Traning Loss: tensor(0.3477)\n",
      "16895 Traning Loss: tensor(0.3648)\n",
      "16896 Traning Loss: tensor(0.3019)\n",
      "16897 Traning Loss: tensor(0.3414)\n",
      "16898 Traning Loss: tensor(0.3786)\n",
      "16899 Traning Loss: tensor(0.3320)\n",
      "16900 Traning Loss: tensor(0.3088)\n",
      "16901 Traning Loss: tensor(0.3226)\n",
      "16902 Traning Loss: tensor(0.3359)\n",
      "16903 Traning Loss: tensor(0.3632)\n",
      "16904 Traning Loss: tensor(0.3257)\n",
      "16905 Traning Loss: tensor(0.3175)\n",
      "16906 Traning Loss: tensor(0.3580)\n",
      "16907 Traning Loss: tensor(0.3666)\n",
      "16908 Traning Loss: tensor(0.3463)\n",
      "16909 Traning Loss: tensor(0.3721)\n",
      "16910 Traning Loss: tensor(0.3040)\n",
      "16911 Traning Loss: tensor(0.3490)\n",
      "16912 Traning Loss: tensor(0.3506)\n",
      "16913 Traning Loss: tensor(0.2930)\n",
      "16914 Traning Loss: tensor(0.3427)\n",
      "16915 Traning Loss: tensor(0.2846)\n",
      "16916 Traning Loss: tensor(0.3541)\n",
      "16917 Traning Loss: tensor(0.3233)\n",
      "16918 Traning Loss: tensor(0.3513)\n",
      "16919 Traning Loss: tensor(0.3279)\n",
      "16920 Traning Loss: tensor(0.2846)\n",
      "16921 Traning Loss: tensor(0.3392)\n",
      "16922 Traning Loss: tensor(0.3650)\n",
      "16923 Traning Loss: tensor(0.2884)\n",
      "16924 Traning Loss: tensor(0.2902)\n",
      "16925 Traning Loss: tensor(0.2792)\n",
      "16926 Traning Loss: tensor(0.3011)\n",
      "16927 Traning Loss: tensor(0.2940)\n",
      "16928 Traning Loss: tensor(0.2937)\n",
      "16929 Traning Loss: tensor(0.3603)\n",
      "16930 Traning Loss: tensor(0.3239)\n",
      "16931 Traning Loss: tensor(0.3414)\n",
      "16932 Traning Loss: tensor(0.3133)\n",
      "16933 Traning Loss: tensor(0.2700)\n",
      "16934 Traning Loss: tensor(0.3394)\n",
      "16935 Traning Loss: tensor(0.3413)\n",
      "16936 Traning Loss: tensor(0.3372)\n",
      "16937 Traning Loss: tensor(0.3140)\n",
      "16938 Traning Loss: tensor(0.3401)\n",
      "16939 Traning Loss: tensor(0.3100)\n",
      "16940 Traning Loss: tensor(0.3327)\n",
      "16941 Traning Loss: tensor(0.2997)\n",
      "16942 Traning Loss: tensor(0.3492)\n",
      "16943 Traning Loss: tensor(0.3102)\n",
      "16944 Traning Loss: tensor(0.3057)\n",
      "16945 Traning Loss: tensor(0.3572)\n",
      "16946 Traning Loss: tensor(0.3382)\n",
      "16947 Traning Loss: tensor(0.3049)\n",
      "16948 Traning Loss: tensor(0.3417)\n",
      "16949 Traning Loss: tensor(0.3219)\n",
      "16950 Traning Loss: tensor(0.3059)\n",
      "16951 Traning Loss: tensor(0.3417)\n",
      "16952 Traning Loss: tensor(0.3187)\n",
      "16953 Traning Loss: tensor(0.3502)\n",
      "16954 Traning Loss: tensor(0.3375)\n",
      "16955 Traning Loss: tensor(0.3104)\n",
      "16956 Traning Loss: tensor(0.3343)\n",
      "16957 Traning Loss: tensor(0.3511)\n",
      "16958 Traning Loss: tensor(0.3303)\n",
      "16959 Traning Loss: tensor(0.3793)\n",
      "16960 Traning Loss: tensor(0.3323)\n",
      "16961 Traning Loss: tensor(0.3460)\n",
      "16962 Traning Loss: tensor(0.3664)\n",
      "16963 Traning Loss: tensor(0.3344)\n",
      "16964 Traning Loss: tensor(0.3285)\n",
      "16965 Traning Loss: tensor(0.3242)\n",
      "16966 Traning Loss: tensor(0.3354)\n",
      "16967 Traning Loss: tensor(0.3536)\n",
      "16968 Traning Loss: tensor(0.3595)\n",
      "16969 Traning Loss: tensor(0.3069)\n",
      "16970 Traning Loss: tensor(0.2845)\n",
      "16971 Traning Loss: tensor(0.3323)\n",
      "16972 Traning Loss: tensor(0.3192)\n",
      "16973 Traning Loss: tensor(0.3303)\n",
      "16974 Traning Loss: tensor(0.2953)\n",
      "16975 Traning Loss: tensor(0.3820)\n",
      "16976 Traning Loss: tensor(0.3199)\n",
      "16977 Traning Loss: tensor(0.3612)\n",
      "16978 Traning Loss: tensor(0.3105)\n",
      "16979 Traning Loss: tensor(0.3194)\n",
      "16980 Traning Loss: tensor(0.3500)\n",
      "16981 Traning Loss: tensor(0.3372)\n",
      "16982 Traning Loss: tensor(0.3124)\n",
      "16983 Traning Loss: tensor(0.3608)\n",
      "16984 Traning Loss: tensor(0.3623)\n",
      "16985 Traning Loss: tensor(0.3045)\n",
      "16986 Traning Loss: tensor(0.3260)\n",
      "16987 Traning Loss: tensor(0.3275)\n",
      "16988 Traning Loss: tensor(0.3220)\n",
      "16989 Traning Loss: tensor(0.3238)\n",
      "16990 Traning Loss: tensor(0.3271)\n",
      "16991 Traning Loss: tensor(0.3303)\n",
      "16992 Traning Loss: tensor(0.3267)\n",
      "16993 Traning Loss: tensor(0.3714)\n",
      "16994 Traning Loss: tensor(0.2882)\n",
      "16995 Traning Loss: tensor(0.3102)\n",
      "16996 Traning Loss: tensor(0.2978)\n",
      "16997 Traning Loss: tensor(0.3085)\n",
      "16998 Traning Loss: tensor(0.3140)\n",
      "16999 Traning Loss: tensor(0.3353)\n",
      "17000 Traning Loss: tensor(0.3293)\n",
      "17001 Traning Loss: tensor(0.3456)\n",
      "17002 Traning Loss: tensor(0.3485)\n",
      "17003 Traning Loss: tensor(0.3759)\n",
      "17004 Traning Loss: tensor(0.3170)\n",
      "17005 Traning Loss: tensor(0.3346)\n",
      "17006 Traning Loss: tensor(0.3528)\n",
      "17007 Traning Loss: tensor(0.3180)\n",
      "17008 Traning Loss: tensor(0.3237)\n",
      "17009 Traning Loss: tensor(0.3291)\n",
      "17010 Traning Loss: tensor(0.3181)\n",
      "17011 Traning Loss: tensor(0.3680)\n",
      "17012 Traning Loss: tensor(0.3345)\n",
      "17013 Traning Loss: tensor(0.2976)\n",
      "17014 Traning Loss: tensor(0.2887)\n",
      "17015 Traning Loss: tensor(0.3534)\n",
      "17016 Traning Loss: tensor(0.3232)\n",
      "17017 Traning Loss: tensor(0.3109)\n",
      "17018 Traning Loss: tensor(0.2930)\n",
      "17019 Traning Loss: tensor(0.3192)\n",
      "17020 Traning Loss: tensor(0.3141)\n",
      "17021 Traning Loss: tensor(0.3236)\n",
      "17022 Traning Loss: tensor(0.3150)\n",
      "17023 Traning Loss: tensor(0.3114)\n",
      "17024 Traning Loss: tensor(0.3112)\n",
      "17025 Traning Loss: tensor(0.3408)\n",
      "17026 Traning Loss: tensor(0.3603)\n",
      "17027 Traning Loss: tensor(0.3353)\n",
      "17028 Traning Loss: tensor(0.2833)\n",
      "17029 Traning Loss: tensor(0.3254)\n",
      "17030 Traning Loss: tensor(0.3081)\n",
      "17031 Traning Loss: tensor(0.3045)\n",
      "17032 Traning Loss: tensor(0.3150)\n",
      "17033 Traning Loss: tensor(0.3172)\n",
      "17034 Traning Loss: tensor(0.3202)\n",
      "17035 Traning Loss: tensor(0.3373)\n",
      "17036 Traning Loss: tensor(0.3601)\n",
      "17037 Traning Loss: tensor(0.2920)\n",
      "17038 Traning Loss: tensor(0.3221)\n",
      "17039 Traning Loss: tensor(0.3015)\n",
      "17040 Traning Loss: tensor(0.3191)\n",
      "17041 Traning Loss: tensor(0.2982)\n",
      "17042 Traning Loss: tensor(0.3205)\n",
      "17043 Traning Loss: tensor(0.3014)\n",
      "17044 Traning Loss: tensor(0.3012)\n",
      "17045 Traning Loss: tensor(0.2784)\n",
      "17046 Traning Loss: tensor(0.3196)\n",
      "17047 Traning Loss: tensor(0.3170)\n",
      "17048 Traning Loss: tensor(0.3290)\n",
      "17049 Traning Loss: tensor(0.2865)\n",
      "17050 Traning Loss: tensor(0.2905)\n",
      "17051 Traning Loss: tensor(0.3263)\n",
      "17052 Traning Loss: tensor(0.2811)\n",
      "17053 Traning Loss: tensor(0.3466)\n",
      "17054 Traning Loss: tensor(0.3045)\n",
      "17055 Traning Loss: tensor(0.2767)\n",
      "17056 Traning Loss: tensor(0.2882)\n",
      "17057 Traning Loss: tensor(0.3137)\n",
      "17058 Traning Loss: tensor(0.2993)\n",
      "17059 Traning Loss: tensor(0.3294)\n",
      "17060 Traning Loss: tensor(0.3060)\n",
      "17061 Traning Loss: tensor(0.2995)\n",
      "17062 Traning Loss: tensor(0.2707)\n",
      "17063 Traning Loss: tensor(0.3400)\n",
      "17064 Traning Loss: tensor(0.2849)\n",
      "17065 Traning Loss: tensor(0.3260)\n",
      "17066 Traning Loss: tensor(0.2989)\n",
      "17067 Traning Loss: tensor(0.2901)\n",
      "17068 Traning Loss: tensor(0.3020)\n",
      "17069 Traning Loss: tensor(0.2983)\n",
      "17070 Traning Loss: tensor(0.3213)\n",
      "17071 Traning Loss: tensor(0.3029)\n",
      "17072 Traning Loss: tensor(0.3550)\n",
      "17073 Traning Loss: tensor(0.3440)\n",
      "17074 Traning Loss: tensor(0.2866)\n",
      "17075 Traning Loss: tensor(0.3066)\n",
      "17076 Traning Loss: tensor(0.3589)\n",
      "17077 Traning Loss: tensor(0.3434)\n",
      "17078 Traning Loss: tensor(0.2967)\n",
      "17079 Traning Loss: tensor(0.3050)\n",
      "17080 Traning Loss: tensor(0.2920)\n",
      "17081 Traning Loss: tensor(0.3213)\n",
      "17082 Traning Loss: tensor(0.3485)\n",
      "17083 Traning Loss: tensor(0.3392)\n",
      "17084 Traning Loss: tensor(0.3126)\n",
      "17085 Traning Loss: tensor(0.2976)\n",
      "17086 Traning Loss: tensor(0.2860)\n",
      "17087 Traning Loss: tensor(0.3268)\n",
      "17088 Traning Loss: tensor(0.3007)\n",
      "17089 Traning Loss: tensor(0.3724)\n",
      "17090 Traning Loss: tensor(0.3584)\n",
      "17091 Traning Loss: tensor(0.3205)\n",
      "17092 Traning Loss: tensor(0.3071)\n",
      "17093 Traning Loss: tensor(0.2849)\n",
      "17094 Traning Loss: tensor(0.2953)\n",
      "17095 Traning Loss: tensor(0.2863)\n",
      "17096 Traning Loss: tensor(0.3013)\n",
      "17097 Traning Loss: tensor(0.3066)\n",
      "17098 Traning Loss: tensor(0.3219)\n",
      "17099 Traning Loss: tensor(0.3060)\n",
      "17100 Traning Loss: tensor(0.2785)\n",
      "17101 Traning Loss: tensor(0.2947)\n",
      "17102 Traning Loss: tensor(0.3291)\n",
      "17103 Traning Loss: tensor(0.3361)\n",
      "17104 Traning Loss: tensor(0.3329)\n",
      "17105 Traning Loss: tensor(0.2918)\n",
      "17106 Traning Loss: tensor(0.2994)\n",
      "17107 Traning Loss: tensor(0.3533)\n",
      "17108 Traning Loss: tensor(0.3035)\n",
      "17109 Traning Loss: tensor(0.2762)\n",
      "17110 Traning Loss: tensor(0.2988)\n",
      "17111 Traning Loss: tensor(0.3557)\n",
      "17112 Traning Loss: tensor(0.3561)\n",
      "17113 Traning Loss: tensor(0.3068)\n",
      "17114 Traning Loss: tensor(0.2924)\n",
      "17115 Traning Loss: tensor(0.3882)\n",
      "17116 Traning Loss: tensor(0.3296)\n",
      "17117 Traning Loss: tensor(0.3321)\n",
      "17118 Traning Loss: tensor(0.3373)\n",
      "17119 Traning Loss: tensor(0.3496)\n",
      "17120 Traning Loss: tensor(0.3101)\n",
      "17121 Traning Loss: tensor(0.3107)\n",
      "17122 Traning Loss: tensor(0.3387)\n",
      "17123 Traning Loss: tensor(0.3162)\n",
      "17124 Traning Loss: tensor(0.2834)\n",
      "17125 Traning Loss: tensor(0.3268)\n",
      "17126 Traning Loss: tensor(0.3656)\n",
      "17127 Traning Loss: tensor(0.2867)\n",
      "17128 Traning Loss: tensor(0.3141)\n",
      "17129 Traning Loss: tensor(0.3256)\n",
      "17130 Traning Loss: tensor(0.2971)\n",
      "17131 Traning Loss: tensor(0.3119)\n",
      "17132 Traning Loss: tensor(0.2981)\n",
      "17133 Traning Loss: tensor(0.3157)\n",
      "17134 Traning Loss: tensor(0.2869)\n",
      "17135 Traning Loss: tensor(0.2830)\n",
      "17136 Traning Loss: tensor(0.2717)\n",
      "17137 Traning Loss: tensor(0.3026)\n",
      "17138 Traning Loss: tensor(0.3145)\n",
      "17139 Traning Loss: tensor(0.2958)\n",
      "17140 Traning Loss: tensor(0.2982)\n",
      "17141 Traning Loss: tensor(0.2926)\n",
      "17142 Traning Loss: tensor(0.3356)\n",
      "17143 Traning Loss: tensor(0.3113)\n",
      "17144 Traning Loss: tensor(0.3347)\n",
      "17145 Traning Loss: tensor(0.2747)\n",
      "17146 Traning Loss: tensor(0.3103)\n",
      "17147 Traning Loss: tensor(0.3065)\n",
      "17148 Traning Loss: tensor(0.2994)\n",
      "17149 Traning Loss: tensor(0.2849)\n",
      "17150 Traning Loss: tensor(0.3001)\n",
      "17151 Traning Loss: tensor(0.3219)\n",
      "17152 Traning Loss: tensor(0.2711)\n",
      "17153 Traning Loss: tensor(0.2778)\n",
      "17154 Traning Loss: tensor(0.3302)\n",
      "17155 Traning Loss: tensor(0.3166)\n",
      "17156 Traning Loss: tensor(0.3043)\n",
      "17157 Traning Loss: tensor(0.2702)\n",
      "17158 Traning Loss: tensor(0.2553)\n",
      "17159 Traning Loss: tensor(0.3139)\n",
      "17160 Traning Loss: tensor(0.3179)\n",
      "17161 Traning Loss: tensor(0.2834)\n",
      "17162 Traning Loss: tensor(0.2823)\n",
      "17163 Traning Loss: tensor(0.3049)\n",
      "17164 Traning Loss: tensor(0.2951)\n",
      "17165 Traning Loss: tensor(0.2863)\n",
      "17166 Traning Loss: tensor(0.3277)\n",
      "17167 Traning Loss: tensor(0.2773)\n",
      "17168 Traning Loss: tensor(0.2700)\n",
      "17169 Traning Loss: tensor(0.2900)\n",
      "17170 Traning Loss: tensor(0.3004)\n",
      "17171 Traning Loss: tensor(0.2885)\n",
      "17172 Traning Loss: tensor(0.3024)\n",
      "17173 Traning Loss: tensor(0.3031)\n",
      "17174 Traning Loss: tensor(0.2888)\n",
      "17175 Traning Loss: tensor(0.2985)\n",
      "17176 Traning Loss: tensor(0.3051)\n",
      "17177 Traning Loss: tensor(0.3029)\n",
      "17178 Traning Loss: tensor(0.3080)\n",
      "17179 Traning Loss: tensor(0.3237)\n",
      "17180 Traning Loss: tensor(0.3065)\n",
      "17181 Traning Loss: tensor(0.2844)\n",
      "17182 Traning Loss: tensor(0.3612)\n",
      "17183 Traning Loss: tensor(0.2974)\n",
      "17184 Traning Loss: tensor(0.2912)\n",
      "17185 Traning Loss: tensor(0.2821)\n",
      "17186 Traning Loss: tensor(0.2931)\n",
      "17187 Traning Loss: tensor(0.3732)\n",
      "17188 Traning Loss: tensor(0.2925)\n",
      "17189 Traning Loss: tensor(0.2914)\n",
      "17190 Traning Loss: tensor(0.3160)\n",
      "17191 Traning Loss: tensor(0.2994)\n",
      "17192 Traning Loss: tensor(0.2793)\n",
      "17193 Traning Loss: tensor(0.2896)\n",
      "17194 Traning Loss: tensor(0.2946)\n",
      "17195 Traning Loss: tensor(0.2754)\n",
      "17196 Traning Loss: tensor(0.3111)\n",
      "17197 Traning Loss: tensor(0.3216)\n",
      "17198 Traning Loss: tensor(0.2690)\n",
      "17199 Traning Loss: tensor(0.2543)\n",
      "17200 Traning Loss: tensor(0.3085)\n",
      "17201 Traning Loss: tensor(0.2839)\n",
      "17202 Traning Loss: tensor(0.2775)\n",
      "17203 Traning Loss: tensor(0.3120)\n",
      "17204 Traning Loss: tensor(0.2843)\n",
      "17205 Traning Loss: tensor(0.2839)\n",
      "17206 Traning Loss: tensor(0.3020)\n",
      "17207 Traning Loss: tensor(0.2919)\n",
      "17208 Traning Loss: tensor(0.3689)\n",
      "17209 Traning Loss: tensor(0.2820)\n",
      "17210 Traning Loss: tensor(0.2925)\n",
      "17211 Traning Loss: tensor(0.3179)\n",
      "17212 Traning Loss: tensor(0.3146)\n",
      "17213 Traning Loss: tensor(0.2871)\n",
      "17214 Traning Loss: tensor(0.2753)\n",
      "17215 Traning Loss: tensor(0.2633)\n",
      "17216 Traning Loss: tensor(0.2977)\n",
      "17217 Traning Loss: tensor(0.2561)\n",
      "17218 Traning Loss: tensor(0.2899)\n",
      "17219 Traning Loss: tensor(0.2877)\n",
      "17220 Traning Loss: tensor(0.3119)\n",
      "17221 Traning Loss: tensor(0.2969)\n",
      "17222 Traning Loss: tensor(0.3169)\n",
      "17223 Traning Loss: tensor(0.3267)\n",
      "17224 Traning Loss: tensor(0.2999)\n",
      "17225 Traning Loss: tensor(0.3568)\n",
      "17226 Traning Loss: tensor(0.3256)\n",
      "17227 Traning Loss: tensor(0.2921)\n",
      "17228 Traning Loss: tensor(0.2844)\n",
      "17229 Traning Loss: tensor(0.3015)\n",
      "17230 Traning Loss: tensor(0.3038)\n",
      "17231 Traning Loss: tensor(0.3478)\n",
      "17232 Traning Loss: tensor(0.2932)\n",
      "17233 Traning Loss: tensor(0.3450)\n",
      "17234 Traning Loss: tensor(0.3032)\n",
      "17235 Traning Loss: tensor(0.3275)\n",
      "17236 Traning Loss: tensor(0.3004)\n",
      "17237 Traning Loss: tensor(0.2707)\n",
      "17238 Traning Loss: tensor(0.2927)\n",
      "17239 Traning Loss: tensor(0.3041)\n",
      "17240 Traning Loss: tensor(0.2598)\n",
      "17241 Traning Loss: tensor(0.2786)\n",
      "17242 Traning Loss: tensor(0.3348)\n",
      "17243 Traning Loss: tensor(0.3356)\n",
      "17244 Traning Loss: tensor(0.3112)\n",
      "17245 Traning Loss: tensor(0.3105)\n",
      "17246 Traning Loss: tensor(0.3188)\n",
      "17247 Traning Loss: tensor(0.2930)\n",
      "17248 Traning Loss: tensor(0.2893)\n",
      "17249 Traning Loss: tensor(0.3062)\n",
      "17250 Traning Loss: tensor(0.3021)\n",
      "17251 Traning Loss: tensor(0.2813)\n",
      "17252 Traning Loss: tensor(0.2768)\n",
      "17253 Traning Loss: tensor(0.3142)\n",
      "17254 Traning Loss: tensor(0.3018)\n",
      "17255 Traning Loss: tensor(0.3148)\n",
      "17256 Traning Loss: tensor(0.3080)\n",
      "17257 Traning Loss: tensor(0.2981)\n",
      "17258 Traning Loss: tensor(0.2794)\n",
      "17259 Traning Loss: tensor(0.3132)\n",
      "17260 Traning Loss: tensor(0.2806)\n",
      "17261 Traning Loss: tensor(0.2785)\n",
      "17262 Traning Loss: tensor(0.3562)\n",
      "17263 Traning Loss: tensor(0.3217)\n",
      "17264 Traning Loss: tensor(0.2796)\n",
      "17265 Traning Loss: tensor(0.3031)\n",
      "17266 Traning Loss: tensor(0.3252)\n",
      "17267 Traning Loss: tensor(0.2444)\n",
      "17268 Traning Loss: tensor(0.3205)\n",
      "17269 Traning Loss: tensor(0.3245)\n",
      "17270 Traning Loss: tensor(0.3038)\n",
      "17271 Traning Loss: tensor(0.3017)\n",
      "17272 Traning Loss: tensor(0.3385)\n",
      "17273 Traning Loss: tensor(0.2623)\n",
      "17274 Traning Loss: tensor(0.2739)\n",
      "17275 Traning Loss: tensor(0.2726)\n",
      "17276 Traning Loss: tensor(0.2973)\n",
      "17277 Traning Loss: tensor(0.3063)\n",
      "17278 Traning Loss: tensor(0.2602)\n",
      "17279 Traning Loss: tensor(0.3167)\n",
      "17280 Traning Loss: tensor(0.2743)\n",
      "17281 Traning Loss: tensor(0.2995)\n",
      "17282 Traning Loss: tensor(0.2683)\n",
      "17283 Traning Loss: tensor(0.2599)\n",
      "17284 Traning Loss: tensor(0.3032)\n",
      "17285 Traning Loss: tensor(0.2597)\n",
      "17286 Traning Loss: tensor(0.2721)\n",
      "17287 Traning Loss: tensor(0.2866)\n",
      "17288 Traning Loss: tensor(0.2735)\n",
      "17289 Traning Loss: tensor(0.2841)\n",
      "17290 Traning Loss: tensor(0.3396)\n",
      "17291 Traning Loss: tensor(0.2884)\n",
      "17292 Traning Loss: tensor(0.3181)\n",
      "17293 Traning Loss: tensor(0.2773)\n",
      "17294 Traning Loss: tensor(0.2771)\n",
      "17295 Traning Loss: tensor(0.2776)\n",
      "17296 Traning Loss: tensor(0.2548)\n",
      "17297 Traning Loss: tensor(0.2795)\n",
      "17298 Traning Loss: tensor(0.2887)\n",
      "17299 Traning Loss: tensor(0.2729)\n",
      "17300 Traning Loss: tensor(0.3046)\n",
      "17301 Traning Loss: tensor(0.3659)\n",
      "17302 Traning Loss: tensor(0.2904)\n",
      "17303 Traning Loss: tensor(0.2965)\n",
      "17304 Traning Loss: tensor(0.2708)\n",
      "17305 Traning Loss: tensor(0.3081)\n",
      "17306 Traning Loss: tensor(0.2821)\n",
      "17307 Traning Loss: tensor(0.2983)\n",
      "17308 Traning Loss: tensor(0.2987)\n",
      "17309 Traning Loss: tensor(0.2981)\n",
      "17310 Traning Loss: tensor(0.2673)\n",
      "17311 Traning Loss: tensor(0.3038)\n",
      "17312 Traning Loss: tensor(0.3249)\n",
      "17313 Traning Loss: tensor(0.2963)\n",
      "17314 Traning Loss: tensor(0.2587)\n",
      "17315 Traning Loss: tensor(0.3225)\n",
      "17316 Traning Loss: tensor(0.2548)\n",
      "17317 Traning Loss: tensor(0.2819)\n",
      "17318 Traning Loss: tensor(0.2617)\n",
      "17319 Traning Loss: tensor(0.2572)\n",
      "17320 Traning Loss: tensor(0.2933)\n",
      "17321 Traning Loss: tensor(0.3223)\n",
      "17322 Traning Loss: tensor(0.2929)\n",
      "17323 Traning Loss: tensor(0.2733)\n",
      "17324 Traning Loss: tensor(0.2878)\n",
      "17325 Traning Loss: tensor(0.3078)\n",
      "17326 Traning Loss: tensor(0.2711)\n",
      "17327 Traning Loss: tensor(0.2989)\n",
      "17328 Traning Loss: tensor(0.2896)\n",
      "17329 Traning Loss: tensor(0.2587)\n",
      "17330 Traning Loss: tensor(0.2865)\n",
      "17331 Traning Loss: tensor(0.2914)\n",
      "17332 Traning Loss: tensor(0.3172)\n",
      "17333 Traning Loss: tensor(0.2988)\n",
      "17334 Traning Loss: tensor(0.2701)\n",
      "17335 Traning Loss: tensor(0.2563)\n",
      "17336 Traning Loss: tensor(0.2485)\n",
      "17337 Traning Loss: tensor(0.2853)\n",
      "17338 Traning Loss: tensor(0.2791)\n",
      "17339 Traning Loss: tensor(0.2974)\n",
      "17340 Traning Loss: tensor(0.2865)\n",
      "17341 Traning Loss: tensor(0.2940)\n",
      "17342 Traning Loss: tensor(0.2943)\n",
      "17343 Traning Loss: tensor(0.3105)\n",
      "17344 Traning Loss: tensor(0.3165)\n",
      "17345 Traning Loss: tensor(0.2652)\n",
      "17346 Traning Loss: tensor(0.2938)\n",
      "17347 Traning Loss: tensor(0.2815)\n",
      "17348 Traning Loss: tensor(0.2509)\n",
      "17349 Traning Loss: tensor(0.2724)\n",
      "17350 Traning Loss: tensor(0.2734)\n",
      "17351 Traning Loss: tensor(0.2918)\n",
      "17352 Traning Loss: tensor(0.2999)\n",
      "17353 Traning Loss: tensor(0.3122)\n",
      "17354 Traning Loss: tensor(0.2971)\n",
      "17355 Traning Loss: tensor(0.2769)\n",
      "17356 Traning Loss: tensor(0.2997)\n",
      "17357 Traning Loss: tensor(0.3088)\n",
      "17358 Traning Loss: tensor(0.2573)\n",
      "17359 Traning Loss: tensor(0.3041)\n",
      "17360 Traning Loss: tensor(0.3275)\n",
      "17361 Traning Loss: tensor(0.2809)\n",
      "17362 Traning Loss: tensor(0.2878)\n",
      "17363 Traning Loss: tensor(0.2912)\n",
      "17364 Traning Loss: tensor(0.3022)\n",
      "17365 Traning Loss: tensor(0.3210)\n",
      "17366 Traning Loss: tensor(0.2538)\n",
      "17367 Traning Loss: tensor(0.3061)\n",
      "17368 Traning Loss: tensor(0.2399)\n",
      "17369 Traning Loss: tensor(0.3128)\n",
      "17370 Traning Loss: tensor(0.2839)\n",
      "17371 Traning Loss: tensor(0.3048)\n",
      "17372 Traning Loss: tensor(0.2859)\n",
      "17373 Traning Loss: tensor(0.2804)\n",
      "17374 Traning Loss: tensor(0.2624)\n",
      "17375 Traning Loss: tensor(0.2978)\n",
      "17376 Traning Loss: tensor(0.2817)\n",
      "17377 Traning Loss: tensor(0.2814)\n",
      "17378 Traning Loss: tensor(0.2765)\n",
      "17379 Traning Loss: tensor(0.2715)\n",
      "17380 Traning Loss: tensor(0.3021)\n",
      "17381 Traning Loss: tensor(0.2709)\n",
      "17382 Traning Loss: tensor(0.2567)\n",
      "17383 Traning Loss: tensor(0.2477)\n",
      "17384 Traning Loss: tensor(0.2545)\n",
      "17385 Traning Loss: tensor(0.2432)\n",
      "17386 Traning Loss: tensor(0.2716)\n",
      "17387 Traning Loss: tensor(0.2526)\n",
      "17388 Traning Loss: tensor(0.2979)\n",
      "17389 Traning Loss: tensor(0.2558)\n",
      "17390 Traning Loss: tensor(0.3057)\n",
      "17391 Traning Loss: tensor(0.2586)\n",
      "17392 Traning Loss: tensor(0.2610)\n",
      "17393 Traning Loss: tensor(0.3098)\n",
      "17394 Traning Loss: tensor(0.2803)\n",
      "17395 Traning Loss: tensor(0.2774)\n",
      "17396 Traning Loss: tensor(0.2543)\n",
      "17397 Traning Loss: tensor(0.2977)\n",
      "17398 Traning Loss: tensor(0.3369)\n",
      "17399 Traning Loss: tensor(0.2503)\n",
      "17400 Traning Loss: tensor(0.2507)\n",
      "17401 Traning Loss: tensor(0.2735)\n",
      "17402 Traning Loss: tensor(0.2592)\n",
      "17403 Traning Loss: tensor(0.2883)\n",
      "17404 Traning Loss: tensor(0.2925)\n",
      "17405 Traning Loss: tensor(0.2528)\n",
      "17406 Traning Loss: tensor(0.2641)\n",
      "17407 Traning Loss: tensor(0.2776)\n",
      "17408 Traning Loss: tensor(0.2477)\n",
      "17409 Traning Loss: tensor(0.2678)\n",
      "17410 Traning Loss: tensor(0.2781)\n",
      "17411 Traning Loss: tensor(0.2835)\n",
      "17412 Traning Loss: tensor(0.2873)\n",
      "17413 Traning Loss: tensor(0.2483)\n",
      "17414 Traning Loss: tensor(0.2397)\n",
      "17415 Traning Loss: tensor(0.2662)\n",
      "17416 Traning Loss: tensor(0.3008)\n",
      "17417 Traning Loss: tensor(0.3187)\n",
      "17418 Traning Loss: tensor(0.3149)\n",
      "17419 Traning Loss: tensor(0.2738)\n",
      "17420 Traning Loss: tensor(0.2912)\n",
      "17421 Traning Loss: tensor(0.2724)\n",
      "17422 Traning Loss: tensor(0.2677)\n",
      "17423 Traning Loss: tensor(0.2367)\n",
      "17424 Traning Loss: tensor(0.2736)\n",
      "17425 Traning Loss: tensor(0.3137)\n",
      "17426 Traning Loss: tensor(0.2888)\n",
      "17427 Traning Loss: tensor(0.2756)\n",
      "17428 Traning Loss: tensor(0.2857)\n",
      "17429 Traning Loss: tensor(0.2710)\n",
      "17430 Traning Loss: tensor(0.2528)\n",
      "17431 Traning Loss: tensor(0.2727)\n",
      "17432 Traning Loss: tensor(0.2911)\n",
      "17433 Traning Loss: tensor(0.2757)\n",
      "17434 Traning Loss: tensor(0.2781)\n",
      "17435 Traning Loss: tensor(0.2859)\n",
      "17436 Traning Loss: tensor(0.2626)\n",
      "17437 Traning Loss: tensor(0.2724)\n",
      "17438 Traning Loss: tensor(0.3062)\n",
      "17439 Traning Loss: tensor(0.3177)\n",
      "17440 Traning Loss: tensor(0.2731)\n",
      "17441 Traning Loss: tensor(0.2866)\n",
      "17442 Traning Loss: tensor(0.2833)\n",
      "17443 Traning Loss: tensor(0.3157)\n",
      "17444 Traning Loss: tensor(0.2571)\n",
      "17445 Traning Loss: tensor(0.3088)\n",
      "17446 Traning Loss: tensor(0.2914)\n",
      "17447 Traning Loss: tensor(0.2751)\n",
      "17448 Traning Loss: tensor(0.2609)\n",
      "17449 Traning Loss: tensor(0.2683)\n",
      "17450 Traning Loss: tensor(0.2471)\n",
      "17451 Traning Loss: tensor(0.2746)\n",
      "17452 Traning Loss: tensor(0.3138)\n",
      "17453 Traning Loss: tensor(0.2431)\n",
      "17454 Traning Loss: tensor(0.2919)\n",
      "17455 Traning Loss: tensor(0.2945)\n",
      "17456 Traning Loss: tensor(0.2879)\n",
      "17457 Traning Loss: tensor(0.2675)\n",
      "17458 Traning Loss: tensor(0.2981)\n",
      "17459 Traning Loss: tensor(0.2812)\n",
      "17460 Traning Loss: tensor(0.2371)\n",
      "17461 Traning Loss: tensor(0.2471)\n",
      "17462 Traning Loss: tensor(0.2775)\n",
      "17463 Traning Loss: tensor(0.2759)\n",
      "17464 Traning Loss: tensor(0.2529)\n",
      "17465 Traning Loss: tensor(0.2795)\n",
      "17466 Traning Loss: tensor(0.3097)\n",
      "17467 Traning Loss: tensor(0.2653)\n",
      "17468 Traning Loss: tensor(0.2523)\n",
      "17469 Traning Loss: tensor(0.2806)\n",
      "17470 Traning Loss: tensor(0.3073)\n",
      "17471 Traning Loss: tensor(0.2517)\n",
      "17472 Traning Loss: tensor(0.2623)\n",
      "17473 Traning Loss: tensor(0.2742)\n",
      "17474 Traning Loss: tensor(0.2645)\n",
      "17475 Traning Loss: tensor(0.2494)\n",
      "17476 Traning Loss: tensor(0.2409)\n",
      "17477 Traning Loss: tensor(0.2490)\n",
      "17478 Traning Loss: tensor(0.2611)\n",
      "17479 Traning Loss: tensor(0.2614)\n",
      "17480 Traning Loss: tensor(0.3143)\n",
      "17481 Traning Loss: tensor(0.2440)\n",
      "17482 Traning Loss: tensor(0.2352)\n",
      "17483 Traning Loss: tensor(0.2692)\n",
      "17484 Traning Loss: tensor(0.2849)\n",
      "17485 Traning Loss: tensor(0.2765)\n",
      "17486 Traning Loss: tensor(0.2705)\n",
      "17487 Traning Loss: tensor(0.2768)\n",
      "17488 Traning Loss: tensor(0.2870)\n",
      "17489 Traning Loss: tensor(0.2511)\n",
      "17490 Traning Loss: tensor(0.2692)\n",
      "17491 Traning Loss: tensor(0.2902)\n",
      "17492 Traning Loss: tensor(0.2495)\n",
      "17493 Traning Loss: tensor(0.2702)\n",
      "17494 Traning Loss: tensor(0.2565)\n",
      "17495 Traning Loss: tensor(0.2427)\n",
      "17496 Traning Loss: tensor(0.2646)\n",
      "17497 Traning Loss: tensor(0.2479)\n",
      "17498 Traning Loss: tensor(0.2687)\n",
      "17499 Traning Loss: tensor(0.2454)\n",
      "17500 Traning Loss: tensor(0.3298)\n",
      "17501 Traning Loss: tensor(0.2509)\n",
      "17502 Traning Loss: tensor(0.2640)\n",
      "17503 Traning Loss: tensor(0.2884)\n",
      "17504 Traning Loss: tensor(0.3011)\n",
      "17505 Traning Loss: tensor(0.3049)\n",
      "17506 Traning Loss: tensor(0.2481)\n",
      "17507 Traning Loss: tensor(0.2597)\n",
      "17508 Traning Loss: tensor(0.3001)\n",
      "17509 Traning Loss: tensor(0.2653)\n",
      "17510 Traning Loss: tensor(0.3058)\n",
      "17511 Traning Loss: tensor(0.2327)\n",
      "17512 Traning Loss: tensor(0.2751)\n",
      "17513 Traning Loss: tensor(0.2391)\n",
      "17514 Traning Loss: tensor(0.2734)\n",
      "17515 Traning Loss: tensor(0.2677)\n",
      "17516 Traning Loss: tensor(0.2321)\n",
      "17517 Traning Loss: tensor(0.2541)\n",
      "17518 Traning Loss: tensor(0.2961)\n",
      "17519 Traning Loss: tensor(0.2305)\n",
      "17520 Traning Loss: tensor(0.2871)\n",
      "17521 Traning Loss: tensor(0.2676)\n",
      "17522 Traning Loss: tensor(0.2707)\n",
      "17523 Traning Loss: tensor(0.2846)\n",
      "17524 Traning Loss: tensor(0.2884)\n",
      "17525 Traning Loss: tensor(0.2455)\n",
      "17526 Traning Loss: tensor(0.2731)\n",
      "17527 Traning Loss: tensor(0.2429)\n",
      "17528 Traning Loss: tensor(0.2244)\n",
      "17529 Traning Loss: tensor(0.2696)\n",
      "17530 Traning Loss: tensor(0.2700)\n",
      "17531 Traning Loss: tensor(0.2783)\n",
      "17532 Traning Loss: tensor(0.2314)\n",
      "17533 Traning Loss: tensor(0.2514)\n",
      "17534 Traning Loss: tensor(0.2549)\n",
      "17535 Traning Loss: tensor(0.2609)\n",
      "17536 Traning Loss: tensor(0.2584)\n",
      "17537 Traning Loss: tensor(0.2719)\n",
      "17538 Traning Loss: tensor(0.2232)\n",
      "17539 Traning Loss: tensor(0.2835)\n",
      "17540 Traning Loss: tensor(0.3100)\n",
      "17541 Traning Loss: tensor(0.3301)\n",
      "17542 Traning Loss: tensor(0.2619)\n",
      "17543 Traning Loss: tensor(0.2835)\n",
      "17544 Traning Loss: tensor(0.2500)\n",
      "17545 Traning Loss: tensor(0.2760)\n",
      "17546 Traning Loss: tensor(0.2779)\n",
      "17547 Traning Loss: tensor(0.2923)\n",
      "17548 Traning Loss: tensor(0.2567)\n",
      "17549 Traning Loss: tensor(0.2648)\n",
      "17550 Traning Loss: tensor(0.2924)\n",
      "17551 Traning Loss: tensor(0.2242)\n",
      "17552 Traning Loss: tensor(0.2712)\n",
      "17553 Traning Loss: tensor(0.2462)\n",
      "17554 Traning Loss: tensor(0.2651)\n",
      "17555 Traning Loss: tensor(0.2654)\n",
      "17556 Traning Loss: tensor(0.2667)\n",
      "17557 Traning Loss: tensor(0.2668)\n",
      "17558 Traning Loss: tensor(0.2578)\n",
      "17559 Traning Loss: tensor(0.2483)\n",
      "17560 Traning Loss: tensor(0.2816)\n",
      "17561 Traning Loss: tensor(0.2833)\n",
      "17562 Traning Loss: tensor(0.2680)\n",
      "17563 Traning Loss: tensor(0.2740)\n",
      "17564 Traning Loss: tensor(0.2926)\n",
      "17565 Traning Loss: tensor(0.2647)\n",
      "17566 Traning Loss: tensor(0.2851)\n",
      "17567 Traning Loss: tensor(0.2704)\n",
      "17568 Traning Loss: tensor(0.2805)\n",
      "17569 Traning Loss: tensor(0.2952)\n",
      "17570 Traning Loss: tensor(0.2446)\n",
      "17571 Traning Loss: tensor(0.2739)\n",
      "17572 Traning Loss: tensor(0.2827)\n",
      "17573 Traning Loss: tensor(0.2656)\n",
      "17574 Traning Loss: tensor(0.2712)\n",
      "17575 Traning Loss: tensor(0.2438)\n",
      "17576 Traning Loss: tensor(0.2649)\n",
      "17577 Traning Loss: tensor(0.2607)\n",
      "17578 Traning Loss: tensor(0.2335)\n",
      "17579 Traning Loss: tensor(0.2531)\n",
      "17580 Traning Loss: tensor(0.2671)\n",
      "17581 Traning Loss: tensor(0.2650)\n",
      "17582 Traning Loss: tensor(0.2323)\n",
      "17583 Traning Loss: tensor(0.2494)\n",
      "17584 Traning Loss: tensor(0.2812)\n",
      "17585 Traning Loss: tensor(0.2356)\n",
      "17586 Traning Loss: tensor(0.2932)\n",
      "17587 Traning Loss: tensor(0.2367)\n",
      "17588 Traning Loss: tensor(0.2632)\n",
      "17589 Traning Loss: tensor(0.2724)\n",
      "17590 Traning Loss: tensor(0.2847)\n",
      "17591 Traning Loss: tensor(0.2789)\n",
      "17592 Traning Loss: tensor(0.3411)\n",
      "17593 Traning Loss: tensor(0.2725)\n",
      "17594 Traning Loss: tensor(0.2841)\n",
      "17595 Traning Loss: tensor(0.2447)\n",
      "17596 Traning Loss: tensor(0.2722)\n",
      "17597 Traning Loss: tensor(0.2674)\n",
      "17598 Traning Loss: tensor(0.2484)\n",
      "17599 Traning Loss: tensor(0.3192)\n",
      "17600 Traning Loss: tensor(0.2557)\n",
      "17601 Traning Loss: tensor(0.2538)\n",
      "17602 Traning Loss: tensor(0.3214)\n",
      "17603 Traning Loss: tensor(0.2529)\n",
      "17604 Traning Loss: tensor(0.2440)\n",
      "17605 Traning Loss: tensor(0.2683)\n",
      "17606 Traning Loss: tensor(0.2899)\n",
      "17607 Traning Loss: tensor(0.2377)\n",
      "17608 Traning Loss: tensor(0.2881)\n",
      "17609 Traning Loss: tensor(0.3054)\n",
      "17610 Traning Loss: tensor(0.2552)\n",
      "17611 Traning Loss: tensor(0.2703)\n",
      "17612 Traning Loss: tensor(0.2331)\n",
      "17613 Traning Loss: tensor(0.2651)\n",
      "17614 Traning Loss: tensor(0.2974)\n",
      "17615 Traning Loss: tensor(0.2643)\n",
      "17616 Traning Loss: tensor(0.2743)\n",
      "17617 Traning Loss: tensor(0.2335)\n",
      "17618 Traning Loss: tensor(0.2604)\n",
      "17619 Traning Loss: tensor(0.2533)\n",
      "17620 Traning Loss: tensor(0.2548)\n",
      "17621 Traning Loss: tensor(0.2843)\n",
      "17622 Traning Loss: tensor(0.2252)\n",
      "17623 Traning Loss: tensor(0.2763)\n",
      "17624 Traning Loss: tensor(0.2421)\n",
      "17625 Traning Loss: tensor(0.2445)\n",
      "17626 Traning Loss: tensor(0.2923)\n",
      "17627 Traning Loss: tensor(0.2363)\n",
      "17628 Traning Loss: tensor(0.2613)\n",
      "17629 Traning Loss: tensor(0.2377)\n",
      "17630 Traning Loss: tensor(0.2540)\n",
      "17631 Traning Loss: tensor(0.2607)\n",
      "17632 Traning Loss: tensor(0.2853)\n",
      "17633 Traning Loss: tensor(0.2678)\n",
      "17634 Traning Loss: tensor(0.2714)\n",
      "17635 Traning Loss: tensor(0.2427)\n",
      "17636 Traning Loss: tensor(0.2523)\n",
      "17637 Traning Loss: tensor(0.2573)\n",
      "17638 Traning Loss: tensor(0.2579)\n",
      "17639 Traning Loss: tensor(0.2531)\n",
      "17640 Traning Loss: tensor(0.2729)\n",
      "17641 Traning Loss: tensor(0.2451)\n",
      "17642 Traning Loss: tensor(0.2981)\n",
      "17643 Traning Loss: tensor(0.2877)\n",
      "17644 Traning Loss: tensor(0.2911)\n",
      "17645 Traning Loss: tensor(0.3156)\n",
      "17646 Traning Loss: tensor(0.2572)\n",
      "17647 Traning Loss: tensor(0.2940)\n",
      "17648 Traning Loss: tensor(0.2530)\n",
      "17649 Traning Loss: tensor(0.2822)\n",
      "17650 Traning Loss: tensor(0.2623)\n",
      "17651 Traning Loss: tensor(0.2828)\n",
      "17652 Traning Loss: tensor(0.2655)\n",
      "17653 Traning Loss: tensor(0.2676)\n",
      "17654 Traning Loss: tensor(0.2436)\n",
      "17655 Traning Loss: tensor(0.3012)\n",
      "17656 Traning Loss: tensor(0.2477)\n",
      "17657 Traning Loss: tensor(0.2620)\n",
      "17658 Traning Loss: tensor(0.2451)\n",
      "17659 Traning Loss: tensor(0.2573)\n",
      "17660 Traning Loss: tensor(0.2553)\n",
      "17661 Traning Loss: tensor(0.2583)\n",
      "17662 Traning Loss: tensor(0.2612)\n",
      "17663 Traning Loss: tensor(0.2383)\n",
      "17664 Traning Loss: tensor(0.2578)\n",
      "17665 Traning Loss: tensor(0.2587)\n",
      "17666 Traning Loss: tensor(0.2528)\n",
      "17667 Traning Loss: tensor(0.2248)\n",
      "17668 Traning Loss: tensor(0.3003)\n",
      "17669 Traning Loss: tensor(0.2226)\n",
      "17670 Traning Loss: tensor(0.2407)\n",
      "17671 Traning Loss: tensor(0.2626)\n",
      "17672 Traning Loss: tensor(0.2522)\n",
      "17673 Traning Loss: tensor(0.2738)\n",
      "17674 Traning Loss: tensor(0.2559)\n",
      "17675 Traning Loss: tensor(0.2268)\n",
      "17676 Traning Loss: tensor(0.2444)\n",
      "17677 Traning Loss: tensor(0.2592)\n",
      "17678 Traning Loss: tensor(0.2811)\n",
      "17679 Traning Loss: tensor(0.2727)\n",
      "17680 Traning Loss: tensor(0.2447)\n",
      "17681 Traning Loss: tensor(0.2518)\n",
      "17682 Traning Loss: tensor(0.2254)\n",
      "17683 Traning Loss: tensor(0.2744)\n",
      "17684 Traning Loss: tensor(0.2471)\n",
      "17685 Traning Loss: tensor(0.2630)\n",
      "17686 Traning Loss: tensor(0.2511)\n",
      "17687 Traning Loss: tensor(0.2441)\n",
      "17688 Traning Loss: tensor(0.2909)\n",
      "17689 Traning Loss: tensor(0.2390)\n",
      "17690 Traning Loss: tensor(0.2458)\n",
      "17691 Traning Loss: tensor(0.3008)\n",
      "17692 Traning Loss: tensor(0.2316)\n",
      "17693 Traning Loss: tensor(0.2328)\n",
      "17694 Traning Loss: tensor(0.2633)\n",
      "17695 Traning Loss: tensor(0.2308)\n",
      "17696 Traning Loss: tensor(0.2676)\n",
      "17697 Traning Loss: tensor(0.2388)\n",
      "17698 Traning Loss: tensor(0.2356)\n",
      "17699 Traning Loss: tensor(0.2396)\n",
      "17700 Traning Loss: tensor(0.2974)\n",
      "17701 Traning Loss: tensor(0.2746)\n",
      "17702 Traning Loss: tensor(0.2753)\n",
      "17703 Traning Loss: tensor(0.2383)\n",
      "17704 Traning Loss: tensor(0.2833)\n",
      "17705 Traning Loss: tensor(0.2661)\n",
      "17706 Traning Loss: tensor(0.2586)\n",
      "17707 Traning Loss: tensor(0.2411)\n",
      "17708 Traning Loss: tensor(0.2647)\n",
      "17709 Traning Loss: tensor(0.2465)\n",
      "17710 Traning Loss: tensor(0.2508)\n",
      "17711 Traning Loss: tensor(0.2429)\n",
      "17712 Traning Loss: tensor(0.2493)\n",
      "17713 Traning Loss: tensor(0.2214)\n",
      "17714 Traning Loss: tensor(0.2463)\n",
      "17715 Traning Loss: tensor(0.2437)\n",
      "17716 Traning Loss: tensor(0.3098)\n",
      "17717 Traning Loss: tensor(0.2741)\n",
      "17718 Traning Loss: tensor(0.2385)\n",
      "17719 Traning Loss: tensor(0.2284)\n",
      "17720 Traning Loss: tensor(0.2243)\n",
      "17721 Traning Loss: tensor(0.2224)\n",
      "17722 Traning Loss: tensor(0.2527)\n",
      "17723 Traning Loss: tensor(0.2472)\n",
      "17724 Traning Loss: tensor(0.2723)\n",
      "17725 Traning Loss: tensor(0.2768)\n",
      "17726 Traning Loss: tensor(0.2137)\n",
      "17727 Traning Loss: tensor(0.2464)\n",
      "17728 Traning Loss: tensor(0.2122)\n",
      "17729 Traning Loss: tensor(0.2471)\n",
      "17730 Traning Loss: tensor(0.2508)\n",
      "17731 Traning Loss: tensor(0.2340)\n",
      "17732 Traning Loss: tensor(0.2661)\n",
      "17733 Traning Loss: tensor(0.2745)\n",
      "17734 Traning Loss: tensor(0.2244)\n",
      "17735 Traning Loss: tensor(0.2403)\n",
      "17736 Traning Loss: tensor(0.2588)\n",
      "17737 Traning Loss: tensor(0.2399)\n",
      "17738 Traning Loss: tensor(0.2367)\n",
      "17739 Traning Loss: tensor(0.2449)\n",
      "17740 Traning Loss: tensor(0.2498)\n",
      "17741 Traning Loss: tensor(0.2590)\n",
      "17742 Traning Loss: tensor(0.2246)\n",
      "17743 Traning Loss: tensor(0.2341)\n",
      "17744 Traning Loss: tensor(0.2313)\n",
      "17745 Traning Loss: tensor(0.2614)\n",
      "17746 Traning Loss: tensor(0.2660)\n",
      "17747 Traning Loss: tensor(0.2659)\n",
      "17748 Traning Loss: tensor(0.2221)\n",
      "17749 Traning Loss: tensor(0.2409)\n",
      "17750 Traning Loss: tensor(0.2638)\n",
      "17751 Traning Loss: tensor(0.2264)\n",
      "17752 Traning Loss: tensor(0.2456)\n",
      "17753 Traning Loss: tensor(0.2201)\n",
      "17754 Traning Loss: tensor(0.2401)\n",
      "17755 Traning Loss: tensor(0.2637)\n",
      "17756 Traning Loss: tensor(0.2097)\n",
      "17757 Traning Loss: tensor(0.2554)\n",
      "17758 Traning Loss: tensor(0.2530)\n",
      "17759 Traning Loss: tensor(0.2570)\n",
      "17760 Traning Loss: tensor(0.2456)\n",
      "17761 Traning Loss: tensor(0.2666)\n",
      "17762 Traning Loss: tensor(0.2466)\n",
      "17763 Traning Loss: tensor(0.2418)\n",
      "17764 Traning Loss: tensor(0.2343)\n",
      "17765 Traning Loss: tensor(0.2837)\n",
      "17766 Traning Loss: tensor(0.2152)\n",
      "17767 Traning Loss: tensor(0.2198)\n",
      "17768 Traning Loss: tensor(0.2295)\n",
      "17769 Traning Loss: tensor(0.2317)\n",
      "17770 Traning Loss: tensor(0.2239)\n",
      "17771 Traning Loss: tensor(0.2379)\n",
      "17772 Traning Loss: tensor(0.2398)\n",
      "17773 Traning Loss: tensor(0.2453)\n",
      "17774 Traning Loss: tensor(0.2486)\n",
      "17775 Traning Loss: tensor(0.2076)\n",
      "17776 Traning Loss: tensor(0.2464)\n",
      "17777 Traning Loss: tensor(0.2432)\n",
      "17778 Traning Loss: tensor(0.2298)\n",
      "17779 Traning Loss: tensor(0.2568)\n",
      "17780 Traning Loss: tensor(0.2411)\n",
      "17781 Traning Loss: tensor(0.2843)\n",
      "17782 Traning Loss: tensor(0.2603)\n",
      "17783 Traning Loss: tensor(0.2599)\n",
      "17784 Traning Loss: tensor(0.2515)\n",
      "17785 Traning Loss: tensor(0.2771)\n",
      "17786 Traning Loss: tensor(0.2327)\n",
      "17787 Traning Loss: tensor(0.2353)\n",
      "17788 Traning Loss: tensor(0.2832)\n",
      "17789 Traning Loss: tensor(0.2399)\n",
      "17790 Traning Loss: tensor(0.2415)\n",
      "17791 Traning Loss: tensor(0.2192)\n",
      "17792 Traning Loss: tensor(0.2072)\n",
      "17793 Traning Loss: tensor(0.2449)\n",
      "17794 Traning Loss: tensor(0.2459)\n",
      "17795 Traning Loss: tensor(0.2226)\n",
      "17796 Traning Loss: tensor(0.2462)\n",
      "17797 Traning Loss: tensor(0.2917)\n",
      "17798 Traning Loss: tensor(0.2693)\n",
      "17799 Traning Loss: tensor(0.2587)\n",
      "17800 Traning Loss: tensor(0.2644)\n",
      "17801 Traning Loss: tensor(0.2254)\n",
      "17802 Traning Loss: tensor(0.2673)\n",
      "17803 Traning Loss: tensor(0.2929)\n",
      "17804 Traning Loss: tensor(0.2182)\n",
      "17805 Traning Loss: tensor(0.2328)\n",
      "17806 Traning Loss: tensor(0.2392)\n",
      "17807 Traning Loss: tensor(0.2399)\n",
      "17808 Traning Loss: tensor(0.2318)\n",
      "17809 Traning Loss: tensor(0.2567)\n",
      "17810 Traning Loss: tensor(0.2634)\n",
      "17811 Traning Loss: tensor(0.2519)\n",
      "17812 Traning Loss: tensor(0.2516)\n",
      "17813 Traning Loss: tensor(0.2403)\n",
      "17814 Traning Loss: tensor(0.2476)\n",
      "17815 Traning Loss: tensor(0.2467)\n",
      "17816 Traning Loss: tensor(0.2562)\n",
      "17817 Traning Loss: tensor(0.2759)\n",
      "17818 Traning Loss: tensor(0.2461)\n",
      "17819 Traning Loss: tensor(0.2165)\n",
      "17820 Traning Loss: tensor(0.2330)\n",
      "17821 Traning Loss: tensor(0.2644)\n",
      "17822 Traning Loss: tensor(0.2240)\n",
      "17823 Traning Loss: tensor(0.2282)\n",
      "17824 Traning Loss: tensor(0.2490)\n",
      "17825 Traning Loss: tensor(0.2551)\n",
      "17826 Traning Loss: tensor(0.2886)\n",
      "17827 Traning Loss: tensor(0.2558)\n",
      "17828 Traning Loss: tensor(0.2743)\n",
      "17829 Traning Loss: tensor(0.2275)\n",
      "17830 Traning Loss: tensor(0.2488)\n",
      "17831 Traning Loss: tensor(0.2488)\n",
      "17832 Traning Loss: tensor(0.2162)\n",
      "17833 Traning Loss: tensor(0.2284)\n",
      "17834 Traning Loss: tensor(0.3001)\n",
      "17835 Traning Loss: tensor(0.2643)\n",
      "17836 Traning Loss: tensor(0.2463)\n",
      "17837 Traning Loss: tensor(0.2612)\n",
      "17838 Traning Loss: tensor(0.2794)\n",
      "17839 Traning Loss: tensor(0.2475)\n",
      "17840 Traning Loss: tensor(0.3276)\n",
      "17841 Traning Loss: tensor(0.2898)\n",
      "17842 Traning Loss: tensor(0.2297)\n",
      "17843 Traning Loss: tensor(0.2527)\n",
      "17844 Traning Loss: tensor(0.2677)\n",
      "17845 Traning Loss: tensor(0.3001)\n",
      "17846 Traning Loss: tensor(0.2653)\n",
      "17847 Traning Loss: tensor(0.2323)\n",
      "17848 Traning Loss: tensor(0.2575)\n",
      "17849 Traning Loss: tensor(0.2847)\n",
      "17850 Traning Loss: tensor(0.2069)\n",
      "17851 Traning Loss: tensor(0.2560)\n",
      "17852 Traning Loss: tensor(0.2580)\n",
      "17853 Traning Loss: tensor(0.2426)\n",
      "17854 Traning Loss: tensor(0.2504)\n",
      "17855 Traning Loss: tensor(0.2112)\n",
      "17856 Traning Loss: tensor(0.2284)\n",
      "17857 Traning Loss: tensor(0.2434)\n",
      "17858 Traning Loss: tensor(0.2305)\n",
      "17859 Traning Loss: tensor(0.2143)\n",
      "17860 Traning Loss: tensor(0.2574)\n",
      "17861 Traning Loss: tensor(0.2272)\n",
      "17862 Traning Loss: tensor(0.2526)\n",
      "17863 Traning Loss: tensor(0.2484)\n",
      "17864 Traning Loss: tensor(0.2545)\n",
      "17865 Traning Loss: tensor(0.2292)\n",
      "17866 Traning Loss: tensor(0.2518)\n",
      "17867 Traning Loss: tensor(0.2428)\n",
      "17868 Traning Loss: tensor(0.2237)\n",
      "17869 Traning Loss: tensor(0.2554)\n",
      "17870 Traning Loss: tensor(0.2301)\n",
      "17871 Traning Loss: tensor(0.2177)\n",
      "17872 Traning Loss: tensor(0.2359)\n",
      "17873 Traning Loss: tensor(0.2173)\n",
      "17874 Traning Loss: tensor(0.2143)\n",
      "17875 Traning Loss: tensor(0.2335)\n",
      "17876 Traning Loss: tensor(0.2689)\n",
      "17877 Traning Loss: tensor(0.2411)\n",
      "17878 Traning Loss: tensor(0.2324)\n",
      "17879 Traning Loss: tensor(0.2290)\n",
      "17880 Traning Loss: tensor(0.2212)\n",
      "17881 Traning Loss: tensor(0.2450)\n",
      "17882 Traning Loss: tensor(0.2219)\n",
      "17883 Traning Loss: tensor(0.2293)\n",
      "17884 Traning Loss: tensor(0.2251)\n",
      "17885 Traning Loss: tensor(0.2314)\n",
      "17886 Traning Loss: tensor(0.2408)\n",
      "17887 Traning Loss: tensor(0.2190)\n",
      "17888 Traning Loss: tensor(0.2333)\n",
      "17889 Traning Loss: tensor(0.2225)\n",
      "17890 Traning Loss: tensor(0.2351)\n",
      "17891 Traning Loss: tensor(0.2289)\n",
      "17892 Traning Loss: tensor(0.2356)\n",
      "17893 Traning Loss: tensor(0.2399)\n",
      "17894 Traning Loss: tensor(0.2193)\n",
      "17895 Traning Loss: tensor(0.2780)\n",
      "17896 Traning Loss: tensor(0.2536)\n",
      "17897 Traning Loss: tensor(0.2377)\n",
      "17898 Traning Loss: tensor(0.2246)\n",
      "17899 Traning Loss: tensor(0.2544)\n",
      "17900 Traning Loss: tensor(0.2443)\n",
      "17901 Traning Loss: tensor(0.2378)\n",
      "17902 Traning Loss: tensor(0.2511)\n",
      "17903 Traning Loss: tensor(0.2298)\n",
      "17904 Traning Loss: tensor(0.2306)\n",
      "17905 Traning Loss: tensor(0.2258)\n",
      "17906 Traning Loss: tensor(0.2386)\n",
      "17907 Traning Loss: tensor(0.2289)\n",
      "17908 Traning Loss: tensor(0.2309)\n",
      "17909 Traning Loss: tensor(0.2393)\n",
      "17910 Traning Loss: tensor(0.2410)\n",
      "17911 Traning Loss: tensor(0.2283)\n",
      "17912 Traning Loss: tensor(0.2345)\n",
      "17913 Traning Loss: tensor(0.2741)\n",
      "17914 Traning Loss: tensor(0.2291)\n",
      "17915 Traning Loss: tensor(0.2382)\n",
      "17916 Traning Loss: tensor(0.2425)\n",
      "17917 Traning Loss: tensor(0.2511)\n",
      "17918 Traning Loss: tensor(0.2529)\n",
      "17919 Traning Loss: tensor(0.2138)\n",
      "17920 Traning Loss: tensor(0.2229)\n",
      "17921 Traning Loss: tensor(0.2700)\n",
      "17922 Traning Loss: tensor(0.2391)\n",
      "17923 Traning Loss: tensor(0.2252)\n",
      "17924 Traning Loss: tensor(0.2573)\n",
      "17925 Traning Loss: tensor(0.2308)\n",
      "17926 Traning Loss: tensor(0.2199)\n",
      "17927 Traning Loss: tensor(0.2570)\n",
      "17928 Traning Loss: tensor(0.2458)\n",
      "17929 Traning Loss: tensor(0.2117)\n",
      "17930 Traning Loss: tensor(0.2492)\n",
      "17931 Traning Loss: tensor(0.2499)\n",
      "17932 Traning Loss: tensor(0.2317)\n",
      "17933 Traning Loss: tensor(0.2137)\n",
      "17934 Traning Loss: tensor(0.2179)\n",
      "17935 Traning Loss: tensor(0.2165)\n",
      "17936 Traning Loss: tensor(0.2199)\n",
      "17937 Traning Loss: tensor(0.2723)\n",
      "17938 Traning Loss: tensor(0.2234)\n",
      "17939 Traning Loss: tensor(0.2549)\n",
      "17940 Traning Loss: tensor(0.2124)\n",
      "17941 Traning Loss: tensor(0.2388)\n",
      "17942 Traning Loss: tensor(0.2255)\n",
      "17943 Traning Loss: tensor(0.2244)\n",
      "17944 Traning Loss: tensor(0.2380)\n",
      "17945 Traning Loss: tensor(0.2152)\n",
      "17946 Traning Loss: tensor(0.2260)\n",
      "17947 Traning Loss: tensor(0.2402)\n",
      "17948 Traning Loss: tensor(0.2166)\n",
      "17949 Traning Loss: tensor(0.2634)\n",
      "17950 Traning Loss: tensor(0.2108)\n",
      "17951 Traning Loss: tensor(0.2405)\n",
      "17952 Traning Loss: tensor(0.2091)\n",
      "17953 Traning Loss: tensor(0.2271)\n",
      "17954 Traning Loss: tensor(0.3142)\n",
      "17955 Traning Loss: tensor(0.2310)\n",
      "17956 Traning Loss: tensor(0.2236)\n",
      "17957 Traning Loss: tensor(0.2061)\n",
      "17958 Traning Loss: tensor(0.2328)\n",
      "17959 Traning Loss: tensor(0.2018)\n",
      "17960 Traning Loss: tensor(0.2191)\n",
      "17961 Traning Loss: tensor(0.2328)\n",
      "17962 Traning Loss: tensor(0.2254)\n",
      "17963 Traning Loss: tensor(0.1941)\n",
      "17964 Traning Loss: tensor(0.2005)\n",
      "17965 Traning Loss: tensor(0.2142)\n",
      "17966 Traning Loss: tensor(0.2219)\n",
      "17967 Traning Loss: tensor(0.2369)\n",
      "17968 Traning Loss: tensor(0.2368)\n",
      "17969 Traning Loss: tensor(0.2184)\n",
      "17970 Traning Loss: tensor(0.2299)\n",
      "17971 Traning Loss: tensor(0.2291)\n",
      "17972 Traning Loss: tensor(0.2096)\n",
      "17973 Traning Loss: tensor(0.2224)\n",
      "17974 Traning Loss: tensor(0.2060)\n",
      "17975 Traning Loss: tensor(0.2407)\n",
      "17976 Traning Loss: tensor(0.2267)\n",
      "17977 Traning Loss: tensor(0.2117)\n",
      "17978 Traning Loss: tensor(0.2160)\n",
      "17979 Traning Loss: tensor(0.2193)\n",
      "17980 Traning Loss: tensor(0.2176)\n",
      "17981 Traning Loss: tensor(0.2481)\n",
      "17982 Traning Loss: tensor(0.2426)\n",
      "17983 Traning Loss: tensor(0.2086)\n",
      "17984 Traning Loss: tensor(0.2481)\n",
      "17985 Traning Loss: tensor(0.2292)\n",
      "17986 Traning Loss: tensor(0.2093)\n",
      "17987 Traning Loss: tensor(0.2215)\n",
      "17988 Traning Loss: tensor(0.2025)\n",
      "17989 Traning Loss: tensor(0.2491)\n",
      "17990 Traning Loss: tensor(0.2255)\n",
      "17991 Traning Loss: tensor(0.2011)\n",
      "17992 Traning Loss: tensor(0.2393)\n",
      "17993 Traning Loss: tensor(0.2213)\n",
      "17994 Traning Loss: tensor(0.2368)\n",
      "17995 Traning Loss: tensor(0.2332)\n",
      "17996 Traning Loss: tensor(0.2088)\n",
      "17997 Traning Loss: tensor(0.2276)\n",
      "17998 Traning Loss: tensor(0.1958)\n",
      "17999 Traning Loss: tensor(0.2037)\n",
      "18000 Traning Loss: tensor(0.2483)\n",
      "18001 Traning Loss: tensor(0.2469)\n",
      "18002 Traning Loss: tensor(0.2282)\n",
      "18003 Traning Loss: tensor(0.2259)\n",
      "18004 Traning Loss: tensor(0.2316)\n",
      "18005 Traning Loss: tensor(0.2158)\n",
      "18006 Traning Loss: tensor(0.2292)\n",
      "18007 Traning Loss: tensor(0.2104)\n",
      "18008 Traning Loss: tensor(0.2263)\n",
      "18009 Traning Loss: tensor(0.2126)\n",
      "18010 Traning Loss: tensor(0.2421)\n",
      "18011 Traning Loss: tensor(0.2174)\n",
      "18012 Traning Loss: tensor(0.2384)\n",
      "18013 Traning Loss: tensor(0.2310)\n",
      "18014 Traning Loss: tensor(0.2056)\n",
      "18015 Traning Loss: tensor(0.1948)\n",
      "18016 Traning Loss: tensor(0.2221)\n",
      "18017 Traning Loss: tensor(0.2045)\n",
      "18018 Traning Loss: tensor(0.2298)\n",
      "18019 Traning Loss: tensor(0.2148)\n",
      "18020 Traning Loss: tensor(0.2451)\n",
      "18021 Traning Loss: tensor(0.2319)\n",
      "18022 Traning Loss: tensor(0.2346)\n",
      "18023 Traning Loss: tensor(0.2357)\n",
      "18024 Traning Loss: tensor(0.2155)\n",
      "18025 Traning Loss: tensor(0.1996)\n",
      "18026 Traning Loss: tensor(0.1961)\n",
      "18027 Traning Loss: tensor(0.2106)\n",
      "18028 Traning Loss: tensor(0.2395)\n",
      "18029 Traning Loss: tensor(0.2082)\n",
      "18030 Traning Loss: tensor(0.2223)\n",
      "18031 Traning Loss: tensor(0.2123)\n",
      "18032 Traning Loss: tensor(0.2061)\n",
      "18033 Traning Loss: tensor(0.2277)\n",
      "18034 Traning Loss: tensor(0.1916)\n",
      "18035 Traning Loss: tensor(0.2160)\n",
      "18036 Traning Loss: tensor(0.2188)\n",
      "18037 Traning Loss: tensor(0.2076)\n",
      "18038 Traning Loss: tensor(0.2362)\n",
      "18039 Traning Loss: tensor(0.2247)\n",
      "18040 Traning Loss: tensor(0.2096)\n",
      "18041 Traning Loss: tensor(0.2355)\n",
      "18042 Traning Loss: tensor(0.2423)\n",
      "18043 Traning Loss: tensor(0.2404)\n",
      "18044 Traning Loss: tensor(0.2610)\n",
      "18045 Traning Loss: tensor(0.2429)\n",
      "18046 Traning Loss: tensor(0.2224)\n",
      "18047 Traning Loss: tensor(0.2281)\n",
      "18048 Traning Loss: tensor(0.2159)\n",
      "18049 Traning Loss: tensor(0.2067)\n",
      "18050 Traning Loss: tensor(0.2215)\n",
      "18051 Traning Loss: tensor(0.2483)\n",
      "18052 Traning Loss: tensor(0.2270)\n",
      "18053 Traning Loss: tensor(0.1900)\n",
      "18054 Traning Loss: tensor(0.2210)\n",
      "18055 Traning Loss: tensor(0.2425)\n",
      "18056 Traning Loss: tensor(0.2336)\n",
      "18057 Traning Loss: tensor(0.2301)\n",
      "18058 Traning Loss: tensor(0.2285)\n",
      "18059 Traning Loss: tensor(0.2209)\n",
      "18060 Traning Loss: tensor(0.2162)\n",
      "18061 Traning Loss: tensor(0.2265)\n",
      "18062 Traning Loss: tensor(0.2420)\n",
      "18063 Traning Loss: tensor(0.2354)\n",
      "18064 Traning Loss: tensor(0.1996)\n",
      "18065 Traning Loss: tensor(0.2044)\n",
      "18066 Traning Loss: tensor(0.2095)\n",
      "18067 Traning Loss: tensor(0.2277)\n",
      "18068 Traning Loss: tensor(0.1988)\n",
      "18069 Traning Loss: tensor(0.2030)\n",
      "18070 Traning Loss: tensor(0.2435)\n",
      "18071 Traning Loss: tensor(0.2044)\n",
      "18072 Traning Loss: tensor(0.2104)\n",
      "18073 Traning Loss: tensor(0.2064)\n",
      "18074 Traning Loss: tensor(0.2057)\n",
      "18075 Traning Loss: tensor(0.2584)\n",
      "18076 Traning Loss: tensor(0.2101)\n",
      "18077 Traning Loss: tensor(0.2686)\n",
      "18078 Traning Loss: tensor(0.2252)\n",
      "18079 Traning Loss: tensor(0.2330)\n",
      "18080 Traning Loss: tensor(0.2093)\n",
      "18081 Traning Loss: tensor(0.2522)\n",
      "18082 Traning Loss: tensor(0.2139)\n",
      "18083 Traning Loss: tensor(0.2181)\n",
      "18084 Traning Loss: tensor(0.2096)\n",
      "18085 Traning Loss: tensor(0.2453)\n",
      "18086 Traning Loss: tensor(0.2151)\n",
      "18087 Traning Loss: tensor(0.2039)\n",
      "18088 Traning Loss: tensor(0.1945)\n",
      "18089 Traning Loss: tensor(0.2270)\n",
      "18090 Traning Loss: tensor(0.2154)\n",
      "18091 Traning Loss: tensor(0.2495)\n",
      "18092 Traning Loss: tensor(0.2329)\n",
      "18093 Traning Loss: tensor(0.2464)\n",
      "18094 Traning Loss: tensor(0.2051)\n",
      "18095 Traning Loss: tensor(0.2811)\n",
      "18096 Traning Loss: tensor(0.2093)\n",
      "18097 Traning Loss: tensor(0.2108)\n",
      "18098 Traning Loss: tensor(0.2059)\n",
      "18099 Traning Loss: tensor(0.2127)\n",
      "18100 Traning Loss: tensor(0.2395)\n",
      "18101 Traning Loss: tensor(0.2067)\n",
      "18102 Traning Loss: tensor(0.2464)\n",
      "18103 Traning Loss: tensor(0.2121)\n",
      "18104 Traning Loss: tensor(0.2407)\n",
      "18105 Traning Loss: tensor(0.2313)\n",
      "18106 Traning Loss: tensor(0.2894)\n",
      "18107 Traning Loss: tensor(0.1885)\n",
      "18108 Traning Loss: tensor(0.2335)\n",
      "18109 Traning Loss: tensor(0.2569)\n",
      "18110 Traning Loss: tensor(0.2163)\n",
      "18111 Traning Loss: tensor(0.1920)\n",
      "18112 Traning Loss: tensor(0.2175)\n",
      "18113 Traning Loss: tensor(0.2576)\n",
      "18114 Traning Loss: tensor(0.2137)\n",
      "18115 Traning Loss: tensor(0.1984)\n",
      "18116 Traning Loss: tensor(0.2406)\n",
      "18117 Traning Loss: tensor(0.2249)\n",
      "18118 Traning Loss: tensor(0.2245)\n",
      "18119 Traning Loss: tensor(0.2456)\n",
      "18120 Traning Loss: tensor(0.2030)\n",
      "18121 Traning Loss: tensor(0.2140)\n",
      "18122 Traning Loss: tensor(0.1962)\n",
      "18123 Traning Loss: tensor(0.2453)\n",
      "18124 Traning Loss: tensor(0.2345)\n",
      "18125 Traning Loss: tensor(0.2130)\n",
      "18126 Traning Loss: tensor(0.2194)\n",
      "18127 Traning Loss: tensor(0.2035)\n",
      "18128 Traning Loss: tensor(0.2202)\n",
      "18129 Traning Loss: tensor(0.2344)\n",
      "18130 Traning Loss: tensor(0.2059)\n",
      "18131 Traning Loss: tensor(0.2067)\n",
      "18132 Traning Loss: tensor(0.2588)\n",
      "18133 Traning Loss: tensor(0.2597)\n",
      "18134 Traning Loss: tensor(0.2199)\n",
      "18135 Traning Loss: tensor(0.2365)\n",
      "18136 Traning Loss: tensor(0.2242)\n",
      "18137 Traning Loss: tensor(0.3469)\n",
      "18138 Traning Loss: tensor(0.2261)\n",
      "18139 Traning Loss: tensor(0.2374)\n",
      "18140 Traning Loss: tensor(0.2341)\n",
      "18141 Traning Loss: tensor(0.2156)\n",
      "18142 Traning Loss: tensor(0.2084)\n",
      "18143 Traning Loss: tensor(0.2069)\n",
      "18144 Traning Loss: tensor(0.2005)\n",
      "18145 Traning Loss: tensor(0.2500)\n",
      "18146 Traning Loss: tensor(0.2165)\n",
      "18147 Traning Loss: tensor(0.2535)\n",
      "18148 Traning Loss: tensor(0.2276)\n",
      "18149 Traning Loss: tensor(0.2002)\n",
      "18150 Traning Loss: tensor(0.2305)\n",
      "18151 Traning Loss: tensor(0.2178)\n",
      "18152 Traning Loss: tensor(0.2056)\n",
      "18153 Traning Loss: tensor(0.2025)\n",
      "18154 Traning Loss: tensor(0.2207)\n",
      "18155 Traning Loss: tensor(0.2203)\n",
      "18156 Traning Loss: tensor(0.2197)\n",
      "18157 Traning Loss: tensor(0.2605)\n",
      "18158 Traning Loss: tensor(0.2034)\n",
      "18159 Traning Loss: tensor(0.2112)\n",
      "18160 Traning Loss: tensor(0.1912)\n",
      "18161 Traning Loss: tensor(0.2120)\n",
      "18162 Traning Loss: tensor(0.2077)\n",
      "18163 Traning Loss: tensor(0.2161)\n",
      "18164 Traning Loss: tensor(0.2175)\n",
      "18165 Traning Loss: tensor(0.2074)\n",
      "18166 Traning Loss: tensor(0.2459)\n",
      "18167 Traning Loss: tensor(0.1991)\n",
      "18168 Traning Loss: tensor(0.1843)\n",
      "18169 Traning Loss: tensor(0.1944)\n",
      "18170 Traning Loss: tensor(0.2275)\n",
      "18171 Traning Loss: tensor(0.2054)\n",
      "18172 Traning Loss: tensor(0.2463)\n",
      "18173 Traning Loss: tensor(0.2144)\n",
      "18174 Traning Loss: tensor(0.2167)\n",
      "18175 Traning Loss: tensor(0.2055)\n",
      "18176 Traning Loss: tensor(0.2141)\n",
      "18177 Traning Loss: tensor(0.2163)\n",
      "18178 Traning Loss: tensor(0.2262)\n",
      "18179 Traning Loss: tensor(0.2423)\n",
      "18180 Traning Loss: tensor(0.2160)\n",
      "18181 Traning Loss: tensor(0.2377)\n",
      "18182 Traning Loss: tensor(0.2380)\n",
      "18183 Traning Loss: tensor(0.2477)\n",
      "18184 Traning Loss: tensor(0.2602)\n",
      "18185 Traning Loss: tensor(0.1958)\n",
      "18186 Traning Loss: tensor(0.2521)\n",
      "18187 Traning Loss: tensor(0.2087)\n",
      "18188 Traning Loss: tensor(0.1909)\n",
      "18189 Traning Loss: tensor(0.2488)\n",
      "18190 Traning Loss: tensor(0.2340)\n",
      "18191 Traning Loss: tensor(0.2203)\n",
      "18192 Traning Loss: tensor(0.2571)\n",
      "18193 Traning Loss: tensor(0.2073)\n",
      "18194 Traning Loss: tensor(0.2595)\n",
      "18195 Traning Loss: tensor(0.2175)\n",
      "18196 Traning Loss: tensor(0.2052)\n",
      "18197 Traning Loss: tensor(0.2695)\n",
      "18198 Traning Loss: tensor(0.1908)\n",
      "18199 Traning Loss: tensor(0.2048)\n",
      "18200 Traning Loss: tensor(0.2192)\n",
      "18201 Traning Loss: tensor(0.2559)\n",
      "18202 Traning Loss: tensor(0.2345)\n",
      "18203 Traning Loss: tensor(0.2293)\n",
      "18204 Traning Loss: tensor(0.2112)\n",
      "18205 Traning Loss: tensor(0.1817)\n",
      "18206 Traning Loss: tensor(0.1975)\n",
      "18207 Traning Loss: tensor(0.2210)\n",
      "18208 Traning Loss: tensor(0.2236)\n",
      "18209 Traning Loss: tensor(0.2027)\n",
      "18210 Traning Loss: tensor(0.2113)\n",
      "18211 Traning Loss: tensor(0.2245)\n",
      "18212 Traning Loss: tensor(0.1883)\n",
      "18213 Traning Loss: tensor(0.2099)\n",
      "18214 Traning Loss: tensor(0.2377)\n",
      "18215 Traning Loss: tensor(0.1988)\n",
      "18216 Traning Loss: tensor(0.2337)\n",
      "18217 Traning Loss: tensor(0.2333)\n",
      "18218 Traning Loss: tensor(0.1956)\n",
      "18219 Traning Loss: tensor(0.2089)\n",
      "18220 Traning Loss: tensor(0.1994)\n",
      "18221 Traning Loss: tensor(0.2083)\n",
      "18222 Traning Loss: tensor(0.2390)\n",
      "18223 Traning Loss: tensor(0.2228)\n",
      "18224 Traning Loss: tensor(0.2412)\n",
      "18225 Traning Loss: tensor(0.2600)\n",
      "18226 Traning Loss: tensor(0.2120)\n",
      "18227 Traning Loss: tensor(0.2001)\n",
      "18228 Traning Loss: tensor(0.2311)\n",
      "18229 Traning Loss: tensor(0.2437)\n",
      "18230 Traning Loss: tensor(0.2113)\n",
      "18231 Traning Loss: tensor(0.1917)\n",
      "18232 Traning Loss: tensor(0.2072)\n",
      "18233 Traning Loss: tensor(0.2259)\n",
      "18234 Traning Loss: tensor(0.2141)\n",
      "18235 Traning Loss: tensor(0.1798)\n",
      "18236 Traning Loss: tensor(0.2157)\n",
      "18237 Traning Loss: tensor(0.2083)\n",
      "18238 Traning Loss: tensor(0.2401)\n",
      "18239 Traning Loss: tensor(0.2194)\n",
      "18240 Traning Loss: tensor(0.2082)\n",
      "18241 Traning Loss: tensor(0.2122)\n",
      "18242 Traning Loss: tensor(0.2024)\n",
      "18243 Traning Loss: tensor(0.2354)\n",
      "18244 Traning Loss: tensor(0.2007)\n",
      "18245 Traning Loss: tensor(0.1865)\n",
      "18246 Traning Loss: tensor(0.1996)\n",
      "18247 Traning Loss: tensor(0.2224)\n",
      "18248 Traning Loss: tensor(0.2157)\n",
      "18249 Traning Loss: tensor(0.2124)\n",
      "18250 Traning Loss: tensor(0.2281)\n",
      "18251 Traning Loss: tensor(0.2089)\n",
      "18252 Traning Loss: tensor(0.2045)\n",
      "18253 Traning Loss: tensor(0.2287)\n",
      "18254 Traning Loss: tensor(0.2284)\n",
      "18255 Traning Loss: tensor(0.2410)\n",
      "18256 Traning Loss: tensor(0.2341)\n",
      "18257 Traning Loss: tensor(0.2049)\n",
      "18258 Traning Loss: tensor(0.2318)\n",
      "18259 Traning Loss: tensor(0.1923)\n",
      "18260 Traning Loss: tensor(0.2086)\n",
      "18261 Traning Loss: tensor(0.2207)\n",
      "18262 Traning Loss: tensor(0.2245)\n",
      "18263 Traning Loss: tensor(0.2013)\n",
      "18264 Traning Loss: tensor(0.2373)\n",
      "18265 Traning Loss: tensor(0.2245)\n",
      "18266 Traning Loss: tensor(0.2016)\n",
      "18267 Traning Loss: tensor(0.2369)\n",
      "18268 Traning Loss: tensor(0.2422)\n",
      "18269 Traning Loss: tensor(0.1981)\n",
      "18270 Traning Loss: tensor(0.1962)\n",
      "18271 Traning Loss: tensor(0.2276)\n",
      "18272 Traning Loss: tensor(0.2024)\n",
      "18273 Traning Loss: tensor(0.1899)\n",
      "18274 Traning Loss: tensor(0.2161)\n",
      "18275 Traning Loss: tensor(0.1906)\n",
      "18276 Traning Loss: tensor(0.2116)\n",
      "18277 Traning Loss: tensor(0.2493)\n",
      "18278 Traning Loss: tensor(0.2060)\n",
      "18279 Traning Loss: tensor(0.2093)\n",
      "18280 Traning Loss: tensor(0.1963)\n",
      "18281 Traning Loss: tensor(0.2071)\n",
      "18282 Traning Loss: tensor(0.2236)\n",
      "18283 Traning Loss: tensor(0.2176)\n",
      "18284 Traning Loss: tensor(0.2137)\n",
      "18285 Traning Loss: tensor(0.1999)\n",
      "18286 Traning Loss: tensor(0.2162)\n",
      "18287 Traning Loss: tensor(0.1972)\n",
      "18288 Traning Loss: tensor(0.1941)\n",
      "18289 Traning Loss: tensor(0.2193)\n",
      "18290 Traning Loss: tensor(0.1990)\n",
      "18291 Traning Loss: tensor(0.2044)\n",
      "18292 Traning Loss: tensor(0.2038)\n",
      "18293 Traning Loss: tensor(0.2432)\n",
      "18294 Traning Loss: tensor(0.2373)\n",
      "18295 Traning Loss: tensor(0.2253)\n",
      "18296 Traning Loss: tensor(0.2054)\n",
      "18297 Traning Loss: tensor(0.2334)\n",
      "18298 Traning Loss: tensor(0.2116)\n",
      "18299 Traning Loss: tensor(0.2031)\n",
      "18300 Traning Loss: tensor(0.2137)\n",
      "18301 Traning Loss: tensor(0.2031)\n",
      "18302 Traning Loss: tensor(0.1784)\n",
      "18303 Traning Loss: tensor(0.2067)\n",
      "18304 Traning Loss: tensor(0.1849)\n",
      "18305 Traning Loss: tensor(0.1879)\n",
      "18306 Traning Loss: tensor(0.2063)\n",
      "18307 Traning Loss: tensor(0.1826)\n",
      "18308 Traning Loss: tensor(0.2391)\n",
      "18309 Traning Loss: tensor(0.1971)\n",
      "18310 Traning Loss: tensor(0.2005)\n",
      "18311 Traning Loss: tensor(0.2035)\n",
      "18312 Traning Loss: tensor(0.2049)\n",
      "18313 Traning Loss: tensor(0.2024)\n",
      "18314 Traning Loss: tensor(0.1684)\n",
      "18315 Traning Loss: tensor(0.2142)\n",
      "18316 Traning Loss: tensor(0.2152)\n",
      "18317 Traning Loss: tensor(0.1956)\n",
      "18318 Traning Loss: tensor(0.1933)\n",
      "18319 Traning Loss: tensor(0.2147)\n",
      "18320 Traning Loss: tensor(0.2227)\n",
      "18321 Traning Loss: tensor(0.2095)\n",
      "18322 Traning Loss: tensor(0.2276)\n",
      "18323 Traning Loss: tensor(0.2048)\n",
      "18324 Traning Loss: tensor(0.2025)\n",
      "18325 Traning Loss: tensor(0.2030)\n",
      "18326 Traning Loss: tensor(0.2078)\n",
      "18327 Traning Loss: tensor(0.2181)\n",
      "18328 Traning Loss: tensor(0.2027)\n",
      "18329 Traning Loss: tensor(0.1753)\n",
      "18330 Traning Loss: tensor(0.2655)\n",
      "18331 Traning Loss: tensor(0.1843)\n",
      "18332 Traning Loss: tensor(0.2385)\n",
      "18333 Traning Loss: tensor(0.2472)\n",
      "18334 Traning Loss: tensor(0.2252)\n",
      "18335 Traning Loss: tensor(0.2358)\n",
      "18336 Traning Loss: tensor(0.1846)\n",
      "18337 Traning Loss: tensor(0.2303)\n",
      "18338 Traning Loss: tensor(0.2102)\n",
      "18339 Traning Loss: tensor(0.2117)\n",
      "18340 Traning Loss: tensor(0.1971)\n",
      "18341 Traning Loss: tensor(0.2003)\n",
      "18342 Traning Loss: tensor(0.1711)\n",
      "18343 Traning Loss: tensor(0.2015)\n",
      "18344 Traning Loss: tensor(0.2150)\n",
      "18345 Traning Loss: tensor(0.1945)\n",
      "18346 Traning Loss: tensor(0.2187)\n",
      "18347 Traning Loss: tensor(0.1964)\n",
      "18348 Traning Loss: tensor(0.1987)\n",
      "18349 Traning Loss: tensor(0.1953)\n",
      "18350 Traning Loss: tensor(0.2357)\n",
      "18351 Traning Loss: tensor(0.1999)\n",
      "18352 Traning Loss: tensor(0.2155)\n",
      "18353 Traning Loss: tensor(0.2149)\n",
      "18354 Traning Loss: tensor(0.1942)\n",
      "18355 Traning Loss: tensor(0.2391)\n",
      "18356 Traning Loss: tensor(0.1925)\n",
      "18357 Traning Loss: tensor(0.2134)\n",
      "18358 Traning Loss: tensor(0.2500)\n",
      "18359 Traning Loss: tensor(0.1879)\n",
      "18360 Traning Loss: tensor(0.1967)\n",
      "18361 Traning Loss: tensor(0.2180)\n",
      "18362 Traning Loss: tensor(0.2143)\n",
      "18363 Traning Loss: tensor(0.2054)\n",
      "18364 Traning Loss: tensor(0.2238)\n",
      "18365 Traning Loss: tensor(0.2355)\n",
      "18366 Traning Loss: tensor(0.2171)\n",
      "18367 Traning Loss: tensor(0.1903)\n",
      "18368 Traning Loss: tensor(0.2227)\n",
      "18369 Traning Loss: tensor(0.2302)\n",
      "18370 Traning Loss: tensor(0.2103)\n",
      "18371 Traning Loss: tensor(0.2121)\n",
      "18372 Traning Loss: tensor(0.1876)\n",
      "18373 Traning Loss: tensor(0.2477)\n",
      "18374 Traning Loss: tensor(0.2117)\n",
      "18375 Traning Loss: tensor(0.1943)\n",
      "18376 Traning Loss: tensor(0.2187)\n",
      "18377 Traning Loss: tensor(0.2287)\n",
      "18378 Traning Loss: tensor(0.2195)\n",
      "18379 Traning Loss: tensor(0.1814)\n",
      "18380 Traning Loss: tensor(0.1832)\n",
      "18381 Traning Loss: tensor(0.2309)\n",
      "18382 Traning Loss: tensor(0.2020)\n",
      "18383 Traning Loss: tensor(0.2021)\n",
      "18384 Traning Loss: tensor(0.1928)\n",
      "18385 Traning Loss: tensor(0.2080)\n",
      "18386 Traning Loss: tensor(0.2205)\n",
      "18387 Traning Loss: tensor(0.1881)\n",
      "18388 Traning Loss: tensor(0.1851)\n",
      "18389 Traning Loss: tensor(0.2071)\n",
      "18390 Traning Loss: tensor(0.2106)\n",
      "18391 Traning Loss: tensor(0.2429)\n",
      "18392 Traning Loss: tensor(0.2292)\n",
      "18393 Traning Loss: tensor(0.2203)\n",
      "18394 Traning Loss: tensor(0.2336)\n",
      "18395 Traning Loss: tensor(0.2370)\n",
      "18396 Traning Loss: tensor(0.2118)\n",
      "18397 Traning Loss: tensor(0.1892)\n",
      "18398 Traning Loss: tensor(0.2253)\n",
      "18399 Traning Loss: tensor(0.1745)\n",
      "18400 Traning Loss: tensor(0.2120)\n",
      "18401 Traning Loss: tensor(0.2190)\n",
      "18402 Traning Loss: tensor(0.2155)\n",
      "18403 Traning Loss: tensor(0.2275)\n",
      "18404 Traning Loss: tensor(0.2150)\n",
      "18405 Traning Loss: tensor(0.2091)\n",
      "18406 Traning Loss: tensor(0.2042)\n",
      "18407 Traning Loss: tensor(0.2052)\n",
      "18408 Traning Loss: tensor(0.1984)\n",
      "18409 Traning Loss: tensor(0.1992)\n",
      "18410 Traning Loss: tensor(0.2051)\n",
      "18411 Traning Loss: tensor(0.1778)\n",
      "18412 Traning Loss: tensor(0.2026)\n",
      "18413 Traning Loss: tensor(0.2159)\n",
      "18414 Traning Loss: tensor(0.2079)\n",
      "18415 Traning Loss: tensor(0.1991)\n",
      "18416 Traning Loss: tensor(0.1771)\n",
      "18417 Traning Loss: tensor(0.1970)\n",
      "18418 Traning Loss: tensor(0.1949)\n",
      "18419 Traning Loss: tensor(0.2138)\n",
      "18420 Traning Loss: tensor(0.1854)\n",
      "18421 Traning Loss: tensor(0.1850)\n",
      "18422 Traning Loss: tensor(0.2124)\n",
      "18423 Traning Loss: tensor(0.2002)\n",
      "18424 Traning Loss: tensor(0.2331)\n",
      "18425 Traning Loss: tensor(0.2134)\n",
      "18426 Traning Loss: tensor(0.2070)\n",
      "18427 Traning Loss: tensor(0.1892)\n",
      "18428 Traning Loss: tensor(0.1821)\n",
      "18429 Traning Loss: tensor(0.1786)\n",
      "18430 Traning Loss: tensor(0.2101)\n",
      "18431 Traning Loss: tensor(0.1996)\n",
      "18432 Traning Loss: tensor(0.2166)\n",
      "18433 Traning Loss: tensor(0.2132)\n",
      "18434 Traning Loss: tensor(0.1946)\n",
      "18435 Traning Loss: tensor(0.1912)\n",
      "18436 Traning Loss: tensor(0.2068)\n",
      "18437 Traning Loss: tensor(0.2133)\n",
      "18438 Traning Loss: tensor(0.2019)\n",
      "18439 Traning Loss: tensor(0.1953)\n",
      "18440 Traning Loss: tensor(0.2034)\n",
      "18441 Traning Loss: tensor(0.1669)\n",
      "18442 Traning Loss: tensor(0.2089)\n",
      "18443 Traning Loss: tensor(0.1643)\n",
      "18444 Traning Loss: tensor(0.2339)\n",
      "18445 Traning Loss: tensor(0.2180)\n",
      "18446 Traning Loss: tensor(0.2045)\n",
      "18447 Traning Loss: tensor(0.1881)\n",
      "18448 Traning Loss: tensor(0.2042)\n",
      "18449 Traning Loss: tensor(0.1992)\n",
      "18450 Traning Loss: tensor(0.2216)\n",
      "18451 Traning Loss: tensor(0.1960)\n",
      "18452 Traning Loss: tensor(0.1803)\n",
      "18453 Traning Loss: tensor(0.2343)\n",
      "18454 Traning Loss: tensor(0.2051)\n",
      "18455 Traning Loss: tensor(0.2088)\n",
      "18456 Traning Loss: tensor(0.2410)\n",
      "18457 Traning Loss: tensor(0.2266)\n",
      "18458 Traning Loss: tensor(0.2118)\n",
      "18459 Traning Loss: tensor(0.1921)\n",
      "18460 Traning Loss: tensor(0.2364)\n",
      "18461 Traning Loss: tensor(0.2104)\n",
      "18462 Traning Loss: tensor(0.1984)\n",
      "18463 Traning Loss: tensor(0.1924)\n",
      "18464 Traning Loss: tensor(0.1844)\n",
      "18465 Traning Loss: tensor(0.2043)\n",
      "18466 Traning Loss: tensor(0.2027)\n",
      "18467 Traning Loss: tensor(0.1998)\n",
      "18468 Traning Loss: tensor(0.2031)\n",
      "18469 Traning Loss: tensor(0.1816)\n",
      "18470 Traning Loss: tensor(0.2355)\n",
      "18471 Traning Loss: tensor(0.1817)\n",
      "18472 Traning Loss: tensor(0.2116)\n",
      "18473 Traning Loss: tensor(0.2016)\n",
      "18474 Traning Loss: tensor(0.2131)\n",
      "18475 Traning Loss: tensor(0.2565)\n",
      "18476 Traning Loss: tensor(0.2451)\n",
      "18477 Traning Loss: tensor(0.2161)\n",
      "18478 Traning Loss: tensor(0.1928)\n",
      "18479 Traning Loss: tensor(0.1951)\n",
      "18480 Traning Loss: tensor(0.2067)\n",
      "18481 Traning Loss: tensor(0.2036)\n",
      "18482 Traning Loss: tensor(0.2015)\n",
      "18483 Traning Loss: tensor(0.2249)\n",
      "18484 Traning Loss: tensor(0.1876)\n",
      "18485 Traning Loss: tensor(0.1847)\n",
      "18486 Traning Loss: tensor(0.1739)\n",
      "18487 Traning Loss: tensor(0.2058)\n",
      "18488 Traning Loss: tensor(0.1988)\n",
      "18489 Traning Loss: tensor(0.1939)\n",
      "18490 Traning Loss: tensor(0.1901)\n",
      "18491 Traning Loss: tensor(0.2136)\n",
      "18492 Traning Loss: tensor(0.1855)\n",
      "18493 Traning Loss: tensor(0.1893)\n",
      "18494 Traning Loss: tensor(0.1937)\n",
      "18495 Traning Loss: tensor(0.2233)\n",
      "18496 Traning Loss: tensor(0.1857)\n",
      "18497 Traning Loss: tensor(0.1884)\n",
      "18498 Traning Loss: tensor(0.2237)\n",
      "18499 Traning Loss: tensor(0.1840)\n",
      "18500 Traning Loss: tensor(0.1915)\n",
      "18501 Traning Loss: tensor(0.2008)\n",
      "18502 Traning Loss: tensor(0.1960)\n",
      "18503 Traning Loss: tensor(0.1925)\n",
      "18504 Traning Loss: tensor(0.1782)\n",
      "18505 Traning Loss: tensor(0.2317)\n",
      "18506 Traning Loss: tensor(0.2005)\n",
      "18507 Traning Loss: tensor(0.2056)\n",
      "18508 Traning Loss: tensor(0.1811)\n",
      "18509 Traning Loss: tensor(0.1954)\n",
      "18510 Traning Loss: tensor(0.1749)\n",
      "18511 Traning Loss: tensor(0.1851)\n",
      "18512 Traning Loss: tensor(0.1932)\n",
      "18513 Traning Loss: tensor(0.1932)\n",
      "18514 Traning Loss: tensor(0.1765)\n",
      "18515 Traning Loss: tensor(0.1972)\n",
      "18516 Traning Loss: tensor(0.1944)\n",
      "18517 Traning Loss: tensor(0.2203)\n",
      "18518 Traning Loss: tensor(0.2015)\n",
      "18519 Traning Loss: tensor(0.2237)\n",
      "18520 Traning Loss: tensor(0.1773)\n",
      "18521 Traning Loss: tensor(0.1977)\n",
      "18522 Traning Loss: tensor(0.1723)\n",
      "18523 Traning Loss: tensor(0.1771)\n",
      "18524 Traning Loss: tensor(0.1821)\n",
      "18525 Traning Loss: tensor(0.1885)\n",
      "18526 Traning Loss: tensor(0.2150)\n",
      "18527 Traning Loss: tensor(0.2286)\n",
      "18528 Traning Loss: tensor(0.1959)\n",
      "18529 Traning Loss: tensor(0.1726)\n",
      "18530 Traning Loss: tensor(0.1923)\n",
      "18531 Traning Loss: tensor(0.2079)\n",
      "18532 Traning Loss: tensor(0.1913)\n",
      "18533 Traning Loss: tensor(0.1932)\n",
      "18534 Traning Loss: tensor(0.2375)\n",
      "18535 Traning Loss: tensor(0.1931)\n",
      "18536 Traning Loss: tensor(0.1855)\n",
      "18537 Traning Loss: tensor(0.1857)\n",
      "18538 Traning Loss: tensor(0.1858)\n",
      "18539 Traning Loss: tensor(0.2081)\n",
      "18540 Traning Loss: tensor(0.2255)\n",
      "18541 Traning Loss: tensor(0.2179)\n",
      "18542 Traning Loss: tensor(0.1900)\n",
      "18543 Traning Loss: tensor(0.1834)\n",
      "18544 Traning Loss: tensor(0.2231)\n",
      "18545 Traning Loss: tensor(0.1632)\n",
      "18546 Traning Loss: tensor(0.1713)\n",
      "18547 Traning Loss: tensor(0.2334)\n",
      "18548 Traning Loss: tensor(0.2114)\n",
      "18549 Traning Loss: tensor(0.2056)\n",
      "18550 Traning Loss: tensor(0.2240)\n",
      "18551 Traning Loss: tensor(0.1969)\n",
      "18552 Traning Loss: tensor(0.1694)\n",
      "18553 Traning Loss: tensor(0.1759)\n",
      "18554 Traning Loss: tensor(0.2039)\n",
      "18555 Traning Loss: tensor(0.2126)\n",
      "18556 Traning Loss: tensor(0.2103)\n",
      "18557 Traning Loss: tensor(0.1873)\n",
      "18558 Traning Loss: tensor(0.1706)\n",
      "18559 Traning Loss: tensor(0.1708)\n",
      "18560 Traning Loss: tensor(0.1927)\n",
      "18561 Traning Loss: tensor(0.1972)\n",
      "18562 Traning Loss: tensor(0.1843)\n",
      "18563 Traning Loss: tensor(0.1870)\n",
      "18564 Traning Loss: tensor(0.1914)\n",
      "18565 Traning Loss: tensor(0.2171)\n",
      "18566 Traning Loss: tensor(0.2063)\n",
      "18567 Traning Loss: tensor(0.2122)\n",
      "18568 Traning Loss: tensor(0.2088)\n",
      "18569 Traning Loss: tensor(0.1920)\n",
      "18570 Traning Loss: tensor(0.2211)\n",
      "18571 Traning Loss: tensor(0.2134)\n",
      "18572 Traning Loss: tensor(0.2075)\n",
      "18573 Traning Loss: tensor(0.2130)\n",
      "18574 Traning Loss: tensor(0.2233)\n",
      "18575 Traning Loss: tensor(0.1809)\n",
      "18576 Traning Loss: tensor(0.2459)\n",
      "18577 Traning Loss: tensor(0.2175)\n",
      "18578 Traning Loss: tensor(0.1930)\n",
      "18579 Traning Loss: tensor(0.2211)\n",
      "18580 Traning Loss: tensor(0.2372)\n",
      "18581 Traning Loss: tensor(0.2233)\n",
      "18582 Traning Loss: tensor(0.1825)\n",
      "18583 Traning Loss: tensor(0.2475)\n",
      "18584 Traning Loss: tensor(0.2005)\n",
      "18585 Traning Loss: tensor(0.1855)\n",
      "18586 Traning Loss: tensor(0.2107)\n",
      "18587 Traning Loss: tensor(0.1926)\n",
      "18588 Traning Loss: tensor(0.1840)\n",
      "18589 Traning Loss: tensor(0.2147)\n",
      "18590 Traning Loss: tensor(0.2291)\n",
      "18591 Traning Loss: tensor(0.1915)\n",
      "18592 Traning Loss: tensor(0.1870)\n",
      "18593 Traning Loss: tensor(0.1895)\n",
      "18594 Traning Loss: tensor(0.2035)\n",
      "18595 Traning Loss: tensor(0.1924)\n",
      "18596 Traning Loss: tensor(0.2317)\n",
      "18597 Traning Loss: tensor(0.2073)\n",
      "18598 Traning Loss: tensor(0.2148)\n",
      "18599 Traning Loss: tensor(0.1956)\n",
      "18600 Traning Loss: tensor(0.1893)\n",
      "18601 Traning Loss: tensor(0.2098)\n",
      "18602 Traning Loss: tensor(0.2052)\n",
      "18603 Traning Loss: tensor(0.2087)\n",
      "18604 Traning Loss: tensor(0.1881)\n",
      "18605 Traning Loss: tensor(0.2100)\n",
      "18606 Traning Loss: tensor(0.1852)\n",
      "18607 Traning Loss: tensor(0.2165)\n",
      "18608 Traning Loss: tensor(0.1888)\n",
      "18609 Traning Loss: tensor(0.1909)\n",
      "18610 Traning Loss: tensor(0.1785)\n",
      "18611 Traning Loss: tensor(0.1850)\n",
      "18612 Traning Loss: tensor(0.2310)\n",
      "18613 Traning Loss: tensor(0.1882)\n",
      "18614 Traning Loss: tensor(0.1938)\n",
      "18615 Traning Loss: tensor(0.1749)\n",
      "18616 Traning Loss: tensor(0.1661)\n",
      "18617 Traning Loss: tensor(0.1927)\n",
      "18618 Traning Loss: tensor(0.1829)\n",
      "18619 Traning Loss: tensor(0.1820)\n",
      "18620 Traning Loss: tensor(0.1938)\n",
      "18621 Traning Loss: tensor(0.1688)\n",
      "18622 Traning Loss: tensor(0.1921)\n",
      "18623 Traning Loss: tensor(0.1817)\n",
      "18624 Traning Loss: tensor(0.1950)\n",
      "18625 Traning Loss: tensor(0.1814)\n",
      "18626 Traning Loss: tensor(0.1722)\n",
      "18627 Traning Loss: tensor(0.1864)\n",
      "18628 Traning Loss: tensor(0.1911)\n",
      "18629 Traning Loss: tensor(0.2087)\n",
      "18630 Traning Loss: tensor(0.2004)\n",
      "18631 Traning Loss: tensor(0.1729)\n",
      "18632 Traning Loss: tensor(0.2360)\n",
      "18633 Traning Loss: tensor(0.2109)\n",
      "18634 Traning Loss: tensor(0.2065)\n",
      "18635 Traning Loss: tensor(0.1827)\n",
      "18636 Traning Loss: tensor(0.1950)\n",
      "18637 Traning Loss: tensor(0.1864)\n",
      "18638 Traning Loss: tensor(0.1767)\n",
      "18639 Traning Loss: tensor(0.1649)\n",
      "18640 Traning Loss: tensor(0.1881)\n",
      "18641 Traning Loss: tensor(0.2118)\n",
      "18642 Traning Loss: tensor(0.2255)\n",
      "18643 Traning Loss: tensor(0.2136)\n",
      "18644 Traning Loss: tensor(0.2199)\n",
      "18645 Traning Loss: tensor(0.1969)\n",
      "18646 Traning Loss: tensor(0.1956)\n",
      "18647 Traning Loss: tensor(0.1781)\n",
      "18648 Traning Loss: tensor(0.2106)\n",
      "18649 Traning Loss: tensor(0.1940)\n",
      "18650 Traning Loss: tensor(0.1675)\n",
      "18651 Traning Loss: tensor(0.1738)\n",
      "18652 Traning Loss: tensor(0.1851)\n",
      "18653 Traning Loss: tensor(0.1524)\n",
      "18654 Traning Loss: tensor(0.1725)\n",
      "18655 Traning Loss: tensor(0.1957)\n",
      "18656 Traning Loss: tensor(0.1579)\n",
      "18657 Traning Loss: tensor(0.1765)\n",
      "18658 Traning Loss: tensor(0.1663)\n",
      "18659 Traning Loss: tensor(0.1770)\n",
      "18660 Traning Loss: tensor(0.1596)\n",
      "18661 Traning Loss: tensor(0.1799)\n",
      "18662 Traning Loss: tensor(0.2034)\n",
      "18663 Traning Loss: tensor(0.1849)\n",
      "18664 Traning Loss: tensor(0.2016)\n",
      "18665 Traning Loss: tensor(0.1669)\n",
      "18666 Traning Loss: tensor(0.2254)\n",
      "18667 Traning Loss: tensor(0.1965)\n",
      "18668 Traning Loss: tensor(0.1869)\n",
      "18669 Traning Loss: tensor(0.1665)\n",
      "18670 Traning Loss: tensor(0.2047)\n",
      "18671 Traning Loss: tensor(0.1782)\n",
      "18672 Traning Loss: tensor(0.1859)\n",
      "18673 Traning Loss: tensor(0.1985)\n",
      "18674 Traning Loss: tensor(0.2031)\n",
      "18675 Traning Loss: tensor(0.1614)\n",
      "18676 Traning Loss: tensor(0.1744)\n",
      "18677 Traning Loss: tensor(0.1748)\n",
      "18678 Traning Loss: tensor(0.2102)\n",
      "18679 Traning Loss: tensor(0.1818)\n",
      "18680 Traning Loss: tensor(0.2162)\n",
      "18681 Traning Loss: tensor(0.1741)\n",
      "18682 Traning Loss: tensor(0.1989)\n",
      "18683 Traning Loss: tensor(0.2251)\n",
      "18684 Traning Loss: tensor(0.1682)\n",
      "18685 Traning Loss: tensor(0.1862)\n",
      "18686 Traning Loss: tensor(0.1797)\n",
      "18687 Traning Loss: tensor(0.1898)\n",
      "18688 Traning Loss: tensor(0.1831)\n",
      "18689 Traning Loss: tensor(0.1675)\n",
      "18690 Traning Loss: tensor(0.2047)\n",
      "18691 Traning Loss: tensor(0.2131)\n",
      "18692 Traning Loss: tensor(0.1930)\n",
      "18693 Traning Loss: tensor(0.2013)\n",
      "18694 Traning Loss: tensor(0.2220)\n",
      "18695 Traning Loss: tensor(0.1746)\n",
      "18696 Traning Loss: tensor(0.2030)\n",
      "18697 Traning Loss: tensor(0.1929)\n",
      "18698 Traning Loss: tensor(0.2028)\n",
      "18699 Traning Loss: tensor(0.1801)\n",
      "18700 Traning Loss: tensor(0.2020)\n",
      "18701 Traning Loss: tensor(0.1757)\n",
      "18702 Traning Loss: tensor(0.2029)\n",
      "18703 Traning Loss: tensor(0.1887)\n",
      "18704 Traning Loss: tensor(0.1735)\n",
      "18705 Traning Loss: tensor(0.1700)\n",
      "18706 Traning Loss: tensor(0.2128)\n",
      "18707 Traning Loss: tensor(0.1834)\n",
      "18708 Traning Loss: tensor(0.1824)\n",
      "18709 Traning Loss: tensor(0.1518)\n",
      "18710 Traning Loss: tensor(0.1965)\n",
      "18711 Traning Loss: tensor(0.1886)\n",
      "18712 Traning Loss: tensor(0.1611)\n",
      "18713 Traning Loss: tensor(0.1952)\n",
      "18714 Traning Loss: tensor(0.1886)\n",
      "18715 Traning Loss: tensor(0.2059)\n",
      "18716 Traning Loss: tensor(0.1702)\n",
      "18717 Traning Loss: tensor(0.1692)\n",
      "18718 Traning Loss: tensor(0.2050)\n",
      "18719 Traning Loss: tensor(0.1804)\n",
      "18720 Traning Loss: tensor(0.1607)\n",
      "18721 Traning Loss: tensor(0.1806)\n",
      "18722 Traning Loss: tensor(0.2092)\n",
      "18723 Traning Loss: tensor(0.1872)\n",
      "18724 Traning Loss: tensor(0.1790)\n",
      "18725 Traning Loss: tensor(0.1831)\n",
      "18726 Traning Loss: tensor(0.1743)\n",
      "18727 Traning Loss: tensor(0.2165)\n",
      "18728 Traning Loss: tensor(0.1831)\n",
      "18729 Traning Loss: tensor(0.1632)\n",
      "18730 Traning Loss: tensor(0.1813)\n",
      "18731 Traning Loss: tensor(0.1597)\n",
      "18732 Traning Loss: tensor(0.1879)\n",
      "18733 Traning Loss: tensor(0.2082)\n",
      "18734 Traning Loss: tensor(0.1732)\n",
      "18735 Traning Loss: tensor(0.2024)\n",
      "18736 Traning Loss: tensor(0.1744)\n",
      "18737 Traning Loss: tensor(0.1729)\n",
      "18738 Traning Loss: tensor(0.1843)\n",
      "18739 Traning Loss: tensor(0.1774)\n",
      "18740 Traning Loss: tensor(0.1914)\n",
      "18741 Traning Loss: tensor(0.1883)\n",
      "18742 Traning Loss: tensor(0.1956)\n",
      "18743 Traning Loss: tensor(0.2407)\n",
      "18744 Traning Loss: tensor(0.1960)\n",
      "18745 Traning Loss: tensor(0.1862)\n",
      "18746 Traning Loss: tensor(0.1953)\n",
      "18747 Traning Loss: tensor(0.1786)\n",
      "18748 Traning Loss: tensor(0.1761)\n",
      "18749 Traning Loss: tensor(0.1832)\n",
      "18750 Traning Loss: tensor(0.2089)\n",
      "18751 Traning Loss: tensor(0.1859)\n",
      "18752 Traning Loss: tensor(0.1988)\n",
      "18753 Traning Loss: tensor(0.1751)\n",
      "18754 Traning Loss: tensor(0.1961)\n",
      "18755 Traning Loss: tensor(0.1887)\n",
      "18756 Traning Loss: tensor(0.1939)\n",
      "18757 Traning Loss: tensor(0.1543)\n",
      "18758 Traning Loss: tensor(0.1962)\n",
      "18759 Traning Loss: tensor(0.1743)\n",
      "18760 Traning Loss: tensor(0.2109)\n",
      "18761 Traning Loss: tensor(0.1856)\n",
      "18762 Traning Loss: tensor(0.2064)\n",
      "18763 Traning Loss: tensor(0.1778)\n",
      "18764 Traning Loss: tensor(0.1831)\n",
      "18765 Traning Loss: tensor(0.2134)\n",
      "18766 Traning Loss: tensor(0.1865)\n",
      "18767 Traning Loss: tensor(0.1951)\n",
      "18768 Traning Loss: tensor(0.1866)\n",
      "18769 Traning Loss: tensor(0.1792)\n",
      "18770 Traning Loss: tensor(0.1850)\n",
      "18771 Traning Loss: tensor(0.1691)\n",
      "18772 Traning Loss: tensor(0.1909)\n",
      "18773 Traning Loss: tensor(0.1709)\n",
      "18774 Traning Loss: tensor(0.1784)\n",
      "18775 Traning Loss: tensor(0.1620)\n",
      "18776 Traning Loss: tensor(0.1837)\n",
      "18777 Traning Loss: tensor(0.1692)\n",
      "18778 Traning Loss: tensor(0.2066)\n",
      "18779 Traning Loss: tensor(0.1897)\n",
      "18780 Traning Loss: tensor(0.1800)\n",
      "18781 Traning Loss: tensor(0.1912)\n",
      "18782 Traning Loss: tensor(0.1674)\n",
      "18783 Traning Loss: tensor(0.1662)\n",
      "18784 Traning Loss: tensor(0.1750)\n",
      "18785 Traning Loss: tensor(0.1959)\n",
      "18786 Traning Loss: tensor(0.1703)\n",
      "18787 Traning Loss: tensor(0.1878)\n",
      "18788 Traning Loss: tensor(0.2004)\n",
      "18789 Traning Loss: tensor(0.1763)\n",
      "18790 Traning Loss: tensor(0.1960)\n",
      "18791 Traning Loss: tensor(0.2006)\n",
      "18792 Traning Loss: tensor(0.1981)\n",
      "18793 Traning Loss: tensor(0.1551)\n",
      "18794 Traning Loss: tensor(0.1693)\n",
      "18795 Traning Loss: tensor(0.2077)\n",
      "18796 Traning Loss: tensor(0.1727)\n",
      "18797 Traning Loss: tensor(0.1512)\n",
      "18798 Traning Loss: tensor(0.1792)\n",
      "18799 Traning Loss: tensor(0.1644)\n",
      "18800 Traning Loss: tensor(0.2047)\n",
      "18801 Traning Loss: tensor(0.1674)\n",
      "18802 Traning Loss: tensor(0.1615)\n",
      "18803 Traning Loss: tensor(0.1742)\n",
      "18804 Traning Loss: tensor(0.2126)\n",
      "18805 Traning Loss: tensor(0.1879)\n",
      "18806 Traning Loss: tensor(0.1847)\n",
      "18807 Traning Loss: tensor(0.1958)\n",
      "18808 Traning Loss: tensor(0.1957)\n",
      "18809 Traning Loss: tensor(0.1795)\n",
      "18810 Traning Loss: tensor(0.1904)\n",
      "18811 Traning Loss: tensor(0.1904)\n",
      "18812 Traning Loss: tensor(0.1658)\n",
      "18813 Traning Loss: tensor(0.1920)\n",
      "18814 Traning Loss: tensor(0.1817)\n",
      "18815 Traning Loss: tensor(0.1675)\n",
      "18816 Traning Loss: tensor(0.1801)\n",
      "18817 Traning Loss: tensor(0.1772)\n",
      "18818 Traning Loss: tensor(0.1881)\n",
      "18819 Traning Loss: tensor(0.1764)\n",
      "18820 Traning Loss: tensor(0.1930)\n",
      "18821 Traning Loss: tensor(0.2152)\n",
      "18822 Traning Loss: tensor(0.1589)\n",
      "18823 Traning Loss: tensor(0.1762)\n",
      "18824 Traning Loss: tensor(0.1952)\n",
      "18825 Traning Loss: tensor(0.1724)\n",
      "18826 Traning Loss: tensor(0.1860)\n",
      "18827 Traning Loss: tensor(0.1840)\n",
      "18828 Traning Loss: tensor(0.1842)\n",
      "18829 Traning Loss: tensor(0.1911)\n",
      "18830 Traning Loss: tensor(0.1673)\n",
      "18831 Traning Loss: tensor(0.1785)\n",
      "18832 Traning Loss: tensor(0.1874)\n",
      "18833 Traning Loss: tensor(0.1785)\n",
      "18834 Traning Loss: tensor(0.1776)\n",
      "18835 Traning Loss: tensor(0.1917)\n",
      "18836 Traning Loss: tensor(0.1731)\n",
      "18837 Traning Loss: tensor(0.1513)\n",
      "18838 Traning Loss: tensor(0.1703)\n",
      "18839 Traning Loss: tensor(0.1886)\n",
      "18840 Traning Loss: tensor(0.1604)\n",
      "18841 Traning Loss: tensor(0.2047)\n",
      "18842 Traning Loss: tensor(0.2148)\n",
      "18843 Traning Loss: tensor(0.1553)\n",
      "18844 Traning Loss: tensor(0.2036)\n",
      "18845 Traning Loss: tensor(0.2103)\n",
      "18846 Traning Loss: tensor(0.1715)\n",
      "18847 Traning Loss: tensor(0.2085)\n",
      "18848 Traning Loss: tensor(0.1917)\n",
      "18849 Traning Loss: tensor(0.1876)\n",
      "18850 Traning Loss: tensor(0.1994)\n",
      "18851 Traning Loss: tensor(0.1503)\n",
      "18852 Traning Loss: tensor(0.1763)\n",
      "18853 Traning Loss: tensor(0.1667)\n",
      "18854 Traning Loss: tensor(0.1718)\n",
      "18855 Traning Loss: tensor(0.1529)\n",
      "18856 Traning Loss: tensor(0.1835)\n",
      "18857 Traning Loss: tensor(0.1814)\n",
      "18858 Traning Loss: tensor(0.1764)\n",
      "18859 Traning Loss: tensor(0.1567)\n",
      "18860 Traning Loss: tensor(0.1925)\n",
      "18861 Traning Loss: tensor(0.1681)\n",
      "18862 Traning Loss: tensor(0.1920)\n",
      "18863 Traning Loss: tensor(0.1658)\n",
      "18864 Traning Loss: tensor(0.1788)\n",
      "18865 Traning Loss: tensor(0.1575)\n",
      "18866 Traning Loss: tensor(0.1866)\n",
      "18867 Traning Loss: tensor(0.1748)\n",
      "18868 Traning Loss: tensor(0.1570)\n",
      "18869 Traning Loss: tensor(0.1484)\n",
      "18870 Traning Loss: tensor(0.1797)\n",
      "18871 Traning Loss: tensor(0.1879)\n",
      "18872 Traning Loss: tensor(0.1708)\n",
      "18873 Traning Loss: tensor(0.1813)\n",
      "18874 Traning Loss: tensor(0.1748)\n",
      "18875 Traning Loss: tensor(0.1723)\n",
      "18876 Traning Loss: tensor(0.1500)\n",
      "18877 Traning Loss: tensor(0.1742)\n",
      "18878 Traning Loss: tensor(0.1911)\n",
      "18879 Traning Loss: tensor(0.1454)\n",
      "18880 Traning Loss: tensor(0.1778)\n",
      "18881 Traning Loss: tensor(0.1726)\n",
      "18882 Traning Loss: tensor(0.1807)\n",
      "18883 Traning Loss: tensor(0.1677)\n",
      "18884 Traning Loss: tensor(0.1836)\n",
      "18885 Traning Loss: tensor(0.1626)\n",
      "18886 Traning Loss: tensor(0.1910)\n",
      "18887 Traning Loss: tensor(0.1779)\n",
      "18888 Traning Loss: tensor(0.1694)\n",
      "18889 Traning Loss: tensor(0.1718)\n",
      "18890 Traning Loss: tensor(0.1367)\n",
      "18891 Traning Loss: tensor(0.2460)\n",
      "18892 Traning Loss: tensor(0.1852)\n",
      "18893 Traning Loss: tensor(0.1872)\n",
      "18894 Traning Loss: tensor(0.1624)\n",
      "18895 Traning Loss: tensor(0.1643)\n",
      "18896 Traning Loss: tensor(0.1879)\n",
      "18897 Traning Loss: tensor(0.1679)\n",
      "18898 Traning Loss: tensor(0.1746)\n",
      "18899 Traning Loss: tensor(0.1714)\n",
      "18900 Traning Loss: tensor(0.1642)\n",
      "18901 Traning Loss: tensor(0.1834)\n",
      "18902 Traning Loss: tensor(0.1853)\n",
      "18903 Traning Loss: tensor(0.2037)\n",
      "18904 Traning Loss: tensor(0.1953)\n",
      "18905 Traning Loss: tensor(0.1653)\n",
      "18906 Traning Loss: tensor(0.1892)\n",
      "18907 Traning Loss: tensor(0.1871)\n",
      "18908 Traning Loss: tensor(0.1786)\n",
      "18909 Traning Loss: tensor(0.1448)\n",
      "18910 Traning Loss: tensor(0.1669)\n",
      "18911 Traning Loss: tensor(0.1888)\n",
      "18912 Traning Loss: tensor(0.1512)\n",
      "18913 Traning Loss: tensor(0.1572)\n",
      "18914 Traning Loss: tensor(0.1722)\n",
      "18915 Traning Loss: tensor(0.1882)\n",
      "18916 Traning Loss: tensor(0.1768)\n",
      "18917 Traning Loss: tensor(0.1983)\n",
      "18918 Traning Loss: tensor(0.1659)\n",
      "18919 Traning Loss: tensor(0.1747)\n",
      "18920 Traning Loss: tensor(0.1774)\n",
      "18921 Traning Loss: tensor(0.1599)\n",
      "18922 Traning Loss: tensor(0.1815)\n",
      "18923 Traning Loss: tensor(0.1823)\n",
      "18924 Traning Loss: tensor(0.1648)\n",
      "18925 Traning Loss: tensor(0.1954)\n",
      "18926 Traning Loss: tensor(0.1836)\n",
      "18927 Traning Loss: tensor(0.1679)\n",
      "18928 Traning Loss: tensor(0.1714)\n",
      "18929 Traning Loss: tensor(0.1443)\n",
      "18930 Traning Loss: tensor(0.1654)\n",
      "18931 Traning Loss: tensor(0.1699)\n",
      "18932 Traning Loss: tensor(0.1831)\n",
      "18933 Traning Loss: tensor(0.1685)\n",
      "18934 Traning Loss: tensor(0.1544)\n",
      "18935 Traning Loss: tensor(0.1579)\n",
      "18936 Traning Loss: tensor(0.1400)\n",
      "18937 Traning Loss: tensor(0.1700)\n",
      "18938 Traning Loss: tensor(0.1480)\n",
      "18939 Traning Loss: tensor(0.2003)\n",
      "18940 Traning Loss: tensor(0.1542)\n",
      "18941 Traning Loss: tensor(0.1934)\n",
      "18942 Traning Loss: tensor(0.1739)\n",
      "18943 Traning Loss: tensor(0.1761)\n",
      "18944 Traning Loss: tensor(0.1708)\n",
      "18945 Traning Loss: tensor(0.1851)\n",
      "18946 Traning Loss: tensor(0.1705)\n",
      "18947 Traning Loss: tensor(0.1480)\n",
      "18948 Traning Loss: tensor(0.1629)\n",
      "18949 Traning Loss: tensor(0.1856)\n",
      "18950 Traning Loss: tensor(0.1534)\n",
      "18951 Traning Loss: tensor(0.1561)\n",
      "18952 Traning Loss: tensor(0.2024)\n",
      "18953 Traning Loss: tensor(0.1664)\n",
      "18954 Traning Loss: tensor(0.1638)\n",
      "18955 Traning Loss: tensor(0.1596)\n",
      "18956 Traning Loss: tensor(0.1659)\n",
      "18957 Traning Loss: tensor(0.1630)\n",
      "18958 Traning Loss: tensor(0.1745)\n",
      "18959 Traning Loss: tensor(0.1989)\n",
      "18960 Traning Loss: tensor(0.1497)\n",
      "18961 Traning Loss: tensor(0.1569)\n",
      "18962 Traning Loss: tensor(0.1741)\n",
      "18963 Traning Loss: tensor(0.1855)\n",
      "18964 Traning Loss: tensor(0.2024)\n",
      "18965 Traning Loss: tensor(0.1570)\n",
      "18966 Traning Loss: tensor(0.1656)\n",
      "18967 Traning Loss: tensor(0.1985)\n",
      "18968 Traning Loss: tensor(0.1597)\n",
      "18969 Traning Loss: tensor(0.1782)\n",
      "18970 Traning Loss: tensor(0.1928)\n",
      "18971 Traning Loss: tensor(0.1620)\n",
      "18972 Traning Loss: tensor(0.1731)\n",
      "18973 Traning Loss: tensor(0.1949)\n",
      "18974 Traning Loss: tensor(0.1887)\n",
      "18975 Traning Loss: tensor(0.1965)\n",
      "18976 Traning Loss: tensor(0.1736)\n",
      "18977 Traning Loss: tensor(0.1712)\n",
      "18978 Traning Loss: tensor(0.1488)\n",
      "18979 Traning Loss: tensor(0.1748)\n",
      "18980 Traning Loss: tensor(0.1563)\n",
      "18981 Traning Loss: tensor(0.1897)\n",
      "18982 Traning Loss: tensor(0.1401)\n",
      "18983 Traning Loss: tensor(0.1717)\n",
      "18984 Traning Loss: tensor(0.1892)\n",
      "18985 Traning Loss: tensor(0.1825)\n",
      "18986 Traning Loss: tensor(0.1620)\n",
      "18987 Traning Loss: tensor(0.1607)\n",
      "18988 Traning Loss: tensor(0.1907)\n",
      "18989 Traning Loss: tensor(0.1658)\n",
      "18990 Traning Loss: tensor(0.1734)\n",
      "18991 Traning Loss: tensor(0.1682)\n",
      "18992 Traning Loss: tensor(0.1609)\n",
      "18993 Traning Loss: tensor(0.1935)\n",
      "18994 Traning Loss: tensor(0.1844)\n",
      "18995 Traning Loss: tensor(0.1704)\n",
      "18996 Traning Loss: tensor(0.1621)\n",
      "18997 Traning Loss: tensor(0.1581)\n",
      "18998 Traning Loss: tensor(0.1778)\n",
      "18999 Traning Loss: tensor(0.1589)\n",
      "19000 Traning Loss: tensor(0.1837)\n",
      "19001 Traning Loss: tensor(0.1586)\n",
      "19002 Traning Loss: tensor(0.1484)\n",
      "19003 Traning Loss: tensor(0.1905)\n",
      "19004 Traning Loss: tensor(0.1550)\n",
      "19005 Traning Loss: tensor(0.1752)\n",
      "19006 Traning Loss: tensor(0.1777)\n",
      "19007 Traning Loss: tensor(0.2006)\n",
      "19008 Traning Loss: tensor(0.1645)\n",
      "19009 Traning Loss: tensor(0.1856)\n",
      "19010 Traning Loss: tensor(0.1756)\n",
      "19011 Traning Loss: tensor(0.1614)\n",
      "19012 Traning Loss: tensor(0.1672)\n",
      "19013 Traning Loss: tensor(0.1949)\n",
      "19014 Traning Loss: tensor(0.1566)\n",
      "19015 Traning Loss: tensor(0.1895)\n",
      "19016 Traning Loss: tensor(0.1564)\n",
      "19017 Traning Loss: tensor(0.1748)\n",
      "19018 Traning Loss: tensor(0.1479)\n",
      "19019 Traning Loss: tensor(0.1841)\n",
      "19020 Traning Loss: tensor(0.1681)\n",
      "19021 Traning Loss: tensor(0.1613)\n",
      "19022 Traning Loss: tensor(0.1968)\n",
      "19023 Traning Loss: tensor(0.1679)\n",
      "19024 Traning Loss: tensor(0.1554)\n",
      "19025 Traning Loss: tensor(0.1543)\n",
      "19026 Traning Loss: tensor(0.2027)\n",
      "19027 Traning Loss: tensor(0.1729)\n",
      "19028 Traning Loss: tensor(0.1854)\n",
      "19029 Traning Loss: tensor(0.1486)\n",
      "19030 Traning Loss: tensor(0.1458)\n",
      "19031 Traning Loss: tensor(0.1495)\n",
      "19032 Traning Loss: tensor(0.1727)\n",
      "19033 Traning Loss: tensor(0.1628)\n",
      "19034 Traning Loss: tensor(0.1653)\n",
      "19035 Traning Loss: tensor(0.1568)\n",
      "19036 Traning Loss: tensor(0.1913)\n",
      "19037 Traning Loss: tensor(0.1675)\n",
      "19038 Traning Loss: tensor(0.1561)\n",
      "19039 Traning Loss: tensor(0.1770)\n",
      "19040 Traning Loss: tensor(0.1654)\n",
      "19041 Traning Loss: tensor(0.1816)\n",
      "19042 Traning Loss: tensor(0.1630)\n",
      "19043 Traning Loss: tensor(0.1550)\n",
      "19044 Traning Loss: tensor(0.1750)\n",
      "19045 Traning Loss: tensor(0.1829)\n",
      "19046 Traning Loss: tensor(0.1816)\n",
      "19047 Traning Loss: tensor(0.1719)\n",
      "19048 Traning Loss: tensor(0.1866)\n",
      "19049 Traning Loss: tensor(0.1689)\n",
      "19050 Traning Loss: tensor(0.2215)\n",
      "19051 Traning Loss: tensor(0.1669)\n",
      "19052 Traning Loss: tensor(0.1790)\n",
      "19053 Traning Loss: tensor(0.1718)\n",
      "19054 Traning Loss: tensor(0.1603)\n",
      "19055 Traning Loss: tensor(0.1629)\n",
      "19056 Traning Loss: tensor(0.1757)\n",
      "19057 Traning Loss: tensor(0.1603)\n",
      "19058 Traning Loss: tensor(0.1720)\n",
      "19059 Traning Loss: tensor(0.1776)\n",
      "19060 Traning Loss: tensor(0.1852)\n",
      "19061 Traning Loss: tensor(0.1505)\n",
      "19062 Traning Loss: tensor(0.1603)\n",
      "19063 Traning Loss: tensor(0.1656)\n",
      "19064 Traning Loss: tensor(0.1664)\n",
      "19065 Traning Loss: tensor(0.1646)\n",
      "19066 Traning Loss: tensor(0.1662)\n",
      "19067 Traning Loss: tensor(0.1882)\n",
      "19068 Traning Loss: tensor(0.1506)\n",
      "19069 Traning Loss: tensor(0.1785)\n",
      "19070 Traning Loss: tensor(0.1766)\n",
      "19071 Traning Loss: tensor(0.1739)\n",
      "19072 Traning Loss: tensor(0.1691)\n",
      "19073 Traning Loss: tensor(0.1740)\n",
      "19074 Traning Loss: tensor(0.1712)\n",
      "19075 Traning Loss: tensor(0.1769)\n",
      "19076 Traning Loss: tensor(0.1703)\n",
      "19077 Traning Loss: tensor(0.1745)\n",
      "19078 Traning Loss: tensor(0.1738)\n",
      "19079 Traning Loss: tensor(0.1644)\n",
      "19080 Traning Loss: tensor(0.1977)\n",
      "19081 Traning Loss: tensor(0.1675)\n",
      "19082 Traning Loss: tensor(0.1632)\n",
      "19083 Traning Loss: tensor(0.1812)\n",
      "19084 Traning Loss: tensor(0.1663)\n",
      "19085 Traning Loss: tensor(0.1727)\n",
      "19086 Traning Loss: tensor(0.1722)\n",
      "19087 Traning Loss: tensor(0.1576)\n",
      "19088 Traning Loss: tensor(0.1423)\n",
      "19089 Traning Loss: tensor(0.1922)\n",
      "19090 Traning Loss: tensor(0.1612)\n",
      "19091 Traning Loss: tensor(0.1589)\n",
      "19092 Traning Loss: tensor(0.1768)\n",
      "19093 Traning Loss: tensor(0.1621)\n",
      "19094 Traning Loss: tensor(0.1637)\n",
      "19095 Traning Loss: tensor(0.1789)\n",
      "19096 Traning Loss: tensor(0.1616)\n",
      "19097 Traning Loss: tensor(0.1652)\n",
      "19098 Traning Loss: tensor(0.1685)\n",
      "19099 Traning Loss: tensor(0.2090)\n",
      "19100 Traning Loss: tensor(0.1768)\n",
      "19101 Traning Loss: tensor(0.1791)\n",
      "19102 Traning Loss: tensor(0.1731)\n",
      "19103 Traning Loss: tensor(0.1836)\n",
      "19104 Traning Loss: tensor(0.1637)\n",
      "19105 Traning Loss: tensor(0.1855)\n",
      "19106 Traning Loss: tensor(0.1470)\n",
      "19107 Traning Loss: tensor(0.1570)\n",
      "19108 Traning Loss: tensor(0.1603)\n",
      "19109 Traning Loss: tensor(0.1517)\n",
      "19110 Traning Loss: tensor(0.1623)\n",
      "19111 Traning Loss: tensor(0.1861)\n",
      "19112 Traning Loss: tensor(0.1547)\n",
      "19113 Traning Loss: tensor(0.1552)\n",
      "19114 Traning Loss: tensor(0.1531)\n",
      "19115 Traning Loss: tensor(0.1609)\n",
      "19116 Traning Loss: tensor(0.1715)\n",
      "19117 Traning Loss: tensor(0.1661)\n",
      "19118 Traning Loss: tensor(0.1904)\n",
      "19119 Traning Loss: tensor(0.1673)\n",
      "19120 Traning Loss: tensor(0.1570)\n",
      "19121 Traning Loss: tensor(0.1519)\n",
      "19122 Traning Loss: tensor(0.1614)\n",
      "19123 Traning Loss: tensor(0.1783)\n",
      "19124 Traning Loss: tensor(0.1742)\n",
      "19125 Traning Loss: tensor(0.1794)\n",
      "19126 Traning Loss: tensor(0.1584)\n",
      "19127 Traning Loss: tensor(0.1821)\n",
      "19128 Traning Loss: tensor(0.1622)\n",
      "19129 Traning Loss: tensor(0.1486)\n",
      "19130 Traning Loss: tensor(0.1771)\n",
      "19131 Traning Loss: tensor(0.1423)\n",
      "19132 Traning Loss: tensor(0.2155)\n",
      "19133 Traning Loss: tensor(0.1508)\n",
      "19134 Traning Loss: tensor(0.1621)\n",
      "19135 Traning Loss: tensor(0.1423)\n",
      "19136 Traning Loss: tensor(0.1680)\n",
      "19137 Traning Loss: tensor(0.1514)\n",
      "19138 Traning Loss: tensor(0.1790)\n",
      "19139 Traning Loss: tensor(0.1545)\n",
      "19140 Traning Loss: tensor(0.1620)\n",
      "19141 Traning Loss: tensor(0.1472)\n",
      "19142 Traning Loss: tensor(0.1542)\n",
      "19143 Traning Loss: tensor(0.1885)\n",
      "19144 Traning Loss: tensor(0.1619)\n",
      "19145 Traning Loss: tensor(0.1843)\n",
      "19146 Traning Loss: tensor(0.1653)\n",
      "19147 Traning Loss: tensor(0.1941)\n",
      "19148 Traning Loss: tensor(0.1793)\n",
      "19149 Traning Loss: tensor(0.1442)\n",
      "19150 Traning Loss: tensor(0.1449)\n",
      "19151 Traning Loss: tensor(0.1467)\n",
      "19152 Traning Loss: tensor(0.2093)\n",
      "19153 Traning Loss: tensor(0.1943)\n",
      "19154 Traning Loss: tensor(0.1670)\n",
      "19155 Traning Loss: tensor(0.1967)\n",
      "19156 Traning Loss: tensor(0.1787)\n",
      "19157 Traning Loss: tensor(0.1642)\n",
      "19158 Traning Loss: tensor(0.1442)\n",
      "19159 Traning Loss: tensor(0.2234)\n",
      "19160 Traning Loss: tensor(0.1402)\n",
      "19161 Traning Loss: tensor(0.1678)\n",
      "19162 Traning Loss: tensor(0.1590)\n",
      "19163 Traning Loss: tensor(0.1727)\n",
      "19164 Traning Loss: tensor(0.1511)\n",
      "19165 Traning Loss: tensor(0.1678)\n",
      "19166 Traning Loss: tensor(0.1680)\n",
      "19167 Traning Loss: tensor(0.1601)\n",
      "19168 Traning Loss: tensor(0.1654)\n",
      "19169 Traning Loss: tensor(0.1606)\n",
      "19170 Traning Loss: tensor(0.1593)\n",
      "19171 Traning Loss: tensor(0.1786)\n",
      "19172 Traning Loss: tensor(0.1735)\n",
      "19173 Traning Loss: tensor(0.1535)\n",
      "19174 Traning Loss: tensor(0.1625)\n",
      "19175 Traning Loss: tensor(0.1955)\n",
      "19176 Traning Loss: tensor(0.1587)\n",
      "19177 Traning Loss: tensor(0.1650)\n",
      "19178 Traning Loss: tensor(0.1442)\n",
      "19179 Traning Loss: tensor(0.1663)\n",
      "19180 Traning Loss: tensor(0.1381)\n",
      "19181 Traning Loss: tensor(0.1642)\n",
      "19182 Traning Loss: tensor(0.1472)\n",
      "19183 Traning Loss: tensor(0.1651)\n",
      "19184 Traning Loss: tensor(0.1953)\n",
      "19185 Traning Loss: tensor(0.1648)\n",
      "19186 Traning Loss: tensor(0.1940)\n",
      "19187 Traning Loss: tensor(0.1638)\n",
      "19188 Traning Loss: tensor(0.1605)\n",
      "19189 Traning Loss: tensor(0.1572)\n",
      "19190 Traning Loss: tensor(0.1481)\n",
      "19191 Traning Loss: tensor(0.1549)\n",
      "19192 Traning Loss: tensor(0.1710)\n",
      "19193 Traning Loss: tensor(0.1445)\n",
      "19194 Traning Loss: tensor(0.1482)\n",
      "19195 Traning Loss: tensor(0.1500)\n",
      "19196 Traning Loss: tensor(0.1796)\n",
      "19197 Traning Loss: tensor(0.1899)\n",
      "19198 Traning Loss: tensor(0.1885)\n",
      "19199 Traning Loss: tensor(0.1613)\n",
      "19200 Traning Loss: tensor(0.1729)\n",
      "19201 Traning Loss: tensor(0.1905)\n",
      "19202 Traning Loss: tensor(0.1408)\n",
      "19203 Traning Loss: tensor(0.1728)\n",
      "19204 Traning Loss: tensor(0.1742)\n",
      "19205 Traning Loss: tensor(0.1785)\n",
      "19206 Traning Loss: tensor(0.1533)\n",
      "19207 Traning Loss: tensor(0.1468)\n",
      "19208 Traning Loss: tensor(0.1759)\n",
      "19209 Traning Loss: tensor(0.1305)\n",
      "19210 Traning Loss: tensor(0.1776)\n",
      "19211 Traning Loss: tensor(0.1611)\n",
      "19212 Traning Loss: tensor(0.1798)\n",
      "19213 Traning Loss: tensor(0.1558)\n",
      "19214 Traning Loss: tensor(0.1579)\n",
      "19215 Traning Loss: tensor(0.1601)\n",
      "19216 Traning Loss: tensor(0.1652)\n",
      "19217 Traning Loss: tensor(0.1502)\n",
      "19218 Traning Loss: tensor(0.1571)\n",
      "19219 Traning Loss: tensor(0.1760)\n",
      "19220 Traning Loss: tensor(0.1714)\n",
      "19221 Traning Loss: tensor(0.1856)\n",
      "19222 Traning Loss: tensor(0.1526)\n",
      "19223 Traning Loss: tensor(0.1815)\n",
      "19224 Traning Loss: tensor(0.1503)\n",
      "19225 Traning Loss: tensor(0.1807)\n",
      "19226 Traning Loss: tensor(0.1706)\n",
      "19227 Traning Loss: tensor(0.1692)\n",
      "19228 Traning Loss: tensor(0.1797)\n",
      "19229 Traning Loss: tensor(0.1621)\n",
      "19230 Traning Loss: tensor(0.1551)\n",
      "19231 Traning Loss: tensor(0.1612)\n",
      "19232 Traning Loss: tensor(0.1560)\n",
      "19233 Traning Loss: tensor(0.1521)\n",
      "19234 Traning Loss: tensor(0.1509)\n",
      "19235 Traning Loss: tensor(0.1435)\n",
      "19236 Traning Loss: tensor(0.1340)\n",
      "19237 Traning Loss: tensor(0.1610)\n",
      "19238 Traning Loss: tensor(0.1495)\n",
      "19239 Traning Loss: tensor(0.1578)\n",
      "19240 Traning Loss: tensor(0.1448)\n",
      "19241 Traning Loss: tensor(0.1695)\n",
      "19242 Traning Loss: tensor(0.1615)\n",
      "19243 Traning Loss: tensor(0.1519)\n",
      "19244 Traning Loss: tensor(0.1647)\n",
      "19245 Traning Loss: tensor(0.1766)\n",
      "19246 Traning Loss: tensor(0.1538)\n",
      "19247 Traning Loss: tensor(0.1821)\n",
      "19248 Traning Loss: tensor(0.1658)\n",
      "19249 Traning Loss: tensor(0.1743)\n",
      "19250 Traning Loss: tensor(0.1535)\n",
      "19251 Traning Loss: tensor(0.1664)\n",
      "19252 Traning Loss: tensor(0.1714)\n",
      "19253 Traning Loss: tensor(0.1750)\n",
      "19254 Traning Loss: tensor(0.1399)\n",
      "19255 Traning Loss: tensor(0.1616)\n",
      "19256 Traning Loss: tensor(0.1565)\n",
      "19257 Traning Loss: tensor(0.1579)\n",
      "19258 Traning Loss: tensor(0.1582)\n",
      "19259 Traning Loss: tensor(0.1671)\n",
      "19260 Traning Loss: tensor(0.1743)\n",
      "19261 Traning Loss: tensor(0.1398)\n",
      "19262 Traning Loss: tensor(0.1693)\n",
      "19263 Traning Loss: tensor(0.1616)\n",
      "19264 Traning Loss: tensor(0.1517)\n",
      "19265 Traning Loss: tensor(0.1557)\n",
      "19266 Traning Loss: tensor(0.1714)\n",
      "19267 Traning Loss: tensor(0.1627)\n",
      "19268 Traning Loss: tensor(0.1491)\n",
      "19269 Traning Loss: tensor(0.2179)\n",
      "19270 Traning Loss: tensor(0.1602)\n",
      "19271 Traning Loss: tensor(0.1497)\n",
      "19272 Traning Loss: tensor(0.1525)\n",
      "19273 Traning Loss: tensor(0.1529)\n",
      "19274 Traning Loss: tensor(0.1821)\n",
      "19275 Traning Loss: tensor(0.1782)\n",
      "19276 Traning Loss: tensor(0.1792)\n",
      "19277 Traning Loss: tensor(0.1738)\n",
      "19278 Traning Loss: tensor(0.1745)\n",
      "19279 Traning Loss: tensor(0.1433)\n",
      "19280 Traning Loss: tensor(0.1824)\n",
      "19281 Traning Loss: tensor(0.1825)\n",
      "19282 Traning Loss: tensor(0.1835)\n",
      "19283 Traning Loss: tensor(0.1526)\n",
      "19284 Traning Loss: tensor(0.1684)\n",
      "19285 Traning Loss: tensor(0.1838)\n",
      "19286 Traning Loss: tensor(0.1739)\n",
      "19287 Traning Loss: tensor(0.1410)\n",
      "19288 Traning Loss: tensor(0.1752)\n",
      "19289 Traning Loss: tensor(0.1691)\n",
      "19290 Traning Loss: tensor(0.1492)\n",
      "19291 Traning Loss: tensor(0.1554)\n",
      "19292 Traning Loss: tensor(0.1562)\n",
      "19293 Traning Loss: tensor(0.1443)\n",
      "19294 Traning Loss: tensor(0.1628)\n",
      "19295 Traning Loss: tensor(0.1849)\n",
      "19296 Traning Loss: tensor(0.1510)\n",
      "19297 Traning Loss: tensor(0.1770)\n",
      "19298 Traning Loss: tensor(0.1706)\n",
      "19299 Traning Loss: tensor(0.1594)\n",
      "19300 Traning Loss: tensor(0.1508)\n",
      "19301 Traning Loss: tensor(0.1348)\n",
      "19302 Traning Loss: tensor(0.1764)\n",
      "19303 Traning Loss: tensor(0.1610)\n",
      "19304 Traning Loss: tensor(0.1905)\n",
      "19305 Traning Loss: tensor(0.1804)\n",
      "19306 Traning Loss: tensor(0.1510)\n",
      "19307 Traning Loss: tensor(0.1696)\n",
      "19308 Traning Loss: tensor(0.1493)\n",
      "19309 Traning Loss: tensor(0.1277)\n",
      "19310 Traning Loss: tensor(0.1477)\n",
      "19311 Traning Loss: tensor(0.1589)\n",
      "19312 Traning Loss: tensor(0.1790)\n",
      "19313 Traning Loss: tensor(0.1535)\n",
      "19314 Traning Loss: tensor(0.1312)\n",
      "19315 Traning Loss: tensor(0.1468)\n",
      "19316 Traning Loss: tensor(0.1862)\n",
      "19317 Traning Loss: tensor(0.1546)\n",
      "19318 Traning Loss: tensor(0.1568)\n",
      "19319 Traning Loss: tensor(0.1443)\n",
      "19320 Traning Loss: tensor(0.1676)\n",
      "19321 Traning Loss: tensor(0.1524)\n",
      "19322 Traning Loss: tensor(0.1328)\n",
      "19323 Traning Loss: tensor(0.1670)\n",
      "19324 Traning Loss: tensor(0.1903)\n",
      "19325 Traning Loss: tensor(0.1450)\n",
      "19326 Traning Loss: tensor(0.1654)\n",
      "19327 Traning Loss: tensor(0.1676)\n",
      "19328 Traning Loss: tensor(0.1583)\n",
      "19329 Traning Loss: tensor(0.1674)\n",
      "19330 Traning Loss: tensor(0.1706)\n",
      "19331 Traning Loss: tensor(0.1548)\n",
      "19332 Traning Loss: tensor(0.1478)\n",
      "19333 Traning Loss: tensor(0.1569)\n",
      "19334 Traning Loss: tensor(0.1509)\n",
      "19335 Traning Loss: tensor(0.1791)\n",
      "19336 Traning Loss: tensor(0.1753)\n",
      "19337 Traning Loss: tensor(0.1576)\n",
      "19338 Traning Loss: tensor(0.1338)\n",
      "19339 Traning Loss: tensor(0.1591)\n",
      "19340 Traning Loss: tensor(0.1412)\n",
      "19341 Traning Loss: tensor(0.1538)\n",
      "19342 Traning Loss: tensor(0.1574)\n",
      "19343 Traning Loss: tensor(0.1866)\n",
      "19344 Traning Loss: tensor(0.1521)\n",
      "19345 Traning Loss: tensor(0.1710)\n",
      "19346 Traning Loss: tensor(0.1813)\n",
      "19347 Traning Loss: tensor(0.1459)\n",
      "19348 Traning Loss: tensor(0.1485)\n",
      "19349 Traning Loss: tensor(0.1692)\n",
      "19350 Traning Loss: tensor(0.1584)\n",
      "19351 Traning Loss: tensor(0.1575)\n",
      "19352 Traning Loss: tensor(0.1801)\n",
      "19353 Traning Loss: tensor(0.1282)\n",
      "19354 Traning Loss: tensor(0.1809)\n",
      "19355 Traning Loss: tensor(0.1552)\n",
      "19356 Traning Loss: tensor(0.1584)\n",
      "19357 Traning Loss: tensor(0.1605)\n",
      "19358 Traning Loss: tensor(0.1551)\n",
      "19359 Traning Loss: tensor(0.1513)\n",
      "19360 Traning Loss: tensor(0.1511)\n",
      "19361 Traning Loss: tensor(0.1515)\n",
      "19362 Traning Loss: tensor(0.1399)\n",
      "19363 Traning Loss: tensor(0.1612)\n",
      "19364 Traning Loss: tensor(0.1711)\n",
      "19365 Traning Loss: tensor(0.1479)\n",
      "19366 Traning Loss: tensor(0.1682)\n",
      "19367 Traning Loss: tensor(0.1583)\n",
      "19368 Traning Loss: tensor(0.1885)\n",
      "19369 Traning Loss: tensor(0.1471)\n",
      "19370 Traning Loss: tensor(0.1653)\n",
      "19371 Traning Loss: tensor(0.1510)\n",
      "19372 Traning Loss: tensor(0.1420)\n",
      "19373 Traning Loss: tensor(0.1351)\n",
      "19374 Traning Loss: tensor(0.1759)\n",
      "19375 Traning Loss: tensor(0.1447)\n",
      "19376 Traning Loss: tensor(0.1832)\n",
      "19377 Traning Loss: tensor(0.1750)\n",
      "19378 Traning Loss: tensor(0.1497)\n",
      "19379 Traning Loss: tensor(0.1549)\n",
      "19380 Traning Loss: tensor(0.1375)\n",
      "19381 Traning Loss: tensor(0.1651)\n",
      "19382 Traning Loss: tensor(0.2087)\n",
      "19383 Traning Loss: tensor(0.1847)\n",
      "19384 Traning Loss: tensor(0.1332)\n",
      "19385 Traning Loss: tensor(0.1434)\n",
      "19386 Traning Loss: tensor(0.1531)\n",
      "19387 Traning Loss: tensor(0.1465)\n",
      "19388 Traning Loss: tensor(0.1298)\n",
      "19389 Traning Loss: tensor(0.1569)\n",
      "19390 Traning Loss: tensor(0.1651)\n",
      "19391 Traning Loss: tensor(0.1479)\n",
      "19392 Traning Loss: tensor(0.1461)\n",
      "19393 Traning Loss: tensor(0.1511)\n",
      "19394 Traning Loss: tensor(0.1803)\n",
      "19395 Traning Loss: tensor(0.1648)\n",
      "19396 Traning Loss: tensor(0.1708)\n",
      "19397 Traning Loss: tensor(0.1375)\n",
      "19398 Traning Loss: tensor(0.1951)\n",
      "19399 Traning Loss: tensor(0.1424)\n",
      "19400 Traning Loss: tensor(0.1585)\n",
      "19401 Traning Loss: tensor(0.1422)\n",
      "19402 Traning Loss: tensor(0.1640)\n",
      "19403 Traning Loss: tensor(0.1779)\n",
      "19404 Traning Loss: tensor(0.1361)\n",
      "19405 Traning Loss: tensor(0.1327)\n",
      "19406 Traning Loss: tensor(0.1296)\n",
      "19407 Traning Loss: tensor(0.1666)\n",
      "19408 Traning Loss: tensor(0.1551)\n",
      "19409 Traning Loss: tensor(0.1465)\n",
      "19410 Traning Loss: tensor(0.1529)\n",
      "19411 Traning Loss: tensor(0.1843)\n",
      "19412 Traning Loss: tensor(0.1404)\n",
      "19413 Traning Loss: tensor(0.1310)\n",
      "19414 Traning Loss: tensor(0.1536)\n",
      "19415 Traning Loss: tensor(0.1616)\n",
      "19416 Traning Loss: tensor(0.1500)\n",
      "19417 Traning Loss: tensor(0.1252)\n",
      "19418 Traning Loss: tensor(0.1457)\n",
      "19419 Traning Loss: tensor(0.1648)\n",
      "19420 Traning Loss: tensor(0.1769)\n",
      "19421 Traning Loss: tensor(0.1641)\n",
      "19422 Traning Loss: tensor(0.1420)\n",
      "19423 Traning Loss: tensor(0.1969)\n",
      "19424 Traning Loss: tensor(0.1514)\n",
      "19425 Traning Loss: tensor(0.1690)\n",
      "19426 Traning Loss: tensor(0.1557)\n",
      "19427 Traning Loss: tensor(0.1604)\n",
      "19428 Traning Loss: tensor(0.1633)\n",
      "19429 Traning Loss: tensor(0.1894)\n",
      "19430 Traning Loss: tensor(0.1554)\n",
      "19431 Traning Loss: tensor(0.1322)\n",
      "19432 Traning Loss: tensor(0.1465)\n",
      "19433 Traning Loss: tensor(0.1597)\n",
      "19434 Traning Loss: tensor(0.1505)\n",
      "19435 Traning Loss: tensor(0.1624)\n",
      "19436 Traning Loss: tensor(0.1737)\n",
      "19437 Traning Loss: tensor(0.1718)\n",
      "19438 Traning Loss: tensor(0.1667)\n",
      "19439 Traning Loss: tensor(0.1367)\n",
      "19440 Traning Loss: tensor(0.1544)\n",
      "19441 Traning Loss: tensor(0.1525)\n",
      "19442 Traning Loss: tensor(0.1712)\n",
      "19443 Traning Loss: tensor(0.1556)\n",
      "19444 Traning Loss: tensor(0.1565)\n",
      "19445 Traning Loss: tensor(0.1592)\n",
      "19446 Traning Loss: tensor(0.1771)\n",
      "19447 Traning Loss: tensor(0.1702)\n",
      "19448 Traning Loss: tensor(0.1679)\n",
      "19449 Traning Loss: tensor(0.1575)\n",
      "19450 Traning Loss: tensor(0.1420)\n",
      "19451 Traning Loss: tensor(0.1665)\n",
      "19452 Traning Loss: tensor(0.1445)\n",
      "19453 Traning Loss: tensor(0.1590)\n",
      "19454 Traning Loss: tensor(0.1745)\n",
      "19455 Traning Loss: tensor(0.1574)\n",
      "19456 Traning Loss: tensor(0.1621)\n",
      "19457 Traning Loss: tensor(0.1501)\n",
      "19458 Traning Loss: tensor(0.1596)\n",
      "19459 Traning Loss: tensor(0.1580)\n",
      "19460 Traning Loss: tensor(0.1714)\n",
      "19461 Traning Loss: tensor(0.1364)\n",
      "19462 Traning Loss: tensor(0.1407)\n",
      "19463 Traning Loss: tensor(0.1446)\n",
      "19464 Traning Loss: tensor(0.1766)\n",
      "19465 Traning Loss: tensor(0.1501)\n",
      "19466 Traning Loss: tensor(0.1827)\n",
      "19467 Traning Loss: tensor(0.1947)\n",
      "19468 Traning Loss: tensor(0.1924)\n",
      "19469 Traning Loss: tensor(0.1646)\n",
      "19470 Traning Loss: tensor(0.1703)\n",
      "19471 Traning Loss: tensor(0.1687)\n",
      "19472 Traning Loss: tensor(0.1419)\n",
      "19473 Traning Loss: tensor(0.1664)\n",
      "19474 Traning Loss: tensor(0.1683)\n",
      "19475 Traning Loss: tensor(0.1456)\n",
      "19476 Traning Loss: tensor(0.1874)\n",
      "19477 Traning Loss: tensor(0.1697)\n",
      "19478 Traning Loss: tensor(0.1827)\n",
      "19479 Traning Loss: tensor(0.1724)\n",
      "19480 Traning Loss: tensor(0.1516)\n",
      "19481 Traning Loss: tensor(0.1565)\n",
      "19482 Traning Loss: tensor(0.1423)\n",
      "19483 Traning Loss: tensor(0.1635)\n",
      "19484 Traning Loss: tensor(0.1384)\n",
      "19485 Traning Loss: tensor(0.1657)\n",
      "19486 Traning Loss: tensor(0.1591)\n",
      "19487 Traning Loss: tensor(0.1493)\n",
      "19488 Traning Loss: tensor(0.1724)\n",
      "19489 Traning Loss: tensor(0.1407)\n",
      "19490 Traning Loss: tensor(0.1431)\n",
      "19491 Traning Loss: tensor(0.1409)\n",
      "19492 Traning Loss: tensor(0.1502)\n",
      "19493 Traning Loss: tensor(0.1751)\n",
      "19494 Traning Loss: tensor(0.1317)\n",
      "19495 Traning Loss: tensor(0.1441)\n",
      "19496 Traning Loss: tensor(0.1375)\n",
      "19497 Traning Loss: tensor(0.1513)\n",
      "19498 Traning Loss: tensor(0.1905)\n",
      "19499 Traning Loss: tensor(0.1366)\n",
      "19500 Traning Loss: tensor(0.1461)\n",
      "19501 Traning Loss: tensor(0.1745)\n",
      "19502 Traning Loss: tensor(0.1721)\n",
      "19503 Traning Loss: tensor(0.1700)\n",
      "19504 Traning Loss: tensor(0.1408)\n",
      "19505 Traning Loss: tensor(0.1392)\n",
      "19506 Traning Loss: tensor(0.1418)\n",
      "19507 Traning Loss: tensor(0.1553)\n",
      "19508 Traning Loss: tensor(0.1723)\n",
      "19509 Traning Loss: tensor(0.1353)\n",
      "19510 Traning Loss: tensor(0.1576)\n",
      "19511 Traning Loss: tensor(0.1691)\n",
      "19512 Traning Loss: tensor(0.1428)\n",
      "19513 Traning Loss: tensor(0.1383)\n",
      "19514 Traning Loss: tensor(0.1572)\n",
      "19515 Traning Loss: tensor(0.1539)\n",
      "19516 Traning Loss: tensor(0.1399)\n",
      "19517 Traning Loss: tensor(0.1578)\n",
      "19518 Traning Loss: tensor(0.1539)\n",
      "19519 Traning Loss: tensor(0.1804)\n",
      "19520 Traning Loss: tensor(0.1510)\n",
      "19521 Traning Loss: tensor(0.1675)\n",
      "19522 Traning Loss: tensor(0.1482)\n",
      "19523 Traning Loss: tensor(0.1479)\n",
      "19524 Traning Loss: tensor(0.1575)\n",
      "19525 Traning Loss: tensor(0.1635)\n",
      "19526 Traning Loss: tensor(0.1500)\n",
      "19527 Traning Loss: tensor(0.1265)\n",
      "19528 Traning Loss: tensor(0.1827)\n",
      "19529 Traning Loss: tensor(0.1781)\n",
      "19530 Traning Loss: tensor(0.1499)\n",
      "19531 Traning Loss: tensor(0.1616)\n",
      "19532 Traning Loss: tensor(0.1541)\n",
      "19533 Traning Loss: tensor(0.1526)\n",
      "19534 Traning Loss: tensor(0.1536)\n",
      "19535 Traning Loss: tensor(0.1601)\n",
      "19536 Traning Loss: tensor(0.1466)\n",
      "19537 Traning Loss: tensor(0.1390)\n",
      "19538 Traning Loss: tensor(0.1322)\n",
      "19539 Traning Loss: tensor(0.1669)\n",
      "19540 Traning Loss: tensor(0.1381)\n",
      "19541 Traning Loss: tensor(0.1420)\n",
      "19542 Traning Loss: tensor(0.1438)\n",
      "19543 Traning Loss: tensor(0.1497)\n",
      "19544 Traning Loss: tensor(0.1537)\n",
      "19545 Traning Loss: tensor(0.1343)\n",
      "19546 Traning Loss: tensor(0.1415)\n",
      "19547 Traning Loss: tensor(0.1498)\n",
      "19548 Traning Loss: tensor(0.1383)\n",
      "19549 Traning Loss: tensor(0.1294)\n",
      "19550 Traning Loss: tensor(0.1616)\n",
      "19551 Traning Loss: tensor(0.1467)\n",
      "19552 Traning Loss: tensor(0.1341)\n",
      "19553 Traning Loss: tensor(0.1583)\n",
      "19554 Traning Loss: tensor(0.1429)\n",
      "19555 Traning Loss: tensor(0.1436)\n",
      "19556 Traning Loss: tensor(0.1421)\n",
      "19557 Traning Loss: tensor(0.1589)\n",
      "19558 Traning Loss: tensor(0.1689)\n",
      "19559 Traning Loss: tensor(0.1321)\n",
      "19560 Traning Loss: tensor(0.1956)\n",
      "19561 Traning Loss: tensor(0.1517)\n",
      "19562 Traning Loss: tensor(0.1510)\n",
      "19563 Traning Loss: tensor(0.1549)\n",
      "19564 Traning Loss: tensor(0.1442)\n",
      "19565 Traning Loss: tensor(0.1580)\n",
      "19566 Traning Loss: tensor(0.1370)\n",
      "19567 Traning Loss: tensor(0.1424)\n",
      "19568 Traning Loss: tensor(0.1423)\n",
      "19569 Traning Loss: tensor(0.1325)\n",
      "19570 Traning Loss: tensor(0.1259)\n",
      "19571 Traning Loss: tensor(0.1450)\n",
      "19572 Traning Loss: tensor(0.1348)\n",
      "19573 Traning Loss: tensor(0.1798)\n",
      "19574 Traning Loss: tensor(0.1207)\n",
      "19575 Traning Loss: tensor(0.1451)\n",
      "19576 Traning Loss: tensor(0.1508)\n",
      "19577 Traning Loss: tensor(0.1520)\n",
      "19578 Traning Loss: tensor(0.1695)\n",
      "19579 Traning Loss: tensor(0.1738)\n",
      "19580 Traning Loss: tensor(0.1355)\n",
      "19581 Traning Loss: tensor(0.1571)\n",
      "19582 Traning Loss: tensor(0.1869)\n",
      "19583 Traning Loss: tensor(0.1462)\n",
      "19584 Traning Loss: tensor(0.1325)\n",
      "19585 Traning Loss: tensor(0.1416)\n",
      "19586 Traning Loss: tensor(0.1387)\n",
      "19587 Traning Loss: tensor(0.1453)\n",
      "19588 Traning Loss: tensor(0.1356)\n",
      "19589 Traning Loss: tensor(0.1747)\n",
      "19590 Traning Loss: tensor(0.1311)\n",
      "19591 Traning Loss: tensor(0.1209)\n",
      "19592 Traning Loss: tensor(0.1479)\n",
      "19593 Traning Loss: tensor(0.1398)\n",
      "19594 Traning Loss: tensor(0.1196)\n",
      "19595 Traning Loss: tensor(0.1528)\n",
      "19596 Traning Loss: tensor(0.1299)\n",
      "19597 Traning Loss: tensor(0.1526)\n",
      "19598 Traning Loss: tensor(0.1475)\n",
      "19599 Traning Loss: tensor(0.1808)\n",
      "19600 Traning Loss: tensor(0.1407)\n",
      "19601 Traning Loss: tensor(0.1610)\n",
      "19602 Traning Loss: tensor(0.1456)\n",
      "19603 Traning Loss: tensor(0.1202)\n",
      "19604 Traning Loss: tensor(0.1538)\n",
      "19605 Traning Loss: tensor(0.1428)\n",
      "19606 Traning Loss: tensor(0.1643)\n",
      "19607 Traning Loss: tensor(0.1488)\n",
      "19608 Traning Loss: tensor(0.1420)\n",
      "19609 Traning Loss: tensor(0.1475)\n",
      "19610 Traning Loss: tensor(0.1351)\n",
      "19611 Traning Loss: tensor(0.1485)\n",
      "19612 Traning Loss: tensor(0.1656)\n",
      "19613 Traning Loss: tensor(0.1543)\n",
      "19614 Traning Loss: tensor(0.1694)\n",
      "19615 Traning Loss: tensor(0.1264)\n",
      "19616 Traning Loss: tensor(0.1473)\n",
      "19617 Traning Loss: tensor(0.1536)\n",
      "19618 Traning Loss: tensor(0.1341)\n",
      "19619 Traning Loss: tensor(0.1255)\n",
      "19620 Traning Loss: tensor(0.1564)\n",
      "19621 Traning Loss: tensor(0.1340)\n",
      "19622 Traning Loss: tensor(0.1381)\n",
      "19623 Traning Loss: tensor(0.1342)\n",
      "19624 Traning Loss: tensor(0.1444)\n",
      "19625 Traning Loss: tensor(0.1426)\n",
      "19626 Traning Loss: tensor(0.1255)\n",
      "19627 Traning Loss: tensor(0.1450)\n",
      "19628 Traning Loss: tensor(0.1443)\n",
      "19629 Traning Loss: tensor(0.1197)\n",
      "19630 Traning Loss: tensor(0.1535)\n",
      "19631 Traning Loss: tensor(0.1513)\n",
      "19632 Traning Loss: tensor(0.1410)\n",
      "19633 Traning Loss: tensor(0.1543)\n",
      "19634 Traning Loss: tensor(0.1342)\n",
      "19635 Traning Loss: tensor(0.1476)\n",
      "19636 Traning Loss: tensor(0.1303)\n",
      "19637 Traning Loss: tensor(0.1274)\n",
      "19638 Traning Loss: tensor(0.1308)\n",
      "19639 Traning Loss: tensor(0.1428)\n",
      "19640 Traning Loss: tensor(0.1468)\n",
      "19641 Traning Loss: tensor(0.1465)\n",
      "19642 Traning Loss: tensor(0.1530)\n",
      "19643 Traning Loss: tensor(0.1286)\n",
      "19644 Traning Loss: tensor(0.1304)\n",
      "19645 Traning Loss: tensor(0.1742)\n",
      "19646 Traning Loss: tensor(0.1395)\n",
      "19647 Traning Loss: tensor(0.1348)\n",
      "19648 Traning Loss: tensor(0.1481)\n",
      "19649 Traning Loss: tensor(0.1327)\n",
      "19650 Traning Loss: tensor(0.1719)\n",
      "19651 Traning Loss: tensor(0.1384)\n",
      "19652 Traning Loss: tensor(0.1360)\n",
      "19653 Traning Loss: tensor(0.1771)\n",
      "19654 Traning Loss: tensor(0.1492)\n",
      "19655 Traning Loss: tensor(0.1623)\n",
      "19656 Traning Loss: tensor(0.1476)\n",
      "19657 Traning Loss: tensor(0.1432)\n",
      "19658 Traning Loss: tensor(0.1555)\n",
      "19659 Traning Loss: tensor(0.1624)\n",
      "19660 Traning Loss: tensor(0.1456)\n",
      "19661 Traning Loss: tensor(0.1496)\n",
      "19662 Traning Loss: tensor(0.1382)\n",
      "19663 Traning Loss: tensor(0.1430)\n",
      "19664 Traning Loss: tensor(0.1352)\n",
      "19665 Traning Loss: tensor(0.1396)\n",
      "19666 Traning Loss: tensor(0.1394)\n",
      "19667 Traning Loss: tensor(0.1489)\n",
      "19668 Traning Loss: tensor(0.1225)\n",
      "19669 Traning Loss: tensor(0.1282)\n",
      "19670 Traning Loss: tensor(0.1740)\n",
      "19671 Traning Loss: tensor(0.1363)\n",
      "19672 Traning Loss: tensor(0.1553)\n",
      "19673 Traning Loss: tensor(0.1422)\n",
      "19674 Traning Loss: tensor(0.1533)\n",
      "19675 Traning Loss: tensor(0.1794)\n",
      "19676 Traning Loss: tensor(0.1510)\n",
      "19677 Traning Loss: tensor(0.1372)\n",
      "19678 Traning Loss: tensor(0.1384)\n",
      "19679 Traning Loss: tensor(0.1487)\n",
      "19680 Traning Loss: tensor(0.1506)\n",
      "19681 Traning Loss: tensor(0.1431)\n",
      "19682 Traning Loss: tensor(0.1212)\n",
      "19683 Traning Loss: tensor(0.1543)\n",
      "19684 Traning Loss: tensor(0.1423)\n",
      "19685 Traning Loss: tensor(0.1222)\n",
      "19686 Traning Loss: tensor(0.1470)\n",
      "19687 Traning Loss: tensor(0.1377)\n",
      "19688 Traning Loss: tensor(0.1302)\n",
      "19689 Traning Loss: tensor(0.1418)\n",
      "19690 Traning Loss: tensor(0.1474)\n",
      "19691 Traning Loss: tensor(0.1749)\n",
      "19692 Traning Loss: tensor(0.1480)\n",
      "19693 Traning Loss: tensor(0.1399)\n",
      "19694 Traning Loss: tensor(0.1309)\n",
      "19695 Traning Loss: tensor(0.1532)\n",
      "19696 Traning Loss: tensor(0.1337)\n",
      "19697 Traning Loss: tensor(0.1494)\n",
      "19698 Traning Loss: tensor(0.1529)\n",
      "19699 Traning Loss: tensor(0.1472)\n",
      "19700 Traning Loss: tensor(0.1478)\n",
      "19701 Traning Loss: tensor(0.1370)\n",
      "19702 Traning Loss: tensor(0.1492)\n",
      "19703 Traning Loss: tensor(0.1313)\n",
      "19704 Traning Loss: tensor(0.1364)\n",
      "19705 Traning Loss: tensor(0.1424)\n",
      "19706 Traning Loss: tensor(0.1623)\n",
      "19707 Traning Loss: tensor(0.1615)\n",
      "19708 Traning Loss: tensor(0.1362)\n",
      "19709 Traning Loss: tensor(0.1546)\n",
      "19710 Traning Loss: tensor(0.1266)\n",
      "19711 Traning Loss: tensor(0.1561)\n",
      "19712 Traning Loss: tensor(0.1353)\n",
      "19713 Traning Loss: tensor(0.1365)\n",
      "19714 Traning Loss: tensor(0.1291)\n",
      "19715 Traning Loss: tensor(0.1370)\n",
      "19716 Traning Loss: tensor(0.1399)\n",
      "19717 Traning Loss: tensor(0.1298)\n",
      "19718 Traning Loss: tensor(0.1344)\n",
      "19719 Traning Loss: tensor(0.1255)\n",
      "19720 Traning Loss: tensor(0.1599)\n",
      "19721 Traning Loss: tensor(0.1614)\n",
      "19722 Traning Loss: tensor(0.1312)\n",
      "19723 Traning Loss: tensor(0.1544)\n",
      "19724 Traning Loss: tensor(0.1486)\n",
      "19725 Traning Loss: tensor(0.1526)\n",
      "19726 Traning Loss: tensor(0.1522)\n",
      "19727 Traning Loss: tensor(0.1322)\n",
      "19728 Traning Loss: tensor(0.1299)\n",
      "19729 Traning Loss: tensor(0.1536)\n",
      "19730 Traning Loss: tensor(0.1553)\n",
      "19731 Traning Loss: tensor(0.1366)\n",
      "19732 Traning Loss: tensor(0.1490)\n",
      "19733 Traning Loss: tensor(0.1512)\n",
      "19734 Traning Loss: tensor(0.1345)\n",
      "19735 Traning Loss: tensor(0.1535)\n",
      "19736 Traning Loss: tensor(0.1434)\n",
      "19737 Traning Loss: tensor(0.1238)\n",
      "19738 Traning Loss: tensor(0.1388)\n",
      "19739 Traning Loss: tensor(0.1444)\n",
      "19740 Traning Loss: tensor(0.1400)\n",
      "19741 Traning Loss: tensor(0.1478)\n",
      "19742 Traning Loss: tensor(0.1432)\n",
      "19743 Traning Loss: tensor(0.1555)\n",
      "19744 Traning Loss: tensor(0.1414)\n",
      "19745 Traning Loss: tensor(0.1658)\n",
      "19746 Traning Loss: tensor(0.1566)\n",
      "19747 Traning Loss: tensor(0.1240)\n",
      "19748 Traning Loss: tensor(0.1424)\n",
      "19749 Traning Loss: tensor(0.1858)\n",
      "19750 Traning Loss: tensor(0.1699)\n",
      "19751 Traning Loss: tensor(0.1288)\n",
      "19752 Traning Loss: tensor(0.1260)\n",
      "19753 Traning Loss: tensor(0.1269)\n",
      "19754 Traning Loss: tensor(0.1411)\n",
      "19755 Traning Loss: tensor(0.1678)\n",
      "19756 Traning Loss: tensor(0.1515)\n",
      "19757 Traning Loss: tensor(0.1391)\n",
      "19758 Traning Loss: tensor(0.1311)\n",
      "19759 Traning Loss: tensor(0.1490)\n",
      "19760 Traning Loss: tensor(0.1319)\n",
      "19761 Traning Loss: tensor(0.1438)\n",
      "19762 Traning Loss: tensor(0.1351)\n",
      "19763 Traning Loss: tensor(0.1239)\n",
      "19764 Traning Loss: tensor(0.1181)\n",
      "19765 Traning Loss: tensor(0.1505)\n",
      "19766 Traning Loss: tensor(0.1496)\n",
      "19767 Traning Loss: tensor(0.1356)\n",
      "19768 Traning Loss: tensor(0.1505)\n",
      "19769 Traning Loss: tensor(0.1506)\n",
      "19770 Traning Loss: tensor(0.1297)\n",
      "19771 Traning Loss: tensor(0.1705)\n",
      "19772 Traning Loss: tensor(0.1314)\n",
      "19773 Traning Loss: tensor(0.1442)\n",
      "19774 Traning Loss: tensor(0.1323)\n",
      "19775 Traning Loss: tensor(0.1357)\n",
      "19776 Traning Loss: tensor(0.1327)\n",
      "19777 Traning Loss: tensor(0.1397)\n",
      "19778 Traning Loss: tensor(0.1467)\n",
      "19779 Traning Loss: tensor(0.1343)\n",
      "19780 Traning Loss: tensor(0.1331)\n",
      "19781 Traning Loss: tensor(0.1514)\n",
      "19782 Traning Loss: tensor(0.1277)\n",
      "19783 Traning Loss: tensor(0.1288)\n",
      "19784 Traning Loss: tensor(0.1325)\n",
      "19785 Traning Loss: tensor(0.1531)\n",
      "19786 Traning Loss: tensor(0.1498)\n",
      "19787 Traning Loss: tensor(0.1349)\n",
      "19788 Traning Loss: tensor(0.1397)\n",
      "19789 Traning Loss: tensor(0.1227)\n",
      "19790 Traning Loss: tensor(0.1361)\n",
      "19791 Traning Loss: tensor(0.1285)\n",
      "19792 Traning Loss: tensor(0.1414)\n",
      "19793 Traning Loss: tensor(0.1404)\n",
      "19794 Traning Loss: tensor(0.1505)\n",
      "19795 Traning Loss: tensor(0.1727)\n",
      "19796 Traning Loss: tensor(0.1276)\n",
      "19797 Traning Loss: tensor(0.1411)\n",
      "19798 Traning Loss: tensor(0.1334)\n",
      "19799 Traning Loss: tensor(0.1425)\n",
      "19800 Traning Loss: tensor(0.1375)\n",
      "19801 Traning Loss: tensor(0.1555)\n",
      "19802 Traning Loss: tensor(0.1307)\n",
      "19803 Traning Loss: tensor(0.1239)\n",
      "19804 Traning Loss: tensor(0.1343)\n",
      "19805 Traning Loss: tensor(0.1208)\n",
      "19806 Traning Loss: tensor(0.1276)\n",
      "19807 Traning Loss: tensor(0.1362)\n",
      "19808 Traning Loss: tensor(0.1599)\n",
      "19809 Traning Loss: tensor(0.1143)\n",
      "19810 Traning Loss: tensor(0.1478)\n",
      "19811 Traning Loss: tensor(0.1455)\n",
      "19812 Traning Loss: tensor(0.1645)\n",
      "19813 Traning Loss: tensor(0.1722)\n",
      "19814 Traning Loss: tensor(0.1333)\n",
      "19815 Traning Loss: tensor(0.1380)\n",
      "19816 Traning Loss: tensor(0.1361)\n",
      "19817 Traning Loss: tensor(0.1327)\n",
      "19818 Traning Loss: tensor(0.1341)\n",
      "19819 Traning Loss: tensor(0.1498)\n",
      "19820 Traning Loss: tensor(0.1215)\n",
      "19821 Traning Loss: tensor(0.1358)\n",
      "19822 Traning Loss: tensor(0.1253)\n",
      "19823 Traning Loss: tensor(0.1520)\n",
      "19824 Traning Loss: tensor(0.1373)\n",
      "19825 Traning Loss: tensor(0.1178)\n",
      "19826 Traning Loss: tensor(0.1441)\n",
      "19827 Traning Loss: tensor(0.1415)\n",
      "19828 Traning Loss: tensor(0.1434)\n",
      "19829 Traning Loss: tensor(0.1400)\n",
      "19830 Traning Loss: tensor(0.1239)\n",
      "19831 Traning Loss: tensor(0.1705)\n",
      "19832 Traning Loss: tensor(0.1301)\n",
      "19833 Traning Loss: tensor(0.1475)\n",
      "19834 Traning Loss: tensor(0.1266)\n",
      "19835 Traning Loss: tensor(0.1225)\n",
      "19836 Traning Loss: tensor(0.1285)\n",
      "19837 Traning Loss: tensor(0.1246)\n",
      "19838 Traning Loss: tensor(0.1317)\n",
      "19839 Traning Loss: tensor(0.1581)\n",
      "19840 Traning Loss: tensor(0.1330)\n",
      "19841 Traning Loss: tensor(0.1432)\n",
      "19842 Traning Loss: tensor(0.1348)\n",
      "19843 Traning Loss: tensor(0.1597)\n",
      "19844 Traning Loss: tensor(0.1301)\n",
      "19845 Traning Loss: tensor(0.1198)\n",
      "19846 Traning Loss: tensor(0.1303)\n",
      "19847 Traning Loss: tensor(0.1488)\n",
      "19848 Traning Loss: tensor(0.1513)\n",
      "19849 Traning Loss: tensor(0.1509)\n",
      "19850 Traning Loss: tensor(0.1553)\n",
      "19851 Traning Loss: tensor(0.1359)\n",
      "19852 Traning Loss: tensor(0.1398)\n",
      "19853 Traning Loss: tensor(0.1487)\n",
      "19854 Traning Loss: tensor(0.1405)\n",
      "19855 Traning Loss: tensor(0.1340)\n",
      "19856 Traning Loss: tensor(0.1334)\n",
      "19857 Traning Loss: tensor(0.1117)\n",
      "19858 Traning Loss: tensor(0.1640)\n",
      "19859 Traning Loss: tensor(0.1164)\n",
      "19860 Traning Loss: tensor(0.1299)\n",
      "19861 Traning Loss: tensor(0.1368)\n",
      "19862 Traning Loss: tensor(0.1393)\n",
      "19863 Traning Loss: tensor(0.1402)\n",
      "19864 Traning Loss: tensor(0.1401)\n",
      "19865 Traning Loss: tensor(0.1521)\n",
      "19866 Traning Loss: tensor(0.1218)\n",
      "19867 Traning Loss: tensor(0.1436)\n",
      "19868 Traning Loss: tensor(0.1437)\n",
      "19869 Traning Loss: tensor(0.1344)\n",
      "19870 Traning Loss: tensor(0.1311)\n",
      "19871 Traning Loss: tensor(0.1487)\n",
      "19872 Traning Loss: tensor(0.1414)\n",
      "19873 Traning Loss: tensor(0.1273)\n",
      "19874 Traning Loss: tensor(0.1267)\n",
      "19875 Traning Loss: tensor(0.1776)\n",
      "19876 Traning Loss: tensor(0.1552)\n",
      "19877 Traning Loss: tensor(0.1591)\n",
      "19878 Traning Loss: tensor(0.1549)\n",
      "19879 Traning Loss: tensor(0.1376)\n",
      "19880 Traning Loss: tensor(0.1366)\n",
      "19881 Traning Loss: tensor(0.1407)\n",
      "19882 Traning Loss: tensor(0.1860)\n",
      "19883 Traning Loss: tensor(0.1210)\n",
      "19884 Traning Loss: tensor(0.1280)\n",
      "19885 Traning Loss: tensor(0.1186)\n",
      "19886 Traning Loss: tensor(0.1357)\n",
      "19887 Traning Loss: tensor(0.1370)\n",
      "19888 Traning Loss: tensor(0.1227)\n",
      "19889 Traning Loss: tensor(0.1278)\n",
      "19890 Traning Loss: tensor(0.1325)\n",
      "19891 Traning Loss: tensor(0.1455)\n",
      "19892 Traning Loss: tensor(0.1165)\n",
      "19893 Traning Loss: tensor(0.1245)\n",
      "19894 Traning Loss: tensor(0.1489)\n",
      "19895 Traning Loss: tensor(0.1381)\n",
      "19896 Traning Loss: tensor(0.1569)\n",
      "19897 Traning Loss: tensor(0.1250)\n",
      "19898 Traning Loss: tensor(0.1314)\n",
      "19899 Traning Loss: tensor(0.1355)\n",
      "19900 Traning Loss: tensor(0.1518)\n",
      "19901 Traning Loss: tensor(0.1477)\n",
      "19902 Traning Loss: tensor(0.1329)\n",
      "19903 Traning Loss: tensor(0.1520)\n",
      "19904 Traning Loss: tensor(0.1720)\n",
      "19905 Traning Loss: tensor(0.1454)\n",
      "19906 Traning Loss: tensor(0.1374)\n",
      "19907 Traning Loss: tensor(0.1349)\n",
      "19908 Traning Loss: tensor(0.1333)\n",
      "19909 Traning Loss: tensor(0.1328)\n",
      "19910 Traning Loss: tensor(0.1344)\n",
      "19911 Traning Loss: tensor(0.1512)\n",
      "19912 Traning Loss: tensor(0.1151)\n",
      "19913 Traning Loss: tensor(0.1356)\n",
      "19914 Traning Loss: tensor(0.1254)\n",
      "19915 Traning Loss: tensor(0.1453)\n",
      "19916 Traning Loss: tensor(0.1566)\n",
      "19917 Traning Loss: tensor(0.1306)\n",
      "19918 Traning Loss: tensor(0.1377)\n",
      "19919 Traning Loss: tensor(0.1201)\n",
      "19920 Traning Loss: tensor(0.1300)\n",
      "19921 Traning Loss: tensor(0.1271)\n",
      "19922 Traning Loss: tensor(0.1501)\n",
      "19923 Traning Loss: tensor(0.1255)\n",
      "19924 Traning Loss: tensor(0.1428)\n",
      "19925 Traning Loss: tensor(0.1445)\n",
      "19926 Traning Loss: tensor(0.1465)\n",
      "19927 Traning Loss: tensor(0.1194)\n",
      "19928 Traning Loss: tensor(0.1499)\n",
      "19929 Traning Loss: tensor(0.1434)\n",
      "19930 Traning Loss: tensor(0.1495)\n",
      "19931 Traning Loss: tensor(0.1368)\n",
      "19932 Traning Loss: tensor(0.1241)\n",
      "19933 Traning Loss: tensor(0.1439)\n",
      "19934 Traning Loss: tensor(0.1267)\n",
      "19935 Traning Loss: tensor(0.1327)\n",
      "19936 Traning Loss: tensor(0.1361)\n",
      "19937 Traning Loss: tensor(0.1409)\n",
      "19938 Traning Loss: tensor(0.1258)\n",
      "19939 Traning Loss: tensor(0.1606)\n",
      "19940 Traning Loss: tensor(0.1477)\n",
      "19941 Traning Loss: tensor(0.1434)\n",
      "19942 Traning Loss: tensor(0.1338)\n",
      "19943 Traning Loss: tensor(0.1215)\n",
      "19944 Traning Loss: tensor(0.1699)\n",
      "19945 Traning Loss: tensor(0.1346)\n",
      "19946 Traning Loss: tensor(0.1379)\n",
      "19947 Traning Loss: tensor(0.1364)\n",
      "19948 Traning Loss: tensor(0.1349)\n",
      "19949 Traning Loss: tensor(0.1295)\n",
      "19950 Traning Loss: tensor(0.1334)\n",
      "19951 Traning Loss: tensor(0.1319)\n",
      "19952 Traning Loss: tensor(0.1703)\n",
      "19953 Traning Loss: tensor(0.1362)\n",
      "19954 Traning Loss: tensor(0.1361)\n",
      "19955 Traning Loss: tensor(0.1440)\n",
      "19956 Traning Loss: tensor(0.1312)\n",
      "19957 Traning Loss: tensor(0.1227)\n",
      "19958 Traning Loss: tensor(0.1400)\n",
      "19959 Traning Loss: tensor(0.1316)\n",
      "19960 Traning Loss: tensor(0.1200)\n",
      "19961 Traning Loss: tensor(0.1350)\n",
      "19962 Traning Loss: tensor(0.1573)\n",
      "19963 Traning Loss: tensor(0.1429)\n",
      "19964 Traning Loss: tensor(0.1465)\n",
      "19965 Traning Loss: tensor(0.1396)\n",
      "19966 Traning Loss: tensor(0.1299)\n",
      "19967 Traning Loss: tensor(0.1315)\n",
      "19968 Traning Loss: tensor(0.1336)\n",
      "19969 Traning Loss: tensor(0.1278)\n",
      "19970 Traning Loss: tensor(0.1221)\n",
      "19971 Traning Loss: tensor(0.1323)\n",
      "19972 Traning Loss: tensor(0.1633)\n",
      "19973 Traning Loss: tensor(0.1564)\n",
      "19974 Traning Loss: tensor(0.1336)\n",
      "19975 Traning Loss: tensor(0.1398)\n",
      "19976 Traning Loss: tensor(0.1281)\n",
      "19977 Traning Loss: tensor(0.1442)\n",
      "19978 Traning Loss: tensor(0.1376)\n",
      "19979 Traning Loss: tensor(0.1518)\n",
      "19980 Traning Loss: tensor(0.1195)\n",
      "19981 Traning Loss: tensor(0.1482)\n",
      "19982 Traning Loss: tensor(0.1576)\n",
      "19983 Traning Loss: tensor(0.1306)\n",
      "19984 Traning Loss: tensor(0.1318)\n",
      "19985 Traning Loss: tensor(0.1569)\n",
      "19986 Traning Loss: tensor(0.1374)\n",
      "19987 Traning Loss: tensor(0.1421)\n",
      "19988 Traning Loss: tensor(0.1413)\n",
      "19989 Traning Loss: tensor(0.1213)\n",
      "19990 Traning Loss: tensor(0.1203)\n",
      "19991 Traning Loss: tensor(0.1293)\n",
      "19992 Traning Loss: tensor(0.1449)\n",
      "19993 Traning Loss: tensor(0.1318)\n",
      "19994 Traning Loss: tensor(0.1277)\n",
      "19995 Traning Loss: tensor(0.1510)\n",
      "19996 Traning Loss: tensor(0.1253)\n",
      "19997 Traning Loss: tensor(0.1434)\n",
      "19998 Traning Loss: tensor(0.1269)\n",
      "19999 Traning Loss: tensor(0.1192)\n"
     ]
    }
   ],
   "source": [
    "### (3) Training / Fitting\n",
    "iterations = 20000\n",
    "previous_validation_loss = 99999999.0\n",
    "\n",
    "for epoch in range(iterations):\n",
    "    optimizer.zero_grad() # to make the gradients zero\n",
    "    \n",
    "    # Loss based on boundary conditions\n",
    "    pt_x_bc = Variable(torch.from_numpy(x_bc).float(), requires_grad=False).to(device)\n",
    "    pt_t_bc = Variable(torch.from_numpy(t_bc).float(), requires_grad=False).to(device)\n",
    "    pt_u_bc = Variable(torch.from_numpy(u_bc).float(), requires_grad=False).to(device)\n",
    "    \n",
    "    net_bc_out = net(pt_x_bc, pt_t_bc) # output of u(x,t)\n",
    "    mse_u = mse_cost_function(net_bc_out, pt_u_bc)\n",
    "    \n",
    "    # Loss based on PDE\n",
    "    x_collocation = np.random.uniform(low=0.0, high=1, size=(500,1))\n",
    "    t_collocation = np.random.uniform(low=0.0, high=0.5, size=(500,1))\n",
    "    all_zeros = np.zeros((500,1))\n",
    "    \n",
    "    \n",
    "    pt_x_collocation = Variable(torch.from_numpy(x_collocation).float(), requires_grad=True).to(device)\n",
    "    pt_t_collocation = Variable(torch.from_numpy(t_collocation).float(), requires_grad=True).to(device)\n",
    "    pt_all_zeros = Variable(torch.from_numpy(all_zeros).float(), requires_grad=False).to(device)\n",
    "    \n",
    "    f_out = f(pt_x_collocation, pt_t_collocation, net) # output of f(x,t)\n",
    "    mse_f = mse_cost_function(f_out, pt_all_zeros)\n",
    "    \n",
    "    # Combining the loss functions:\n",
    "    #  simply added the y_loss and PDE_loss to produce the final loss\n",
    "    loss = mse_u + mse_f\n",
    "    \n",
    "    \n",
    "    loss.backward() # This is for computing gradients using backward propagation\n",
    "    optimizer.step() # This is equivalent to : theta_new = theta_old - alpha * derivative of J w.r.t theta\n",
    "\n",
    "    with torch.autograd.no_grad():\n",
    "    \tprint(epoch,\"Traning Loss:\",loss.data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They used a 3D visualisation module to produce the visualisation of the solved PDE without explicitly providing the general/universal solution. \n",
    "- Can we view the converged neural network as the general/universal solution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "# ax = fig.gca(projection='3d')\n",
    "ax = fig.add_subplot(111, projection='3d')  # Correct way to specify 3D projection\n",
    "\n",
    "x=np.arange(0,1,0.02)\n",
    "t=np.arange(0,0.5,0.02)\n",
    "ms_x, ms_t = np.meshgrid(x, t)\n",
    "## Just because meshgrid is used, we need to do the following adjustment\n",
    "x = np.ravel(ms_x).reshape(-1,1)\n",
    "t = np.ravel(ms_t).reshape(-1,1)\n",
    "\n",
    "pt_x = Variable(torch.from_numpy(x).float(), requires_grad=True).to(device)\n",
    "pt_t = Variable(torch.from_numpy(t).float(), requires_grad=True).to(device)\n",
    "pt_u = net(pt_x,pt_t)\n",
    "u=pt_u.data.cpu().numpy()\n",
    "ms_u = u.reshape(ms_x.shape)\n",
    "\n",
    "surf = ax.plot_surface(ms_x,ms_t,ms_u, cmap=cm.coolwarm,linewidth=0, antialiased=False)\n",
    "             \n",
    "             \n",
    "\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "torch.save(net.state_dict(), \"model_uxt_diffusion.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
